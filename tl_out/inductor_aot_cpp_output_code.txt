#include <torch/csrc/inductor/aoti_runtime/interface.h>
#include <torch/csrc/inductor/aoti_runtime/model.h>
// Definition of AOTI runtime interface functions

#include <torch/csrc/inductor/aoti_runtime/interface.h>
#include <torch/csrc/inductor/aoti_runtime/model_container.h>

#include <iostream>
#include <sstream>
#include <stdexcept>
#include <vector>

#define CONVERT_EXCEPTION_TO_ERROR_CODE(...)                 \
    try {                                                      \
    __VA_ARGS__                                              \
    } catch (const std::exception& e) {                        \
    std::cerr << "Error: " << e.what() << std::endl;         \
    return AOTI_RUNTIME_FAILURE;                             \
    } catch (...) {                                            \
    std::cerr << "Unknown exception occurred." << std::endl; \
    return AOTI_RUNTIME_FAILURE;                             \
    }                                                          \
    return AOTI_RUNTIME_SUCCESS;

#define AOTI_VECTOR_SIZE_CHECK(actual_size, expected_size, name)  \
    do {                                                            \
    AOTI_RUNTIME_CHECK(                                           \
        actual_size == expected_size,                             \
        "expected " + std::string(name) + " vector size to be " + \
            std::to_string(expected_size) + ", but got " +        \
            std::to_string(actual_size));                         \
    } while (0)

// AOTInductor uses at::addmm_out, which doesn't supports
// arguments that requires gradient. For this reason, we
// enforce no_grad context for run APIs.
//
// A RAII, thread local (!) guard that enables or disables grad mode upon
// construction, and sets it back to the original value upon destruction.
struct AOTINoGradGuard {
    AOTINoGradGuard() : prev_mode(aoti_torch_grad_mode_is_enabled()) {
    aoti_torch_grad_mode_set_enabled(false);
    }
    ~AOTINoGradGuard() {
    aoti_torch_grad_mode_set_enabled(prev_mode);
    }
    bool prev_mode;
};

extern "C" {

AOTIRuntimeError AOTInductorModelContainerCreate(
    AOTInductorModelContainerHandle* container_handle,
    size_t num_models,
    bool is_cpu,
    const char* cubin_dir) {
        return AOTInductorModelContainerCreateWithDevice(
        container_handle,
        num_models,
        is_cpu ? "cpu" : "cuda",
        cubin_dir);
}

AOTIRuntimeError AOTInductorModelContainerCreateWithDevice(
    AOTInductorModelContainerHandle* container_handle,
    size_t num_models,
    const char* device_str,
    const char* cubin_dir) {
    if (num_models == 0) {
    std::cerr << "Error: num_models must be positive, but got 0" << std::endl;
    return AOTI_RUNTIME_FAILURE;
    }
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    std::optional<std::string> cubin_dir_opt;
    if (cubin_dir != nullptr) {
        cubin_dir_opt.emplace(cubin_dir);
    }
    auto* container = new torch::aot_inductor::AOTInductorModelContainer(
        num_models, std::string(device_str), cubin_dir_opt);
    *container_handle =
        reinterpret_cast<AOTInductorModelContainerHandle>(container);
    })
}

AOTIRuntimeError AOTInductorModelContainerDelete(
    AOTInductorModelContainerHandle container_handle) {
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    delete container;
    });
}

AOTIRuntimeError AOTInductorModelContainerRun(
    AOTInductorModelContainerHandle container_handle,
    AtenTensorHandle* input_handles, // array of input AtenTensorHandle; handles
                                        // are stolen; the array itself is borrowed
    size_t num_inputs,
    AtenTensorHandle*
        output_handles, // array for writing output AtenTensorHandle; handles
                        // will be stolen by the caller; the array itself is
                        // borrowed
    size_t num_outputs,
    AOTInductorStreamHandle stream_handle,
    AOTIProxyExecutorHandle proxy_executor_handle) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    AOTI_VECTOR_SIZE_CHECK(num_inputs, container->num_inputs(), "inputs");
    AOTI_VECTOR_SIZE_CHECK(num_outputs, container->num_outputs(), "outputs");

    auto stream =
        reinterpret_cast<torch::aot_inductor::DeviceStreamType>(stream_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    AOTINoGradGuard guard;
    container->run(
        input_handles, output_handles, stream, proxy_executor_handle);
    })
}

AOTIRuntimeError AOTInductorModelContainerGetNumConstants(
    AOTInductorModelContainerHandle container_handle,
    size_t* num_constants) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE(
    { *num_constants = container->num_constants(); })
}

AOTIRuntimeError AOTInductorModelContainerGetConstantName(
    AOTInductorModelContainerHandle container_handle,
    size_t idx,
    const char** name) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE(
    { *name = container->constant_name(idx); })
}

AOTIRuntimeError AOTInductorModelContainerGetConstantOriginalFQN(
    AOTInductorModelContainerHandle container_handle,
    size_t idx,
    const char** original_fqn) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE(
    { *original_fqn = container->constant_original_fqn(idx); })
}

AOTIRuntimeError AOTInductorModelContainerGetConstantFromFolded(
    AOTInductorModelContainerHandle container_handle,
    size_t idx,
    bool* from_folded) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({ *from_folded = container->constant_from_folded(idx); })
}

AOTIRuntimeError AOTInductorModelContainerGetConstantType(
    AOTInductorModelContainerHandle container_handle,
    size_t idx,
    int32_t* type) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({ *type = container->constant_type(idx); })
}

AOTIRuntimeError AOTInductorModelContainerGetConstantDtype(
    AOTInductorModelContainerHandle container_handle,
    size_t idx,
    int32_t* dtype) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE(
    { *dtype = container->constant_dtype(idx); })
}

AOTIRuntimeError AOTInductorModelContainerUpdateConstantBuffer(
    AOTInductorModelContainerHandle container_handle,
    AOTInductorConstantMapHandle constant_map_handle,
    bool use_inactive,
    bool validate_full_update) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    auto input_map = reinterpret_cast<std::unordered_map<std::string, AtenTensorHandle>*>(constant_map_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    container->update_constant_buffer(
        *input_map, use_inactive, validate_full_update);
    })
}

AOTIRuntimeError AOTInductorModelContainerUpdateInactiveConstantBuffer(
    AOTInductorModelContainerHandle container_handle,
    AOTInductorConstantMapHandle constant_map_handle) {
    return AOTInductorModelContainerUpdateConstantBuffer(container_handle,
            constant_map_handle,
            /*use_inactive*/ true,
            /*validate_full_update*/ true);
}

AOTIRuntimeError AOTInductorModelContainerRunConstantFolding(
    AOTInductorModelContainerHandle container_handle,
    bool use_inactive,
    AOTInductorStreamHandle stream_handle,
    AOTIProxyExecutorHandle proxy_executor_handle) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    auto stream =
        reinterpret_cast<torch::aot_inductor::DeviceStreamType>(stream_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    AOTINoGradGuard guard;
    container->run_const_fold(use_inactive, stream, proxy_executor_handle);
    })
}

AOTIRuntimeError AOTInductorModelContainerSwapConstantBuffer(
    AOTInductorModelContainerHandle container_handle) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    container->swap_constant_buffer();
    })
}

AOTIRuntimeError AOTInductorModelContainerGetNumInputs(
    AOTInductorModelContainerHandle container_handle,
    size_t* ret_num_inputs) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE(
        { *ret_num_inputs = container->num_inputs(); })
}

AOTIRuntimeError AOTInductorModelContainerGetInputName(
    AOTInductorModelContainerHandle container_handle,
    size_t input_idx,
    const char** ret_input_names) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE(
        { *ret_input_names = container->input_name(input_idx); })
}

AOTIRuntimeError AOTInductorModelContainerGetNumOutputs(
    AOTInductorModelContainerHandle container_handle,
    size_t* ret_num_outputs) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE(
        { *ret_num_outputs = container->num_outputs(); })
}

AOTIRuntimeError AOTInductorModelContainerGetOutputName(
    AOTInductorModelContainerHandle container_handle,
    size_t output_idx,
    const char** ret_output_names) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE(
        { *ret_output_names = container->output_name(output_idx); })
}

AOTIRuntimeError AOTInductorModelContainerGetCallSpec(
    AOTInductorModelContainerHandle container_handle,
    const char** in_spec,
    const char** out_spec) {
    auto* container =
        reinterpret_cast<torch::aot_inductor::AOTInductorModelContainer*>(
            container_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    *in_spec = container->get_in_spec();
    *out_spec = container->get_out_spec();
    })
}

AOTIRuntimeError AOTInductorModelCreate(
    AOTInductorModelHandle* model_handle,
    AOTInductorConstantMapHandle constant_map_handle){
    CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto constant_map = std::make_shared<torch::aot_inductor::ConstantMap>();
        auto constant_array = std::make_shared<std::vector<torch::aot_inductor::ConstantHandle>>();
        auto input_map = reinterpret_cast<std::unordered_map<std::string, AtenTensorHandle>*>(constant_map_handle);

        auto model = new torch::aot_inductor::AOTInductorModel(
            constant_map,
            constant_array,
            "cpu", // device_str is hardcoded, as AOTInductorModelCreate is only use for CPU models
            ""
        );

        if (input_map) {
        for (auto const& kv : *input_map) {
            constant_map->emplace(kv.first, kv.second);
        }
        } else {
        model->load_constants();
        }

        *model_handle = reinterpret_cast<AOTInductorModelHandle>(model);
    })}

AOTIRuntimeError AOTInductorModelRun(
    AOTInductorModelHandle model_handle,
    AtenTensorHandle* input_handles,
    AtenTensorHandle* output_handles) {
    auto model =
        reinterpret_cast<torch::aot_inductor::AOTInductorModel*>(model_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    AOTINoGradGuard guard;
    model->run_impl(
        input_handles,
        output_handles,
        (torch::aot_inductor::DeviceStreamType) nullptr,
        nullptr);
    })
}

AOTIRuntimeError AOTInductorModelDelete(AOTInductorModelHandle model_handle){
    CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto model = reinterpret_cast<torch::aot_inductor::AOTInductorModel*>(
            model_handle);
        delete model;
    })}

AOTIRuntimeError AOTInductorModelGetNumOutputs(
    AOTInductorModelHandle model_handle,
    size_t* ret_num_outputs) {
    CONVERT_EXCEPTION_TO_ERROR_CODE({
        auto model = reinterpret_cast<torch::aot_inductor::AOTInductorModel*>(model_handle);
        *ret_num_outputs = model->num_outputs();
    })
}

AOTIRuntimeError AOTInductorModelUpdateConstantsMap(
    AOTInductorModelHandle model_handle,
    AOTInductorConstantMapHandle constant_map_handle) {
    auto model =
        reinterpret_cast<torch::aot_inductor::AOTInductorModel*>(model_handle);
    CONVERT_EXCEPTION_TO_ERROR_CODE({
    auto constant_map = std::make_shared<torch::aot_inductor::ConstantMap>();
    auto input_map =
        reinterpret_cast<std::unordered_map<std::string, AtenTensorHandle>*>(
            constant_map_handle);

    for (auto const& kv : *input_map) {
        constant_map->emplace(kv.first, kv.second);
    }
    model->update_constants_map(std::move(constant_map));
    })
}

} // extern "C"

#include <torch/csrc/inductor/aoti_runtime/arrayref_tensor.h>
#include <torch/csrc/inductor/aoti_runtime/thread_local.h>
#include <torch/csrc/inductor/aoti_runtime/scalar_to_tensor.h>
#include <torch/csrc/inductor/aoti_torch/generated/c_shim_cuda.h>

#include <c10/util/generic_math.h>
typedef at::Half half;
typedef at::BFloat16 bfloat16;

// Round up to the nearest multiple of 64
[[maybe_unused]] static int64_t align(int64_t nbytes) {
    return (nbytes + 64 - 1) & -64;
}
#include <filesystem>
#include <torch/csrc/inductor/aoti_runtime/utils_cuda.h>

#define CUDA_DRIVER_CHECK(EXPR)                    \
do {                                               \
    CUresult code = EXPR;                          \
    const char *msg;                               \
    CUresult code_get_error = cuGetErrorString(code, &msg); \
    if (code_get_error != CUDA_SUCCESS) {          \
        throw std::runtime_error(                  \
            std::string("CUDA driver error: ") +   \
            std::string("invalid error code!"));   \
    }                                              \
    if (code != CUDA_SUCCESS) {                    \
        throw std::runtime_error(                  \
            std::string("CUDA driver error: ") +   \
            std::string(msg));                     \
    }                                              \
} while (0);

namespace {

struct Grid {
    Grid(uint32_t x, uint32_t y, uint32_t z)
        : grid_x(x), grid_y(y), grid_z(z) {}
    uint32_t grid_x;
    uint32_t grid_y;
    uint32_t grid_z;

    bool is_non_zero() {
        return grid_x > 0 && grid_y > 0 && grid_z > 0;
    }
};

}  // anonymous namespace

static inline CUfunction loadKernel(
        std::string filePath,
        const std::string &funcName,
        uint32_t sharedMemBytes,
        const std::optional<std::string> &cubinDir = std::nullopt) {
    if (cubinDir) {
        std::filesystem::path p1{*cubinDir};
        std::filesystem::path p2{filePath};
        filePath = (p1 / p2.filename()).string();
    }

    CUmodule mod;
    CUfunction func;
    CUDA_DRIVER_CHECK(cuModuleLoad(&mod, filePath.c_str()));
    CUDA_DRIVER_CHECK(cuModuleGetFunction(&func, mod, funcName.c_str()));
    if (sharedMemBytes > 0) {
        CUDA_DRIVER_CHECK(cuFuncSetAttribute(
            func,
            CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES,
            sharedMemBytes
        ))
    }
    return func;
}

static inline void launchKernel(
        CUfunction func,
        uint32_t gridX,
        uint32_t gridY,
        uint32_t gridZ,
        uint32_t numWarps,
        uint32_t sharedMemBytes,
        void* args[],
        cudaStream_t stream) {
    CUDA_DRIVER_CHECK(cuLaunchKernel(
        func, gridX, gridY, gridZ, 32*numWarps, 1, 1, sharedMemBytes, stream, args, nullptr
    ));
}
CACHE_TORCH_DTYPE(float16);
CACHE_TORCH_DTYPE(float32);
CACHE_TORCH_DTYPE(int64);
CACHE_TORCH_DEVICE(cuda);
CACHE_TORCH_LAYOUT(strided);
namespace torch::aot_inductor {

namespace {
class AOTInductorModelKernels : public AOTInductorModelKernelsBase {
    public:
    CUfunction triton_per_fused_add_cat_native_layer_norm_206{nullptr};
    CUfunction triton_per_fused_add_native_layer_norm_170{nullptr};
    CUfunction triton_per_fused_add_native_layer_norm_179{nullptr};
    CUfunction triton_per_fused_add_native_layer_norm_200{nullptr};
    CUfunction triton_per_fused_add_native_layer_norm_208{nullptr};
    CUfunction triton_per_fused_add_native_layer_norm_69{nullptr};
    CUfunction triton_per_fused_add_native_layer_norm_repeat_80{nullptr};
    CUfunction triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175{nullptr};
    CUfunction triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216{nullptr};
    CUfunction triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51{nullptr};
    CUfunction triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77{nullptr};
    CUfunction triton_per_fused_addmm_native_layer_norm_13{nullptr};
    CUfunction triton_per_fused_addmm_native_layer_norm_186{nullptr};
    CUfunction triton_per_fused_clone_mul_native_layer_norm_sigmoid_172{nullptr};
    CUfunction triton_per_fused_clone_mul_native_layer_norm_sigmoid_173{nullptr};
    CUfunction triton_per_fused_clone_mul_native_layer_norm_sigmoid_68{nullptr};
    CUfunction triton_per_fused_native_layer_norm_repeat_70{nullptr};
    CUfunction triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218{nullptr};
    CUfunction triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214{nullptr};
    CUfunction triton_poi_fused_add_addmm_nan_to_num_relu_213{nullptr};
    CUfunction triton_poi_fused_addmm_1{nullptr};
    CUfunction triton_poi_fused_addmm_10{nullptr};
    CUfunction triton_poi_fused_addmm_184{nullptr};
    CUfunction triton_poi_fused_addmm_6{nullptr};
    CUfunction triton_poi_fused_addmm_84{nullptr};
    CUfunction triton_poi_fused_addmm_9{nullptr};
    CUfunction triton_poi_fused_addmm_cat_49{nullptr};
    CUfunction triton_poi_fused_addmm_mul_sigmoid_215{nullptr};
    CUfunction triton_poi_fused_addmm_mul_sigmoid_72{nullptr};
    CUfunction triton_poi_fused_addmm_nan_to_num_relu_211{nullptr};
    CUfunction triton_poi_fused_addmm_native_layer_norm_189{nullptr};
    CUfunction triton_poi_fused_bmm_197{nullptr};
    CUfunction triton_poi_fused_bmm_198{nullptr};
    CUfunction triton_poi_fused_cat_0{nullptr};
    CUfunction triton_poi_fused_cat_100{nullptr};
    CUfunction triton_poi_fused_cat_101{nullptr};
    CUfunction triton_poi_fused_cat_102{nullptr};
    CUfunction triton_poi_fused_cat_103{nullptr};
    CUfunction triton_poi_fused_cat_104{nullptr};
    CUfunction triton_poi_fused_cat_105{nullptr};
    CUfunction triton_poi_fused_cat_106{nullptr};
    CUfunction triton_poi_fused_cat_107{nullptr};
    CUfunction triton_poi_fused_cat_108{nullptr};
    CUfunction triton_poi_fused_cat_109{nullptr};
    CUfunction triton_poi_fused_cat_110{nullptr};
    CUfunction triton_poi_fused_cat_111{nullptr};
    CUfunction triton_poi_fused_cat_112{nullptr};
    CUfunction triton_poi_fused_cat_113{nullptr};
    CUfunction triton_poi_fused_cat_114{nullptr};
    CUfunction triton_poi_fused_cat_115{nullptr};
    CUfunction triton_poi_fused_cat_116{nullptr};
    CUfunction triton_poi_fused_cat_117{nullptr};
    CUfunction triton_poi_fused_cat_118{nullptr};
    CUfunction triton_poi_fused_cat_119{nullptr};
    CUfunction triton_poi_fused_cat_120{nullptr};
    CUfunction triton_poi_fused_cat_121{nullptr};
    CUfunction triton_poi_fused_cat_122{nullptr};
    CUfunction triton_poi_fused_cat_123{nullptr};
    CUfunction triton_poi_fused_cat_124{nullptr};
    CUfunction triton_poi_fused_cat_125{nullptr};
    CUfunction triton_poi_fused_cat_126{nullptr};
    CUfunction triton_poi_fused_cat_127{nullptr};
    CUfunction triton_poi_fused_cat_128{nullptr};
    CUfunction triton_poi_fused_cat_129{nullptr};
    CUfunction triton_poi_fused_cat_130{nullptr};
    CUfunction triton_poi_fused_cat_131{nullptr};
    CUfunction triton_poi_fused_cat_132{nullptr};
    CUfunction triton_poi_fused_cat_133{nullptr};
    CUfunction triton_poi_fused_cat_134{nullptr};
    CUfunction triton_poi_fused_cat_135{nullptr};
    CUfunction triton_poi_fused_cat_136{nullptr};
    CUfunction triton_poi_fused_cat_137{nullptr};
    CUfunction triton_poi_fused_cat_138{nullptr};
    CUfunction triton_poi_fused_cat_139{nullptr};
    CUfunction triton_poi_fused_cat_140{nullptr};
    CUfunction triton_poi_fused_cat_141{nullptr};
    CUfunction triton_poi_fused_cat_142{nullptr};
    CUfunction triton_poi_fused_cat_143{nullptr};
    CUfunction triton_poi_fused_cat_144{nullptr};
    CUfunction triton_poi_fused_cat_145{nullptr};
    CUfunction triton_poi_fused_cat_146{nullptr};
    CUfunction triton_poi_fused_cat_147{nullptr};
    CUfunction triton_poi_fused_cat_148{nullptr};
    CUfunction triton_poi_fused_cat_149{nullptr};
    CUfunction triton_poi_fused_cat_150{nullptr};
    CUfunction triton_poi_fused_cat_151{nullptr};
    CUfunction triton_poi_fused_cat_152{nullptr};
    CUfunction triton_poi_fused_cat_153{nullptr};
    CUfunction triton_poi_fused_cat_154{nullptr};
    CUfunction triton_poi_fused_cat_155{nullptr};
    CUfunction triton_poi_fused_cat_156{nullptr};
    CUfunction triton_poi_fused_cat_157{nullptr};
    CUfunction triton_poi_fused_cat_158{nullptr};
    CUfunction triton_poi_fused_cat_159{nullptr};
    CUfunction triton_poi_fused_cat_160{nullptr};
    CUfunction triton_poi_fused_cat_167{nullptr};
    CUfunction triton_poi_fused_cat_168{nullptr};
    CUfunction triton_poi_fused_cat_2{nullptr};
    CUfunction triton_poi_fused_cat_3{nullptr};
    CUfunction triton_poi_fused_cat_4{nullptr};
    CUfunction triton_poi_fused_cat_5{nullptr};
    CUfunction triton_poi_fused_cat_52{nullptr};
    CUfunction triton_poi_fused_cat_53{nullptr};
    CUfunction triton_poi_fused_cat_54{nullptr};
    CUfunction triton_poi_fused_cat_55{nullptr};
    CUfunction triton_poi_fused_cat_56{nullptr};
    CUfunction triton_poi_fused_cat_57{nullptr};
    CUfunction triton_poi_fused_cat_58{nullptr};
    CUfunction triton_poi_fused_cat_59{nullptr};
    CUfunction triton_poi_fused_cat_60{nullptr};
    CUfunction triton_poi_fused_cat_61{nullptr};
    CUfunction triton_poi_fused_cat_62{nullptr};
    CUfunction triton_poi_fused_cat_63{nullptr};
    CUfunction triton_poi_fused_cat_64{nullptr};
    CUfunction triton_poi_fused_cat_65{nullptr};
    CUfunction triton_poi_fused_cat_66{nullptr};
    CUfunction triton_poi_fused_cat_7{nullptr};
    CUfunction triton_poi_fused_cat_74{nullptr};
    CUfunction triton_poi_fused_cat_8{nullptr};
    CUfunction triton_poi_fused_cat_89{nullptr};
    CUfunction triton_poi_fused_cat_90{nullptr};
    CUfunction triton_poi_fused_cat_93{nullptr};
    CUfunction triton_poi_fused_cat_94{nullptr};
    CUfunction triton_poi_fused_cat_95{nullptr};
    CUfunction triton_poi_fused_cat_96{nullptr};
    CUfunction triton_poi_fused_cat_97{nullptr};
    CUfunction triton_poi_fused_cat_98{nullptr};
    CUfunction triton_poi_fused_cat_99{nullptr};
    CUfunction triton_poi_fused_cat_permute_pooled_embs_auto_grad_11{nullptr};
    CUfunction triton_poi_fused_clamp_nan_to_num_91{nullptr};
    CUfunction triton_poi_fused_clone_161{nullptr};
    CUfunction triton_poi_fused_clone_162{nullptr};
    CUfunction triton_poi_fused_clone_163{nullptr};
    CUfunction triton_poi_fused_clone_164{nullptr};
    CUfunction triton_poi_fused_clone_165{nullptr};
    CUfunction triton_poi_fused_clone_166{nullptr};
    CUfunction triton_poi_fused_clone_nan_to_num_relu_86{nullptr};
    CUfunction triton_poi_fused_gelu_82{nullptr};
    CUfunction triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193{nullptr};
    CUfunction triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194{nullptr};
    CUfunction triton_red_fused_add_cat_native_layer_norm_196{nullptr};
    CUfunction triton_red_fused_addcmul_addmm_native_layer_norm_188{nullptr};
    CUfunction triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182{nullptr};
    CUfunction triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190{nullptr};
    CUfunction triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192{nullptr};
    CUfunction triton_red_fused_addmm_native_layer_norm_176{nullptr};
    CUfunction triton_red_fused_addmm_native_layer_norm_177{nullptr};
    CUfunction triton_red_fused_addmm_native_layer_norm_202{nullptr};
    CUfunction triton_red_fused_cat_native_layer_norm_183{nullptr};
    CUfunction triton_red_fused_mul_native_layer_norm_sigmoid_75{nullptr};
    CUfunction triton_red_fused_native_layer_norm_181{nullptr};
    CUfunction triton_red_fused_native_layer_norm_205{nullptr};
    CUfunction triton_tem_fused_addmm_12{nullptr};
    CUfunction triton_tem_fused_addmm_14{nullptr};
    CUfunction triton_tem_fused_addmm_15{nullptr};
    CUfunction triton_tem_fused_addmm_16{nullptr};
    CUfunction triton_tem_fused_addmm_17{nullptr};
    CUfunction triton_tem_fused_addmm_171{nullptr};
    CUfunction triton_tem_fused_addmm_18{nullptr};
    CUfunction triton_tem_fused_addmm_185{nullptr};
    CUfunction triton_tem_fused_addmm_19{nullptr};
    CUfunction triton_tem_fused_addmm_191{nullptr};
    CUfunction triton_tem_fused_addmm_20{nullptr};
    CUfunction triton_tem_fused_addmm_201{nullptr};
    CUfunction triton_tem_fused_addmm_209{nullptr};
    CUfunction triton_tem_fused_addmm_21{nullptr};
    CUfunction triton_tem_fused_addmm_210{nullptr};
    CUfunction triton_tem_fused_addmm_22{nullptr};
    CUfunction triton_tem_fused_addmm_23{nullptr};
    CUfunction triton_tem_fused_addmm_24{nullptr};
    CUfunction triton_tem_fused_addmm_25{nullptr};
    CUfunction triton_tem_fused_addmm_26{nullptr};
    CUfunction triton_tem_fused_addmm_27{nullptr};
    CUfunction triton_tem_fused_addmm_28{nullptr};
    CUfunction triton_tem_fused_addmm_29{nullptr};
    CUfunction triton_tem_fused_addmm_30{nullptr};
    CUfunction triton_tem_fused_addmm_31{nullptr};
    CUfunction triton_tem_fused_addmm_32{nullptr};
    CUfunction triton_tem_fused_addmm_33{nullptr};
    CUfunction triton_tem_fused_addmm_34{nullptr};
    CUfunction triton_tem_fused_addmm_35{nullptr};
    CUfunction triton_tem_fused_addmm_36{nullptr};
    CUfunction triton_tem_fused_addmm_37{nullptr};
    CUfunction triton_tem_fused_addmm_38{nullptr};
    CUfunction triton_tem_fused_addmm_39{nullptr};
    CUfunction triton_tem_fused_addmm_40{nullptr};
    CUfunction triton_tem_fused_addmm_41{nullptr};
    CUfunction triton_tem_fused_addmm_42{nullptr};
    CUfunction triton_tem_fused_addmm_43{nullptr};
    CUfunction triton_tem_fused_addmm_44{nullptr};
    CUfunction triton_tem_fused_addmm_45{nullptr};
    CUfunction triton_tem_fused_addmm_46{nullptr};
    CUfunction triton_tem_fused_addmm_47{nullptr};
    CUfunction triton_tem_fused_addmm_48{nullptr};
    CUfunction triton_tem_fused_addmm_67{nullptr};
    CUfunction triton_tem_fused_addmm_78{nullptr};
    CUfunction triton_tem_fused_addmm_81{nullptr};
    CUfunction triton_tem_fused_addmm_83{nullptr};
    CUfunction triton_tem_fused_addmm_85{nullptr};
    CUfunction triton_tem_fused_addmm_88{nullptr};
    CUfunction triton_tem_fused_addmm_cat_50{nullptr};
    CUfunction triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76{nullptr};
    CUfunction triton_tem_fused_addmm_clone_nan_to_num_relu_87{nullptr};
    CUfunction triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195{nullptr};
    CUfunction triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217{nullptr};
    CUfunction triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71{nullptr};
    CUfunction triton_tem_fused_addmm_mul_sigmoid_73{nullptr};
    CUfunction triton_tem_fused_addmm_nan_to_num_relu_212{nullptr};
    CUfunction triton_tem_fused_addmm_native_layer_norm_174{nullptr};
    CUfunction triton_tem_fused_addmm_native_layer_norm_187{nullptr};
    CUfunction triton_tem_fused_baddbmm_clamp_nan_to_num_92{nullptr};
    CUfunction triton_tem_fused_bmm_169{nullptr};
    CUfunction triton_tem_fused_bmm_178{nullptr};
    CUfunction triton_tem_fused_bmm_199{nullptr};
    CUfunction triton_tem_fused_bmm_203{nullptr};
    CUfunction triton_tem_fused_bmm_207{nullptr};
    CUfunction triton_tem_fused_bmm_native_layer_norm_180{nullptr};
    CUfunction triton_tem_fused_bmm_native_layer_norm_204{nullptr};
    CUfunction triton_tem_fused_mm_79{nullptr};
};
}  // namespace

AOTInductorModel::AOTInductorModel(std::shared_ptr<ConstantMap> constants_map,
                                    std::shared_ptr<std::vector<ConstantHandle>> constants_array,
                                    const std::string& device_str,
                                    std::optional<std::string> cubin_dir,
                                    bool include_weights)
    : AOTInductorModelBase(9, 2, 1190, device_str, cubin_dir, true) {
    inputs_info_[0].name = "arg606_1";
    inputs_info_[1].name = "arg607_1";
    inputs_info_[2].name = "arg608_1";
    inputs_info_[3].name = "arg609_1";
    inputs_info_[4].name = "arg610_1";
    inputs_info_[5].name = "arg611_1";
    inputs_info_[6].name = "arg612_1";
    inputs_info_[7].name = "arg613_1";
    inputs_info_[8].name = "arg614_1";
    constants_info_[0].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[0].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[0].offset = 0;
    constants_info_[0].data_size = 92160;
    constants_info_[0].from_folded = false;
    constants_info_[0].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[0].shape = {192, 240};
    constants_info_[0].stride = {240, 1};
    constants_info_[0].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[0].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[1].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[1].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1].offset = 0;
    constants_info_[1].data_size = 384;
    constants_info_[1].from_folded = false;
    constants_info_[1].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[1].shape = {192};
    constants_info_[1].stride = {1};
    constants_info_[1].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[2].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_1_scale";
    constants_info_[2].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[2].offset = 0;
    constants_info_[2].data_size = 384;
    constants_info_[2].from_folded = false;
    constants_info_[2].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[2].shape = {192};
    constants_info_[2].stride = {1};
    constants_info_[2].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[2].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3.submodules.1.scale";
    constants_info_[3].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_1_bias";
    constants_info_[3].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[3].offset = 0;
    constants_info_[3].data_size = 384;
    constants_info_[3].from_folded = false;
    constants_info_[3].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[3].shape = {192};
    constants_info_[3].stride = {1};
    constants_info_[3].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[3].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3.submodules.1.bias";
    constants_info_[4].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[4].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[4].offset = 0;
    constants_info_[4].data_size = 92160;
    constants_info_[4].from_folded = false;
    constants_info_[4].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[4].shape = {192, 240};
    constants_info_[4].stride = {240, 1};
    constants_info_[4].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[4].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[5].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[5].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[5].offset = 0;
    constants_info_[5].data_size = 384;
    constants_info_[5].from_folded = false;
    constants_info_[5].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[5].shape = {192};
    constants_info_[5].stride = {1};
    constants_info_[5].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[5].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[6].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_1_scale";
    constants_info_[6].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[6].offset = 0;
    constants_info_[6].data_size = 384;
    constants_info_[6].from_folded = false;
    constants_info_[6].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[6].shape = {192};
    constants_info_[6].stride = {1};
    constants_info_[6].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[6].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2.submodules.1.scale";
    constants_info_[7].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_1_bias";
    constants_info_[7].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[7].offset = 0;
    constants_info_[7].data_size = 384;
    constants_info_[7].from_folded = false;
    constants_info_[7].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[7].shape = {192};
    constants_info_[7].stride = {1};
    constants_info_[7].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[7].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2.submodules.1.bias";
    constants_info_[8].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[8].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[8].offset = 0;
    constants_info_[8].data_size = 73728;
    constants_info_[8].from_folded = false;
    constants_info_[8].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[8].shape = {192, 192};
    constants_info_[8].stride = {192, 1};
    constants_info_[8].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[8].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[9].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[9].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[9].offset = 0;
    constants_info_[9].data_size = 384;
    constants_info_[9].from_folded = false;
    constants_info_[9].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[9].shape = {192};
    constants_info_[9].stride = {1};
    constants_info_[9].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[9].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[10].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_1_scale";
    constants_info_[10].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[10].offset = 0;
    constants_info_[10].data_size = 384;
    constants_info_[10].from_folded = false;
    constants_info_[10].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[10].shape = {192};
    constants_info_[10].stride = {1};
    constants_info_[10].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[10].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1.submodules.1.scale";
    constants_info_[11].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_1_bias";
    constants_info_[11].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[11].offset = 0;
    constants_info_[11].data_size = 384;
    constants_info_[11].from_folded = false;
    constants_info_[11].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[11].shape = {192};
    constants_info_[11].stride = {1};
    constants_info_[11].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[11].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1.submodules.1.bias";
    constants_info_[12].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[12].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[12].offset = 0;
    constants_info_[12].data_size = 73728;
    constants_info_[12].from_folded = false;
    constants_info_[12].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[12].shape = {192, 192};
    constants_info_[12].stride = {192, 1};
    constants_info_[12].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[12].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[13].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[13].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[13].offset = 0;
    constants_info_[13].data_size = 384;
    constants_info_[13].from_folded = false;
    constants_info_[13].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[13].shape = {192};
    constants_info_[13].stride = {1};
    constants_info_[13].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[13].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[14].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_1_scale";
    constants_info_[14].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[14].offset = 0;
    constants_info_[14].data_size = 384;
    constants_info_[14].from_folded = false;
    constants_info_[14].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[14].shape = {192};
    constants_info_[14].stride = {1};
    constants_info_[14].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[14].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0.submodules.1.scale";
    constants_info_[15].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_1_bias";
    constants_info_[15].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[15].offset = 0;
    constants_info_[15].data_size = 384;
    constants_info_[15].from_folded = false;
    constants_info_[15].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[15].shape = {192};
    constants_info_[15].stride = {1};
    constants_info_[15].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[15].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0.submodules.1.bias";
    constants_info_[16].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[16].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[16].offset = 0;
    constants_info_[16].data_size = 36864;
    constants_info_[16].from_folded = false;
    constants_info_[16].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[16].shape = {192, 96};
    constants_info_[16].stride = {96, 1};
    constants_info_[16].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[16].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[17].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[17].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[17].offset = 0;
    constants_info_[17].data_size = 384;
    constants_info_[17].from_folded = false;
    constants_info_[17].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[17].shape = {192};
    constants_info_[17].stride = {1};
    constants_info_[17].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[17].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[18].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[18].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[18].offset = 0;
    constants_info_[18].data_size = 384;
    constants_info_[18].from_folded = false;
    constants_info_[18].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[18].shape = {192};
    constants_info_[18].stride = {1};
    constants_info_[18].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[18].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[19].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[19].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[19].offset = 0;
    constants_info_[19].data_size = 384;
    constants_info_[19].from_folded = false;
    constants_info_[19].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[19].shape = {192};
    constants_info_[19].stride = {1};
    constants_info_[19].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[19].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[20].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[20].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[20].offset = 0;
    constants_info_[20].data_size = 27648;
    constants_info_[20].from_folded = false;
    constants_info_[20].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[20].shape = {192, 72};
    constants_info_[20].stride = {72, 1};
    constants_info_[20].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[20].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[21].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[21].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[21].offset = 0;
    constants_info_[21].data_size = 384;
    constants_info_[21].from_folded = false;
    constants_info_[21].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[21].shape = {192};
    constants_info_[21].stride = {1};
    constants_info_[21].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[21].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[22].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[22].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[22].offset = 0;
    constants_info_[22].data_size = 384;
    constants_info_[22].from_folded = false;
    constants_info_[22].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[22].shape = {192};
    constants_info_[22].stride = {1};
    constants_info_[22].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[22].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[23].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[23].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[23].offset = 0;
    constants_info_[23].data_size = 384;
    constants_info_[23].from_folded = false;
    constants_info_[23].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[23].shape = {192};
    constants_info_[23].stride = {1};
    constants_info_[23].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[23].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[24].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[24].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[24].offset = 0;
    constants_info_[24].data_size = 36864;
    constants_info_[24].from_folded = false;
    constants_info_[24].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[24].shape = {192, 96};
    constants_info_[24].stride = {96, 1};
    constants_info_[24].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[24].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[25].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[25].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[25].offset = 0;
    constants_info_[25].data_size = 384;
    constants_info_[25].from_folded = false;
    constants_info_[25].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[25].shape = {192};
    constants_info_[25].stride = {1};
    constants_info_[25].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[25].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[26].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[26].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[26].offset = 0;
    constants_info_[26].data_size = 384;
    constants_info_[26].from_folded = false;
    constants_info_[26].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[26].shape = {192};
    constants_info_[26].stride = {1};
    constants_info_[26].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[26].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[27].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[27].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[27].offset = 0;
    constants_info_[27].data_size = 384;
    constants_info_[27].from_folded = false;
    constants_info_[27].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[27].shape = {192};
    constants_info_[27].stride = {1};
    constants_info_[27].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[27].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[28].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[28].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[28].offset = 0;
    constants_info_[28].data_size = 36864;
    constants_info_[28].from_folded = false;
    constants_info_[28].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[28].shape = {192, 96};
    constants_info_[28].stride = {96, 1};
    constants_info_[28].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[28].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[29].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[29].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[29].offset = 0;
    constants_info_[29].data_size = 384;
    constants_info_[29].from_folded = false;
    constants_info_[29].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[29].shape = {192};
    constants_info_[29].stride = {1};
    constants_info_[29].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[29].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[30].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[30].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[30].offset = 0;
    constants_info_[30].data_size = 384;
    constants_info_[30].from_folded = false;
    constants_info_[30].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[30].shape = {192};
    constants_info_[30].stride = {1};
    constants_info_[30].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[30].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[31].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[31].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[31].offset = 0;
    constants_info_[31].data_size = 384;
    constants_info_[31].from_folded = false;
    constants_info_[31].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[31].shape = {192};
    constants_info_[31].stride = {1};
    constants_info_[31].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[31].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[32].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[32].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[32].offset = 0;
    constants_info_[32].data_size = 36864;
    constants_info_[32].from_folded = false;
    constants_info_[32].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[32].shape = {192, 96};
    constants_info_[32].stride = {96, 1};
    constants_info_[32].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[32].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[33].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[33].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[33].offset = 0;
    constants_info_[33].data_size = 384;
    constants_info_[33].from_folded = false;
    constants_info_[33].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[33].shape = {192};
    constants_info_[33].stride = {1};
    constants_info_[33].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[33].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[34].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_1_scale";
    constants_info_[34].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[34].offset = 0;
    constants_info_[34].data_size = 384;
    constants_info_[34].from_folded = false;
    constants_info_[34].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[34].shape = {192};
    constants_info_[34].stride = {1};
    constants_info_[34].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[34].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3.submodules.1.scale";
    constants_info_[35].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_1_bias";
    constants_info_[35].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[35].offset = 0;
    constants_info_[35].data_size = 384;
    constants_info_[35].from_folded = false;
    constants_info_[35].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[35].shape = {192};
    constants_info_[35].stride = {1};
    constants_info_[35].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[35].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3.submodules.1.bias";
    constants_info_[36].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[36].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[36].offset = 0;
    constants_info_[36].data_size = 36864;
    constants_info_[36].from_folded = false;
    constants_info_[36].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[36].shape = {192, 96};
    constants_info_[36].stride = {96, 1};
    constants_info_[36].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[36].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[37].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[37].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[37].offset = 0;
    constants_info_[37].data_size = 384;
    constants_info_[37].from_folded = false;
    constants_info_[37].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[37].shape = {192};
    constants_info_[37].stride = {1};
    constants_info_[37].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[37].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[38].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[38].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[38].offset = 0;
    constants_info_[38].data_size = 384;
    constants_info_[38].from_folded = false;
    constants_info_[38].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[38].shape = {192};
    constants_info_[38].stride = {1};
    constants_info_[38].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[38].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[39].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[39].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[39].offset = 0;
    constants_info_[39].data_size = 384;
    constants_info_[39].from_folded = false;
    constants_info_[39].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[39].shape = {192};
    constants_info_[39].stride = {1};
    constants_info_[39].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[39].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[40].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[40].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[40].offset = 0;
    constants_info_[40].data_size = 27648;
    constants_info_[40].from_folded = false;
    constants_info_[40].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[40].shape = {192, 72};
    constants_info_[40].stride = {72, 1};
    constants_info_[40].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[40].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[41].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[41].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[41].offset = 0;
    constants_info_[41].data_size = 384;
    constants_info_[41].from_folded = false;
    constants_info_[41].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[41].shape = {192};
    constants_info_[41].stride = {1};
    constants_info_[41].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[41].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[42].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[42].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[42].offset = 0;
    constants_info_[42].data_size = 384;
    constants_info_[42].from_folded = false;
    constants_info_[42].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[42].shape = {192};
    constants_info_[42].stride = {1};
    constants_info_[42].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[42].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[43].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[43].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[43].offset = 0;
    constants_info_[43].data_size = 384;
    constants_info_[43].from_folded = false;
    constants_info_[43].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[43].shape = {192};
    constants_info_[43].stride = {1};
    constants_info_[43].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[43].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[44].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[44].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[44].offset = 0;
    constants_info_[44].data_size = 36864;
    constants_info_[44].from_folded = false;
    constants_info_[44].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[44].shape = {192, 96};
    constants_info_[44].stride = {96, 1};
    constants_info_[44].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[44].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[45].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[45].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[45].offset = 0;
    constants_info_[45].data_size = 384;
    constants_info_[45].from_folded = false;
    constants_info_[45].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[45].shape = {192};
    constants_info_[45].stride = {1};
    constants_info_[45].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[45].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[46].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[46].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[46].offset = 0;
    constants_info_[46].data_size = 384;
    constants_info_[46].from_folded = false;
    constants_info_[46].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[46].shape = {192};
    constants_info_[46].stride = {1};
    constants_info_[46].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[46].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[47].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[47].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[47].offset = 0;
    constants_info_[47].data_size = 384;
    constants_info_[47].from_folded = false;
    constants_info_[47].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[47].shape = {192};
    constants_info_[47].stride = {1};
    constants_info_[47].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[47].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[48].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[48].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[48].offset = 0;
    constants_info_[48].data_size = 36864;
    constants_info_[48].from_folded = false;
    constants_info_[48].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[48].shape = {192, 96};
    constants_info_[48].stride = {96, 1};
    constants_info_[48].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[48].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[49].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[49].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[49].offset = 0;
    constants_info_[49].data_size = 384;
    constants_info_[49].from_folded = false;
    constants_info_[49].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[49].shape = {192};
    constants_info_[49].stride = {1};
    constants_info_[49].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[49].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[50].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_1_scale";
    constants_info_[50].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[50].offset = 0;
    constants_info_[50].data_size = 384;
    constants_info_[50].from_folded = false;
    constants_info_[50].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[50].shape = {192};
    constants_info_[50].stride = {1};
    constants_info_[50].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[50].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3.submodules.1.scale";
    constants_info_[51].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_1_bias";
    constants_info_[51].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[51].offset = 0;
    constants_info_[51].data_size = 384;
    constants_info_[51].from_folded = false;
    constants_info_[51].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[51].shape = {192};
    constants_info_[51].stride = {1};
    constants_info_[51].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[51].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3.submodules.1.bias";
    constants_info_[52].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[52].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[52].offset = 0;
    constants_info_[52].data_size = 36864;
    constants_info_[52].from_folded = false;
    constants_info_[52].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[52].shape = {192, 96};
    constants_info_[52].stride = {96, 1};
    constants_info_[52].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[52].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[53].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[53].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[53].offset = 0;
    constants_info_[53].data_size = 384;
    constants_info_[53].from_folded = false;
    constants_info_[53].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[53].shape = {192};
    constants_info_[53].stride = {1};
    constants_info_[53].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[53].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[54].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[54].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[54].offset = 0;
    constants_info_[54].data_size = 384;
    constants_info_[54].from_folded = false;
    constants_info_[54].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[54].shape = {192};
    constants_info_[54].stride = {1};
    constants_info_[54].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[54].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[55].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[55].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[55].offset = 0;
    constants_info_[55].data_size = 384;
    constants_info_[55].from_folded = false;
    constants_info_[55].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[55].shape = {192};
    constants_info_[55].stride = {1};
    constants_info_[55].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[55].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[56].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[56].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[56].offset = 0;
    constants_info_[56].data_size = 27648;
    constants_info_[56].from_folded = false;
    constants_info_[56].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[56].shape = {192, 72};
    constants_info_[56].stride = {72, 1};
    constants_info_[56].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[56].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[57].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[57].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[57].offset = 0;
    constants_info_[57].data_size = 384;
    constants_info_[57].from_folded = false;
    constants_info_[57].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[57].shape = {192};
    constants_info_[57].stride = {1};
    constants_info_[57].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[57].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[58].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[58].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[58].offset = 0;
    constants_info_[58].data_size = 384;
    constants_info_[58].from_folded = false;
    constants_info_[58].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[58].shape = {192};
    constants_info_[58].stride = {1};
    constants_info_[58].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[58].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[59].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[59].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[59].offset = 0;
    constants_info_[59].data_size = 384;
    constants_info_[59].from_folded = false;
    constants_info_[59].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[59].shape = {192};
    constants_info_[59].stride = {1};
    constants_info_[59].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[59].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[60].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[60].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[60].offset = 0;
    constants_info_[60].data_size = 36864;
    constants_info_[60].from_folded = false;
    constants_info_[60].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[60].shape = {192, 96};
    constants_info_[60].stride = {96, 1};
    constants_info_[60].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[60].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[61].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[61].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[61].offset = 0;
    constants_info_[61].data_size = 384;
    constants_info_[61].from_folded = false;
    constants_info_[61].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[61].shape = {192};
    constants_info_[61].stride = {1};
    constants_info_[61].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[61].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[62].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[62].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[62].offset = 0;
    constants_info_[62].data_size = 384;
    constants_info_[62].from_folded = false;
    constants_info_[62].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[62].shape = {192};
    constants_info_[62].stride = {1};
    constants_info_[62].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[62].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[63].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[63].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[63].offset = 0;
    constants_info_[63].data_size = 384;
    constants_info_[63].from_folded = false;
    constants_info_[63].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[63].shape = {192};
    constants_info_[63].stride = {1};
    constants_info_[63].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[63].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[64].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[64].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[64].offset = 0;
    constants_info_[64].data_size = 24576;
    constants_info_[64].from_folded = false;
    constants_info_[64].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[64].shape = {192, 64};
    constants_info_[64].stride = {64, 1};
    constants_info_[64].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[64].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[65].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[65].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[65].offset = 0;
    constants_info_[65].data_size = 384;
    constants_info_[65].from_folded = false;
    constants_info_[65].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[65].shape = {192};
    constants_info_[65].stride = {1};
    constants_info_[65].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[65].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[66].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[66].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[66].offset = 0;
    constants_info_[66].data_size = 384;
    constants_info_[66].from_folded = false;
    constants_info_[66].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[66].shape = {192};
    constants_info_[66].stride = {1};
    constants_info_[66].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[66].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[67].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[67].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[67].offset = 0;
    constants_info_[67].data_size = 384;
    constants_info_[67].from_folded = false;
    constants_info_[67].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[67].shape = {192};
    constants_info_[67].stride = {1};
    constants_info_[67].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[67].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[68].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[68].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[68].offset = 0;
    constants_info_[68].data_size = 36864;
    constants_info_[68].from_folded = false;
    constants_info_[68].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[68].shape = {192, 96};
    constants_info_[68].stride = {96, 1};
    constants_info_[68].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[68].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[69].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[69].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[69].offset = 0;
    constants_info_[69].data_size = 384;
    constants_info_[69].from_folded = false;
    constants_info_[69].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[69].shape = {192};
    constants_info_[69].stride = {1};
    constants_info_[69].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[69].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[70].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[70].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[70].offset = 0;
    constants_info_[70].data_size = 384;
    constants_info_[70].from_folded = false;
    constants_info_[70].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[70].shape = {192};
    constants_info_[70].stride = {1};
    constants_info_[70].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[70].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[71].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[71].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[71].offset = 0;
    constants_info_[71].data_size = 384;
    constants_info_[71].from_folded = false;
    constants_info_[71].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[71].shape = {192};
    constants_info_[71].stride = {1};
    constants_info_[71].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[71].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[72].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[72].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[72].offset = 0;
    constants_info_[72].data_size = 24576;
    constants_info_[72].from_folded = false;
    constants_info_[72].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[72].shape = {192, 64};
    constants_info_[72].stride = {64, 1};
    constants_info_[72].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[72].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[73].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[73].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[73].offset = 0;
    constants_info_[73].data_size = 384;
    constants_info_[73].from_folded = false;
    constants_info_[73].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[73].shape = {192};
    constants_info_[73].stride = {1};
    constants_info_[73].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[73].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[74].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[74].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[74].offset = 0;
    constants_info_[74].data_size = 384;
    constants_info_[74].from_folded = false;
    constants_info_[74].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[74].shape = {192};
    constants_info_[74].stride = {1};
    constants_info_[74].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[74].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[75].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[75].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[75].offset = 0;
    constants_info_[75].data_size = 384;
    constants_info_[75].from_folded = false;
    constants_info_[75].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[75].shape = {192};
    constants_info_[75].stride = {1};
    constants_info_[75].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[75].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[76].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[76].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[76].offset = 0;
    constants_info_[76].data_size = 27648;
    constants_info_[76].from_folded = false;
    constants_info_[76].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[76].shape = {192, 72};
    constants_info_[76].stride = {72, 1};
    constants_info_[76].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[76].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[77].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[77].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[77].offset = 0;
    constants_info_[77].data_size = 384;
    constants_info_[77].from_folded = false;
    constants_info_[77].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[77].shape = {192};
    constants_info_[77].stride = {1};
    constants_info_[77].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[77].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[78].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[78].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[78].offset = 0;
    constants_info_[78].data_size = 384;
    constants_info_[78].from_folded = false;
    constants_info_[78].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[78].shape = {192};
    constants_info_[78].stride = {1};
    constants_info_[78].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[78].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[79].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[79].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[79].offset = 0;
    constants_info_[79].data_size = 384;
    constants_info_[79].from_folded = false;
    constants_info_[79].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[79].shape = {192};
    constants_info_[79].stride = {1};
    constants_info_[79].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[79].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[80].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[80].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[80].offset = 0;
    constants_info_[80].data_size = 27648;
    constants_info_[80].from_folded = false;
    constants_info_[80].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[80].shape = {192, 72};
    constants_info_[80].stride = {72, 1};
    constants_info_[80].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[80].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[81].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[81].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[81].offset = 0;
    constants_info_[81].data_size = 384;
    constants_info_[81].from_folded = false;
    constants_info_[81].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[81].shape = {192};
    constants_info_[81].stride = {1};
    constants_info_[81].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[81].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[82].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[82].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[82].offset = 0;
    constants_info_[82].data_size = 384;
    constants_info_[82].from_folded = false;
    constants_info_[82].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[82].shape = {192};
    constants_info_[82].stride = {1};
    constants_info_[82].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[82].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[83].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[83].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[83].offset = 0;
    constants_info_[83].data_size = 384;
    constants_info_[83].from_folded = false;
    constants_info_[83].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[83].shape = {192};
    constants_info_[83].stride = {1};
    constants_info_[83].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[83].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[84].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[84].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[84].offset = 0;
    constants_info_[84].data_size = 36864;
    constants_info_[84].from_folded = false;
    constants_info_[84].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[84].shape = {192, 96};
    constants_info_[84].stride = {96, 1};
    constants_info_[84].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[84].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[85].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[85].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[85].offset = 0;
    constants_info_[85].data_size = 384;
    constants_info_[85].from_folded = false;
    constants_info_[85].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[85].shape = {192};
    constants_info_[85].stride = {1};
    constants_info_[85].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[85].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[86].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[86].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[86].offset = 0;
    constants_info_[86].data_size = 384;
    constants_info_[86].from_folded = false;
    constants_info_[86].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[86].shape = {192};
    constants_info_[86].stride = {1};
    constants_info_[86].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[86].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[87].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[87].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[87].offset = 0;
    constants_info_[87].data_size = 384;
    constants_info_[87].from_folded = false;
    constants_info_[87].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[87].shape = {192};
    constants_info_[87].stride = {1};
    constants_info_[87].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[87].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[88].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[88].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[88].offset = 0;
    constants_info_[88].data_size = 24576;
    constants_info_[88].from_folded = false;
    constants_info_[88].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[88].shape = {192, 64};
    constants_info_[88].stride = {64, 1};
    constants_info_[88].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[88].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[89].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[89].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[89].offset = 0;
    constants_info_[89].data_size = 384;
    constants_info_[89].from_folded = false;
    constants_info_[89].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[89].shape = {192};
    constants_info_[89].stride = {1};
    constants_info_[89].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[89].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[90].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_1_scale";
    constants_info_[90].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[90].offset = 0;
    constants_info_[90].data_size = 384;
    constants_info_[90].from_folded = false;
    constants_info_[90].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[90].shape = {192};
    constants_info_[90].stride = {1};
    constants_info_[90].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[90].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR.submodules.1.scale";
    constants_info_[91].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_1_bias";
    constants_info_[91].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[91].offset = 0;
    constants_info_[91].data_size = 384;
    constants_info_[91].from_folded = false;
    constants_info_[91].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[91].shape = {192};
    constants_info_[91].stride = {1};
    constants_info_[91].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[91].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR.submodules.1.bias";
    constants_info_[92].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[92].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[92].offset = 0;
    constants_info_[92].data_size = 27648;
    constants_info_[92].from_folded = false;
    constants_info_[92].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[92].shape = {192, 72};
    constants_info_[92].stride = {72, 1};
    constants_info_[92].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[92].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[93].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[93].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[93].offset = 0;
    constants_info_[93].data_size = 384;
    constants_info_[93].from_folded = false;
    constants_info_[93].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[93].shape = {192};
    constants_info_[93].stride = {1};
    constants_info_[93].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[93].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[94].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[94].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[94].offset = 0;
    constants_info_[94].data_size = 384;
    constants_info_[94].from_folded = false;
    constants_info_[94].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[94].shape = {192};
    constants_info_[94].stride = {1};
    constants_info_[94].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[94].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[95].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[95].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[95].offset = 0;
    constants_info_[95].data_size = 384;
    constants_info_[95].from_folded = false;
    constants_info_[95].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[95].shape = {192};
    constants_info_[95].stride = {1};
    constants_info_[95].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[95].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[96].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[96].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[96].offset = 0;
    constants_info_[96].data_size = 27648;
    constants_info_[96].from_folded = false;
    constants_info_[96].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[96].shape = {192, 72};
    constants_info_[96].stride = {72, 1};
    constants_info_[96].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[96].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[97].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[97].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[97].offset = 0;
    constants_info_[97].data_size = 384;
    constants_info_[97].from_folded = false;
    constants_info_[97].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[97].shape = {192};
    constants_info_[97].stride = {1};
    constants_info_[97].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[97].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[98].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_1_scale";
    constants_info_[98].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[98].offset = 0;
    constants_info_[98].data_size = 384;
    constants_info_[98].from_folded = false;
    constants_info_[98].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[98].shape = {192};
    constants_info_[98].stride = {1};
    constants_info_[98].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[98].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2.submodules.1.scale";
    constants_info_[99].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_1_bias";
    constants_info_[99].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[99].offset = 0;
    constants_info_[99].data_size = 384;
    constants_info_[99].from_folded = false;
    constants_info_[99].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[99].shape = {192};
    constants_info_[99].stride = {1};
    constants_info_[99].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[99].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2.submodules.1.bias";
    constants_info_[100].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[100].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[100].offset = 0;
    constants_info_[100].data_size = 27648;
    constants_info_[100].from_folded = false;
    constants_info_[100].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[100].shape = {192, 72};
    constants_info_[100].stride = {72, 1};
    constants_info_[100].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[100].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[101].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[101].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[101].offset = 0;
    constants_info_[101].data_size = 384;
    constants_info_[101].from_folded = false;
    constants_info_[101].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[101].shape = {192};
    constants_info_[101].stride = {1};
    constants_info_[101].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[101].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[102].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[102].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[102].offset = 0;
    constants_info_[102].data_size = 384;
    constants_info_[102].from_folded = false;
    constants_info_[102].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[102].shape = {192};
    constants_info_[102].stride = {1};
    constants_info_[102].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[102].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[103].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[103].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[103].offset = 0;
    constants_info_[103].data_size = 384;
    constants_info_[103].from_folded = false;
    constants_info_[103].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[103].shape = {192};
    constants_info_[103].stride = {1};
    constants_info_[103].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[103].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[104].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[104].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[104].offset = 0;
    constants_info_[104].data_size = 24576;
    constants_info_[104].from_folded = false;
    constants_info_[104].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[104].shape = {192, 64};
    constants_info_[104].stride = {64, 1};
    constants_info_[104].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[104].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[105].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[105].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[105].offset = 0;
    constants_info_[105].data_size = 384;
    constants_info_[105].from_folded = false;
    constants_info_[105].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[105].shape = {192};
    constants_info_[105].stride = {1};
    constants_info_[105].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[105].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[106].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[106].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[106].offset = 0;
    constants_info_[106].data_size = 384;
    constants_info_[106].from_folded = false;
    constants_info_[106].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[106].shape = {192};
    constants_info_[106].stride = {1};
    constants_info_[106].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[106].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[107].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[107].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[107].offset = 0;
    constants_info_[107].data_size = 384;
    constants_info_[107].from_folded = false;
    constants_info_[107].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[107].shape = {192};
    constants_info_[107].stride = {1};
    constants_info_[107].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[107].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[108].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[108].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[108].offset = 0;
    constants_info_[108].data_size = 24576;
    constants_info_[108].from_folded = false;
    constants_info_[108].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[108].shape = {192, 64};
    constants_info_[108].stride = {64, 1};
    constants_info_[108].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[108].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[109].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[109].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[109].offset = 0;
    constants_info_[109].data_size = 384;
    constants_info_[109].from_folded = false;
    constants_info_[109].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[109].shape = {192};
    constants_info_[109].stride = {1};
    constants_info_[109].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[109].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[110].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[110].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[110].offset = 0;
    constants_info_[110].data_size = 384;
    constants_info_[110].from_folded = false;
    constants_info_[110].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[110].shape = {192};
    constants_info_[110].stride = {1};
    constants_info_[110].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[110].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[111].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[111].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[111].offset = 0;
    constants_info_[111].data_size = 384;
    constants_info_[111].from_folded = false;
    constants_info_[111].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[111].shape = {192};
    constants_info_[111].stride = {1};
    constants_info_[111].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[111].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[112].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[112].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[112].offset = 0;
    constants_info_[112].data_size = 24576;
    constants_info_[112].from_folded = false;
    constants_info_[112].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[112].shape = {192, 64};
    constants_info_[112].stride = {64, 1};
    constants_info_[112].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[112].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[113].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[113].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[113].offset = 0;
    constants_info_[113].data_size = 384;
    constants_info_[113].from_folded = false;
    constants_info_[113].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[113].shape = {192};
    constants_info_[113].stride = {1};
    constants_info_[113].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[113].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[114].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[114].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[114].offset = 0;
    constants_info_[114].data_size = 384;
    constants_info_[114].from_folded = false;
    constants_info_[114].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[114].shape = {192};
    constants_info_[114].stride = {1};
    constants_info_[114].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[114].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[115].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[115].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[115].offset = 0;
    constants_info_[115].data_size = 384;
    constants_info_[115].from_folded = false;
    constants_info_[115].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[115].shape = {192};
    constants_info_[115].stride = {1};
    constants_info_[115].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[115].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[116].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[116].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[116].offset = 0;
    constants_info_[116].data_size = 55296;
    constants_info_[116].from_folded = false;
    constants_info_[116].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[116].shape = {192, 144};
    constants_info_[116].stride = {144, 1};
    constants_info_[116].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[116].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[117].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[117].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[117].offset = 0;
    constants_info_[117].data_size = 384;
    constants_info_[117].from_folded = false;
    constants_info_[117].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[117].shape = {192};
    constants_info_[117].stride = {1};
    constants_info_[117].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[117].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[118].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_1_scale";
    constants_info_[118].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[118].offset = 0;
    constants_info_[118].data_size = 384;
    constants_info_[118].from_folded = false;
    constants_info_[118].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[118].shape = {192};
    constants_info_[118].stride = {1};
    constants_info_[118].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[118].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0.submodules.1.scale";
    constants_info_[119].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_1_bias";
    constants_info_[119].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[119].offset = 0;
    constants_info_[119].data_size = 384;
    constants_info_[119].from_folded = false;
    constants_info_[119].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[119].shape = {192};
    constants_info_[119].stride = {1};
    constants_info_[119].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[119].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0.submodules.1.bias";
    constants_info_[120].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[120].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[120].offset = 0;
    constants_info_[120].data_size = 55296;
    constants_info_[120].from_folded = false;
    constants_info_[120].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[120].shape = {192, 144};
    constants_info_[120].stride = {144, 1};
    constants_info_[120].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[120].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[121].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[121].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[121].offset = 0;
    constants_info_[121].data_size = 384;
    constants_info_[121].from_folded = false;
    constants_info_[121].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[121].shape = {192};
    constants_info_[121].stride = {1};
    constants_info_[121].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[121].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[122].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_1_scale";
    constants_info_[122].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[122].offset = 0;
    constants_info_[122].data_size = 384;
    constants_info_[122].from_folded = false;
    constants_info_[122].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[122].shape = {192};
    constants_info_[122].stride = {1};
    constants_info_[122].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[122].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1.submodules.1.scale";
    constants_info_[123].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_1_bias";
    constants_info_[123].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[123].offset = 0;
    constants_info_[123].data_size = 384;
    constants_info_[123].from_folded = false;
    constants_info_[123].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[123].shape = {192};
    constants_info_[123].stride = {1};
    constants_info_[123].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[123].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1.submodules.1.bias";
    constants_info_[124].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[124].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[124].offset = 0;
    constants_info_[124].data_size = 24576;
    constants_info_[124].from_folded = false;
    constants_info_[124].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[124].shape = {192, 64};
    constants_info_[124].stride = {64, 1};
    constants_info_[124].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[124].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[125].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[125].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[125].offset = 0;
    constants_info_[125].data_size = 384;
    constants_info_[125].from_folded = false;
    constants_info_[125].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[125].shape = {192};
    constants_info_[125].stride = {1};
    constants_info_[125].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[125].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[126].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[126].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[126].offset = 0;
    constants_info_[126].data_size = 384;
    constants_info_[126].from_folded = false;
    constants_info_[126].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[126].shape = {192};
    constants_info_[126].stride = {1};
    constants_info_[126].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[126].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[127].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[127].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[127].offset = 0;
    constants_info_[127].data_size = 384;
    constants_info_[127].from_folded = false;
    constants_info_[127].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[127].shape = {192};
    constants_info_[127].stride = {1};
    constants_info_[127].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[127].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[128].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[128].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[128].offset = 0;
    constants_info_[128].data_size = 24576;
    constants_info_[128].from_folded = false;
    constants_info_[128].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[128].shape = {192, 64};
    constants_info_[128].stride = {64, 1};
    constants_info_[128].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[128].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[129].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[129].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[129].offset = 0;
    constants_info_[129].data_size = 384;
    constants_info_[129].from_folded = false;
    constants_info_[129].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[129].shape = {192};
    constants_info_[129].stride = {1};
    constants_info_[129].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[129].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[130].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[130].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[130].offset = 0;
    constants_info_[130].data_size = 384;
    constants_info_[130].from_folded = false;
    constants_info_[130].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[130].shape = {192};
    constants_info_[130].stride = {1};
    constants_info_[130].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[130].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[131].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[131].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[131].offset = 0;
    constants_info_[131].data_size = 384;
    constants_info_[131].from_folded = false;
    constants_info_[131].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[131].shape = {192};
    constants_info_[131].stride = {1};
    constants_info_[131].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[131].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[132].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[132].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[132].offset = 0;
    constants_info_[132].data_size = 24576;
    constants_info_[132].from_folded = false;
    constants_info_[132].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[132].shape = {192, 64};
    constants_info_[132].stride = {64, 1};
    constants_info_[132].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[132].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[133].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[133].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[133].offset = 0;
    constants_info_[133].data_size = 384;
    constants_info_[133].from_folded = false;
    constants_info_[133].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[133].shape = {192};
    constants_info_[133].stride = {1};
    constants_info_[133].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[133].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[134].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[134].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[134].offset = 0;
    constants_info_[134].data_size = 384;
    constants_info_[134].from_folded = false;
    constants_info_[134].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[134].shape = {192};
    constants_info_[134].stride = {1};
    constants_info_[134].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[134].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[135].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[135].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[135].offset = 0;
    constants_info_[135].data_size = 384;
    constants_info_[135].from_folded = false;
    constants_info_[135].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[135].shape = {192};
    constants_info_[135].stride = {1};
    constants_info_[135].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[135].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[136].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[136].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[136].offset = 0;
    constants_info_[136].data_size = 36864;
    constants_info_[136].from_folded = false;
    constants_info_[136].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[136].shape = {192, 96};
    constants_info_[136].stride = {96, 1};
    constants_info_[136].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[136].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[137].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[137].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[137].offset = 0;
    constants_info_[137].data_size = 384;
    constants_info_[137].from_folded = false;
    constants_info_[137].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[137].shape = {192};
    constants_info_[137].stride = {1};
    constants_info_[137].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[137].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[138].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_1_scale";
    constants_info_[138].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[138].offset = 0;
    constants_info_[138].data_size = 384;
    constants_info_[138].from_folded = false;
    constants_info_[138].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[138].shape = {192};
    constants_info_[138].stride = {1};
    constants_info_[138].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[138].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3.submodules.1.scale";
    constants_info_[139].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_1_bias";
    constants_info_[139].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[139].offset = 0;
    constants_info_[139].data_size = 384;
    constants_info_[139].from_folded = false;
    constants_info_[139].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[139].shape = {192};
    constants_info_[139].stride = {1};
    constants_info_[139].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[139].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3.submodules.1.bias";
    constants_info_[140].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[140].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[140].offset = 0;
    constants_info_[140].data_size = 36864;
    constants_info_[140].from_folded = false;
    constants_info_[140].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[140].shape = {192, 96};
    constants_info_[140].stride = {96, 1};
    constants_info_[140].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[140].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[141].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[141].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[141].offset = 0;
    constants_info_[141].data_size = 384;
    constants_info_[141].from_folded = false;
    constants_info_[141].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[141].shape = {192};
    constants_info_[141].stride = {1};
    constants_info_[141].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[141].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[142].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_1_scale";
    constants_info_[142].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[142].offset = 0;
    constants_info_[142].data_size = 384;
    constants_info_[142].from_folded = false;
    constants_info_[142].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[142].shape = {192};
    constants_info_[142].stride = {1};
    constants_info_[142].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[142].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3.submodules.1.scale";
    constants_info_[143].name = "submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_1_bias";
    constants_info_[143].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[143].offset = 0;
    constants_info_[143].data_size = 384;
    constants_info_[143].from_folded = false;
    constants_info_[143].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[143].shape = {192};
    constants_info_[143].stride = {1};
    constants_info_[143].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[143].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3.submodules.1.bias";
    constants_info_[144].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[144].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[144].offset = 0;
    constants_info_[144].data_size = 2590256;
    constants_info_[144].from_folded = false;
    constants_info_[144].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[144].shape = {214, 6052};
    constants_info_[144].stride = {6052, 1};
    constants_info_[144].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[144].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[145].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[145].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[145].offset = 0;
    constants_info_[145].data_size = 428;
    constants_info_[145].from_folded = false;
    constants_info_[145].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[145].shape = {214};
    constants_info_[145].stride = {1};
    constants_info_[145].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[145].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[146].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_w";
    constants_info_[146].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[146].offset = 0;
    constants_info_[146].data_size = 508368;
    constants_info_[146].from_folded = false;
    constants_info_[146].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[146].shape = {42, 6052};
    constants_info_[146].stride = {6052, 1};
    constants_info_[146].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[146].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.0.arch.submodules.0.submodules.0.shards.1.w";
    constants_info_[147].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_b";
    constants_info_[147].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[147].offset = 0;
    constants_info_[147].data_size = 84;
    constants_info_[147].from_folded = false;
    constants_info_[147].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[147].shape = {42};
    constants_info_[147].stride = {1};
    constants_info_[147].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[147].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.0.arch.submodules.0.submodules.0.shards.1.b";
    constants_info_[148].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale";
    constants_info_[148].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[148].offset = 0;
    constants_info_[148].data_size = 512;
    constants_info_[148].from_folded = false;
    constants_info_[148].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[148].shape = {256};
    constants_info_[148].stride = {1};
    constants_info_[148].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[148].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.0.arch.submodules.0.submodules.1.norm.submodules.0.scale";
    constants_info_[149].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias";
    constants_info_[149].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[149].offset = 0;
    constants_info_[149].data_size = 512;
    constants_info_[149].from_folded = false;
    constants_info_[149].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[149].shape = {256};
    constants_info_[149].stride = {1};
    constants_info_[149].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[149].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.0.arch.submodules.0.submodules.1.norm.submodules.0.bias";
    constants_info_[150].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w";
    constants_info_[150].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[150].offset = 0;
    constants_info_[150].data_size = 1549312;
    constants_info_[150].from_folded = false;
    constants_info_[150].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[150].shape = {3026, 256};
    constants_info_[150].stride = {256, 1};
    constants_info_[150].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[150].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.1.shards.0.w";
    constants_info_[151].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b";
    constants_info_[151].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[151].offset = 0;
    constants_info_[151].data_size = 6052;
    constants_info_[151].from_folded = false;
    constants_info_[151].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[151].shape = {3026};
    constants_info_[151].stride = {1};
    constants_info_[151].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[151].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.1.shards.0.b";
    constants_info_[152].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w";
    constants_info_[152].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[152].offset = 0;
    constants_info_[152].data_size = 1549312;
    constants_info_[152].from_folded = false;
    constants_info_[152].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[152].shape = {256, 3026};
    constants_info_[152].stride = {3026, 1};
    constants_info_[152].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[152].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.linear_archs.0.shards.0.w";
    constants_info_[153].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b";
    constants_info_[153].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[153].offset = 0;
    constants_info_[153].data_size = 512;
    constants_info_[153].from_folded = false;
    constants_info_[153].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[153].shape = {256};
    constants_info_[153].stride = {1};
    constants_info_[153].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[153].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.linear_archs.0.shards.0.b";
    constants_info_[154].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale";
    constants_info_[154].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[154].offset = 0;
    constants_info_[154].data_size = 6564;
    constants_info_[154].from_folded = false;
    constants_info_[154].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[154].shape = {3282};
    constants_info_[154].stride = {1};
    constants_info_[154].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[154].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.activations.0.norm.submodules.0.scale";
    constants_info_[155].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias";
    constants_info_[155].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[155].offset = 0;
    constants_info_[155].data_size = 6564;
    constants_info_[155].from_folded = false;
    constants_info_[155].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[155].shape = {3282};
    constants_info_[155].stride = {1};
    constants_info_[155].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[155].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.activations.0.norm.submodules.0.bias";
    constants_info_[156].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_w";
    constants_info_[156].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[156].offset = 0;
    constants_info_[156].data_size = 1260288;
    constants_info_[156].from_folded = false;
    constants_info_[156].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[156].shape = {192, 3282};
    constants_info_[156].stride = {3282, 1};
    constants_info_[156].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[156].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_0.submodules.0.shards.0.w";
    constants_info_[157].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_b";
    constants_info_[157].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[157].offset = 0;
    constants_info_[157].data_size = 384;
    constants_info_[157].from_folded = false;
    constants_info_[157].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[157].shape = {192};
    constants_info_[157].stride = {1};
    constants_info_[157].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[157].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_0.submodules.0.shards.0.b";
    constants_info_[158].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_w";
    constants_info_[158].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[158].offset = 0;
    constants_info_[158].data_size = 1260288;
    constants_info_[158].from_folded = false;
    constants_info_[158].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[158].shape = {192, 3282};
    constants_info_[158].stride = {3282, 1};
    constants_info_[158].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[158].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_1.submodules.0.shards.0.w";
    constants_info_[159].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_b";
    constants_info_[159].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[159].offset = 0;
    constants_info_[159].data_size = 384;
    constants_info_[159].from_folded = false;
    constants_info_[159].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[159].shape = {192};
    constants_info_[159].stride = {1};
    constants_info_[159].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[159].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_1.submodules.0.shards.0.b";
    constants_info_[160].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_w";
    constants_info_[160].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[160].offset = 0;
    constants_info_[160].data_size = 1260288;
    constants_info_[160].from_folded = false;
    constants_info_[160].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[160].shape = {192, 3282};
    constants_info_[160].stride = {3282, 1};
    constants_info_[160].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[160].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_2.submodules.0.shards.0.w";
    constants_info_[161].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_b";
    constants_info_[161].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[161].offset = 0;
    constants_info_[161].data_size = 384;
    constants_info_[161].from_folded = false;
    constants_info_[161].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[161].shape = {192};
    constants_info_[161].stride = {1};
    constants_info_[161].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[161].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_2.submodules.0.shards.0.b";
    constants_info_[162].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_w";
    constants_info_[162].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[162].offset = 0;
    constants_info_[162].data_size = 1260288;
    constants_info_[162].from_folded = false;
    constants_info_[162].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[162].shape = {192, 3282};
    constants_info_[162].stride = {3282, 1};
    constants_info_[162].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[162].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_3.submodules.0.shards.0.w";
    constants_info_[163].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_b";
    constants_info_[163].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[163].offset = 0;
    constants_info_[163].data_size = 384;
    constants_info_[163].from_folded = false;
    constants_info_[163].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[163].shape = {192};
    constants_info_[163].stride = {1};
    constants_info_[163].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[163].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_3.submodules.0.shards.0.b";
    constants_info_[164].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_w";
    constants_info_[164].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[164].offset = 0;
    constants_info_[164].data_size = 1260288;
    constants_info_[164].from_folded = false;
    constants_info_[164].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[164].shape = {192, 3282};
    constants_info_[164].stride = {3282, 1};
    constants_info_[164].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[164].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_4.submodules.0.shards.0.w";
    constants_info_[165].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_b";
    constants_info_[165].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[165].offset = 0;
    constants_info_[165].data_size = 384;
    constants_info_[165].from_folded = false;
    constants_info_[165].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[165].shape = {192};
    constants_info_[165].stride = {1};
    constants_info_[165].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[165].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_4.submodules.0.shards.0.b";
    constants_info_[166].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_w";
    constants_info_[166].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[166].offset = 0;
    constants_info_[166].data_size = 1260288;
    constants_info_[166].from_folded = false;
    constants_info_[166].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[166].shape = {192, 3282};
    constants_info_[166].stride = {3282, 1};
    constants_info_[166].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[166].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_5.submodules.0.shards.0.w";
    constants_info_[167].name = "submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_b";
    constants_info_[167].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[167].offset = 0;
    constants_info_[167].data_size = 384;
    constants_info_[167].from_folded = false;
    constants_info_[167].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[167].shape = {192};
    constants_info_[167].stride = {1};
    constants_info_[167].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[167].original_fqn = "submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs.0.submodules.dense_embedding_5.submodules.0.shards.0.b";
    constants_info_[168].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[168].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[168].offset = 0;
    constants_info_[168].data_size = 358400;
    constants_info_[168].from_folded = false;
    constants_info_[168].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[168].shape = {256, 700};
    constants_info_[168].stride = {700, 1};
    constants_info_[168].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[168].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[169].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[169].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[169].offset = 0;
    constants_info_[169].data_size = 512;
    constants_info_[169].from_folded = false;
    constants_info_[169].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[169].shape = {256};
    constants_info_[169].stride = {1};
    constants_info_[169].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[169].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[170].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale";
    constants_info_[170].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[170].offset = 0;
    constants_info_[170].data_size = 512;
    constants_info_[170].from_folded = false;
    constants_info_[170].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[170].shape = {256};
    constants_info_[170].stride = {1};
    constants_info_[170].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[170].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch.submodules.0.arch.submodules.0.submodules.1.norm.submodules.0.scale";
    constants_info_[171].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias";
    constants_info_[171].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[171].offset = 0;
    constants_info_[171].data_size = 512;
    constants_info_[171].from_folded = false;
    constants_info_[171].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[171].shape = {256};
    constants_info_[171].stride = {1};
    constants_info_[171].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[171].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch.submodules.0.arch.submodules.0.submodules.1.norm.submodules.0.bias";
    constants_info_[172].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w";
    constants_info_[172].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[172].offset = 0;
    constants_info_[172].data_size = 524288;
    constants_info_[172].from_folded = false;
    constants_info_[172].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[172].shape = {1024, 256};
    constants_info_[172].stride = {256, 1};
    constants_info_[172].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[172].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch.submodules.0.arch.submodules.1.submodules.0.shards.0.w";
    constants_info_[173].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b";
    constants_info_[173].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[173].offset = 0;
    constants_info_[173].data_size = 2048;
    constants_info_[173].from_folded = false;
    constants_info_[173].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[173].shape = {1024};
    constants_info_[173].stride = {1};
    constants_info_[173].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[173].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch.submodules.0.arch.submodules.1.submodules.0.shards.0.b";
    constants_info_[174].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale";
    constants_info_[174].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[174].offset = 0;
    constants_info_[174].data_size = 2048;
    constants_info_[174].from_folded = false;
    constants_info_[174].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[174].shape = {1024};
    constants_info_[174].stride = {1};
    constants_info_[174].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[174].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch.submodules.0.arch.submodules.1.submodules.1.norm.submodules.0.scale";
    constants_info_[175].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias";
    constants_info_[175].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[175].offset = 0;
    constants_info_[175].data_size = 2048;
    constants_info_[175].from_folded = false;
    constants_info_[175].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[175].shape = {1024};
    constants_info_[175].stride = {1};
    constants_info_[175].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[175].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch.submodules.0.arch.submodules.1.submodules.1.norm.submodules.0.bias";
    constants_info_[176].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_w";
    constants_info_[176].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[176].offset = 0;
    constants_info_[176].data_size = 358400;
    constants_info_[176].from_folded = false;
    constants_info_[176].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[176].shape = {256, 700};
    constants_info_[176].stride = {700, 1};
    constants_info_[176].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[176].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch_to_dot.submodules.0.arch.submodules.0.submodules.0.shards.0.w";
    constants_info_[177].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[177].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[177].offset = 0;
    constants_info_[177].data_size = 512;
    constants_info_[177].from_folded = false;
    constants_info_[177].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[177].shape = {256};
    constants_info_[177].stride = {1};
    constants_info_[177].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[177].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch_to_dot.submodules.0.arch.submodules.0.submodules.0.shards.0.b";
    constants_info_[178].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w";
    constants_info_[178].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[178].offset = 0;
    constants_info_[178].data_size = 491520;
    constants_info_[178].from_folded = false;
    constants_info_[178].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[178].shape = {960, 256};
    constants_info_[178].stride = {256, 1};
    constants_info_[178].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[178].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch_to_dot.submodules.0.arch.submodules.1.submodules.0.shards.0.w";
    constants_info_[179].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b";
    constants_info_[179].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[179].offset = 0;
    constants_info_[179].data_size = 1920;
    constants_info_[179].from_folded = false;
    constants_info_[179].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[179].shape = {960};
    constants_info_[179].stride = {1};
    constants_info_[179].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[179].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch_to_dot.submodules.0.arch.submodules.1.submodules.0.shards.0.b";
    constants_info_[180].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w";
    constants_info_[180].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[180].offset = 0;
    constants_info_[180].data_size = 2949120;
    constants_info_[180].from_folded = false;
    constants_info_[180].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[180].shape = {1536, 960};
    constants_info_[180].stride = {960, 1};
    constants_info_[180].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[180].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch_to_dot.submodules.1.linear_arch.shards.0.w";
    constants_info_[181].name = "submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b";
    constants_info_[181].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[181].offset = 0;
    constants_info_[181].data_size = 3072;
    constants_info_[181].from_folded = false;
    constants_info_[181].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[181].shape = {1536};
    constants_info_[181].stride = {1};
    constants_info_[181].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[181].original_fqn = "submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list.0.specialized_arch_to_dot.submodules.1.linear_arch.shards.0.b";
    constants_info_[182].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb";
    constants_info_[182].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[182].offset = 0;
    constants_info_[182].data_size = 25600;
    constants_info_[182].from_folded = false;
    constants_info_[182].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[182].shape = {1, 200, 64};
    constants_info_[182].stride = {12800, 64, 1};
    constants_info_[182].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[182].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.pos_emb";
    constants_info_[183].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb";
    constants_info_[183].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[183].offset = 0;
    constants_info_[183].data_size = 4096;
    constants_info_[183].from_folded = false;
    constants_info_[183].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[183].shape = {1, 32, 64};
    constants_info_[183].stride = {2048, 64, 1};
    constants_info_[183].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[183].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.seed_emb";
    constants_info_[184].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight";
    constants_info_[184].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[184].offset = 0;
    constants_info_[184].data_size = 128;
    constants_info_[184].from_folded = false;
    constants_info_[184].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[184].shape = {64};
    constants_info_[184].stride = {1};
    constants_info_[184].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[184].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_y.0.weight";
    constants_info_[185].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias";
    constants_info_[185].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[185].offset = 0;
    constants_info_[185].data_size = 128;
    constants_info_[185].from_folded = false;
    constants_info_[185].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[185].shape = {64};
    constants_info_[185].stride = {1};
    constants_info_[185].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[185].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_y.0.bias";
    constants_info_[186].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight";
    constants_info_[186].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[186].offset = 0;
    constants_info_[186].data_size = 8192;
    constants_info_[186].from_folded = false;
    constants_info_[186].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[186].shape = {64, 64};
    constants_info_[186].stride = {64, 1};
    constants_info_[186].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[186].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.attns.0.k_proj.weight";
    constants_info_[187].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight";
    constants_info_[187].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[187].offset = 0;
    constants_info_[187].data_size = 8192;
    constants_info_[187].from_folded = false;
    constants_info_[187].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[187].shape = {64, 64};
    constants_info_[187].stride = {64, 1};
    constants_info_[187].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[187].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.attns.0.q_proj.weight";
    constants_info_[188].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias";
    constants_info_[188].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[188].offset = 0;
    constants_info_[188].data_size = 128;
    constants_info_[188].from_folded = false;
    constants_info_[188].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[188].shape = {64};
    constants_info_[188].stride = {1};
    constants_info_[188].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[188].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.attns.0.q_proj.bias";
    constants_info_[189].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight";
    constants_info_[189].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[189].offset = 0;
    constants_info_[189].data_size = 128;
    constants_info_[189].from_folded = false;
    constants_info_[189].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[189].shape = {64};
    constants_info_[189].stride = {1};
    constants_info_[189].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[189].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_x.0.weight";
    constants_info_[190].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias";
    constants_info_[190].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[190].offset = 0;
    constants_info_[190].data_size = 128;
    constants_info_[190].from_folded = false;
    constants_info_[190].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[190].shape = {64};
    constants_info_[190].stride = {1};
    constants_info_[190].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[190].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_x.0.bias";
    constants_info_[191].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight";
    constants_info_[191].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[191].offset = 0;
    constants_info_[191].data_size = 128;
    constants_info_[191].from_folded = false;
    constants_info_[191].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[191].shape = {64};
    constants_info_[191].stride = {1};
    constants_info_[191].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[191].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_ffn.0.weight";
    constants_info_[192].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias";
    constants_info_[192].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[192].offset = 0;
    constants_info_[192].data_size = 128;
    constants_info_[192].from_folded = false;
    constants_info_[192].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[192].shape = {64};
    constants_info_[192].stride = {1};
    constants_info_[192].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[192].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_ffn.0.bias";
    constants_info_[193].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_weight";
    constants_info_[193].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[193].offset = 0;
    constants_info_[193].data_size = 16384;
    constants_info_[193].from_folded = false;
    constants_info_[193].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[193].shape = {128, 64};
    constants_info_[193].stride = {64, 1};
    constants_info_[193].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[193].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.mlps.0.0.weight";
    constants_info_[194].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias";
    constants_info_[194].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[194].offset = 0;
    constants_info_[194].data_size = 256;
    constants_info_[194].from_folded = false;
    constants_info_[194].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[194].shape = {128};
    constants_info_[194].stride = {1};
    constants_info_[194].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[194].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.mlps.0.0.bias";
    constants_info_[195].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_weight";
    constants_info_[195].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[195].offset = 0;
    constants_info_[195].data_size = 16384;
    constants_info_[195].from_folded = false;
    constants_info_[195].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[195].shape = {64, 128};
    constants_info_[195].stride = {128, 1};
    constants_info_[195].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[195].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.mlps.0.2.weight";
    constants_info_[196].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias";
    constants_info_[196].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[196].offset = 0;
    constants_info_[196].data_size = 128;
    constants_info_[196].from_folded = false;
    constants_info_[196].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[196].shape = {64};
    constants_info_[196].stride = {1};
    constants_info_[196].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[196].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.mlps.0.2.bias";
    constants_info_[197].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb";
    constants_info_[197].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[197].offset = 0;
    constants_info_[197].data_size = 25600;
    constants_info_[197].from_folded = false;
    constants_info_[197].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[197].shape = {1, 200, 64};
    constants_info_[197].stride = {12800, 64, 1};
    constants_info_[197].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[197].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.pos_emb";
    constants_info_[198].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb";
    constants_info_[198].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[198].offset = 0;
    constants_info_[198].data_size = 4096;
    constants_info_[198].from_folded = false;
    constants_info_[198].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[198].shape = {1, 32, 64};
    constants_info_[198].stride = {2048, 64, 1};
    constants_info_[198].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[198].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.seed_emb";
    constants_info_[199].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight";
    constants_info_[199].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[199].offset = 0;
    constants_info_[199].data_size = 128;
    constants_info_[199].from_folded = false;
    constants_info_[199].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[199].shape = {64};
    constants_info_[199].stride = {1};
    constants_info_[199].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[199].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_y.0.weight";
    constants_info_[200].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias";
    constants_info_[200].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[200].offset = 0;
    constants_info_[200].data_size = 128;
    constants_info_[200].from_folded = false;
    constants_info_[200].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[200].shape = {64};
    constants_info_[200].stride = {1};
    constants_info_[200].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[200].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_y.0.bias";
    constants_info_[201].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight";
    constants_info_[201].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[201].offset = 0;
    constants_info_[201].data_size = 8192;
    constants_info_[201].from_folded = false;
    constants_info_[201].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[201].shape = {64, 64};
    constants_info_[201].stride = {64, 1};
    constants_info_[201].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[201].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.attns.0.k_proj.weight";
    constants_info_[202].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight";
    constants_info_[202].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[202].offset = 0;
    constants_info_[202].data_size = 8192;
    constants_info_[202].from_folded = false;
    constants_info_[202].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[202].shape = {64, 64};
    constants_info_[202].stride = {64, 1};
    constants_info_[202].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[202].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.attns.0.q_proj.weight";
    constants_info_[203].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias";
    constants_info_[203].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[203].offset = 0;
    constants_info_[203].data_size = 128;
    constants_info_[203].from_folded = false;
    constants_info_[203].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[203].shape = {64};
    constants_info_[203].stride = {1};
    constants_info_[203].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[203].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.attns.0.q_proj.bias";
    constants_info_[204].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight";
    constants_info_[204].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[204].offset = 0;
    constants_info_[204].data_size = 128;
    constants_info_[204].from_folded = false;
    constants_info_[204].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[204].shape = {64};
    constants_info_[204].stride = {1};
    constants_info_[204].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[204].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_x.0.weight";
    constants_info_[205].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias";
    constants_info_[205].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[205].offset = 0;
    constants_info_[205].data_size = 128;
    constants_info_[205].from_folded = false;
    constants_info_[205].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[205].shape = {64};
    constants_info_[205].stride = {1};
    constants_info_[205].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[205].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_x.0.bias";
    constants_info_[206].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight";
    constants_info_[206].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[206].offset = 0;
    constants_info_[206].data_size = 128;
    constants_info_[206].from_folded = false;
    constants_info_[206].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[206].shape = {64};
    constants_info_[206].stride = {1};
    constants_info_[206].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[206].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_ffn.0.weight";
    constants_info_[207].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias";
    constants_info_[207].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[207].offset = 0;
    constants_info_[207].data_size = 128;
    constants_info_[207].from_folded = false;
    constants_info_[207].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[207].shape = {64};
    constants_info_[207].stride = {1};
    constants_info_[207].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[207].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_ffn.0.bias";
    constants_info_[208].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_weight";
    constants_info_[208].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[208].offset = 0;
    constants_info_[208].data_size = 16384;
    constants_info_[208].from_folded = false;
    constants_info_[208].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[208].shape = {128, 64};
    constants_info_[208].stride = {64, 1};
    constants_info_[208].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[208].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.mlps.0.0.weight";
    constants_info_[209].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias";
    constants_info_[209].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[209].offset = 0;
    constants_info_[209].data_size = 256;
    constants_info_[209].from_folded = false;
    constants_info_[209].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[209].shape = {128};
    constants_info_[209].stride = {1};
    constants_info_[209].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[209].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.mlps.0.0.bias";
    constants_info_[210].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_weight";
    constants_info_[210].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[210].offset = 0;
    constants_info_[210].data_size = 16384;
    constants_info_[210].from_folded = false;
    constants_info_[210].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[210].shape = {64, 128};
    constants_info_[210].stride = {128, 1};
    constants_info_[210].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[210].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.mlps.0.2.weight";
    constants_info_[211].name = "submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias";
    constants_info_[211].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[211].offset = 0;
    constants_info_[211].data_size = 128;
    constants_info_[211].from_folded = false;
    constants_info_[211].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[211].shape = {64};
    constants_info_[211].stride = {1};
    constants_info_[211].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[211].original_fqn = "submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.mlps.0.2.bias";
    constants_info_[212].name = "submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias";
    constants_info_[212].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[212].offset = 0;
    constants_info_[212].data_size = 24576;
    constants_info_[212].from_folded = false;
    constants_info_[212].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[212].shape = {64, 1, 192};
    constants_info_[212].stride = {192, 192, 1};
    constants_info_[212].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[212].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_projection_arch.first_fused_mlp.0.mlp_net.0.bias";
    constants_info_[213].name = "submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight";
    constants_info_[213].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[213].offset = 0;
    constants_info_[213].data_size = 1572864;
    constants_info_[213].from_folded = false;
    constants_info_[213].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[213].shape = {64, 64, 192};
    constants_info_[213].stride = {12288, 192, 1};
    constants_info_[213].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[213].original_fqn = "submod_0.main_module.impl.impl.shared_arch.embedding_projection_arch.first_fused_mlp.0.mlp_net.0.weight";
    constants_info_[214].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w";
    constants_info_[214].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[214].offset = 0;
    constants_info_[214].data_size = 159384;
    constants_info_[214].from_folded = false;
    constants_info_[214].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[214].shape = {174, 458};
    constants_info_[214].stride = {458, 1};
    constants_info_[214].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[214].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._fused_lce_module._compression_w";
    constants_info_[215].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b";
    constants_info_[215].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[215].offset = 0;
    constants_info_[215].data_size = 348;
    constants_info_[215].from_folded = false;
    constants_info_[215].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[215].shape = {174, 1};
    constants_info_[215].stride = {1, 1};
    constants_info_[215].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[215].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._fused_lce_module._compression_b";
    constants_info_[216].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w";
    constants_info_[216].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[216].offset = 0;
    constants_info_[216].data_size = 384;
    constants_info_[216].from_folded = false;
    constants_info_[216].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[216].shape = {192};
    constants_info_[216].stride = {1};
    constants_info_[216].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[216].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._fused_lce_module._ln_lce._init_w";
    constants_info_[217].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b";
    constants_info_[217].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[217].offset = 0;
    constants_info_[217].data_size = 384;
    constants_info_[217].from_folded = false;
    constants_info_[217].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[217].shape = {192};
    constants_info_[217].stride = {1};
    constants_info_[217].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[217].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._fused_lce_module._ln_lce._init_b";
    constants_info_[218].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_weight";
    constants_info_[218].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[218].offset = 0;
    constants_info_[218].data_size = 7077888;
    constants_info_[218].from_folded = false;
    constants_info_[218].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[218].shape = {768, 4608};
    constants_info_[218].stride = {4608, 1};
    constants_info_[218].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[218].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.0.weight";
    constants_info_[219].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_bias";
    constants_info_[219].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[219].offset = 0;
    constants_info_[219].data_size = 1536;
    constants_info_[219].from_folded = false;
    constants_info_[219].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[219].shape = {768};
    constants_info_[219].stride = {1};
    constants_info_[219].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[219].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.0.bias";
    constants_info_[220].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[220].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[220].offset = 0;
    constants_info_[220].data_size = 1536;
    constants_info_[220].from_folded = false;
    constants_info_[220].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[220].shape = {768};
    constants_info_[220].stride = {1};
    constants_info_[220].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[220].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.1.norm.0.weight";
    constants_info_[221].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[221].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[221].offset = 0;
    constants_info_[221].data_size = 1536;
    constants_info_[221].from_folded = false;
    constants_info_[221].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[221].shape = {768};
    constants_info_[221].stride = {1};
    constants_info_[221].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[221].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.1.norm.0.bias";
    constants_info_[222].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[222].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[222].offset = 0;
    constants_info_[222].data_size = 1536;
    constants_info_[222].from_folded = false;
    constants_info_[222].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[222].shape = {768};
    constants_info_[222].stride = {1};
    constants_info_[222].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[222].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.2._init_w";
    constants_info_[223].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[223].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[223].offset = 0;
    constants_info_[223].data_size = 1536;
    constants_info_[223].from_folded = false;
    constants_info_[223].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[223].shape = {768};
    constants_info_[223].stride = {1};
    constants_info_[223].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[223].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.2._init_b";
    constants_info_[224].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_weight";
    constants_info_[224].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[224].offset = 0;
    constants_info_[224].data_size = 1179648;
    constants_info_[224].from_folded = false;
    constants_info_[224].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[224].shape = {768, 768};
    constants_info_[224].stride = {768, 1};
    constants_info_[224].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[224].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.3.weight";
    constants_info_[225].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[225].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[225].offset = 0;
    constants_info_[225].data_size = 1536;
    constants_info_[225].from_folded = false;
    constants_info_[225].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[225].shape = {768};
    constants_info_[225].stride = {1};
    constants_info_[225].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[225].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.3.bias";
    constants_info_[226].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[226].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[226].offset = 0;
    constants_info_[226].data_size = 1536;
    constants_info_[226].from_folded = false;
    constants_info_[226].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[226].shape = {768};
    constants_info_[226].stride = {1};
    constants_info_[226].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[226].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.4.norm.0.weight";
    constants_info_[227].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[227].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[227].offset = 0;
    constants_info_[227].data_size = 1536;
    constants_info_[227].from_folded = false;
    constants_info_[227].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[227].shape = {768};
    constants_info_[227].stride = {1};
    constants_info_[227].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[227].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.4.norm.0.bias";
    constants_info_[228].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[228].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[228].offset = 0;
    constants_info_[228].data_size = 1536;
    constants_info_[228].from_folded = false;
    constants_info_[228].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[228].shape = {768};
    constants_info_[228].stride = {1};
    constants_info_[228].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[228].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.5._init_w";
    constants_info_[229].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[229].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[229].offset = 0;
    constants_info_[229].data_size = 1536;
    constants_info_[229].from_folded = false;
    constants_info_[229].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[229].shape = {768};
    constants_info_[229].stride = {1};
    constants_info_[229].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[229].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_mlp.mlp_net.5._init_b";
    constants_info_[230].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_weight";
    constants_info_[230].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[230].offset = 0;
    constants_info_[230].data_size = 7077888;
    constants_info_[230].from_folded = false;
    constants_info_[230].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[230].shape = {768, 4608};
    constants_info_[230].stride = {4608, 1};
    constants_info_[230].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[230].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.0.weight";
    constants_info_[231].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_bias";
    constants_info_[231].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[231].offset = 0;
    constants_info_[231].data_size = 1536;
    constants_info_[231].from_folded = false;
    constants_info_[231].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[231].shape = {768};
    constants_info_[231].stride = {1};
    constants_info_[231].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[231].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.0.bias";
    constants_info_[232].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[232].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[232].offset = 0;
    constants_info_[232].data_size = 1536;
    constants_info_[232].from_folded = false;
    constants_info_[232].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[232].shape = {768};
    constants_info_[232].stride = {1};
    constants_info_[232].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[232].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.1.norm.0.weight";
    constants_info_[233].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[233].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[233].offset = 0;
    constants_info_[233].data_size = 1536;
    constants_info_[233].from_folded = false;
    constants_info_[233].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[233].shape = {768};
    constants_info_[233].stride = {1};
    constants_info_[233].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[233].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.1.norm.0.bias";
    constants_info_[234].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[234].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[234].offset = 0;
    constants_info_[234].data_size = 1536;
    constants_info_[234].from_folded = false;
    constants_info_[234].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[234].shape = {768};
    constants_info_[234].stride = {1};
    constants_info_[234].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[234].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.2._init_w";
    constants_info_[235].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[235].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[235].offset = 0;
    constants_info_[235].data_size = 1536;
    constants_info_[235].from_folded = false;
    constants_info_[235].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[235].shape = {768};
    constants_info_[235].stride = {1};
    constants_info_[235].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[235].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.2._init_b";
    constants_info_[236].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_weight";
    constants_info_[236].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[236].offset = 0;
    constants_info_[236].data_size = 1179648;
    constants_info_[236].from_folded = false;
    constants_info_[236].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[236].shape = {768, 768};
    constants_info_[236].stride = {768, 1};
    constants_info_[236].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[236].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.3.weight";
    constants_info_[237].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[237].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[237].offset = 0;
    constants_info_[237].data_size = 1536;
    constants_info_[237].from_folded = false;
    constants_info_[237].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[237].shape = {768};
    constants_info_[237].stride = {1};
    constants_info_[237].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[237].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.3.bias";
    constants_info_[238].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[238].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[238].offset = 0;
    constants_info_[238].data_size = 1536;
    constants_info_[238].from_folded = false;
    constants_info_[238].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[238].shape = {768};
    constants_info_[238].stride = {1};
    constants_info_[238].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[238].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.4.norm.0.weight";
    constants_info_[239].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[239].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[239].offset = 0;
    constants_info_[239].data_size = 1536;
    constants_info_[239].from_folded = false;
    constants_info_[239].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[239].shape = {768};
    constants_info_[239].stride = {1};
    constants_info_[239].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[239].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.4.norm.0.bias";
    constants_info_[240].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[240].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[240].offset = 0;
    constants_info_[240].data_size = 1536;
    constants_info_[240].from_folded = false;
    constants_info_[240].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[240].shape = {768};
    constants_info_[240].stride = {1};
    constants_info_[240].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[240].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.5._init_w";
    constants_info_[241].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[241].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[241].offset = 0;
    constants_info_[241].data_size = 1536;
    constants_info_[241].from_folded = false;
    constants_info_[241].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[241].shape = {768};
    constants_info_[241].stride = {1};
    constants_info_[241].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[241].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_mlp.mlp_net.5._init_b";
    constants_info_[242].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight";
    constants_info_[242].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[242].offset = 0;
    constants_info_[242].data_size = 33767424;
    constants_info_[242].from_folded = false;
    constants_info_[242].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[242].shape = {21984, 768};
    constants_info_[242].stride = {768, 1};
    constants_info_[242].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[242].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_post_match_mlp.mlp_net.0.weight";
    constants_info_[243].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[243].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[243].offset = 0;
    constants_info_[243].data_size = 43968;
    constants_info_[243].from_folded = false;
    constants_info_[243].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[243].shape = {21984};
    constants_info_[243].stride = {1};
    constants_info_[243].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[243].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_post_match_mlp.mlp_net.0.bias";
    constants_info_[244].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[244].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[244].offset = 0;
    constants_info_[244].data_size = 43968;
    constants_info_[244].from_folded = false;
    constants_info_[244].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[244].shape = {21984};
    constants_info_[244].stride = {1};
    constants_info_[244].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[244].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_post_match_mlp.mlp_net.1._init_w";
    constants_info_[245].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[245].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[245].offset = 0;
    constants_info_[245].data_size = 43968;
    constants_info_[245].from_folded = false;
    constants_info_[245].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[245].shape = {21984};
    constants_info_[245].stride = {1};
    constants_info_[245].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[245].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._weight_arch_post_match_mlp.mlp_net.1._init_b";
    constants_info_[246].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight";
    constants_info_[246].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[246].offset = 0;
    constants_info_[246].data_size = 14155776;
    constants_info_[246].from_folded = false;
    constants_info_[246].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[246].shape = {9216, 768};
    constants_info_[246].stride = {768, 1};
    constants_info_[246].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[246].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_post_match_mlp.mlp_net.0.weight";
    constants_info_[247].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[247].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[247].offset = 0;
    constants_info_[247].data_size = 18432;
    constants_info_[247].from_folded = false;
    constants_info_[247].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[247].shape = {9216};
    constants_info_[247].stride = {1};
    constants_info_[247].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[247].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_post_match_mlp.mlp_net.0.bias";
    constants_info_[248].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[248].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[248].offset = 0;
    constants_info_[248].data_size = 18432;
    constants_info_[248].from_folded = false;
    constants_info_[248].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[248].shape = {9216};
    constants_info_[248].stride = {1};
    constants_info_[248].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[248].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_post_match_mlp.mlp_net.1._init_w";
    constants_info_[249].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[249].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[249].offset = 0;
    constants_info_[249].data_size = 18432;
    constants_info_[249].from_folded = false;
    constants_info_[249].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[249].shape = {9216};
    constants_info_[249].stride = {1};
    constants_info_[249].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[249].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp._resnet_arch_post_match_mlp.mlp_net.1._init_b";
    constants_info_[250].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w";
    constants_info_[250].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[250].offset = 0;
    constants_info_[250].data_size = 96;
    constants_info_[250].from_folded = false;
    constants_info_[250].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[250].shape = {48};
    constants_info_[250].stride = {1};
    constants_info_[250].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[250].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp.compressed_tensor_ln._init_w";
    constants_info_[251].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b";
    constants_info_[251].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[251].offset = 0;
    constants_info_[251].data_size = 96;
    constants_info_[251].from_folded = false;
    constants_info_[251].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[251].shape = {48};
    constants_info_[251].stride = {1};
    constants_info_[251].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[251].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcpp.compressed_tensor_ln._init_b";
    constants_info_[252].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w";
    constants_info_[252].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[252].offset = 0;
    constants_info_[252].data_size = 43968;
    constants_info_[252].from_folded = false;
    constants_info_[252].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[252].shape = {21984};
    constants_info_[252].stride = {1};
    constants_info_[252].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[252].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcpp_ln._init_w";
    constants_info_[253].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b";
    constants_info_[253].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[253].offset = 0;
    constants_info_[253].data_size = 43968;
    constants_info_[253].from_folded = false;
    constants_info_[253].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[253].shape = {21984};
    constants_info_[253].stride = {1};
    constants_info_[253].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[253].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcpp_ln._init_b";
    constants_info_[254].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_weight";
    constants_info_[254].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[254].offset = 0;
    constants_info_[254].data_size = 90046464;
    constants_info_[254].from_folded = false;
    constants_info_[254].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[254].shape = {2048, 21984};
    constants_info_[254].stride = {21984, 1};
    constants_info_[254].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[254].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcpp_fc._mlps.0.mlp_net.0.weight";
    constants_info_[255].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[255].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[255].offset = 0;
    constants_info_[255].data_size = 4096;
    constants_info_[255].from_folded = false;
    constants_info_[255].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[255].shape = {2048};
    constants_info_[255].stride = {1};
    constants_info_[255].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[255].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcpp_fc._mlps.0.mlp_net.0.bias";
    constants_info_[256].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[256].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[256].offset = 0;
    constants_info_[256].data_size = 4096;
    constants_info_[256].from_folded = false;
    constants_info_[256].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[256].shape = {2048};
    constants_info_[256].stride = {1};
    constants_info_[256].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[256].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcpp_fc._mlps.0.mlp_net.1.norm.0.weight";
    constants_info_[257].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[257].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[257].offset = 0;
    constants_info_[257].data_size = 4096;
    constants_info_[257].from_folded = false;
    constants_info_[257].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[257].shape = {2048};
    constants_info_[257].stride = {1};
    constants_info_[257].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[257].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcpp_fc._mlps.0.mlp_net.1.norm.0.bias";
    constants_info_[258].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[258].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[258].offset = 0;
    constants_info_[258].data_size = 4096;
    constants_info_[258].from_folded = false;
    constants_info_[258].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[258].shape = {2048};
    constants_info_[258].stride = {1};
    constants_info_[258].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[258].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcpp_fc._mlps.0.mlp_net.2._init_w";
    constants_info_[259].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[259].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[259].offset = 0;
    constants_info_[259].data_size = 4096;
    constants_info_[259].from_folded = false;
    constants_info_[259].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[259].shape = {2048};
    constants_info_[259].stride = {1};
    constants_info_[259].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[259].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcpp_fc._mlps.0.mlp_net.2._init_b";
    constants_info_[260].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w";
    constants_info_[260].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[260].offset = 0;
    constants_info_[260].data_size = 12708;
    constants_info_[260].from_folded = false;
    constants_info_[260].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[260].shape = {6354};
    constants_info_[260].stride = {1};
    constants_info_[260].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[260].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._ln_on_dsi._init_w";
    constants_info_[261].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b";
    constants_info_[261].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[261].offset = 0;
    constants_info_[261].data_size = 12708;
    constants_info_[261].from_folded = false;
    constants_info_[261].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[261].shape = {6354};
    constants_info_[261].stride = {1};
    constants_info_[261].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[261].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._ln_on_dsi._init_b";
    constants_info_[262].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight";
    constants_info_[262].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[262].offset = 0;
    constants_info_[262].data_size = 4879872;
    constants_info_[262].from_folded = false;
    constants_info_[262].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[262].shape = {384, 6354};
    constants_info_[262].stride = {6354, 1};
    constants_info_[262].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[262].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcn._dcn_low_rank_mlps.0.mlp_net.0.weight";
    constants_info_[263].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[263].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[263].offset = 0;
    constants_info_[263].data_size = 768;
    constants_info_[263].from_folded = false;
    constants_info_[263].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[263].shape = {384};
    constants_info_[263].stride = {1};
    constants_info_[263].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[263].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcn._dcn_low_rank_mlps.0.mlp_net.0.bias";
    constants_info_[264].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[264].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[264].offset = 0;
    constants_info_[264].data_size = 768;
    constants_info_[264].from_folded = false;
    constants_info_[264].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[264].shape = {384};
    constants_info_[264].stride = {1};
    constants_info_[264].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[264].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcn._dcn_low_rank_mlps.0.mlp_net.1._init_w";
    constants_info_[265].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[265].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[265].offset = 0;
    constants_info_[265].data_size = 768;
    constants_info_[265].from_folded = false;
    constants_info_[265].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[265].shape = {384};
    constants_info_[265].stride = {1};
    constants_info_[265].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[265].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcn._dcn_low_rank_mlps.0.mlp_net.1._init_b";
    constants_info_[266].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_weight";
    constants_info_[266].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[266].offset = 0;
    constants_info_[266].data_size = 4879872;
    constants_info_[266].from_folded = false;
    constants_info_[266].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[266].shape = {6354, 384};
    constants_info_[266].stride = {384, 1};
    constants_info_[266].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[266].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcn._dcn_match_mlps.0.mlp_net.0.weight";
    constants_info_[267].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[267].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[267].offset = 0;
    constants_info_[267].data_size = 12708;
    constants_info_[267].from_folded = false;
    constants_info_[267].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[267].shape = {6354};
    constants_info_[267].stride = {1};
    constants_info_[267].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[267].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcn._dcn_match_mlps.0.mlp_net.0.bias";
    constants_info_[268].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[268].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[268].offset = 0;
    constants_info_[268].data_size = 12708;
    constants_info_[268].from_folded = false;
    constants_info_[268].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[268].shape = {6354};
    constants_info_[268].stride = {1};
    constants_info_[268].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[268].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcn._dcn_match_mlps.0.mlp_net.1._init_w";
    constants_info_[269].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[269].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[269].offset = 0;
    constants_info_[269].data_size = 12708;
    constants_info_[269].from_folded = false;
    constants_info_[269].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[269].shape = {6354};
    constants_info_[269].stride = {1};
    constants_info_[269].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[269].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._dcn._dcn_match_mlps.0.mlp_net.1._init_b";
    constants_info_[270].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w";
    constants_info_[270].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[270].offset = 0;
    constants_info_[270].data_size = 12708;
    constants_info_[270].from_folded = false;
    constants_info_[270].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[270].shape = {6354};
    constants_info_[270].stride = {1};
    constants_info_[270].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[270].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcn_ln._init_w";
    constants_info_[271].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b";
    constants_info_[271].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[271].offset = 0;
    constants_info_[271].data_size = 12708;
    constants_info_[271].from_folded = false;
    constants_info_[271].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[271].shape = {6354};
    constants_info_[271].stride = {1};
    constants_info_[271].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[271].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._post_dcn_ln._init_b";
    constants_info_[272].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_weight";
    constants_info_[272].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[272].offset = 0;
    constants_info_[272].data_size = 39038976;
    constants_info_[272].from_folded = false;
    constants_info_[272].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[272].shape = {3072, 6354};
    constants_info_[272].stride = {6354, 1};
    constants_info_[272].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[272].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.0.mlp_net.0.weight";
    constants_info_[273].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[273].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[273].offset = 0;
    constants_info_[273].data_size = 6144;
    constants_info_[273].from_folded = false;
    constants_info_[273].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[273].shape = {3072};
    constants_info_[273].stride = {1};
    constants_info_[273].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[273].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.0.mlp_net.0.bias";
    constants_info_[274].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[274].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[274].offset = 0;
    constants_info_[274].data_size = 6144;
    constants_info_[274].from_folded = false;
    constants_info_[274].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[274].shape = {3072};
    constants_info_[274].stride = {1};
    constants_info_[274].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[274].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.0.mlp_net.1.norm.0.weight";
    constants_info_[275].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[275].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[275].offset = 0;
    constants_info_[275].data_size = 6144;
    constants_info_[275].from_folded = false;
    constants_info_[275].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[275].shape = {3072};
    constants_info_[275].stride = {1};
    constants_info_[275].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[275].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.0.mlp_net.1.norm.0.bias";
    constants_info_[276].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[276].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[276].offset = 0;
    constants_info_[276].data_size = 6144;
    constants_info_[276].from_folded = false;
    constants_info_[276].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[276].shape = {3072};
    constants_info_[276].stride = {1};
    constants_info_[276].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[276].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.0.mlp_net.2._init_w";
    constants_info_[277].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[277].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[277].offset = 0;
    constants_info_[277].data_size = 6144;
    constants_info_[277].from_folded = false;
    constants_info_[277].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[277].shape = {3072};
    constants_info_[277].stride = {1};
    constants_info_[277].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[277].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.0.mlp_net.2._init_b";
    constants_info_[278].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_weight";
    constants_info_[278].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[278].offset = 0;
    constants_info_[278].data_size = 9437184;
    constants_info_[278].from_folded = false;
    constants_info_[278].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[278].shape = {1536, 3072};
    constants_info_[278].stride = {3072, 1};
    constants_info_[278].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[278].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.1.mlp_net.0.weight";
    constants_info_[279].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[279].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[279].offset = 0;
    constants_info_[279].data_size = 3072;
    constants_info_[279].from_folded = false;
    constants_info_[279].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[279].shape = {1536};
    constants_info_[279].stride = {1};
    constants_info_[279].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[279].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.1.mlp_net.0.bias";
    constants_info_[280].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[280].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[280].offset = 0;
    constants_info_[280].data_size = 3072;
    constants_info_[280].from_folded = false;
    constants_info_[280].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[280].shape = {1536};
    constants_info_[280].stride = {1};
    constants_info_[280].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[280].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.1.mlp_net.1.norm.0.weight";
    constants_info_[281].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[281].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[281].offset = 0;
    constants_info_[281].data_size = 3072;
    constants_info_[281].from_folded = false;
    constants_info_[281].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[281].shape = {1536};
    constants_info_[281].stride = {1};
    constants_info_[281].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[281].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.1.mlp_net.1.norm.0.bias";
    constants_info_[282].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[282].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[282].offset = 0;
    constants_info_[282].data_size = 3072;
    constants_info_[282].from_folded = false;
    constants_info_[282].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[282].shape = {1536};
    constants_info_[282].stride = {1};
    constants_info_[282].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[282].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.1.mlp_net.2._init_w";
    constants_info_[283].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[283].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[283].offset = 0;
    constants_info_[283].data_size = 3072;
    constants_info_[283].from_folded = false;
    constants_info_[283].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[283].shape = {1536};
    constants_info_[283].stride = {1};
    constants_info_[283].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[283].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.1.mlp_net.2._init_b";
    constants_info_[284].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_weight";
    constants_info_[284].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[284].offset = 0;
    constants_info_[284].data_size = 9437184;
    constants_info_[284].from_folded = false;
    constants_info_[284].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[284].shape = {3072, 1536};
    constants_info_[284].stride = {1536, 1};
    constants_info_[284].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[284].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.2.mlp_net.0.weight";
    constants_info_[285].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[285].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[285].offset = 0;
    constants_info_[285].data_size = 6144;
    constants_info_[285].from_folded = false;
    constants_info_[285].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[285].shape = {3072};
    constants_info_[285].stride = {1};
    constants_info_[285].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[285].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.2.mlp_net.0.bias";
    constants_info_[286].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[286].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[286].offset = 0;
    constants_info_[286].data_size = 6144;
    constants_info_[286].from_folded = false;
    constants_info_[286].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[286].shape = {3072};
    constants_info_[286].stride = {1};
    constants_info_[286].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[286].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.2.mlp_net.1._init_w";
    constants_info_[287].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[287].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[287].offset = 0;
    constants_info_[287].data_size = 6144;
    constants_info_[287].from_folded = false;
    constants_info_[287].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[287].shape = {3072};
    constants_info_[287].stride = {1};
    constants_info_[287].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[287].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.2.mlp_net.1._init_b";
    constants_info_[288].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_weight";
    constants_info_[288].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[288].offset = 0;
    constants_info_[288].data_size = 9437184;
    constants_info_[288].from_folded = false;
    constants_info_[288].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[288].shape = {1536, 3072};
    constants_info_[288].stride = {3072, 1};
    constants_info_[288].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[288].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.3.mlp_net.0.weight";
    constants_info_[289].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[289].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[289].offset = 0;
    constants_info_[289].data_size = 3072;
    constants_info_[289].from_folded = false;
    constants_info_[289].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[289].shape = {1536};
    constants_info_[289].stride = {1};
    constants_info_[289].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[289].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.3.mlp_net.0.bias";
    constants_info_[290].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[290].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[290].offset = 0;
    constants_info_[290].data_size = 3072;
    constants_info_[290].from_folded = false;
    constants_info_[290].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[290].shape = {1536};
    constants_info_[290].stride = {1};
    constants_info_[290].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[290].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.3.mlp_net.1.norm.0.weight";
    constants_info_[291].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[291].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[291].offset = 0;
    constants_info_[291].data_size = 3072;
    constants_info_[291].from_folded = false;
    constants_info_[291].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[291].shape = {1536};
    constants_info_[291].stride = {1};
    constants_info_[291].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[291].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.3.mlp_net.1.norm.0.bias";
    constants_info_[292].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[292].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[292].offset = 0;
    constants_info_[292].data_size = 3072;
    constants_info_[292].from_folded = false;
    constants_info_[292].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[292].shape = {1536};
    constants_info_[292].stride = {1};
    constants_info_[292].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[292].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.3.mlp_net.2._init_w";
    constants_info_[293].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[293].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[293].offset = 0;
    constants_info_[293].data_size = 3072;
    constants_info_[293].from_folded = false;
    constants_info_[293].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[293].shape = {1536};
    constants_info_[293].stride = {1};
    constants_info_[293].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[293].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.3.mlp_net.2._init_b";
    constants_info_[294].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_weight";
    constants_info_[294].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[294].offset = 0;
    constants_info_[294].data_size = 9437184;
    constants_info_[294].from_folded = false;
    constants_info_[294].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[294].shape = {3072, 1536};
    constants_info_[294].stride = {1536, 1};
    constants_info_[294].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[294].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.4.mlp_net.0.weight";
    constants_info_[295].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[295].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[295].offset = 0;
    constants_info_[295].data_size = 6144;
    constants_info_[295].from_folded = false;
    constants_info_[295].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[295].shape = {3072};
    constants_info_[295].stride = {1};
    constants_info_[295].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[295].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.4.mlp_net.0.bias";
    constants_info_[296].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[296].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[296].offset = 0;
    constants_info_[296].data_size = 6144;
    constants_info_[296].from_folded = false;
    constants_info_[296].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[296].shape = {3072};
    constants_info_[296].stride = {1};
    constants_info_[296].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[296].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.4.mlp_net.1._init_w";
    constants_info_[297].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[297].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[297].offset = 0;
    constants_info_[297].data_size = 6144;
    constants_info_[297].from_folded = false;
    constants_info_[297].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[297].shape = {3072};
    constants_info_[297].stride = {1};
    constants_info_[297].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[297].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._mlps.4.mlp_net.1._init_b";
    constants_info_[298].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[298].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[298].offset = 0;
    constants_info_[298].data_size = 6144;
    constants_info_[298].from_folded = false;
    constants_info_[298].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[298].shape = {3072};
    constants_info_[298].stride = {1};
    constants_info_[298].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[298].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._residual_activation.2.norm.0.weight";
    constants_info_[299].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[299].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[299].offset = 0;
    constants_info_[299].data_size = 6144;
    constants_info_[299].from_folded = false;
    constants_info_[299].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[299].shape = {3072};
    constants_info_[299].stride = {1};
    constants_info_[299].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[299].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._residual_activation.2.norm.0.bias";
    constants_info_[300].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[300].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[300].offset = 0;
    constants_info_[300].data_size = 6144;
    constants_info_[300].from_folded = false;
    constants_info_[300].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[300].shape = {3072};
    constants_info_[300].stride = {1};
    constants_info_[300].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[300].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._residual_activation.4.norm.0.weight";
    constants_info_[301].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[301].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[301].offset = 0;
    constants_info_[301].data_size = 6144;
    constants_info_[301].from_folded = false;
    constants_info_[301].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[301].shape = {3072};
    constants_info_[301].stride = {1};
    constants_info_[301].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[301].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._residual_mlp._residual_activation.4.norm.0.bias";
    constants_info_[302].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_weight";
    constants_info_[302].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[302].offset = 0;
    constants_info_[302].data_size = 56623104;
    constants_info_[302].from_folded = false;
    constants_info_[302].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[302].shape = {9216, 3072};
    constants_info_[302].stride = {3072, 1};
    constants_info_[302].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[302].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._snn_projection.mlp_net.0.weight";
    constants_info_[303].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias";
    constants_info_[303].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[303].offset = 0;
    constants_info_[303].data_size = 18432;
    constants_info_[303].from_folded = false;
    constants_info_[303].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[303].shape = {9216};
    constants_info_[303].stride = {1};
    constants_info_[303].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[303].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._snn_projection.mlp_net.0.bias";
    constants_info_[304].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w";
    constants_info_[304].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[304].offset = 0;
    constants_info_[304].data_size = 384;
    constants_info_[304].from_folded = false;
    constants_info_[304].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[304].shape = {192};
    constants_info_[304].stride = {1};
    constants_info_[304].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[304].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._ln_on_dhen_layer._init_w";
    constants_info_[305].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b";
    constants_info_[305].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[305].offset = 0;
    constants_info_[305].data_size = 384;
    constants_info_[305].from_folded = false;
    constants_info_[305].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[305].shape = {192};
    constants_info_[305].stride = {1};
    constants_info_[305].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[305].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.0._ln_on_dhen_layer._init_b";
    constants_info_[306].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w";
    constants_info_[306].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[306].offset = 0;
    constants_info_[306].data_size = 14688;
    constants_info_[306].from_folded = false;
    constants_info_[306].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[306].shape = {72, 102};
    constants_info_[306].stride = {102, 1};
    constants_info_[306].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[306].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._fused_lce_module._compression_w";
    constants_info_[307].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b";
    constants_info_[307].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[307].offset = 0;
    constants_info_[307].data_size = 144;
    constants_info_[307].from_folded = false;
    constants_info_[307].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[307].shape = {72, 1};
    constants_info_[307].stride = {1, 1};
    constants_info_[307].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[307].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._fused_lce_module._compression_b";
    constants_info_[308].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w";
    constants_info_[308].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[308].offset = 0;
    constants_info_[308].data_size = 384;
    constants_info_[308].from_folded = false;
    constants_info_[308].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[308].shape = {192};
    constants_info_[308].stride = {1};
    constants_info_[308].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[308].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._fused_lce_module._ln_lce._init_w";
    constants_info_[309].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b";
    constants_info_[309].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[309].offset = 0;
    constants_info_[309].data_size = 384;
    constants_info_[309].from_folded = false;
    constants_info_[309].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[309].shape = {192};
    constants_info_[309].stride = {1};
    constants_info_[309].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[309].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._fused_lce_module._ln_lce._init_b";
    constants_info_[310].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_weight";
    constants_info_[310].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[310].offset = 0;
    constants_info_[310].data_size = 7077888;
    constants_info_[310].from_folded = false;
    constants_info_[310].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[310].shape = {768, 4608};
    constants_info_[310].stride = {4608, 1};
    constants_info_[310].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[310].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.0.weight";
    constants_info_[311].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_bias";
    constants_info_[311].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[311].offset = 0;
    constants_info_[311].data_size = 1536;
    constants_info_[311].from_folded = false;
    constants_info_[311].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[311].shape = {768};
    constants_info_[311].stride = {1};
    constants_info_[311].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[311].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.0.bias";
    constants_info_[312].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[312].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[312].offset = 0;
    constants_info_[312].data_size = 1536;
    constants_info_[312].from_folded = false;
    constants_info_[312].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[312].shape = {768};
    constants_info_[312].stride = {1};
    constants_info_[312].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[312].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.1.norm.0.weight";
    constants_info_[313].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[313].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[313].offset = 0;
    constants_info_[313].data_size = 1536;
    constants_info_[313].from_folded = false;
    constants_info_[313].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[313].shape = {768};
    constants_info_[313].stride = {1};
    constants_info_[313].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[313].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.1.norm.0.bias";
    constants_info_[314].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[314].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[314].offset = 0;
    constants_info_[314].data_size = 1536;
    constants_info_[314].from_folded = false;
    constants_info_[314].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[314].shape = {768};
    constants_info_[314].stride = {1};
    constants_info_[314].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[314].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.2._init_w";
    constants_info_[315].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[315].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[315].offset = 0;
    constants_info_[315].data_size = 1536;
    constants_info_[315].from_folded = false;
    constants_info_[315].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[315].shape = {768};
    constants_info_[315].stride = {1};
    constants_info_[315].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[315].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.2._init_b";
    constants_info_[316].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_weight";
    constants_info_[316].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[316].offset = 0;
    constants_info_[316].data_size = 1179648;
    constants_info_[316].from_folded = false;
    constants_info_[316].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[316].shape = {768, 768};
    constants_info_[316].stride = {768, 1};
    constants_info_[316].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[316].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.3.weight";
    constants_info_[317].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[317].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[317].offset = 0;
    constants_info_[317].data_size = 1536;
    constants_info_[317].from_folded = false;
    constants_info_[317].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[317].shape = {768};
    constants_info_[317].stride = {1};
    constants_info_[317].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[317].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.3.bias";
    constants_info_[318].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[318].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[318].offset = 0;
    constants_info_[318].data_size = 1536;
    constants_info_[318].from_folded = false;
    constants_info_[318].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[318].shape = {768};
    constants_info_[318].stride = {1};
    constants_info_[318].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[318].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.4.norm.0.weight";
    constants_info_[319].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[319].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[319].offset = 0;
    constants_info_[319].data_size = 1536;
    constants_info_[319].from_folded = false;
    constants_info_[319].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[319].shape = {768};
    constants_info_[319].stride = {1};
    constants_info_[319].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[319].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.4.norm.0.bias";
    constants_info_[320].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[320].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[320].offset = 0;
    constants_info_[320].data_size = 1536;
    constants_info_[320].from_folded = false;
    constants_info_[320].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[320].shape = {768};
    constants_info_[320].stride = {1};
    constants_info_[320].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[320].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.5._init_w";
    constants_info_[321].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[321].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[321].offset = 0;
    constants_info_[321].data_size = 1536;
    constants_info_[321].from_folded = false;
    constants_info_[321].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[321].shape = {768};
    constants_info_[321].stride = {1};
    constants_info_[321].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[321].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_mlp.mlp_net.5._init_b";
    constants_info_[322].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_weight";
    constants_info_[322].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[322].offset = 0;
    constants_info_[322].data_size = 7077888;
    constants_info_[322].from_folded = false;
    constants_info_[322].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[322].shape = {768, 4608};
    constants_info_[322].stride = {4608, 1};
    constants_info_[322].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[322].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.0.weight";
    constants_info_[323].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_bias";
    constants_info_[323].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[323].offset = 0;
    constants_info_[323].data_size = 1536;
    constants_info_[323].from_folded = false;
    constants_info_[323].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[323].shape = {768};
    constants_info_[323].stride = {1};
    constants_info_[323].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[323].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.0.bias";
    constants_info_[324].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[324].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[324].offset = 0;
    constants_info_[324].data_size = 1536;
    constants_info_[324].from_folded = false;
    constants_info_[324].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[324].shape = {768};
    constants_info_[324].stride = {1};
    constants_info_[324].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[324].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.1.norm.0.weight";
    constants_info_[325].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[325].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[325].offset = 0;
    constants_info_[325].data_size = 1536;
    constants_info_[325].from_folded = false;
    constants_info_[325].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[325].shape = {768};
    constants_info_[325].stride = {1};
    constants_info_[325].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[325].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.1.norm.0.bias";
    constants_info_[326].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[326].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[326].offset = 0;
    constants_info_[326].data_size = 1536;
    constants_info_[326].from_folded = false;
    constants_info_[326].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[326].shape = {768};
    constants_info_[326].stride = {1};
    constants_info_[326].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[326].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.2._init_w";
    constants_info_[327].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[327].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[327].offset = 0;
    constants_info_[327].data_size = 1536;
    constants_info_[327].from_folded = false;
    constants_info_[327].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[327].shape = {768};
    constants_info_[327].stride = {1};
    constants_info_[327].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[327].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.2._init_b";
    constants_info_[328].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_weight";
    constants_info_[328].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[328].offset = 0;
    constants_info_[328].data_size = 1179648;
    constants_info_[328].from_folded = false;
    constants_info_[328].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[328].shape = {768, 768};
    constants_info_[328].stride = {768, 1};
    constants_info_[328].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[328].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.3.weight";
    constants_info_[329].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[329].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[329].offset = 0;
    constants_info_[329].data_size = 1536;
    constants_info_[329].from_folded = false;
    constants_info_[329].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[329].shape = {768};
    constants_info_[329].stride = {1};
    constants_info_[329].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[329].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.3.bias";
    constants_info_[330].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[330].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[330].offset = 0;
    constants_info_[330].data_size = 1536;
    constants_info_[330].from_folded = false;
    constants_info_[330].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[330].shape = {768};
    constants_info_[330].stride = {1};
    constants_info_[330].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[330].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.4.norm.0.weight";
    constants_info_[331].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[331].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[331].offset = 0;
    constants_info_[331].data_size = 1536;
    constants_info_[331].from_folded = false;
    constants_info_[331].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[331].shape = {768};
    constants_info_[331].stride = {1};
    constants_info_[331].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[331].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.4.norm.0.bias";
    constants_info_[332].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[332].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[332].offset = 0;
    constants_info_[332].data_size = 1536;
    constants_info_[332].from_folded = false;
    constants_info_[332].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[332].shape = {768};
    constants_info_[332].stride = {1};
    constants_info_[332].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[332].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.5._init_w";
    constants_info_[333].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[333].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[333].offset = 0;
    constants_info_[333].data_size = 1536;
    constants_info_[333].from_folded = false;
    constants_info_[333].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[333].shape = {768};
    constants_info_[333].stride = {1};
    constants_info_[333].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[333].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_mlp.mlp_net.5._init_b";
    constants_info_[334].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight";
    constants_info_[334].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[334].offset = 0;
    constants_info_[334].data_size = 7520256;
    constants_info_[334].from_folded = false;
    constants_info_[334].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[334].shape = {4896, 768};
    constants_info_[334].stride = {768, 1};
    constants_info_[334].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[334].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_post_match_mlp.mlp_net.0.weight";
    constants_info_[335].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[335].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[335].offset = 0;
    constants_info_[335].data_size = 9792;
    constants_info_[335].from_folded = false;
    constants_info_[335].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[335].shape = {4896};
    constants_info_[335].stride = {1};
    constants_info_[335].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[335].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_post_match_mlp.mlp_net.0.bias";
    constants_info_[336].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[336].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[336].offset = 0;
    constants_info_[336].data_size = 9792;
    constants_info_[336].from_folded = false;
    constants_info_[336].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[336].shape = {4896};
    constants_info_[336].stride = {1};
    constants_info_[336].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[336].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_post_match_mlp.mlp_net.1._init_w";
    constants_info_[337].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[337].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[337].offset = 0;
    constants_info_[337].data_size = 9792;
    constants_info_[337].from_folded = false;
    constants_info_[337].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[337].shape = {4896};
    constants_info_[337].stride = {1};
    constants_info_[337].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[337].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._weight_arch_post_match_mlp.mlp_net.1._init_b";
    constants_info_[338].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight";
    constants_info_[338].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[338].offset = 0;
    constants_info_[338].data_size = 14155776;
    constants_info_[338].from_folded = false;
    constants_info_[338].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[338].shape = {9216, 768};
    constants_info_[338].stride = {768, 1};
    constants_info_[338].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[338].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_post_match_mlp.mlp_net.0.weight";
    constants_info_[339].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[339].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[339].offset = 0;
    constants_info_[339].data_size = 18432;
    constants_info_[339].from_folded = false;
    constants_info_[339].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[339].shape = {9216};
    constants_info_[339].stride = {1};
    constants_info_[339].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[339].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_post_match_mlp.mlp_net.0.bias";
    constants_info_[340].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[340].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[340].offset = 0;
    constants_info_[340].data_size = 18432;
    constants_info_[340].from_folded = false;
    constants_info_[340].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[340].shape = {9216};
    constants_info_[340].stride = {1};
    constants_info_[340].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[340].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_post_match_mlp.mlp_net.1._init_w";
    constants_info_[341].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[341].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[341].offset = 0;
    constants_info_[341].data_size = 18432;
    constants_info_[341].from_folded = false;
    constants_info_[341].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[341].shape = {9216};
    constants_info_[341].stride = {1};
    constants_info_[341].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[341].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp._resnet_arch_post_match_mlp.mlp_net.1._init_b";
    constants_info_[342].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w";
    constants_info_[342].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[342].offset = 0;
    constants_info_[342].data_size = 96;
    constants_info_[342].from_folded = false;
    constants_info_[342].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[342].shape = {48};
    constants_info_[342].stride = {1};
    constants_info_[342].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[342].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp.compressed_tensor_ln._init_w";
    constants_info_[343].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b";
    constants_info_[343].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[343].offset = 0;
    constants_info_[343].data_size = 96;
    constants_info_[343].from_folded = false;
    constants_info_[343].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[343].shape = {48};
    constants_info_[343].stride = {1};
    constants_info_[343].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[343].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcpp.compressed_tensor_ln._init_b";
    constants_info_[344].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w";
    constants_info_[344].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[344].offset = 0;
    constants_info_[344].data_size = 9792;
    constants_info_[344].from_folded = false;
    constants_info_[344].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[344].shape = {4896};
    constants_info_[344].stride = {1};
    constants_info_[344].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[344].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcpp_ln._init_w";
    constants_info_[345].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b";
    constants_info_[345].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[345].offset = 0;
    constants_info_[345].data_size = 9792;
    constants_info_[345].from_folded = false;
    constants_info_[345].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[345].shape = {4896};
    constants_info_[345].stride = {1};
    constants_info_[345].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[345].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcpp_ln._init_b";
    constants_info_[346].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_weight";
    constants_info_[346].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[346].offset = 0;
    constants_info_[346].data_size = 20054016;
    constants_info_[346].from_folded = false;
    constants_info_[346].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[346].shape = {2048, 4896};
    constants_info_[346].stride = {4896, 1};
    constants_info_[346].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[346].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcpp_fc._mlps.0.mlp_net.0.weight";
    constants_info_[347].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[347].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[347].offset = 0;
    constants_info_[347].data_size = 4096;
    constants_info_[347].from_folded = false;
    constants_info_[347].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[347].shape = {2048};
    constants_info_[347].stride = {1};
    constants_info_[347].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[347].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcpp_fc._mlps.0.mlp_net.0.bias";
    constants_info_[348].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[348].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[348].offset = 0;
    constants_info_[348].data_size = 4096;
    constants_info_[348].from_folded = false;
    constants_info_[348].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[348].shape = {2048};
    constants_info_[348].stride = {1};
    constants_info_[348].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[348].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcpp_fc._mlps.0.mlp_net.1.norm.0.weight";
    constants_info_[349].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[349].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[349].offset = 0;
    constants_info_[349].data_size = 4096;
    constants_info_[349].from_folded = false;
    constants_info_[349].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[349].shape = {2048};
    constants_info_[349].stride = {1};
    constants_info_[349].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[349].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcpp_fc._mlps.0.mlp_net.1.norm.0.bias";
    constants_info_[350].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[350].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[350].offset = 0;
    constants_info_[350].data_size = 4096;
    constants_info_[350].from_folded = false;
    constants_info_[350].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[350].shape = {2048};
    constants_info_[350].stride = {1};
    constants_info_[350].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[350].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcpp_fc._mlps.0.mlp_net.2._init_w";
    constants_info_[351].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[351].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[351].offset = 0;
    constants_info_[351].data_size = 4096;
    constants_info_[351].from_folded = false;
    constants_info_[351].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[351].shape = {2048};
    constants_info_[351].stride = {1};
    constants_info_[351].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[351].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcpp_fc._mlps.0.mlp_net.2._init_b";
    constants_info_[352].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w";
    constants_info_[352].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[352].offset = 0;
    constants_info_[352].data_size = 12708;
    constants_info_[352].from_folded = false;
    constants_info_[352].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[352].shape = {6354};
    constants_info_[352].stride = {1};
    constants_info_[352].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[352].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._ln_on_dsi._init_w";
    constants_info_[353].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b";
    constants_info_[353].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[353].offset = 0;
    constants_info_[353].data_size = 12708;
    constants_info_[353].from_folded = false;
    constants_info_[353].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[353].shape = {6354};
    constants_info_[353].stride = {1};
    constants_info_[353].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[353].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._ln_on_dsi._init_b";
    constants_info_[354].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight";
    constants_info_[354].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[354].offset = 0;
    constants_info_[354].data_size = 4879872;
    constants_info_[354].from_folded = false;
    constants_info_[354].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[354].shape = {384, 6354};
    constants_info_[354].stride = {6354, 1};
    constants_info_[354].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[354].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcn._dcn_low_rank_mlps.0.mlp_net.0.weight";
    constants_info_[355].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[355].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[355].offset = 0;
    constants_info_[355].data_size = 768;
    constants_info_[355].from_folded = false;
    constants_info_[355].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[355].shape = {384};
    constants_info_[355].stride = {1};
    constants_info_[355].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[355].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcn._dcn_low_rank_mlps.0.mlp_net.0.bias";
    constants_info_[356].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[356].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[356].offset = 0;
    constants_info_[356].data_size = 768;
    constants_info_[356].from_folded = false;
    constants_info_[356].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[356].shape = {384};
    constants_info_[356].stride = {1};
    constants_info_[356].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[356].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcn._dcn_low_rank_mlps.0.mlp_net.1._init_w";
    constants_info_[357].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[357].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[357].offset = 0;
    constants_info_[357].data_size = 768;
    constants_info_[357].from_folded = false;
    constants_info_[357].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[357].shape = {384};
    constants_info_[357].stride = {1};
    constants_info_[357].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[357].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcn._dcn_low_rank_mlps.0.mlp_net.1._init_b";
    constants_info_[358].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_weight";
    constants_info_[358].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[358].offset = 0;
    constants_info_[358].data_size = 4879872;
    constants_info_[358].from_folded = false;
    constants_info_[358].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[358].shape = {6354, 384};
    constants_info_[358].stride = {384, 1};
    constants_info_[358].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[358].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcn._dcn_match_mlps.0.mlp_net.0.weight";
    constants_info_[359].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[359].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[359].offset = 0;
    constants_info_[359].data_size = 12708;
    constants_info_[359].from_folded = false;
    constants_info_[359].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[359].shape = {6354};
    constants_info_[359].stride = {1};
    constants_info_[359].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[359].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcn._dcn_match_mlps.0.mlp_net.0.bias";
    constants_info_[360].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[360].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[360].offset = 0;
    constants_info_[360].data_size = 12708;
    constants_info_[360].from_folded = false;
    constants_info_[360].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[360].shape = {6354};
    constants_info_[360].stride = {1};
    constants_info_[360].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[360].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcn._dcn_match_mlps.0.mlp_net.1._init_w";
    constants_info_[361].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[361].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[361].offset = 0;
    constants_info_[361].data_size = 12708;
    constants_info_[361].from_folded = false;
    constants_info_[361].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[361].shape = {6354};
    constants_info_[361].stride = {1};
    constants_info_[361].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[361].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._dcn._dcn_match_mlps.0.mlp_net.1._init_b";
    constants_info_[362].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w";
    constants_info_[362].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[362].offset = 0;
    constants_info_[362].data_size = 12708;
    constants_info_[362].from_folded = false;
    constants_info_[362].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[362].shape = {6354};
    constants_info_[362].stride = {1};
    constants_info_[362].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[362].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcn_ln._init_w";
    constants_info_[363].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b";
    constants_info_[363].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[363].offset = 0;
    constants_info_[363].data_size = 12708;
    constants_info_[363].from_folded = false;
    constants_info_[363].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[363].shape = {6354};
    constants_info_[363].stride = {1};
    constants_info_[363].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[363].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._post_dcn_ln._init_b";
    constants_info_[364].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_weight";
    constants_info_[364].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[364].offset = 0;
    constants_info_[364].data_size = 39038976;
    constants_info_[364].from_folded = false;
    constants_info_[364].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[364].shape = {3072, 6354};
    constants_info_[364].stride = {6354, 1};
    constants_info_[364].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[364].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.0.mlp_net.0.weight";
    constants_info_[365].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[365].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[365].offset = 0;
    constants_info_[365].data_size = 6144;
    constants_info_[365].from_folded = false;
    constants_info_[365].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[365].shape = {3072};
    constants_info_[365].stride = {1};
    constants_info_[365].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[365].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.0.mlp_net.0.bias";
    constants_info_[366].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[366].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[366].offset = 0;
    constants_info_[366].data_size = 6144;
    constants_info_[366].from_folded = false;
    constants_info_[366].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[366].shape = {3072};
    constants_info_[366].stride = {1};
    constants_info_[366].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[366].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.0.mlp_net.1.norm.0.weight";
    constants_info_[367].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[367].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[367].offset = 0;
    constants_info_[367].data_size = 6144;
    constants_info_[367].from_folded = false;
    constants_info_[367].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[367].shape = {3072};
    constants_info_[367].stride = {1};
    constants_info_[367].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[367].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.0.mlp_net.1.norm.0.bias";
    constants_info_[368].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[368].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[368].offset = 0;
    constants_info_[368].data_size = 6144;
    constants_info_[368].from_folded = false;
    constants_info_[368].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[368].shape = {3072};
    constants_info_[368].stride = {1};
    constants_info_[368].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[368].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.0.mlp_net.2._init_w";
    constants_info_[369].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[369].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[369].offset = 0;
    constants_info_[369].data_size = 6144;
    constants_info_[369].from_folded = false;
    constants_info_[369].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[369].shape = {3072};
    constants_info_[369].stride = {1};
    constants_info_[369].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[369].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.0.mlp_net.2._init_b";
    constants_info_[370].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_weight";
    constants_info_[370].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[370].offset = 0;
    constants_info_[370].data_size = 9437184;
    constants_info_[370].from_folded = false;
    constants_info_[370].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[370].shape = {1536, 3072};
    constants_info_[370].stride = {3072, 1};
    constants_info_[370].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[370].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.1.mlp_net.0.weight";
    constants_info_[371].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[371].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[371].offset = 0;
    constants_info_[371].data_size = 3072;
    constants_info_[371].from_folded = false;
    constants_info_[371].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[371].shape = {1536};
    constants_info_[371].stride = {1};
    constants_info_[371].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[371].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.1.mlp_net.0.bias";
    constants_info_[372].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[372].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[372].offset = 0;
    constants_info_[372].data_size = 3072;
    constants_info_[372].from_folded = false;
    constants_info_[372].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[372].shape = {1536};
    constants_info_[372].stride = {1};
    constants_info_[372].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[372].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.1.mlp_net.1.norm.0.weight";
    constants_info_[373].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[373].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[373].offset = 0;
    constants_info_[373].data_size = 3072;
    constants_info_[373].from_folded = false;
    constants_info_[373].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[373].shape = {1536};
    constants_info_[373].stride = {1};
    constants_info_[373].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[373].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.1.mlp_net.1.norm.0.bias";
    constants_info_[374].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[374].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[374].offset = 0;
    constants_info_[374].data_size = 3072;
    constants_info_[374].from_folded = false;
    constants_info_[374].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[374].shape = {1536};
    constants_info_[374].stride = {1};
    constants_info_[374].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[374].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.1.mlp_net.2._init_w";
    constants_info_[375].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[375].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[375].offset = 0;
    constants_info_[375].data_size = 3072;
    constants_info_[375].from_folded = false;
    constants_info_[375].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[375].shape = {1536};
    constants_info_[375].stride = {1};
    constants_info_[375].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[375].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.1.mlp_net.2._init_b";
    constants_info_[376].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_weight";
    constants_info_[376].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[376].offset = 0;
    constants_info_[376].data_size = 9437184;
    constants_info_[376].from_folded = false;
    constants_info_[376].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[376].shape = {3072, 1536};
    constants_info_[376].stride = {1536, 1};
    constants_info_[376].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[376].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.2.mlp_net.0.weight";
    constants_info_[377].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[377].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[377].offset = 0;
    constants_info_[377].data_size = 6144;
    constants_info_[377].from_folded = false;
    constants_info_[377].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[377].shape = {3072};
    constants_info_[377].stride = {1};
    constants_info_[377].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[377].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.2.mlp_net.0.bias";
    constants_info_[378].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[378].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[378].offset = 0;
    constants_info_[378].data_size = 6144;
    constants_info_[378].from_folded = false;
    constants_info_[378].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[378].shape = {3072};
    constants_info_[378].stride = {1};
    constants_info_[378].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[378].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.2.mlp_net.1._init_w";
    constants_info_[379].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[379].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[379].offset = 0;
    constants_info_[379].data_size = 6144;
    constants_info_[379].from_folded = false;
    constants_info_[379].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[379].shape = {3072};
    constants_info_[379].stride = {1};
    constants_info_[379].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[379].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.2.mlp_net.1._init_b";
    constants_info_[380].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_weight";
    constants_info_[380].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[380].offset = 0;
    constants_info_[380].data_size = 9437184;
    constants_info_[380].from_folded = false;
    constants_info_[380].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[380].shape = {1536, 3072};
    constants_info_[380].stride = {3072, 1};
    constants_info_[380].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[380].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.3.mlp_net.0.weight";
    constants_info_[381].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[381].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[381].offset = 0;
    constants_info_[381].data_size = 3072;
    constants_info_[381].from_folded = false;
    constants_info_[381].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[381].shape = {1536};
    constants_info_[381].stride = {1};
    constants_info_[381].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[381].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.3.mlp_net.0.bias";
    constants_info_[382].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[382].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[382].offset = 0;
    constants_info_[382].data_size = 3072;
    constants_info_[382].from_folded = false;
    constants_info_[382].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[382].shape = {1536};
    constants_info_[382].stride = {1};
    constants_info_[382].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[382].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.3.mlp_net.1.norm.0.weight";
    constants_info_[383].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[383].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[383].offset = 0;
    constants_info_[383].data_size = 3072;
    constants_info_[383].from_folded = false;
    constants_info_[383].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[383].shape = {1536};
    constants_info_[383].stride = {1};
    constants_info_[383].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[383].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.3.mlp_net.1.norm.0.bias";
    constants_info_[384].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[384].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[384].offset = 0;
    constants_info_[384].data_size = 3072;
    constants_info_[384].from_folded = false;
    constants_info_[384].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[384].shape = {1536};
    constants_info_[384].stride = {1};
    constants_info_[384].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[384].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.3.mlp_net.2._init_w";
    constants_info_[385].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[385].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[385].offset = 0;
    constants_info_[385].data_size = 3072;
    constants_info_[385].from_folded = false;
    constants_info_[385].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[385].shape = {1536};
    constants_info_[385].stride = {1};
    constants_info_[385].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[385].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.3.mlp_net.2._init_b";
    constants_info_[386].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_weight";
    constants_info_[386].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[386].offset = 0;
    constants_info_[386].data_size = 9437184;
    constants_info_[386].from_folded = false;
    constants_info_[386].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[386].shape = {3072, 1536};
    constants_info_[386].stride = {1536, 1};
    constants_info_[386].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[386].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.4.mlp_net.0.weight";
    constants_info_[387].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[387].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[387].offset = 0;
    constants_info_[387].data_size = 6144;
    constants_info_[387].from_folded = false;
    constants_info_[387].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[387].shape = {3072};
    constants_info_[387].stride = {1};
    constants_info_[387].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[387].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.4.mlp_net.0.bias";
    constants_info_[388].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[388].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[388].offset = 0;
    constants_info_[388].data_size = 6144;
    constants_info_[388].from_folded = false;
    constants_info_[388].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[388].shape = {3072};
    constants_info_[388].stride = {1};
    constants_info_[388].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[388].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.4.mlp_net.1._init_w";
    constants_info_[389].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[389].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[389].offset = 0;
    constants_info_[389].data_size = 6144;
    constants_info_[389].from_folded = false;
    constants_info_[389].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[389].shape = {3072};
    constants_info_[389].stride = {1};
    constants_info_[389].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[389].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._mlps.4.mlp_net.1._init_b";
    constants_info_[390].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[390].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[390].offset = 0;
    constants_info_[390].data_size = 6144;
    constants_info_[390].from_folded = false;
    constants_info_[390].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[390].shape = {3072};
    constants_info_[390].stride = {1};
    constants_info_[390].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[390].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._residual_activation.2.norm.0.weight";
    constants_info_[391].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[391].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[391].offset = 0;
    constants_info_[391].data_size = 6144;
    constants_info_[391].from_folded = false;
    constants_info_[391].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[391].shape = {3072};
    constants_info_[391].stride = {1};
    constants_info_[391].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[391].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._residual_activation.2.norm.0.bias";
    constants_info_[392].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[392].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[392].offset = 0;
    constants_info_[392].data_size = 6144;
    constants_info_[392].from_folded = false;
    constants_info_[392].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[392].shape = {3072};
    constants_info_[392].stride = {1};
    constants_info_[392].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[392].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._residual_activation.4.norm.0.weight";
    constants_info_[393].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[393].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[393].offset = 0;
    constants_info_[393].data_size = 6144;
    constants_info_[393].from_folded = false;
    constants_info_[393].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[393].shape = {3072};
    constants_info_[393].stride = {1};
    constants_info_[393].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[393].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._residual_mlp._residual_activation.4.norm.0.bias";
    constants_info_[394].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_weight";
    constants_info_[394].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[394].offset = 0;
    constants_info_[394].data_size = 56623104;
    constants_info_[394].from_folded = false;
    constants_info_[394].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[394].shape = {9216, 3072};
    constants_info_[394].stride = {3072, 1};
    constants_info_[394].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[394].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._snn_projection.mlp_net.0.weight";
    constants_info_[395].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias";
    constants_info_[395].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[395].offset = 0;
    constants_info_[395].data_size = 18432;
    constants_info_[395].from_folded = false;
    constants_info_[395].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[395].shape = {9216};
    constants_info_[395].stride = {1};
    constants_info_[395].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[395].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._snn_projection.mlp_net.0.bias";
    constants_info_[396].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w";
    constants_info_[396].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[396].offset = 0;
    constants_info_[396].data_size = 384;
    constants_info_[396].from_folded = false;
    constants_info_[396].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[396].shape = {192};
    constants_info_[396].stride = {1};
    constants_info_[396].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[396].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._ln_on_dhen_layer._init_w";
    constants_info_[397].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b";
    constants_info_[397].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[397].offset = 0;
    constants_info_[397].data_size = 384;
    constants_info_[397].from_folded = false;
    constants_info_[397].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[397].shape = {192};
    constants_info_[397].stride = {1};
    constants_info_[397].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[397].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.1._ln_on_dhen_layer._init_b";
    constants_info_[398].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w";
    constants_info_[398].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[398].offset = 0;
    constants_info_[398].data_size = 14688;
    constants_info_[398].from_folded = false;
    constants_info_[398].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[398].shape = {72, 102};
    constants_info_[398].stride = {102, 1};
    constants_info_[398].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[398].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._fused_lce_module._compression_w";
    constants_info_[399].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b";
    constants_info_[399].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[399].offset = 0;
    constants_info_[399].data_size = 144;
    constants_info_[399].from_folded = false;
    constants_info_[399].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[399].shape = {72, 1};
    constants_info_[399].stride = {1, 1};
    constants_info_[399].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[399].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._fused_lce_module._compression_b";
    constants_info_[400].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w";
    constants_info_[400].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[400].offset = 0;
    constants_info_[400].data_size = 384;
    constants_info_[400].from_folded = false;
    constants_info_[400].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[400].shape = {192};
    constants_info_[400].stride = {1};
    constants_info_[400].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[400].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._fused_lce_module._ln_lce._init_w";
    constants_info_[401].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b";
    constants_info_[401].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[401].offset = 0;
    constants_info_[401].data_size = 384;
    constants_info_[401].from_folded = false;
    constants_info_[401].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[401].shape = {192};
    constants_info_[401].stride = {1};
    constants_info_[401].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[401].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._fused_lce_module._ln_lce._init_b";
    constants_info_[402].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_weight";
    constants_info_[402].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[402].offset = 0;
    constants_info_[402].data_size = 7077888;
    constants_info_[402].from_folded = false;
    constants_info_[402].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[402].shape = {768, 4608};
    constants_info_[402].stride = {4608, 1};
    constants_info_[402].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[402].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.0.weight";
    constants_info_[403].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_bias";
    constants_info_[403].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[403].offset = 0;
    constants_info_[403].data_size = 1536;
    constants_info_[403].from_folded = false;
    constants_info_[403].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[403].shape = {768};
    constants_info_[403].stride = {1};
    constants_info_[403].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[403].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.0.bias";
    constants_info_[404].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[404].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[404].offset = 0;
    constants_info_[404].data_size = 1536;
    constants_info_[404].from_folded = false;
    constants_info_[404].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[404].shape = {768};
    constants_info_[404].stride = {1};
    constants_info_[404].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[404].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.1.norm.0.weight";
    constants_info_[405].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[405].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[405].offset = 0;
    constants_info_[405].data_size = 1536;
    constants_info_[405].from_folded = false;
    constants_info_[405].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[405].shape = {768};
    constants_info_[405].stride = {1};
    constants_info_[405].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[405].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.1.norm.0.bias";
    constants_info_[406].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[406].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[406].offset = 0;
    constants_info_[406].data_size = 1536;
    constants_info_[406].from_folded = false;
    constants_info_[406].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[406].shape = {768};
    constants_info_[406].stride = {1};
    constants_info_[406].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[406].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.2._init_w";
    constants_info_[407].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[407].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[407].offset = 0;
    constants_info_[407].data_size = 1536;
    constants_info_[407].from_folded = false;
    constants_info_[407].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[407].shape = {768};
    constants_info_[407].stride = {1};
    constants_info_[407].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[407].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.2._init_b";
    constants_info_[408].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_weight";
    constants_info_[408].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[408].offset = 0;
    constants_info_[408].data_size = 1179648;
    constants_info_[408].from_folded = false;
    constants_info_[408].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[408].shape = {768, 768};
    constants_info_[408].stride = {768, 1};
    constants_info_[408].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[408].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.3.weight";
    constants_info_[409].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[409].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[409].offset = 0;
    constants_info_[409].data_size = 1536;
    constants_info_[409].from_folded = false;
    constants_info_[409].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[409].shape = {768};
    constants_info_[409].stride = {1};
    constants_info_[409].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[409].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.3.bias";
    constants_info_[410].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[410].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[410].offset = 0;
    constants_info_[410].data_size = 1536;
    constants_info_[410].from_folded = false;
    constants_info_[410].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[410].shape = {768};
    constants_info_[410].stride = {1};
    constants_info_[410].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[410].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.4.norm.0.weight";
    constants_info_[411].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[411].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[411].offset = 0;
    constants_info_[411].data_size = 1536;
    constants_info_[411].from_folded = false;
    constants_info_[411].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[411].shape = {768};
    constants_info_[411].stride = {1};
    constants_info_[411].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[411].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.4.norm.0.bias";
    constants_info_[412].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[412].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[412].offset = 0;
    constants_info_[412].data_size = 1536;
    constants_info_[412].from_folded = false;
    constants_info_[412].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[412].shape = {768};
    constants_info_[412].stride = {1};
    constants_info_[412].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[412].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.5._init_w";
    constants_info_[413].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[413].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[413].offset = 0;
    constants_info_[413].data_size = 1536;
    constants_info_[413].from_folded = false;
    constants_info_[413].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[413].shape = {768};
    constants_info_[413].stride = {1};
    constants_info_[413].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[413].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_mlp.mlp_net.5._init_b";
    constants_info_[414].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_weight";
    constants_info_[414].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[414].offset = 0;
    constants_info_[414].data_size = 7077888;
    constants_info_[414].from_folded = false;
    constants_info_[414].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[414].shape = {768, 4608};
    constants_info_[414].stride = {4608, 1};
    constants_info_[414].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[414].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.0.weight";
    constants_info_[415].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_bias";
    constants_info_[415].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[415].offset = 0;
    constants_info_[415].data_size = 1536;
    constants_info_[415].from_folded = false;
    constants_info_[415].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[415].shape = {768};
    constants_info_[415].stride = {1};
    constants_info_[415].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[415].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.0.bias";
    constants_info_[416].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[416].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[416].offset = 0;
    constants_info_[416].data_size = 1536;
    constants_info_[416].from_folded = false;
    constants_info_[416].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[416].shape = {768};
    constants_info_[416].stride = {1};
    constants_info_[416].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[416].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.1.norm.0.weight";
    constants_info_[417].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[417].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[417].offset = 0;
    constants_info_[417].data_size = 1536;
    constants_info_[417].from_folded = false;
    constants_info_[417].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[417].shape = {768};
    constants_info_[417].stride = {1};
    constants_info_[417].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[417].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.1.norm.0.bias";
    constants_info_[418].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[418].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[418].offset = 0;
    constants_info_[418].data_size = 1536;
    constants_info_[418].from_folded = false;
    constants_info_[418].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[418].shape = {768};
    constants_info_[418].stride = {1};
    constants_info_[418].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[418].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.2._init_w";
    constants_info_[419].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[419].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[419].offset = 0;
    constants_info_[419].data_size = 1536;
    constants_info_[419].from_folded = false;
    constants_info_[419].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[419].shape = {768};
    constants_info_[419].stride = {1};
    constants_info_[419].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[419].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.2._init_b";
    constants_info_[420].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_weight";
    constants_info_[420].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[420].offset = 0;
    constants_info_[420].data_size = 1179648;
    constants_info_[420].from_folded = false;
    constants_info_[420].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[420].shape = {768, 768};
    constants_info_[420].stride = {768, 1};
    constants_info_[420].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[420].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.3.weight";
    constants_info_[421].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[421].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[421].offset = 0;
    constants_info_[421].data_size = 1536;
    constants_info_[421].from_folded = false;
    constants_info_[421].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[421].shape = {768};
    constants_info_[421].stride = {1};
    constants_info_[421].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[421].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.3.bias";
    constants_info_[422].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[422].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[422].offset = 0;
    constants_info_[422].data_size = 1536;
    constants_info_[422].from_folded = false;
    constants_info_[422].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[422].shape = {768};
    constants_info_[422].stride = {1};
    constants_info_[422].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[422].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.4.norm.0.weight";
    constants_info_[423].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[423].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[423].offset = 0;
    constants_info_[423].data_size = 1536;
    constants_info_[423].from_folded = false;
    constants_info_[423].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[423].shape = {768};
    constants_info_[423].stride = {1};
    constants_info_[423].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[423].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.4.norm.0.bias";
    constants_info_[424].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[424].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[424].offset = 0;
    constants_info_[424].data_size = 1536;
    constants_info_[424].from_folded = false;
    constants_info_[424].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[424].shape = {768};
    constants_info_[424].stride = {1};
    constants_info_[424].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[424].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.5._init_w";
    constants_info_[425].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[425].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[425].offset = 0;
    constants_info_[425].data_size = 1536;
    constants_info_[425].from_folded = false;
    constants_info_[425].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[425].shape = {768};
    constants_info_[425].stride = {1};
    constants_info_[425].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[425].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_mlp.mlp_net.5._init_b";
    constants_info_[426].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight";
    constants_info_[426].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[426].offset = 0;
    constants_info_[426].data_size = 7520256;
    constants_info_[426].from_folded = false;
    constants_info_[426].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[426].shape = {4896, 768};
    constants_info_[426].stride = {768, 1};
    constants_info_[426].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[426].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_post_match_mlp.mlp_net.0.weight";
    constants_info_[427].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[427].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[427].offset = 0;
    constants_info_[427].data_size = 9792;
    constants_info_[427].from_folded = false;
    constants_info_[427].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[427].shape = {4896};
    constants_info_[427].stride = {1};
    constants_info_[427].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[427].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_post_match_mlp.mlp_net.0.bias";
    constants_info_[428].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[428].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[428].offset = 0;
    constants_info_[428].data_size = 9792;
    constants_info_[428].from_folded = false;
    constants_info_[428].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[428].shape = {4896};
    constants_info_[428].stride = {1};
    constants_info_[428].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[428].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_post_match_mlp.mlp_net.1._init_w";
    constants_info_[429].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[429].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[429].offset = 0;
    constants_info_[429].data_size = 9792;
    constants_info_[429].from_folded = false;
    constants_info_[429].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[429].shape = {4896};
    constants_info_[429].stride = {1};
    constants_info_[429].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[429].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._weight_arch_post_match_mlp.mlp_net.1._init_b";
    constants_info_[430].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight";
    constants_info_[430].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[430].offset = 0;
    constants_info_[430].data_size = 14155776;
    constants_info_[430].from_folded = false;
    constants_info_[430].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[430].shape = {9216, 768};
    constants_info_[430].stride = {768, 1};
    constants_info_[430].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[430].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_post_match_mlp.mlp_net.0.weight";
    constants_info_[431].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[431].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[431].offset = 0;
    constants_info_[431].data_size = 18432;
    constants_info_[431].from_folded = false;
    constants_info_[431].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[431].shape = {9216};
    constants_info_[431].stride = {1};
    constants_info_[431].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[431].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_post_match_mlp.mlp_net.0.bias";
    constants_info_[432].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[432].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[432].offset = 0;
    constants_info_[432].data_size = 18432;
    constants_info_[432].from_folded = false;
    constants_info_[432].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[432].shape = {9216};
    constants_info_[432].stride = {1};
    constants_info_[432].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[432].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_post_match_mlp.mlp_net.1._init_w";
    constants_info_[433].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[433].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[433].offset = 0;
    constants_info_[433].data_size = 18432;
    constants_info_[433].from_folded = false;
    constants_info_[433].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[433].shape = {9216};
    constants_info_[433].stride = {1};
    constants_info_[433].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[433].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp._resnet_arch_post_match_mlp.mlp_net.1._init_b";
    constants_info_[434].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w";
    constants_info_[434].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[434].offset = 0;
    constants_info_[434].data_size = 96;
    constants_info_[434].from_folded = false;
    constants_info_[434].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[434].shape = {48};
    constants_info_[434].stride = {1};
    constants_info_[434].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[434].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp.compressed_tensor_ln._init_w";
    constants_info_[435].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b";
    constants_info_[435].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[435].offset = 0;
    constants_info_[435].data_size = 96;
    constants_info_[435].from_folded = false;
    constants_info_[435].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[435].shape = {48};
    constants_info_[435].stride = {1};
    constants_info_[435].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[435].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcpp.compressed_tensor_ln._init_b";
    constants_info_[436].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w";
    constants_info_[436].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[436].offset = 0;
    constants_info_[436].data_size = 9792;
    constants_info_[436].from_folded = false;
    constants_info_[436].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[436].shape = {4896};
    constants_info_[436].stride = {1};
    constants_info_[436].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[436].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcpp_ln._init_w";
    constants_info_[437].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b";
    constants_info_[437].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[437].offset = 0;
    constants_info_[437].data_size = 9792;
    constants_info_[437].from_folded = false;
    constants_info_[437].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[437].shape = {4896};
    constants_info_[437].stride = {1};
    constants_info_[437].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[437].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcpp_ln._init_b";
    constants_info_[438].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_weight";
    constants_info_[438].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[438].offset = 0;
    constants_info_[438].data_size = 20054016;
    constants_info_[438].from_folded = false;
    constants_info_[438].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[438].shape = {2048, 4896};
    constants_info_[438].stride = {4896, 1};
    constants_info_[438].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[438].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcpp_fc._mlps.0.mlp_net.0.weight";
    constants_info_[439].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[439].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[439].offset = 0;
    constants_info_[439].data_size = 4096;
    constants_info_[439].from_folded = false;
    constants_info_[439].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[439].shape = {2048};
    constants_info_[439].stride = {1};
    constants_info_[439].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[439].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcpp_fc._mlps.0.mlp_net.0.bias";
    constants_info_[440].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[440].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[440].offset = 0;
    constants_info_[440].data_size = 4096;
    constants_info_[440].from_folded = false;
    constants_info_[440].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[440].shape = {2048};
    constants_info_[440].stride = {1};
    constants_info_[440].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[440].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcpp_fc._mlps.0.mlp_net.1.norm.0.weight";
    constants_info_[441].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[441].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[441].offset = 0;
    constants_info_[441].data_size = 4096;
    constants_info_[441].from_folded = false;
    constants_info_[441].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[441].shape = {2048};
    constants_info_[441].stride = {1};
    constants_info_[441].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[441].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcpp_fc._mlps.0.mlp_net.1.norm.0.bias";
    constants_info_[442].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[442].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[442].offset = 0;
    constants_info_[442].data_size = 4096;
    constants_info_[442].from_folded = false;
    constants_info_[442].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[442].shape = {2048};
    constants_info_[442].stride = {1};
    constants_info_[442].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[442].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcpp_fc._mlps.0.mlp_net.2._init_w";
    constants_info_[443].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[443].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[443].offset = 0;
    constants_info_[443].data_size = 4096;
    constants_info_[443].from_folded = false;
    constants_info_[443].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[443].shape = {2048};
    constants_info_[443].stride = {1};
    constants_info_[443].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[443].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcpp_fc._mlps.0.mlp_net.2._init_b";
    constants_info_[444].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w";
    constants_info_[444].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[444].offset = 0;
    constants_info_[444].data_size = 12708;
    constants_info_[444].from_folded = false;
    constants_info_[444].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[444].shape = {6354};
    constants_info_[444].stride = {1};
    constants_info_[444].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[444].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._ln_on_dsi._init_w";
    constants_info_[445].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b";
    constants_info_[445].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[445].offset = 0;
    constants_info_[445].data_size = 12708;
    constants_info_[445].from_folded = false;
    constants_info_[445].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[445].shape = {6354};
    constants_info_[445].stride = {1};
    constants_info_[445].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[445].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._ln_on_dsi._init_b";
    constants_info_[446].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight";
    constants_info_[446].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[446].offset = 0;
    constants_info_[446].data_size = 4879872;
    constants_info_[446].from_folded = false;
    constants_info_[446].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[446].shape = {384, 6354};
    constants_info_[446].stride = {6354, 1};
    constants_info_[446].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[446].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcn._dcn_low_rank_mlps.0.mlp_net.0.weight";
    constants_info_[447].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[447].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[447].offset = 0;
    constants_info_[447].data_size = 768;
    constants_info_[447].from_folded = false;
    constants_info_[447].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[447].shape = {384};
    constants_info_[447].stride = {1};
    constants_info_[447].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[447].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcn._dcn_low_rank_mlps.0.mlp_net.0.bias";
    constants_info_[448].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[448].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[448].offset = 0;
    constants_info_[448].data_size = 768;
    constants_info_[448].from_folded = false;
    constants_info_[448].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[448].shape = {384};
    constants_info_[448].stride = {1};
    constants_info_[448].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[448].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcn._dcn_low_rank_mlps.0.mlp_net.1._init_w";
    constants_info_[449].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[449].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[449].offset = 0;
    constants_info_[449].data_size = 768;
    constants_info_[449].from_folded = false;
    constants_info_[449].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[449].shape = {384};
    constants_info_[449].stride = {1};
    constants_info_[449].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[449].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcn._dcn_low_rank_mlps.0.mlp_net.1._init_b";
    constants_info_[450].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_weight";
    constants_info_[450].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[450].offset = 0;
    constants_info_[450].data_size = 4879872;
    constants_info_[450].from_folded = false;
    constants_info_[450].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[450].shape = {6354, 384};
    constants_info_[450].stride = {384, 1};
    constants_info_[450].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[450].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcn._dcn_match_mlps.0.mlp_net.0.weight";
    constants_info_[451].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[451].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[451].offset = 0;
    constants_info_[451].data_size = 12708;
    constants_info_[451].from_folded = false;
    constants_info_[451].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[451].shape = {6354};
    constants_info_[451].stride = {1};
    constants_info_[451].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[451].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcn._dcn_match_mlps.0.mlp_net.0.bias";
    constants_info_[452].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[452].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[452].offset = 0;
    constants_info_[452].data_size = 12708;
    constants_info_[452].from_folded = false;
    constants_info_[452].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[452].shape = {6354};
    constants_info_[452].stride = {1};
    constants_info_[452].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[452].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcn._dcn_match_mlps.0.mlp_net.1._init_w";
    constants_info_[453].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[453].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[453].offset = 0;
    constants_info_[453].data_size = 12708;
    constants_info_[453].from_folded = false;
    constants_info_[453].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[453].shape = {6354};
    constants_info_[453].stride = {1};
    constants_info_[453].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[453].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._dcn._dcn_match_mlps.0.mlp_net.1._init_b";
    constants_info_[454].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w";
    constants_info_[454].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[454].offset = 0;
    constants_info_[454].data_size = 12708;
    constants_info_[454].from_folded = false;
    constants_info_[454].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[454].shape = {6354};
    constants_info_[454].stride = {1};
    constants_info_[454].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[454].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcn_ln._init_w";
    constants_info_[455].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b";
    constants_info_[455].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[455].offset = 0;
    constants_info_[455].data_size = 12708;
    constants_info_[455].from_folded = false;
    constants_info_[455].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[455].shape = {6354};
    constants_info_[455].stride = {1};
    constants_info_[455].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[455].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._post_dcn_ln._init_b";
    constants_info_[456].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_weight";
    constants_info_[456].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[456].offset = 0;
    constants_info_[456].data_size = 39038976;
    constants_info_[456].from_folded = false;
    constants_info_[456].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[456].shape = {3072, 6354};
    constants_info_[456].stride = {6354, 1};
    constants_info_[456].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[456].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.0.mlp_net.0.weight";
    constants_info_[457].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[457].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[457].offset = 0;
    constants_info_[457].data_size = 6144;
    constants_info_[457].from_folded = false;
    constants_info_[457].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[457].shape = {3072};
    constants_info_[457].stride = {1};
    constants_info_[457].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[457].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.0.mlp_net.0.bias";
    constants_info_[458].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[458].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[458].offset = 0;
    constants_info_[458].data_size = 6144;
    constants_info_[458].from_folded = false;
    constants_info_[458].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[458].shape = {3072};
    constants_info_[458].stride = {1};
    constants_info_[458].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[458].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.0.mlp_net.1.norm.0.weight";
    constants_info_[459].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[459].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[459].offset = 0;
    constants_info_[459].data_size = 6144;
    constants_info_[459].from_folded = false;
    constants_info_[459].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[459].shape = {3072};
    constants_info_[459].stride = {1};
    constants_info_[459].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[459].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.0.mlp_net.1.norm.0.bias";
    constants_info_[460].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[460].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[460].offset = 0;
    constants_info_[460].data_size = 6144;
    constants_info_[460].from_folded = false;
    constants_info_[460].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[460].shape = {3072};
    constants_info_[460].stride = {1};
    constants_info_[460].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[460].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.0.mlp_net.2._init_w";
    constants_info_[461].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[461].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[461].offset = 0;
    constants_info_[461].data_size = 6144;
    constants_info_[461].from_folded = false;
    constants_info_[461].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[461].shape = {3072};
    constants_info_[461].stride = {1};
    constants_info_[461].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[461].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.0.mlp_net.2._init_b";
    constants_info_[462].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_weight";
    constants_info_[462].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[462].offset = 0;
    constants_info_[462].data_size = 9437184;
    constants_info_[462].from_folded = false;
    constants_info_[462].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[462].shape = {1536, 3072};
    constants_info_[462].stride = {3072, 1};
    constants_info_[462].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[462].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.1.mlp_net.0.weight";
    constants_info_[463].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[463].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[463].offset = 0;
    constants_info_[463].data_size = 3072;
    constants_info_[463].from_folded = false;
    constants_info_[463].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[463].shape = {1536};
    constants_info_[463].stride = {1};
    constants_info_[463].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[463].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.1.mlp_net.0.bias";
    constants_info_[464].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[464].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[464].offset = 0;
    constants_info_[464].data_size = 3072;
    constants_info_[464].from_folded = false;
    constants_info_[464].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[464].shape = {1536};
    constants_info_[464].stride = {1};
    constants_info_[464].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[464].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.1.mlp_net.1.norm.0.weight";
    constants_info_[465].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[465].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[465].offset = 0;
    constants_info_[465].data_size = 3072;
    constants_info_[465].from_folded = false;
    constants_info_[465].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[465].shape = {1536};
    constants_info_[465].stride = {1};
    constants_info_[465].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[465].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.1.mlp_net.1.norm.0.bias";
    constants_info_[466].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[466].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[466].offset = 0;
    constants_info_[466].data_size = 3072;
    constants_info_[466].from_folded = false;
    constants_info_[466].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[466].shape = {1536};
    constants_info_[466].stride = {1};
    constants_info_[466].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[466].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.1.mlp_net.2._init_w";
    constants_info_[467].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[467].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[467].offset = 0;
    constants_info_[467].data_size = 3072;
    constants_info_[467].from_folded = false;
    constants_info_[467].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[467].shape = {1536};
    constants_info_[467].stride = {1};
    constants_info_[467].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[467].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.1.mlp_net.2._init_b";
    constants_info_[468].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_weight";
    constants_info_[468].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[468].offset = 0;
    constants_info_[468].data_size = 9437184;
    constants_info_[468].from_folded = false;
    constants_info_[468].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[468].shape = {3072, 1536};
    constants_info_[468].stride = {1536, 1};
    constants_info_[468].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[468].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.2.mlp_net.0.weight";
    constants_info_[469].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[469].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[469].offset = 0;
    constants_info_[469].data_size = 6144;
    constants_info_[469].from_folded = false;
    constants_info_[469].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[469].shape = {3072};
    constants_info_[469].stride = {1};
    constants_info_[469].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[469].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.2.mlp_net.0.bias";
    constants_info_[470].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[470].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[470].offset = 0;
    constants_info_[470].data_size = 6144;
    constants_info_[470].from_folded = false;
    constants_info_[470].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[470].shape = {3072};
    constants_info_[470].stride = {1};
    constants_info_[470].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[470].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.2.mlp_net.1._init_w";
    constants_info_[471].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[471].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[471].offset = 0;
    constants_info_[471].data_size = 6144;
    constants_info_[471].from_folded = false;
    constants_info_[471].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[471].shape = {3072};
    constants_info_[471].stride = {1};
    constants_info_[471].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[471].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.2.mlp_net.1._init_b";
    constants_info_[472].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_weight";
    constants_info_[472].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[472].offset = 0;
    constants_info_[472].data_size = 9437184;
    constants_info_[472].from_folded = false;
    constants_info_[472].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[472].shape = {1536, 3072};
    constants_info_[472].stride = {3072, 1};
    constants_info_[472].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[472].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.3.mlp_net.0.weight";
    constants_info_[473].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[473].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[473].offset = 0;
    constants_info_[473].data_size = 3072;
    constants_info_[473].from_folded = false;
    constants_info_[473].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[473].shape = {1536};
    constants_info_[473].stride = {1};
    constants_info_[473].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[473].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.3.mlp_net.0.bias";
    constants_info_[474].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[474].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[474].offset = 0;
    constants_info_[474].data_size = 3072;
    constants_info_[474].from_folded = false;
    constants_info_[474].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[474].shape = {1536};
    constants_info_[474].stride = {1};
    constants_info_[474].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[474].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.3.mlp_net.1.norm.0.weight";
    constants_info_[475].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[475].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[475].offset = 0;
    constants_info_[475].data_size = 3072;
    constants_info_[475].from_folded = false;
    constants_info_[475].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[475].shape = {1536};
    constants_info_[475].stride = {1};
    constants_info_[475].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[475].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.3.mlp_net.1.norm.0.bias";
    constants_info_[476].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[476].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[476].offset = 0;
    constants_info_[476].data_size = 3072;
    constants_info_[476].from_folded = false;
    constants_info_[476].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[476].shape = {1536};
    constants_info_[476].stride = {1};
    constants_info_[476].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[476].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.3.mlp_net.2._init_w";
    constants_info_[477].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[477].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[477].offset = 0;
    constants_info_[477].data_size = 3072;
    constants_info_[477].from_folded = false;
    constants_info_[477].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[477].shape = {1536};
    constants_info_[477].stride = {1};
    constants_info_[477].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[477].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.3.mlp_net.2._init_b";
    constants_info_[478].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_weight";
    constants_info_[478].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[478].offset = 0;
    constants_info_[478].data_size = 9437184;
    constants_info_[478].from_folded = false;
    constants_info_[478].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[478].shape = {3072, 1536};
    constants_info_[478].stride = {1536, 1};
    constants_info_[478].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[478].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.4.mlp_net.0.weight";
    constants_info_[479].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[479].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[479].offset = 0;
    constants_info_[479].data_size = 6144;
    constants_info_[479].from_folded = false;
    constants_info_[479].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[479].shape = {3072};
    constants_info_[479].stride = {1};
    constants_info_[479].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[479].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.4.mlp_net.0.bias";
    constants_info_[480].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[480].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[480].offset = 0;
    constants_info_[480].data_size = 6144;
    constants_info_[480].from_folded = false;
    constants_info_[480].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[480].shape = {3072};
    constants_info_[480].stride = {1};
    constants_info_[480].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[480].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.4.mlp_net.1._init_w";
    constants_info_[481].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[481].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[481].offset = 0;
    constants_info_[481].data_size = 6144;
    constants_info_[481].from_folded = false;
    constants_info_[481].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[481].shape = {3072};
    constants_info_[481].stride = {1};
    constants_info_[481].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[481].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._mlps.4.mlp_net.1._init_b";
    constants_info_[482].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[482].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[482].offset = 0;
    constants_info_[482].data_size = 6144;
    constants_info_[482].from_folded = false;
    constants_info_[482].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[482].shape = {3072};
    constants_info_[482].stride = {1};
    constants_info_[482].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[482].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._residual_activation.2.norm.0.weight";
    constants_info_[483].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[483].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[483].offset = 0;
    constants_info_[483].data_size = 6144;
    constants_info_[483].from_folded = false;
    constants_info_[483].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[483].shape = {3072};
    constants_info_[483].stride = {1};
    constants_info_[483].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[483].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._residual_activation.2.norm.0.bias";
    constants_info_[484].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[484].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[484].offset = 0;
    constants_info_[484].data_size = 6144;
    constants_info_[484].from_folded = false;
    constants_info_[484].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[484].shape = {3072};
    constants_info_[484].stride = {1};
    constants_info_[484].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[484].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._residual_activation.4.norm.0.weight";
    constants_info_[485].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[485].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[485].offset = 0;
    constants_info_[485].data_size = 6144;
    constants_info_[485].from_folded = false;
    constants_info_[485].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[485].shape = {3072};
    constants_info_[485].stride = {1};
    constants_info_[485].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[485].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._residual_mlp._residual_activation.4.norm.0.bias";
    constants_info_[486].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_weight";
    constants_info_[486].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[486].offset = 0;
    constants_info_[486].data_size = 56623104;
    constants_info_[486].from_folded = false;
    constants_info_[486].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[486].shape = {9216, 3072};
    constants_info_[486].stride = {3072, 1};
    constants_info_[486].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[486].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._snn_projection.mlp_net.0.weight";
    constants_info_[487].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias";
    constants_info_[487].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[487].offset = 0;
    constants_info_[487].data_size = 18432;
    constants_info_[487].from_folded = false;
    constants_info_[487].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[487].shape = {9216};
    constants_info_[487].stride = {1};
    constants_info_[487].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[487].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._snn_projection.mlp_net.0.bias";
    constants_info_[488].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w";
    constants_info_[488].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[488].offset = 0;
    constants_info_[488].data_size = 384;
    constants_info_[488].from_folded = false;
    constants_info_[488].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[488].shape = {192};
    constants_info_[488].stride = {1};
    constants_info_[488].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[488].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._ln_on_dhen_layer._init_w";
    constants_info_[489].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b";
    constants_info_[489].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[489].offset = 0;
    constants_info_[489].data_size = 384;
    constants_info_[489].from_folded = false;
    constants_info_[489].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[489].shape = {192};
    constants_info_[489].stride = {1};
    constants_info_[489].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[489].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.2._ln_on_dhen_layer._init_b";
    constants_info_[490].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w";
    constants_info_[490].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[490].offset = 0;
    constants_info_[490].data_size = 4896;
    constants_info_[490].from_folded = false;
    constants_info_[490].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[490].shape = {24, 102};
    constants_info_[490].stride = {102, 1};
    constants_info_[490].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[490].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._input_compression._compression_w";
    constants_info_[491].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b";
    constants_info_[491].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[491].offset = 0;
    constants_info_[491].data_size = 48;
    constants_info_[491].from_folded = false;
    constants_info_[491].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[491].shape = {24, 1};
    constants_info_[491].stride = {1, 1};
    constants_info_[491].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[491].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._input_compression._compression_b";
    constants_info_[492].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w";
    constants_info_[492].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[492].offset = 0;
    constants_info_[492].data_size = 384;
    constants_info_[492].from_folded = false;
    constants_info_[492].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[492].shape = {192};
    constants_info_[492].stride = {1};
    constants_info_[492].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[492].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._input_compression._ln_lce._init_w";
    constants_info_[493].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b";
    constants_info_[493].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[493].offset = 0;
    constants_info_[493].data_size = 384;
    constants_info_[493].from_folded = false;
    constants_info_[493].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[493].shape = {192};
    constants_info_[493].stride = {1};
    constants_info_[493].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[493].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._input_compression._ln_lce._init_b";
    constants_info_[494].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_weight";
    constants_info_[494].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[494].offset = 0;
    constants_info_[494].data_size = 7077888;
    constants_info_[494].from_folded = false;
    constants_info_[494].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[494].shape = {768, 4608};
    constants_info_[494].stride = {4608, 1};
    constants_info_[494].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[494].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.0.weight";
    constants_info_[495].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_bias";
    constants_info_[495].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[495].offset = 0;
    constants_info_[495].data_size = 1536;
    constants_info_[495].from_folded = false;
    constants_info_[495].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[495].shape = {768};
    constants_info_[495].stride = {1};
    constants_info_[495].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[495].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.0.bias";
    constants_info_[496].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[496].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[496].offset = 0;
    constants_info_[496].data_size = 1536;
    constants_info_[496].from_folded = false;
    constants_info_[496].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[496].shape = {768};
    constants_info_[496].stride = {1};
    constants_info_[496].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[496].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.1.norm.0.weight";
    constants_info_[497].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[497].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[497].offset = 0;
    constants_info_[497].data_size = 1536;
    constants_info_[497].from_folded = false;
    constants_info_[497].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[497].shape = {768};
    constants_info_[497].stride = {1};
    constants_info_[497].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[497].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.1.norm.0.bias";
    constants_info_[498].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[498].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[498].offset = 0;
    constants_info_[498].data_size = 1536;
    constants_info_[498].from_folded = false;
    constants_info_[498].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[498].shape = {768};
    constants_info_[498].stride = {1};
    constants_info_[498].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[498].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.2._init_w";
    constants_info_[499].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[499].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[499].offset = 0;
    constants_info_[499].data_size = 1536;
    constants_info_[499].from_folded = false;
    constants_info_[499].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[499].shape = {768};
    constants_info_[499].stride = {1};
    constants_info_[499].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[499].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.2._init_b";
    constants_info_[500].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_weight";
    constants_info_[500].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[500].offset = 0;
    constants_info_[500].data_size = 1179648;
    constants_info_[500].from_folded = false;
    constants_info_[500].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[500].shape = {768, 768};
    constants_info_[500].stride = {768, 1};
    constants_info_[500].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[500].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.3.weight";
    constants_info_[501].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[501].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[501].offset = 0;
    constants_info_[501].data_size = 1536;
    constants_info_[501].from_folded = false;
    constants_info_[501].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[501].shape = {768};
    constants_info_[501].stride = {1};
    constants_info_[501].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[501].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.3.bias";
    constants_info_[502].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[502].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[502].offset = 0;
    constants_info_[502].data_size = 1536;
    constants_info_[502].from_folded = false;
    constants_info_[502].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[502].shape = {768};
    constants_info_[502].stride = {1};
    constants_info_[502].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[502].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.4.norm.0.weight";
    constants_info_[503].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[503].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[503].offset = 0;
    constants_info_[503].data_size = 1536;
    constants_info_[503].from_folded = false;
    constants_info_[503].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[503].shape = {768};
    constants_info_[503].stride = {1};
    constants_info_[503].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[503].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.4.norm.0.bias";
    constants_info_[504].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[504].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[504].offset = 0;
    constants_info_[504].data_size = 1536;
    constants_info_[504].from_folded = false;
    constants_info_[504].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[504].shape = {768};
    constants_info_[504].stride = {1};
    constants_info_[504].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[504].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.5._init_w";
    constants_info_[505].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[505].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[505].offset = 0;
    constants_info_[505].data_size = 1536;
    constants_info_[505].from_folded = false;
    constants_info_[505].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[505].shape = {768};
    constants_info_[505].stride = {1};
    constants_info_[505].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[505].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_mlp.mlp_net.5._init_b";
    constants_info_[506].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_weight";
    constants_info_[506].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[506].offset = 0;
    constants_info_[506].data_size = 7077888;
    constants_info_[506].from_folded = false;
    constants_info_[506].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[506].shape = {768, 4608};
    constants_info_[506].stride = {4608, 1};
    constants_info_[506].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[506].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.0.weight";
    constants_info_[507].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_bias";
    constants_info_[507].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[507].offset = 0;
    constants_info_[507].data_size = 1536;
    constants_info_[507].from_folded = false;
    constants_info_[507].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[507].shape = {768};
    constants_info_[507].stride = {1};
    constants_info_[507].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[507].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.0.bias";
    constants_info_[508].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[508].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[508].offset = 0;
    constants_info_[508].data_size = 1536;
    constants_info_[508].from_folded = false;
    constants_info_[508].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[508].shape = {768};
    constants_info_[508].stride = {1};
    constants_info_[508].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[508].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.1.norm.0.weight";
    constants_info_[509].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[509].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[509].offset = 0;
    constants_info_[509].data_size = 1536;
    constants_info_[509].from_folded = false;
    constants_info_[509].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[509].shape = {768};
    constants_info_[509].stride = {1};
    constants_info_[509].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[509].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.1.norm.0.bias";
    constants_info_[510].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[510].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[510].offset = 0;
    constants_info_[510].data_size = 1536;
    constants_info_[510].from_folded = false;
    constants_info_[510].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[510].shape = {768};
    constants_info_[510].stride = {1};
    constants_info_[510].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[510].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.2._init_w";
    constants_info_[511].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[511].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[511].offset = 0;
    constants_info_[511].data_size = 1536;
    constants_info_[511].from_folded = false;
    constants_info_[511].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[511].shape = {768};
    constants_info_[511].stride = {1};
    constants_info_[511].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[511].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.2._init_b";
    constants_info_[512].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_weight";
    constants_info_[512].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[512].offset = 0;
    constants_info_[512].data_size = 1179648;
    constants_info_[512].from_folded = false;
    constants_info_[512].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[512].shape = {768, 768};
    constants_info_[512].stride = {768, 1};
    constants_info_[512].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[512].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.3.weight";
    constants_info_[513].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[513].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[513].offset = 0;
    constants_info_[513].data_size = 1536;
    constants_info_[513].from_folded = false;
    constants_info_[513].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[513].shape = {768};
    constants_info_[513].stride = {1};
    constants_info_[513].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[513].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.3.bias";
    constants_info_[514].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[514].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[514].offset = 0;
    constants_info_[514].data_size = 1536;
    constants_info_[514].from_folded = false;
    constants_info_[514].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[514].shape = {768};
    constants_info_[514].stride = {1};
    constants_info_[514].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[514].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.4.norm.0.weight";
    constants_info_[515].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[515].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[515].offset = 0;
    constants_info_[515].data_size = 1536;
    constants_info_[515].from_folded = false;
    constants_info_[515].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[515].shape = {768};
    constants_info_[515].stride = {1};
    constants_info_[515].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[515].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.4.norm.0.bias";
    constants_info_[516].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[516].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[516].offset = 0;
    constants_info_[516].data_size = 1536;
    constants_info_[516].from_folded = false;
    constants_info_[516].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[516].shape = {768};
    constants_info_[516].stride = {1};
    constants_info_[516].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[516].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.5._init_w";
    constants_info_[517].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[517].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[517].offset = 0;
    constants_info_[517].data_size = 1536;
    constants_info_[517].from_folded = false;
    constants_info_[517].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[517].shape = {768};
    constants_info_[517].stride = {1};
    constants_info_[517].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[517].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_mlp.mlp_net.5._init_b";
    constants_info_[518].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight";
    constants_info_[518].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[518].offset = 0;
    constants_info_[518].data_size = 7520256;
    constants_info_[518].from_folded = false;
    constants_info_[518].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[518].shape = {4896, 768};
    constants_info_[518].stride = {768, 1};
    constants_info_[518].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[518].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_post_match_mlp.mlp_net.0.weight";
    constants_info_[519].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[519].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[519].offset = 0;
    constants_info_[519].data_size = 9792;
    constants_info_[519].from_folded = false;
    constants_info_[519].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[519].shape = {4896};
    constants_info_[519].stride = {1};
    constants_info_[519].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[519].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_post_match_mlp.mlp_net.0.bias";
    constants_info_[520].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[520].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[520].offset = 0;
    constants_info_[520].data_size = 9792;
    constants_info_[520].from_folded = false;
    constants_info_[520].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[520].shape = {4896};
    constants_info_[520].stride = {1};
    constants_info_[520].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[520].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_post_match_mlp.mlp_net.1._init_w";
    constants_info_[521].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[521].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[521].offset = 0;
    constants_info_[521].data_size = 9792;
    constants_info_[521].from_folded = false;
    constants_info_[521].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[521].shape = {4896};
    constants_info_[521].stride = {1};
    constants_info_[521].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[521].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._weight_arch_post_match_mlp.mlp_net.1._init_b";
    constants_info_[522].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight";
    constants_info_[522].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[522].offset = 0;
    constants_info_[522].data_size = 14155776;
    constants_info_[522].from_folded = false;
    constants_info_[522].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[522].shape = {9216, 768};
    constants_info_[522].stride = {768, 1};
    constants_info_[522].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[522].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_post_match_mlp.mlp_net.0.weight";
    constants_info_[523].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[523].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[523].offset = 0;
    constants_info_[523].data_size = 18432;
    constants_info_[523].from_folded = false;
    constants_info_[523].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[523].shape = {9216};
    constants_info_[523].stride = {1};
    constants_info_[523].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[523].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_post_match_mlp.mlp_net.0.bias";
    constants_info_[524].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[524].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[524].offset = 0;
    constants_info_[524].data_size = 18432;
    constants_info_[524].from_folded = false;
    constants_info_[524].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[524].shape = {9216};
    constants_info_[524].stride = {1};
    constants_info_[524].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[524].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_post_match_mlp.mlp_net.1._init_w";
    constants_info_[525].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[525].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[525].offset = 0;
    constants_info_[525].data_size = 18432;
    constants_info_[525].from_folded = false;
    constants_info_[525].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[525].shape = {9216};
    constants_info_[525].stride = {1};
    constants_info_[525].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[525].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp._resnet_arch_post_match_mlp.mlp_net.1._init_b";
    constants_info_[526].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w";
    constants_info_[526].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[526].offset = 0;
    constants_info_[526].data_size = 96;
    constants_info_[526].from_folded = false;
    constants_info_[526].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[526].shape = {48};
    constants_info_[526].stride = {1};
    constants_info_[526].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[526].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp.compressed_tensor_ln._init_w";
    constants_info_[527].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b";
    constants_info_[527].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[527].offset = 0;
    constants_info_[527].data_size = 96;
    constants_info_[527].from_folded = false;
    constants_info_[527].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[527].shape = {48};
    constants_info_[527].stride = {1};
    constants_info_[527].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[527].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcpp.compressed_tensor_ln._init_b";
    constants_info_[528].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w";
    constants_info_[528].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[528].offset = 0;
    constants_info_[528].data_size = 9792;
    constants_info_[528].from_folded = false;
    constants_info_[528].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[528].shape = {4896};
    constants_info_[528].stride = {1};
    constants_info_[528].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[528].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcpp_ln._init_w";
    constants_info_[529].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b";
    constants_info_[529].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[529].offset = 0;
    constants_info_[529].data_size = 9792;
    constants_info_[529].from_folded = false;
    constants_info_[529].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[529].shape = {4896};
    constants_info_[529].stride = {1};
    constants_info_[529].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[529].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcpp_ln._init_b";
    constants_info_[530].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_weight";
    constants_info_[530].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[530].offset = 0;
    constants_info_[530].data_size = 20054016;
    constants_info_[530].from_folded = false;
    constants_info_[530].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[530].shape = {2048, 4896};
    constants_info_[530].stride = {4896, 1};
    constants_info_[530].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[530].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcpp_fc._mlps.0.mlp_net.0.weight";
    constants_info_[531].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[531].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[531].offset = 0;
    constants_info_[531].data_size = 4096;
    constants_info_[531].from_folded = false;
    constants_info_[531].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[531].shape = {2048};
    constants_info_[531].stride = {1};
    constants_info_[531].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[531].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcpp_fc._mlps.0.mlp_net.0.bias";
    constants_info_[532].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[532].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[532].offset = 0;
    constants_info_[532].data_size = 4096;
    constants_info_[532].from_folded = false;
    constants_info_[532].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[532].shape = {2048};
    constants_info_[532].stride = {1};
    constants_info_[532].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[532].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcpp_fc._mlps.0.mlp_net.1.norm.0.weight";
    constants_info_[533].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[533].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[533].offset = 0;
    constants_info_[533].data_size = 4096;
    constants_info_[533].from_folded = false;
    constants_info_[533].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[533].shape = {2048};
    constants_info_[533].stride = {1};
    constants_info_[533].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[533].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcpp_fc._mlps.0.mlp_net.1.norm.0.bias";
    constants_info_[534].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[534].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[534].offset = 0;
    constants_info_[534].data_size = 4096;
    constants_info_[534].from_folded = false;
    constants_info_[534].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[534].shape = {2048};
    constants_info_[534].stride = {1};
    constants_info_[534].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[534].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcpp_fc._mlps.0.mlp_net.2._init_w";
    constants_info_[535].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[535].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[535].offset = 0;
    constants_info_[535].data_size = 4096;
    constants_info_[535].from_folded = false;
    constants_info_[535].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[535].shape = {2048};
    constants_info_[535].stride = {1};
    constants_info_[535].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[535].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcpp_fc._mlps.0.mlp_net.2._init_b";
    constants_info_[536].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w";
    constants_info_[536].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[536].offset = 0;
    constants_info_[536].data_size = 12708;
    constants_info_[536].from_folded = false;
    constants_info_[536].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[536].shape = {6354};
    constants_info_[536].stride = {1};
    constants_info_[536].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[536].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._ln_on_dsi._init_w";
    constants_info_[537].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b";
    constants_info_[537].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[537].offset = 0;
    constants_info_[537].data_size = 12708;
    constants_info_[537].from_folded = false;
    constants_info_[537].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[537].shape = {6354};
    constants_info_[537].stride = {1};
    constants_info_[537].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[537].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._ln_on_dsi._init_b";
    constants_info_[538].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight";
    constants_info_[538].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[538].offset = 0;
    constants_info_[538].data_size = 4879872;
    constants_info_[538].from_folded = false;
    constants_info_[538].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[538].shape = {384, 6354};
    constants_info_[538].stride = {6354, 1};
    constants_info_[538].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[538].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcn._dcn_low_rank_mlps.0.mlp_net.0.weight";
    constants_info_[539].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[539].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[539].offset = 0;
    constants_info_[539].data_size = 768;
    constants_info_[539].from_folded = false;
    constants_info_[539].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[539].shape = {384};
    constants_info_[539].stride = {1};
    constants_info_[539].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[539].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcn._dcn_low_rank_mlps.0.mlp_net.0.bias";
    constants_info_[540].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[540].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[540].offset = 0;
    constants_info_[540].data_size = 768;
    constants_info_[540].from_folded = false;
    constants_info_[540].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[540].shape = {384};
    constants_info_[540].stride = {1};
    constants_info_[540].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[540].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcn._dcn_low_rank_mlps.0.mlp_net.1._init_w";
    constants_info_[541].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[541].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[541].offset = 0;
    constants_info_[541].data_size = 768;
    constants_info_[541].from_folded = false;
    constants_info_[541].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[541].shape = {384};
    constants_info_[541].stride = {1};
    constants_info_[541].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[541].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcn._dcn_low_rank_mlps.0.mlp_net.1._init_b";
    constants_info_[542].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_weight";
    constants_info_[542].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[542].offset = 0;
    constants_info_[542].data_size = 4879872;
    constants_info_[542].from_folded = false;
    constants_info_[542].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[542].shape = {6354, 384};
    constants_info_[542].stride = {384, 1};
    constants_info_[542].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[542].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcn._dcn_match_mlps.0.mlp_net.0.weight";
    constants_info_[543].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[543].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[543].offset = 0;
    constants_info_[543].data_size = 12708;
    constants_info_[543].from_folded = false;
    constants_info_[543].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[543].shape = {6354};
    constants_info_[543].stride = {1};
    constants_info_[543].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[543].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcn._dcn_match_mlps.0.mlp_net.0.bias";
    constants_info_[544].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[544].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[544].offset = 0;
    constants_info_[544].data_size = 12708;
    constants_info_[544].from_folded = false;
    constants_info_[544].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[544].shape = {6354};
    constants_info_[544].stride = {1};
    constants_info_[544].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[544].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcn._dcn_match_mlps.0.mlp_net.1._init_w";
    constants_info_[545].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[545].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[545].offset = 0;
    constants_info_[545].data_size = 12708;
    constants_info_[545].from_folded = false;
    constants_info_[545].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[545].shape = {6354};
    constants_info_[545].stride = {1};
    constants_info_[545].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[545].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._dcn._dcn_match_mlps.0.mlp_net.1._init_b";
    constants_info_[546].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w";
    constants_info_[546].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[546].offset = 0;
    constants_info_[546].data_size = 12708;
    constants_info_[546].from_folded = false;
    constants_info_[546].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[546].shape = {6354};
    constants_info_[546].stride = {1};
    constants_info_[546].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[546].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcn_ln._init_w";
    constants_info_[547].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b";
    constants_info_[547].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[547].offset = 0;
    constants_info_[547].data_size = 12708;
    constants_info_[547].from_folded = false;
    constants_info_[547].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[547].shape = {6354};
    constants_info_[547].stride = {1};
    constants_info_[547].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[547].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._post_dcn_ln._init_b";
    constants_info_[548].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_weight";
    constants_info_[548].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[548].offset = 0;
    constants_info_[548].data_size = 39038976;
    constants_info_[548].from_folded = false;
    constants_info_[548].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[548].shape = {3072, 6354};
    constants_info_[548].stride = {6354, 1};
    constants_info_[548].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[548].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.0.mlp_net.0.weight";
    constants_info_[549].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[549].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[549].offset = 0;
    constants_info_[549].data_size = 6144;
    constants_info_[549].from_folded = false;
    constants_info_[549].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[549].shape = {3072};
    constants_info_[549].stride = {1};
    constants_info_[549].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[549].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.0.mlp_net.0.bias";
    constants_info_[550].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[550].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[550].offset = 0;
    constants_info_[550].data_size = 6144;
    constants_info_[550].from_folded = false;
    constants_info_[550].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[550].shape = {3072};
    constants_info_[550].stride = {1};
    constants_info_[550].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[550].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.0.mlp_net.1.norm.0.weight";
    constants_info_[551].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[551].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[551].offset = 0;
    constants_info_[551].data_size = 6144;
    constants_info_[551].from_folded = false;
    constants_info_[551].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[551].shape = {3072};
    constants_info_[551].stride = {1};
    constants_info_[551].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[551].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.0.mlp_net.1.norm.0.bias";
    constants_info_[552].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[552].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[552].offset = 0;
    constants_info_[552].data_size = 6144;
    constants_info_[552].from_folded = false;
    constants_info_[552].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[552].shape = {3072};
    constants_info_[552].stride = {1};
    constants_info_[552].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[552].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.0.mlp_net.2._init_w";
    constants_info_[553].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[553].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[553].offset = 0;
    constants_info_[553].data_size = 6144;
    constants_info_[553].from_folded = false;
    constants_info_[553].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[553].shape = {3072};
    constants_info_[553].stride = {1};
    constants_info_[553].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[553].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.0.mlp_net.2._init_b";
    constants_info_[554].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_weight";
    constants_info_[554].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[554].offset = 0;
    constants_info_[554].data_size = 9437184;
    constants_info_[554].from_folded = false;
    constants_info_[554].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[554].shape = {1536, 3072};
    constants_info_[554].stride = {3072, 1};
    constants_info_[554].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[554].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.1.mlp_net.0.weight";
    constants_info_[555].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[555].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[555].offset = 0;
    constants_info_[555].data_size = 3072;
    constants_info_[555].from_folded = false;
    constants_info_[555].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[555].shape = {1536};
    constants_info_[555].stride = {1};
    constants_info_[555].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[555].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.1.mlp_net.0.bias";
    constants_info_[556].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[556].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[556].offset = 0;
    constants_info_[556].data_size = 3072;
    constants_info_[556].from_folded = false;
    constants_info_[556].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[556].shape = {1536};
    constants_info_[556].stride = {1};
    constants_info_[556].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[556].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.1.mlp_net.1.norm.0.weight";
    constants_info_[557].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[557].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[557].offset = 0;
    constants_info_[557].data_size = 3072;
    constants_info_[557].from_folded = false;
    constants_info_[557].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[557].shape = {1536};
    constants_info_[557].stride = {1};
    constants_info_[557].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[557].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.1.mlp_net.1.norm.0.bias";
    constants_info_[558].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[558].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[558].offset = 0;
    constants_info_[558].data_size = 3072;
    constants_info_[558].from_folded = false;
    constants_info_[558].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[558].shape = {1536};
    constants_info_[558].stride = {1};
    constants_info_[558].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[558].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.1.mlp_net.2._init_w";
    constants_info_[559].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[559].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[559].offset = 0;
    constants_info_[559].data_size = 3072;
    constants_info_[559].from_folded = false;
    constants_info_[559].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[559].shape = {1536};
    constants_info_[559].stride = {1};
    constants_info_[559].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[559].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.1.mlp_net.2._init_b";
    constants_info_[560].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_weight";
    constants_info_[560].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[560].offset = 0;
    constants_info_[560].data_size = 9437184;
    constants_info_[560].from_folded = false;
    constants_info_[560].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[560].shape = {3072, 1536};
    constants_info_[560].stride = {1536, 1};
    constants_info_[560].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[560].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.2.mlp_net.0.weight";
    constants_info_[561].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[561].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[561].offset = 0;
    constants_info_[561].data_size = 6144;
    constants_info_[561].from_folded = false;
    constants_info_[561].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[561].shape = {3072};
    constants_info_[561].stride = {1};
    constants_info_[561].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[561].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.2.mlp_net.0.bias";
    constants_info_[562].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[562].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[562].offset = 0;
    constants_info_[562].data_size = 6144;
    constants_info_[562].from_folded = false;
    constants_info_[562].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[562].shape = {3072};
    constants_info_[562].stride = {1};
    constants_info_[562].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[562].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.2.mlp_net.1._init_w";
    constants_info_[563].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[563].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[563].offset = 0;
    constants_info_[563].data_size = 6144;
    constants_info_[563].from_folded = false;
    constants_info_[563].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[563].shape = {3072};
    constants_info_[563].stride = {1};
    constants_info_[563].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[563].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.2.mlp_net.1._init_b";
    constants_info_[564].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_weight";
    constants_info_[564].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[564].offset = 0;
    constants_info_[564].data_size = 9437184;
    constants_info_[564].from_folded = false;
    constants_info_[564].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[564].shape = {1536, 3072};
    constants_info_[564].stride = {3072, 1};
    constants_info_[564].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[564].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.3.mlp_net.0.weight";
    constants_info_[565].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[565].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[565].offset = 0;
    constants_info_[565].data_size = 3072;
    constants_info_[565].from_folded = false;
    constants_info_[565].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[565].shape = {1536};
    constants_info_[565].stride = {1};
    constants_info_[565].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[565].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.3.mlp_net.0.bias";
    constants_info_[566].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[566].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[566].offset = 0;
    constants_info_[566].data_size = 3072;
    constants_info_[566].from_folded = false;
    constants_info_[566].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[566].shape = {1536};
    constants_info_[566].stride = {1};
    constants_info_[566].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[566].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.3.mlp_net.1.norm.0.weight";
    constants_info_[567].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[567].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[567].offset = 0;
    constants_info_[567].data_size = 3072;
    constants_info_[567].from_folded = false;
    constants_info_[567].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[567].shape = {1536};
    constants_info_[567].stride = {1};
    constants_info_[567].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[567].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.3.mlp_net.1.norm.0.bias";
    constants_info_[568].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[568].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[568].offset = 0;
    constants_info_[568].data_size = 3072;
    constants_info_[568].from_folded = false;
    constants_info_[568].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[568].shape = {1536};
    constants_info_[568].stride = {1};
    constants_info_[568].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[568].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.3.mlp_net.2._init_w";
    constants_info_[569].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[569].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[569].offset = 0;
    constants_info_[569].data_size = 3072;
    constants_info_[569].from_folded = false;
    constants_info_[569].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[569].shape = {1536};
    constants_info_[569].stride = {1};
    constants_info_[569].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[569].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.3.mlp_net.2._init_b";
    constants_info_[570].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_weight";
    constants_info_[570].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[570].offset = 0;
    constants_info_[570].data_size = 9437184;
    constants_info_[570].from_folded = false;
    constants_info_[570].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[570].shape = {3072, 1536};
    constants_info_[570].stride = {1536, 1};
    constants_info_[570].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[570].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.4.mlp_net.0.weight";
    constants_info_[571].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[571].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[571].offset = 0;
    constants_info_[571].data_size = 6144;
    constants_info_[571].from_folded = false;
    constants_info_[571].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[571].shape = {3072};
    constants_info_[571].stride = {1};
    constants_info_[571].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[571].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.4.mlp_net.0.bias";
    constants_info_[572].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[572].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[572].offset = 0;
    constants_info_[572].data_size = 6144;
    constants_info_[572].from_folded = false;
    constants_info_[572].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[572].shape = {3072};
    constants_info_[572].stride = {1};
    constants_info_[572].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[572].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.4.mlp_net.1._init_w";
    constants_info_[573].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[573].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[573].offset = 0;
    constants_info_[573].data_size = 6144;
    constants_info_[573].from_folded = false;
    constants_info_[573].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[573].shape = {3072};
    constants_info_[573].stride = {1};
    constants_info_[573].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[573].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._mlps.4.mlp_net.1._init_b";
    constants_info_[574].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[574].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[574].offset = 0;
    constants_info_[574].data_size = 6144;
    constants_info_[574].from_folded = false;
    constants_info_[574].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[574].shape = {3072};
    constants_info_[574].stride = {1};
    constants_info_[574].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[574].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._residual_activation.2.norm.0.weight";
    constants_info_[575].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[575].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[575].offset = 0;
    constants_info_[575].data_size = 6144;
    constants_info_[575].from_folded = false;
    constants_info_[575].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[575].shape = {3072};
    constants_info_[575].stride = {1};
    constants_info_[575].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[575].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._residual_activation.2.norm.0.bias";
    constants_info_[576].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[576].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[576].offset = 0;
    constants_info_[576].data_size = 6144;
    constants_info_[576].from_folded = false;
    constants_info_[576].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[576].shape = {3072};
    constants_info_[576].stride = {1};
    constants_info_[576].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[576].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._residual_activation.4.norm.0.weight";
    constants_info_[577].name = "submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[577].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[577].offset = 0;
    constants_info_[577].data_size = 6144;
    constants_info_[577].from_folded = false;
    constants_info_[577].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[577].shape = {3072};
    constants_info_[577].stride = {1};
    constants_info_[577].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[577].original_fqn = "submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers.3._residual_mlp._residual_activation.4.norm.0.bias";
    constants_info_[578].name = "submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w";
    constants_info_[578].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[578].offset = 0;
    constants_info_[578].data_size = 3145728;
    constants_info_[578].from_folded = false;
    constants_info_[578].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[578].shape = {512, 3072};
    constants_info_[578].stride = {3072, 1};
    constants_info_[578].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[578].original_fqn = "submod_0.main_module.impl.impl.shared_arch.cyclegan.encoder.linear_archs.0.shards.0.w";
    constants_info_[579].name = "submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b";
    constants_info_[579].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[579].offset = 0;
    constants_info_[579].data_size = 1024;
    constants_info_[579].from_folded = false;
    constants_info_[579].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[579].shape = {512};
    constants_info_[579].stride = {1};
    constants_info_[579].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[579].original_fqn = "submod_0.main_module.impl.impl.shared_arch.cyclegan.encoder.linear_archs.0.shards.0.b";
    constants_info_[580].name = "submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w";
    constants_info_[580].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[580].offset = 0;
    constants_info_[580].data_size = 3145728;
    constants_info_[580].from_folded = false;
    constants_info_[580].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[580].shape = {3072, 512};
    constants_info_[580].stride = {512, 1};
    constants_info_[580].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[580].original_fqn = "submod_0.main_module.impl.impl.shared_arch.cyclegan.encoder.linear_archs.1.shards.0.w";
    constants_info_[581].name = "submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b";
    constants_info_[581].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[581].offset = 0;
    constants_info_[581].data_size = 6144;
    constants_info_[581].from_folded = false;
    constants_info_[581].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[581].shape = {3072};
    constants_info_[581].stride = {1};
    constants_info_[581].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[581].original_fqn = "submod_0.main_module.impl.impl.shared_arch.cyclegan.encoder.linear_archs.1.shards.0.b";
    constants_info_[582].name = "submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w";
    constants_info_[582].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[582].offset = 0;
    constants_info_[582].data_size = 3145728;
    constants_info_[582].from_folded = false;
    constants_info_[582].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[582].shape = {512, 3072};
    constants_info_[582].stride = {3072, 1};
    constants_info_[582].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[582].original_fqn = "submod_0.main_module.impl.impl.shared_arch.cyclegan.decoder.linear_archs.0.shards.0.w";
    constants_info_[583].name = "submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b";
    constants_info_[583].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[583].offset = 0;
    constants_info_[583].data_size = 1024;
    constants_info_[583].from_folded = false;
    constants_info_[583].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[583].shape = {512};
    constants_info_[583].stride = {1};
    constants_info_[583].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[583].original_fqn = "submod_0.main_module.impl.impl.shared_arch.cyclegan.decoder.linear_archs.0.shards.0.b";
    constants_info_[584].name = "submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w";
    constants_info_[584].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[584].offset = 0;
    constants_info_[584].data_size = 3145728;
    constants_info_[584].from_folded = false;
    constants_info_[584].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[584].shape = {3072, 512};
    constants_info_[584].stride = {512, 1};
    constants_info_[584].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[584].original_fqn = "submod_0.main_module.impl.impl.shared_arch.cyclegan.decoder.linear_archs.1.shards.0.w";
    constants_info_[585].name = "submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b";
    constants_info_[585].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[585].offset = 0;
    constants_info_[585].data_size = 6144;
    constants_info_[585].from_folded = false;
    constants_info_[585].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[585].shape = {3072};
    constants_info_[585].stride = {1};
    constants_info_[585].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[585].original_fqn = "submod_0.main_module.impl.impl.shared_arch.cyclegan.decoder.linear_archs.1.shards.0.b";
    constants_info_[586].name = "submod_0_main_module_impl_impl_dependent_tasks_1_SALR_STANDALONE_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias";
    constants_info_[586].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[586].offset = 0;
    constants_info_[586].data_size = 2;
    constants_info_[586].from_folded = false;
    constants_info_[586].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[586].shape = {1};
    constants_info_[586].stride = {1};
    constants_info_[586].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[586].original_fqn = "submod_0.main_module.impl.impl.dependent_tasks.1:SALR_STANDALONE.aggregator_module.task_arch.sparse_aggregates_logistic_regression.global_bias";
    constants_info_[587].name = "submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w";
    constants_info_[587].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[587].offset = 0;
    constants_info_[587].data_size = 18874368;
    constants_info_[587].from_folded = false;
    constants_info_[587].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[587].shape = {3072, 3072};
    constants_info_[587].stride = {3072, 1};
    constants_info_[587].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[587].original_fqn = "submod_0.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.0.shards.0.w";
    constants_info_[588].name = "submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b";
    constants_info_[588].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[588].offset = 0;
    constants_info_[588].data_size = 6144;
    constants_info_[588].from_folded = false;
    constants_info_[588].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[588].shape = {3072};
    constants_info_[588].stride = {1};
    constants_info_[588].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[588].original_fqn = "submod_0.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.dense_arch.dense_projection_arch.gating_archs.0.gn_arch.submodules.0.shards.0.b";
    constants_info_[589].name = "submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w";
    constants_info_[589].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[589].offset = 0;
    constants_info_[589].data_size = 3145728;
    constants_info_[589].from_folded = false;
    constants_info_[589].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[589].shape = {512, 3072};
    constants_info_[589].stride = {3072, 1};
    constants_info_[589].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[589].original_fqn = "submod_0.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.dense_arch.dense_projection_arch.linear_archs.0.shards.0.w";
    constants_info_[590].name = "submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b";
    constants_info_[590].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[590].offset = 0;
    constants_info_[590].data_size = 1024;
    constants_info_[590].from_folded = false;
    constants_info_[590].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[590].shape = {512};
    constants_info_[590].stride = {1};
    constants_info_[590].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[590].original_fqn = "submod_0.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.dense_arch.dense_projection_arch.linear_archs.0.shards.0.b";
    constants_info_[591].name = "submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w";
    constants_info_[591].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[591].offset = 0;
    constants_info_[591].data_size = 1024;
    constants_info_[591].from_folded = false;
    constants_info_[591].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[591].shape = {1, 512};
    constants_info_[591].stride = {512, 1};
    constants_info_[591].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[591].original_fqn = "submod_0.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.dense_arch.dense_projection_arch.linear_archs.1.shards.0.w";
    constants_info_[592].name = "submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b";
    constants_info_[592].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[592].offset = 0;
    constants_info_[592].data_size = 2;
    constants_info_[592].from_folded = false;
    constants_info_[592].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[592].shape = {1};
    constants_info_[592].stride = {1};
    constants_info_[592].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[592].original_fqn = "submod_0.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.dense_arch.dense_projection_arch.linear_archs.1.shards.0.b";
    constants_info_[593].name = "submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale";
    constants_info_[593].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[593].offset = 0;
    constants_info_[593].data_size = 1024;
    constants_info_[593].from_folded = false;
    constants_info_[593].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[593].shape = {512};
    constants_info_[593].stride = {1};
    constants_info_[593].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[593].original_fqn = "submod_0.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.dense_arch.dense_projection_arch.activations.0.norm.submodules.0.scale";
    constants_info_[594].name = "submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias";
    constants_info_[594].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[594].offset = 0;
    constants_info_[594].data_size = 1024;
    constants_info_[594].from_folded = false;
    constants_info_[594].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[594].shape = {512};
    constants_info_[594].stride = {1};
    constants_info_[594].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[594].original_fqn = "submod_0.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.dense_arch.dense_projection_arch.activations.0.norm.submodules.0.bias";
    constants_info_[595].name = "_tensor_constant2";
    constants_info_[595].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[595].offset = 0;
    constants_info_[595].data_size = 2;
    constants_info_[595].from_folded = false;
    constants_info_[595].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::TensorConstant);
    constants_info_[595].shape = {1};
    constants_info_[595].stride = {1};
    constants_info_[595].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[595].original_fqn = "_tensor_constant2";
    constants_info_[596].name = "submod_0_cat_fusion_gpu__offset_dim_list";
    constants_info_[596].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[596].offset = 0;
    constants_info_[596].data_size = 2216;
    constants_info_[596].from_folded = false;
    constants_info_[596].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[596].shape = {277};
    constants_info_[596].stride = {1};
    constants_info_[596].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[596].original_fqn = "submod_0.cat_fusion_gpu._offset_dim_list";
    constants_info_[597].name = "submod_0_cat_fusion_gpu__permute";
    constants_info_[597].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[597].offset = 0;
    constants_info_[597].data_size = 2208;
    constants_info_[597].from_folded = false;
    constants_info_[597].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[597].shape = {276};
    constants_info_[597].stride = {1};
    constants_info_[597].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[597].original_fqn = "submod_0.cat_fusion_gpu._permute";
    constants_info_[598].name = "submod_0_cat_fusion_gpu__inv_permute";
    constants_info_[598].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[598].offset = 0;
    constants_info_[598].data_size = 2208;
    constants_info_[598].from_folded = false;
    constants_info_[598].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[598].shape = {276};
    constants_info_[598].stride = {1};
    constants_info_[598].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[598].original_fqn = "submod_0.cat_fusion_gpu._inv_permute";
    constants_info_[599].name = "submod_0_cat_fusion_gpu__inv_offset_dim_list";
    constants_info_[599].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[599].offset = 0;
    constants_info_[599].data_size = 2216;
    constants_info_[599].from_folded = false;
    constants_info_[599].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[599].shape = {277};
    constants_info_[599].stride = {1};
    constants_info_[599].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[599].original_fqn = "submod_0.cat_fusion_gpu._inv_offset_dim_list";
    constants_info_[600].name = "submod_0_cat_fusion_cpu__offset_dim_list";
    constants_info_[600].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[600].offset = 0;
    constants_info_[600].data_size = 1464;
    constants_info_[600].from_folded = false;
    constants_info_[600].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[600].shape = {183};
    constants_info_[600].stride = {1};
    constants_info_[600].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[600].original_fqn = "submod_0.cat_fusion_cpu._offset_dim_list";
    constants_info_[601].name = "submod_0_cat_fusion_cpu__permute";
    constants_info_[601].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[601].offset = 0;
    constants_info_[601].data_size = 1456;
    constants_info_[601].from_folded = false;
    constants_info_[601].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[601].shape = {182};
    constants_info_[601].stride = {1};
    constants_info_[601].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[601].original_fqn = "submod_0.cat_fusion_cpu._permute";
    constants_info_[602].name = "submod_0_cat_fusion_cpu__inv_permute";
    constants_info_[602].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[602].offset = 0;
    constants_info_[602].data_size = 1456;
    constants_info_[602].from_folded = false;
    constants_info_[602].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[602].shape = {182};
    constants_info_[602].stride = {1};
    constants_info_[602].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[602].original_fqn = "submod_0.cat_fusion_cpu._inv_permute";
    constants_info_[603].name = "submod_0_cat_fusion_cpu__inv_offset_dim_list";
    constants_info_[603].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[603].offset = 0;
    constants_info_[603].data_size = 1464;
    constants_info_[603].from_folded = false;
    constants_info_[603].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[603].shape = {183};
    constants_info_[603].stride = {1};
    constants_info_[603].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[603].original_fqn = "submod_0.cat_fusion_cpu._inv_offset_dim_list";
    constants_info_[604].name = "submod_1__tensor_constant1";
    constants_info_[604].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[604].offset = 0;
    constants_info_[604].data_size = 2;
    constants_info_[604].from_folded = false;
    constants_info_[604].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[604].shape = {};
    constants_info_[604].stride = {};
    constants_info_[604].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[604].original_fqn = "submod_1._tensor_constant1";
    constants_info_[605].name = "submod_1_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_calibration_positive_weight_calibration_bias";
    constants_info_[605].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[605].offset = 0;
    constants_info_[605].data_size = 2;
    constants_info_[605].from_folded = false;
    constants_info_[605].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::Unknown);
    constants_info_[605].shape = {1};
    constants_info_[605].stride = {1};
    constants_info_[605].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[605].original_fqn = "submod_1.main_module.impl.impl.task_archs.1:Optimized.prediction_arch.calibration.positive_weight_calibration_bias";
    constants_info_[606].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[606].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[606].offset = 0;
    constants_info_[606].data_size = 384;
    constants_info_[606].from_folded = true;
    constants_info_[606].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[606].shape = {192};
    constants_info_[606].stride = {1};
    constants_info_[606].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[606].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[607].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale";
    constants_info_[607].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[607].offset = 0;
    constants_info_[607].data_size = 384;
    constants_info_[607].from_folded = true;
    constants_info_[607].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[607].shape = {192};
    constants_info_[607].stride = {1};
    constants_info_[607].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[607].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale";
    constants_info_[608].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias";
    constants_info_[608].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[608].offset = 0;
    constants_info_[608].data_size = 384;
    constants_info_[608].from_folded = true;
    constants_info_[608].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[608].shape = {192};
    constants_info_[608].stride = {1};
    constants_info_[608].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[608].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias";
    constants_info_[609].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[609].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[609].offset = 0;
    constants_info_[609].data_size = 384;
    constants_info_[609].from_folded = true;
    constants_info_[609].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[609].shape = {192};
    constants_info_[609].stride = {1};
    constants_info_[609].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[609].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[610].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale";
    constants_info_[610].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[610].offset = 0;
    constants_info_[610].data_size = 384;
    constants_info_[610].from_folded = true;
    constants_info_[610].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[610].shape = {192};
    constants_info_[610].stride = {1};
    constants_info_[610].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[610].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale";
    constants_info_[611].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias";
    constants_info_[611].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[611].offset = 0;
    constants_info_[611].data_size = 384;
    constants_info_[611].from_folded = true;
    constants_info_[611].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[611].shape = {192};
    constants_info_[611].stride = {1};
    constants_info_[611].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[611].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias";
    constants_info_[612].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[612].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[612].offset = 0;
    constants_info_[612].data_size = 384;
    constants_info_[612].from_folded = true;
    constants_info_[612].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[612].shape = {192};
    constants_info_[612].stride = {1};
    constants_info_[612].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[612].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[613].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale";
    constants_info_[613].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[613].offset = 0;
    constants_info_[613].data_size = 384;
    constants_info_[613].from_folded = true;
    constants_info_[613].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[613].shape = {192};
    constants_info_[613].stride = {1};
    constants_info_[613].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[613].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale";
    constants_info_[614].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias";
    constants_info_[614].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[614].offset = 0;
    constants_info_[614].data_size = 384;
    constants_info_[614].from_folded = true;
    constants_info_[614].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[614].shape = {192};
    constants_info_[614].stride = {1};
    constants_info_[614].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[614].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias";
    constants_info_[615].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[615].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[615].offset = 0;
    constants_info_[615].data_size = 384;
    constants_info_[615].from_folded = true;
    constants_info_[615].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[615].shape = {192};
    constants_info_[615].stride = {1};
    constants_info_[615].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[615].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[616].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale";
    constants_info_[616].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[616].offset = 0;
    constants_info_[616].data_size = 384;
    constants_info_[616].from_folded = true;
    constants_info_[616].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[616].shape = {192};
    constants_info_[616].stride = {1};
    constants_info_[616].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[616].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale";
    constants_info_[617].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias";
    constants_info_[617].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[617].offset = 0;
    constants_info_[617].data_size = 384;
    constants_info_[617].from_folded = true;
    constants_info_[617].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[617].shape = {192};
    constants_info_[617].stride = {1};
    constants_info_[617].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[617].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias";
    constants_info_[618].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[618].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[618].offset = 0;
    constants_info_[618].data_size = 384;
    constants_info_[618].from_folded = true;
    constants_info_[618].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[618].shape = {192};
    constants_info_[618].stride = {1};
    constants_info_[618].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[618].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[619].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale";
    constants_info_[619].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[619].offset = 0;
    constants_info_[619].data_size = 384;
    constants_info_[619].from_folded = true;
    constants_info_[619].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[619].shape = {192};
    constants_info_[619].stride = {1};
    constants_info_[619].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[619].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale";
    constants_info_[620].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias";
    constants_info_[620].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[620].offset = 0;
    constants_info_[620].data_size = 384;
    constants_info_[620].from_folded = true;
    constants_info_[620].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[620].shape = {192};
    constants_info_[620].stride = {1};
    constants_info_[620].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[620].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias";
    constants_info_[621].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[621].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[621].offset = 0;
    constants_info_[621].data_size = 384;
    constants_info_[621].from_folded = true;
    constants_info_[621].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[621].shape = {192};
    constants_info_[621].stride = {1};
    constants_info_[621].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[621].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[622].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale";
    constants_info_[622].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[622].offset = 0;
    constants_info_[622].data_size = 384;
    constants_info_[622].from_folded = true;
    constants_info_[622].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[622].shape = {192};
    constants_info_[622].stride = {1};
    constants_info_[622].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[622].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale";
    constants_info_[623].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias";
    constants_info_[623].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[623].offset = 0;
    constants_info_[623].data_size = 384;
    constants_info_[623].from_folded = true;
    constants_info_[623].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[623].shape = {192};
    constants_info_[623].stride = {1};
    constants_info_[623].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[623].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias";
    constants_info_[624].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[624].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[624].offset = 0;
    constants_info_[624].data_size = 384;
    constants_info_[624].from_folded = true;
    constants_info_[624].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[624].shape = {192};
    constants_info_[624].stride = {1};
    constants_info_[624].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[624].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[625].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale";
    constants_info_[625].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[625].offset = 0;
    constants_info_[625].data_size = 384;
    constants_info_[625].from_folded = true;
    constants_info_[625].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[625].shape = {192};
    constants_info_[625].stride = {1};
    constants_info_[625].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[625].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale";
    constants_info_[626].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias";
    constants_info_[626].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[626].offset = 0;
    constants_info_[626].data_size = 384;
    constants_info_[626].from_folded = true;
    constants_info_[626].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[626].shape = {192};
    constants_info_[626].stride = {1};
    constants_info_[626].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[626].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias";
    constants_info_[627].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[627].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[627].offset = 0;
    constants_info_[627].data_size = 384;
    constants_info_[627].from_folded = true;
    constants_info_[627].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[627].shape = {192};
    constants_info_[627].stride = {1};
    constants_info_[627].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[627].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[628].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale";
    constants_info_[628].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[628].offset = 0;
    constants_info_[628].data_size = 384;
    constants_info_[628].from_folded = true;
    constants_info_[628].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[628].shape = {192};
    constants_info_[628].stride = {1};
    constants_info_[628].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[628].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale";
    constants_info_[629].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias";
    constants_info_[629].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[629].offset = 0;
    constants_info_[629].data_size = 384;
    constants_info_[629].from_folded = true;
    constants_info_[629].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[629].shape = {192};
    constants_info_[629].stride = {1};
    constants_info_[629].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[629].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias";
    constants_info_[630].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[630].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[630].offset = 0;
    constants_info_[630].data_size = 384;
    constants_info_[630].from_folded = true;
    constants_info_[630].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[630].shape = {192};
    constants_info_[630].stride = {1};
    constants_info_[630].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[630].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[631].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale";
    constants_info_[631].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[631].offset = 0;
    constants_info_[631].data_size = 384;
    constants_info_[631].from_folded = true;
    constants_info_[631].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[631].shape = {192};
    constants_info_[631].stride = {1};
    constants_info_[631].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[631].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale";
    constants_info_[632].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias";
    constants_info_[632].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[632].offset = 0;
    constants_info_[632].data_size = 384;
    constants_info_[632].from_folded = true;
    constants_info_[632].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[632].shape = {192};
    constants_info_[632].stride = {1};
    constants_info_[632].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[632].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias";
    constants_info_[633].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[633].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[633].offset = 0;
    constants_info_[633].data_size = 384;
    constants_info_[633].from_folded = true;
    constants_info_[633].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[633].shape = {192};
    constants_info_[633].stride = {1};
    constants_info_[633].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[633].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[634].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale";
    constants_info_[634].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[634].offset = 0;
    constants_info_[634].data_size = 384;
    constants_info_[634].from_folded = true;
    constants_info_[634].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[634].shape = {192};
    constants_info_[634].stride = {1};
    constants_info_[634].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[634].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale";
    constants_info_[635].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias";
    constants_info_[635].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[635].offset = 0;
    constants_info_[635].data_size = 384;
    constants_info_[635].from_folded = true;
    constants_info_[635].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[635].shape = {192};
    constants_info_[635].stride = {1};
    constants_info_[635].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[635].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias";
    constants_info_[636].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[636].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[636].offset = 0;
    constants_info_[636].data_size = 384;
    constants_info_[636].from_folded = true;
    constants_info_[636].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[636].shape = {192};
    constants_info_[636].stride = {1};
    constants_info_[636].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[636].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[637].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale";
    constants_info_[637].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[637].offset = 0;
    constants_info_[637].data_size = 384;
    constants_info_[637].from_folded = true;
    constants_info_[637].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[637].shape = {192};
    constants_info_[637].stride = {1};
    constants_info_[637].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[637].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale";
    constants_info_[638].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias";
    constants_info_[638].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[638].offset = 0;
    constants_info_[638].data_size = 384;
    constants_info_[638].from_folded = true;
    constants_info_[638].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[638].shape = {192};
    constants_info_[638].stride = {1};
    constants_info_[638].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[638].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias";
    constants_info_[639].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[639].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[639].offset = 0;
    constants_info_[639].data_size = 384;
    constants_info_[639].from_folded = true;
    constants_info_[639].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[639].shape = {192};
    constants_info_[639].stride = {1};
    constants_info_[639].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[639].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[640].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale";
    constants_info_[640].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[640].offset = 0;
    constants_info_[640].data_size = 384;
    constants_info_[640].from_folded = true;
    constants_info_[640].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[640].shape = {192};
    constants_info_[640].stride = {1};
    constants_info_[640].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[640].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale";
    constants_info_[641].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias";
    constants_info_[641].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[641].offset = 0;
    constants_info_[641].data_size = 384;
    constants_info_[641].from_folded = true;
    constants_info_[641].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[641].shape = {192};
    constants_info_[641].stride = {1};
    constants_info_[641].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[641].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias";
    constants_info_[642].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[642].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[642].offset = 0;
    constants_info_[642].data_size = 384;
    constants_info_[642].from_folded = true;
    constants_info_[642].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[642].shape = {192};
    constants_info_[642].stride = {1};
    constants_info_[642].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[642].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[643].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale";
    constants_info_[643].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[643].offset = 0;
    constants_info_[643].data_size = 384;
    constants_info_[643].from_folded = true;
    constants_info_[643].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[643].shape = {192};
    constants_info_[643].stride = {1};
    constants_info_[643].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[643].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale";
    constants_info_[644].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias";
    constants_info_[644].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[644].offset = 0;
    constants_info_[644].data_size = 384;
    constants_info_[644].from_folded = true;
    constants_info_[644].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[644].shape = {192};
    constants_info_[644].stride = {1};
    constants_info_[644].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[644].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias";
    constants_info_[645].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[645].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[645].offset = 0;
    constants_info_[645].data_size = 384;
    constants_info_[645].from_folded = true;
    constants_info_[645].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[645].shape = {192};
    constants_info_[645].stride = {1};
    constants_info_[645].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[645].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[646].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale";
    constants_info_[646].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[646].offset = 0;
    constants_info_[646].data_size = 384;
    constants_info_[646].from_folded = true;
    constants_info_[646].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[646].shape = {192};
    constants_info_[646].stride = {1};
    constants_info_[646].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[646].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale";
    constants_info_[647].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias";
    constants_info_[647].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[647].offset = 0;
    constants_info_[647].data_size = 384;
    constants_info_[647].from_folded = true;
    constants_info_[647].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[647].shape = {192};
    constants_info_[647].stride = {1};
    constants_info_[647].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[647].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias";
    constants_info_[648].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[648].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[648].offset = 0;
    constants_info_[648].data_size = 384;
    constants_info_[648].from_folded = true;
    constants_info_[648].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[648].shape = {192};
    constants_info_[648].stride = {1};
    constants_info_[648].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[648].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[649].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale";
    constants_info_[649].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[649].offset = 0;
    constants_info_[649].data_size = 384;
    constants_info_[649].from_folded = true;
    constants_info_[649].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[649].shape = {192};
    constants_info_[649].stride = {1};
    constants_info_[649].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[649].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale";
    constants_info_[650].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias";
    constants_info_[650].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[650].offset = 0;
    constants_info_[650].data_size = 384;
    constants_info_[650].from_folded = true;
    constants_info_[650].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[650].shape = {192};
    constants_info_[650].stride = {1};
    constants_info_[650].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[650].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias";
    constants_info_[651].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[651].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[651].offset = 0;
    constants_info_[651].data_size = 384;
    constants_info_[651].from_folded = true;
    constants_info_[651].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[651].shape = {192};
    constants_info_[651].stride = {1};
    constants_info_[651].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[651].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[652].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale";
    constants_info_[652].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[652].offset = 0;
    constants_info_[652].data_size = 384;
    constants_info_[652].from_folded = true;
    constants_info_[652].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[652].shape = {192};
    constants_info_[652].stride = {1};
    constants_info_[652].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[652].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale";
    constants_info_[653].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias";
    constants_info_[653].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[653].offset = 0;
    constants_info_[653].data_size = 384;
    constants_info_[653].from_folded = true;
    constants_info_[653].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[653].shape = {192};
    constants_info_[653].stride = {1};
    constants_info_[653].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[653].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias";
    constants_info_[654].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[654].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[654].offset = 0;
    constants_info_[654].data_size = 384;
    constants_info_[654].from_folded = true;
    constants_info_[654].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[654].shape = {192};
    constants_info_[654].stride = {1};
    constants_info_[654].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[654].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[655].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale";
    constants_info_[655].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[655].offset = 0;
    constants_info_[655].data_size = 384;
    constants_info_[655].from_folded = true;
    constants_info_[655].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[655].shape = {192};
    constants_info_[655].stride = {1};
    constants_info_[655].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[655].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale";
    constants_info_[656].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias";
    constants_info_[656].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[656].offset = 0;
    constants_info_[656].data_size = 384;
    constants_info_[656].from_folded = true;
    constants_info_[656].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[656].shape = {192};
    constants_info_[656].stride = {1};
    constants_info_[656].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[656].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias";
    constants_info_[657].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[657].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[657].offset = 0;
    constants_info_[657].data_size = 384;
    constants_info_[657].from_folded = true;
    constants_info_[657].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[657].shape = {192};
    constants_info_[657].stride = {1};
    constants_info_[657].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[657].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[658].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale";
    constants_info_[658].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[658].offset = 0;
    constants_info_[658].data_size = 384;
    constants_info_[658].from_folded = true;
    constants_info_[658].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[658].shape = {192};
    constants_info_[658].stride = {1};
    constants_info_[658].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[658].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale";
    constants_info_[659].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias";
    constants_info_[659].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[659].offset = 0;
    constants_info_[659].data_size = 384;
    constants_info_[659].from_folded = true;
    constants_info_[659].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[659].shape = {192};
    constants_info_[659].stride = {1};
    constants_info_[659].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[659].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias";
    constants_info_[660].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[660].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[660].offset = 0;
    constants_info_[660].data_size = 384;
    constants_info_[660].from_folded = true;
    constants_info_[660].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[660].shape = {192};
    constants_info_[660].stride = {1};
    constants_info_[660].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[660].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[661].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale";
    constants_info_[661].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[661].offset = 0;
    constants_info_[661].data_size = 384;
    constants_info_[661].from_folded = true;
    constants_info_[661].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[661].shape = {192};
    constants_info_[661].stride = {1};
    constants_info_[661].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[661].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale";
    constants_info_[662].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias";
    constants_info_[662].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[662].offset = 0;
    constants_info_[662].data_size = 384;
    constants_info_[662].from_folded = true;
    constants_info_[662].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[662].shape = {192};
    constants_info_[662].stride = {1};
    constants_info_[662].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[662].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias";
    constants_info_[663].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[663].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[663].offset = 0;
    constants_info_[663].data_size = 384;
    constants_info_[663].from_folded = true;
    constants_info_[663].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[663].shape = {192};
    constants_info_[663].stride = {1};
    constants_info_[663].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[663].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[664].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale";
    constants_info_[664].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[664].offset = 0;
    constants_info_[664].data_size = 384;
    constants_info_[664].from_folded = true;
    constants_info_[664].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[664].shape = {192};
    constants_info_[664].stride = {1};
    constants_info_[664].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[664].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale";
    constants_info_[665].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias";
    constants_info_[665].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[665].offset = 0;
    constants_info_[665].data_size = 384;
    constants_info_[665].from_folded = true;
    constants_info_[665].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[665].shape = {192};
    constants_info_[665].stride = {1};
    constants_info_[665].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[665].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias";
    constants_info_[666].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[666].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[666].offset = 0;
    constants_info_[666].data_size = 384;
    constants_info_[666].from_folded = true;
    constants_info_[666].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[666].shape = {192};
    constants_info_[666].stride = {1};
    constants_info_[666].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[666].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[667].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale";
    constants_info_[667].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[667].offset = 0;
    constants_info_[667].data_size = 384;
    constants_info_[667].from_folded = true;
    constants_info_[667].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[667].shape = {192};
    constants_info_[667].stride = {1};
    constants_info_[667].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[667].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale";
    constants_info_[668].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias";
    constants_info_[668].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[668].offset = 0;
    constants_info_[668].data_size = 384;
    constants_info_[668].from_folded = true;
    constants_info_[668].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[668].shape = {192};
    constants_info_[668].stride = {1};
    constants_info_[668].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[668].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias";
    constants_info_[669].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[669].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[669].offset = 0;
    constants_info_[669].data_size = 384;
    constants_info_[669].from_folded = true;
    constants_info_[669].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[669].shape = {192};
    constants_info_[669].stride = {1};
    constants_info_[669].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[669].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[670].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale";
    constants_info_[670].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[670].offset = 0;
    constants_info_[670].data_size = 384;
    constants_info_[670].from_folded = true;
    constants_info_[670].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[670].shape = {192};
    constants_info_[670].stride = {1};
    constants_info_[670].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[670].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale";
    constants_info_[671].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias";
    constants_info_[671].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[671].offset = 0;
    constants_info_[671].data_size = 384;
    constants_info_[671].from_folded = true;
    constants_info_[671].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[671].shape = {192};
    constants_info_[671].stride = {1};
    constants_info_[671].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[671].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias";
    constants_info_[672].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[672].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[672].offset = 0;
    constants_info_[672].data_size = 384;
    constants_info_[672].from_folded = true;
    constants_info_[672].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[672].shape = {192};
    constants_info_[672].stride = {1};
    constants_info_[672].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[672].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[673].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale";
    constants_info_[673].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[673].offset = 0;
    constants_info_[673].data_size = 384;
    constants_info_[673].from_folded = true;
    constants_info_[673].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[673].shape = {192};
    constants_info_[673].stride = {1};
    constants_info_[673].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[673].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale";
    constants_info_[674].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias";
    constants_info_[674].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[674].offset = 0;
    constants_info_[674].data_size = 384;
    constants_info_[674].from_folded = true;
    constants_info_[674].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[674].shape = {192};
    constants_info_[674].stride = {1};
    constants_info_[674].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[674].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias";
    constants_info_[675].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[675].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[675].offset = 0;
    constants_info_[675].data_size = 384;
    constants_info_[675].from_folded = true;
    constants_info_[675].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[675].shape = {192};
    constants_info_[675].stride = {1};
    constants_info_[675].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[675].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[676].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale";
    constants_info_[676].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[676].offset = 0;
    constants_info_[676].data_size = 384;
    constants_info_[676].from_folded = true;
    constants_info_[676].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[676].shape = {192};
    constants_info_[676].stride = {1};
    constants_info_[676].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[676].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale";
    constants_info_[677].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias";
    constants_info_[677].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[677].offset = 0;
    constants_info_[677].data_size = 384;
    constants_info_[677].from_folded = true;
    constants_info_[677].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[677].shape = {192};
    constants_info_[677].stride = {1};
    constants_info_[677].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[677].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias";
    constants_info_[678].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[678].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[678].offset = 0;
    constants_info_[678].data_size = 384;
    constants_info_[678].from_folded = true;
    constants_info_[678].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[678].shape = {192};
    constants_info_[678].stride = {1};
    constants_info_[678].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[678].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[679].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale";
    constants_info_[679].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[679].offset = 0;
    constants_info_[679].data_size = 384;
    constants_info_[679].from_folded = true;
    constants_info_[679].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[679].shape = {192};
    constants_info_[679].stride = {1};
    constants_info_[679].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[679].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale";
    constants_info_[680].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias";
    constants_info_[680].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[680].offset = 0;
    constants_info_[680].data_size = 384;
    constants_info_[680].from_folded = true;
    constants_info_[680].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[680].shape = {192};
    constants_info_[680].stride = {1};
    constants_info_[680].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[680].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias";
    constants_info_[681].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[681].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[681].offset = 0;
    constants_info_[681].data_size = 384;
    constants_info_[681].from_folded = true;
    constants_info_[681].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[681].shape = {192};
    constants_info_[681].stride = {1};
    constants_info_[681].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[681].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[682].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale";
    constants_info_[682].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[682].offset = 0;
    constants_info_[682].data_size = 384;
    constants_info_[682].from_folded = true;
    constants_info_[682].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[682].shape = {192};
    constants_info_[682].stride = {1};
    constants_info_[682].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[682].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale";
    constants_info_[683].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias";
    constants_info_[683].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[683].offset = 0;
    constants_info_[683].data_size = 384;
    constants_info_[683].from_folded = true;
    constants_info_[683].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[683].shape = {192};
    constants_info_[683].stride = {1};
    constants_info_[683].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[683].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias";
    constants_info_[684].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[684].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[684].offset = 0;
    constants_info_[684].data_size = 384;
    constants_info_[684].from_folded = true;
    constants_info_[684].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[684].shape = {192};
    constants_info_[684].stride = {1};
    constants_info_[684].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[684].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[685].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale";
    constants_info_[685].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[685].offset = 0;
    constants_info_[685].data_size = 384;
    constants_info_[685].from_folded = true;
    constants_info_[685].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[685].shape = {192};
    constants_info_[685].stride = {1};
    constants_info_[685].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[685].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale";
    constants_info_[686].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias";
    constants_info_[686].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[686].offset = 0;
    constants_info_[686].data_size = 384;
    constants_info_[686].from_folded = true;
    constants_info_[686].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[686].shape = {192};
    constants_info_[686].stride = {1};
    constants_info_[686].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[686].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias";
    constants_info_[687].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[687].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[687].offset = 0;
    constants_info_[687].data_size = 384;
    constants_info_[687].from_folded = true;
    constants_info_[687].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[687].shape = {192};
    constants_info_[687].stride = {1};
    constants_info_[687].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[687].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[688].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale";
    constants_info_[688].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[688].offset = 0;
    constants_info_[688].data_size = 384;
    constants_info_[688].from_folded = true;
    constants_info_[688].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[688].shape = {192};
    constants_info_[688].stride = {1};
    constants_info_[688].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[688].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale";
    constants_info_[689].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias";
    constants_info_[689].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[689].offset = 0;
    constants_info_[689].data_size = 384;
    constants_info_[689].from_folded = true;
    constants_info_[689].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[689].shape = {192};
    constants_info_[689].stride = {1};
    constants_info_[689].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[689].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias";
    constants_info_[690].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[690].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[690].offset = 0;
    constants_info_[690].data_size = 384;
    constants_info_[690].from_folded = true;
    constants_info_[690].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[690].shape = {192};
    constants_info_[690].stride = {1};
    constants_info_[690].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[690].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[691].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale";
    constants_info_[691].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[691].offset = 0;
    constants_info_[691].data_size = 384;
    constants_info_[691].from_folded = true;
    constants_info_[691].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[691].shape = {192};
    constants_info_[691].stride = {1};
    constants_info_[691].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[691].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale";
    constants_info_[692].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias";
    constants_info_[692].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[692].offset = 0;
    constants_info_[692].data_size = 384;
    constants_info_[692].from_folded = true;
    constants_info_[692].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[692].shape = {192};
    constants_info_[692].stride = {1};
    constants_info_[692].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[692].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias";
    constants_info_[693].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[693].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[693].offset = 0;
    constants_info_[693].data_size = 384;
    constants_info_[693].from_folded = true;
    constants_info_[693].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[693].shape = {192};
    constants_info_[693].stride = {1};
    constants_info_[693].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[693].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[694].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale";
    constants_info_[694].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[694].offset = 0;
    constants_info_[694].data_size = 384;
    constants_info_[694].from_folded = true;
    constants_info_[694].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[694].shape = {192};
    constants_info_[694].stride = {1};
    constants_info_[694].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[694].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale";
    constants_info_[695].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias";
    constants_info_[695].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[695].offset = 0;
    constants_info_[695].data_size = 384;
    constants_info_[695].from_folded = true;
    constants_info_[695].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[695].shape = {192};
    constants_info_[695].stride = {1};
    constants_info_[695].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[695].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias";
    constants_info_[696].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[696].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[696].offset = 0;
    constants_info_[696].data_size = 384;
    constants_info_[696].from_folded = true;
    constants_info_[696].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[696].shape = {192};
    constants_info_[696].stride = {1};
    constants_info_[696].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[696].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[697].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale";
    constants_info_[697].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[697].offset = 0;
    constants_info_[697].data_size = 384;
    constants_info_[697].from_folded = true;
    constants_info_[697].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[697].shape = {192};
    constants_info_[697].stride = {1};
    constants_info_[697].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[697].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale";
    constants_info_[698].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias";
    constants_info_[698].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[698].offset = 0;
    constants_info_[698].data_size = 384;
    constants_info_[698].from_folded = true;
    constants_info_[698].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[698].shape = {192};
    constants_info_[698].stride = {1};
    constants_info_[698].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[698].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias";
    constants_info_[699].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[699].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[699].offset = 0;
    constants_info_[699].data_size = 384;
    constants_info_[699].from_folded = true;
    constants_info_[699].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[699].shape = {192};
    constants_info_[699].stride = {1};
    constants_info_[699].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[699].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[700].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale";
    constants_info_[700].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[700].offset = 0;
    constants_info_[700].data_size = 384;
    constants_info_[700].from_folded = true;
    constants_info_[700].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[700].shape = {192};
    constants_info_[700].stride = {1};
    constants_info_[700].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[700].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale";
    constants_info_[701].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias";
    constants_info_[701].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[701].offset = 0;
    constants_info_[701].data_size = 384;
    constants_info_[701].from_folded = true;
    constants_info_[701].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[701].shape = {192};
    constants_info_[701].stride = {1};
    constants_info_[701].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[701].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias";
    constants_info_[702].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[702].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[702].offset = 0;
    constants_info_[702].data_size = 384;
    constants_info_[702].from_folded = true;
    constants_info_[702].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[702].shape = {192};
    constants_info_[702].stride = {1};
    constants_info_[702].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[702].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[703].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale";
    constants_info_[703].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[703].offset = 0;
    constants_info_[703].data_size = 384;
    constants_info_[703].from_folded = true;
    constants_info_[703].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[703].shape = {192};
    constants_info_[703].stride = {1};
    constants_info_[703].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[703].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale";
    constants_info_[704].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias";
    constants_info_[704].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[704].offset = 0;
    constants_info_[704].data_size = 384;
    constants_info_[704].from_folded = true;
    constants_info_[704].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[704].shape = {192};
    constants_info_[704].stride = {1};
    constants_info_[704].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[704].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias";
    constants_info_[705].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[705].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[705].offset = 0;
    constants_info_[705].data_size = 384;
    constants_info_[705].from_folded = true;
    constants_info_[705].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[705].shape = {192};
    constants_info_[705].stride = {1};
    constants_info_[705].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[705].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[706].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale";
    constants_info_[706].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[706].offset = 0;
    constants_info_[706].data_size = 384;
    constants_info_[706].from_folded = true;
    constants_info_[706].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[706].shape = {192};
    constants_info_[706].stride = {1};
    constants_info_[706].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[706].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale";
    constants_info_[707].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias";
    constants_info_[707].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[707].offset = 0;
    constants_info_[707].data_size = 384;
    constants_info_[707].from_folded = true;
    constants_info_[707].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[707].shape = {192};
    constants_info_[707].stride = {1};
    constants_info_[707].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[707].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias";
    constants_info_[708].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[708].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[708].offset = 0;
    constants_info_[708].data_size = 384;
    constants_info_[708].from_folded = true;
    constants_info_[708].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[708].shape = {192};
    constants_info_[708].stride = {1};
    constants_info_[708].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[708].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[709].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale";
    constants_info_[709].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[709].offset = 0;
    constants_info_[709].data_size = 384;
    constants_info_[709].from_folded = true;
    constants_info_[709].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[709].shape = {192};
    constants_info_[709].stride = {1};
    constants_info_[709].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[709].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale";
    constants_info_[710].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias";
    constants_info_[710].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[710].offset = 0;
    constants_info_[710].data_size = 384;
    constants_info_[710].from_folded = true;
    constants_info_[710].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[710].shape = {192};
    constants_info_[710].stride = {1};
    constants_info_[710].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[710].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias";
    constants_info_[711].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[711].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[711].offset = 0;
    constants_info_[711].data_size = 384;
    constants_info_[711].from_folded = true;
    constants_info_[711].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[711].shape = {192};
    constants_info_[711].stride = {1};
    constants_info_[711].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[711].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b";
    constants_info_[712].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale";
    constants_info_[712].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[712].offset = 0;
    constants_info_[712].data_size = 384;
    constants_info_[712].from_folded = true;
    constants_info_[712].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[712].shape = {192};
    constants_info_[712].stride = {1};
    constants_info_[712].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[712].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale";
    constants_info_[713].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias";
    constants_info_[713].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[713].offset = 0;
    constants_info_[713].data_size = 384;
    constants_info_[713].from_folded = true;
    constants_info_[713].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[713].shape = {192};
    constants_info_[713].stride = {1};
    constants_info_[713].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[713].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias";
    constants_info_[714].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale";
    constants_info_[714].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[714].offset = 0;
    constants_info_[714].data_size = 512;
    constants_info_[714].from_folded = true;
    constants_info_[714].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[714].shape = {256};
    constants_info_[714].stride = {1};
    constants_info_[714].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[714].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale";
    constants_info_[715].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias";
    constants_info_[715].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[715].offset = 0;
    constants_info_[715].data_size = 512;
    constants_info_[715].from_folded = true;
    constants_info_[715].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[715].shape = {256};
    constants_info_[715].stride = {1};
    constants_info_[715].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[715].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias";
    constants_info_[716].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b";
    constants_info_[716].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[716].offset = 0;
    constants_info_[716].data_size = 6052;
    constants_info_[716].from_folded = true;
    constants_info_[716].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[716].shape = {3026};
    constants_info_[716].stride = {1};
    constants_info_[716].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[716].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b";
    constants_info_[717].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b";
    constants_info_[717].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[717].offset = 0;
    constants_info_[717].data_size = 512;
    constants_info_[717].from_folded = true;
    constants_info_[717].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[717].shape = {256};
    constants_info_[717].stride = {1};
    constants_info_[717].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[717].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b";
    constants_info_[718].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale";
    constants_info_[718].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[718].offset = 0;
    constants_info_[718].data_size = 6564;
    constants_info_[718].from_folded = true;
    constants_info_[718].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[718].shape = {3282};
    constants_info_[718].stride = {1};
    constants_info_[718].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[718].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale";
    constants_info_[719].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias";
    constants_info_[719].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[719].offset = 0;
    constants_info_[719].data_size = 6564;
    constants_info_[719].from_folded = true;
    constants_info_[719].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[719].shape = {3282};
    constants_info_[719].stride = {1};
    constants_info_[719].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[719].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias";
    constants_info_[720].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale";
    constants_info_[720].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[720].offset = 0;
    constants_info_[720].data_size = 512;
    constants_info_[720].from_folded = true;
    constants_info_[720].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[720].shape = {256};
    constants_info_[720].stride = {1};
    constants_info_[720].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[720].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale";
    constants_info_[721].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias";
    constants_info_[721].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[721].offset = 0;
    constants_info_[721].data_size = 512;
    constants_info_[721].from_folded = true;
    constants_info_[721].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[721].shape = {256};
    constants_info_[721].stride = {1};
    constants_info_[721].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[721].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias";
    constants_info_[722].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b";
    constants_info_[722].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[722].offset = 0;
    constants_info_[722].data_size = 2048;
    constants_info_[722].from_folded = true;
    constants_info_[722].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[722].shape = {1024};
    constants_info_[722].stride = {1};
    constants_info_[722].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[722].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b";
    constants_info_[723].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale";
    constants_info_[723].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[723].offset = 0;
    constants_info_[723].data_size = 2048;
    constants_info_[723].from_folded = true;
    constants_info_[723].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[723].shape = {1024};
    constants_info_[723].stride = {1};
    constants_info_[723].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[723].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale";
    constants_info_[724].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias";
    constants_info_[724].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[724].offset = 0;
    constants_info_[724].data_size = 2048;
    constants_info_[724].from_folded = true;
    constants_info_[724].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[724].shape = {1024};
    constants_info_[724].stride = {1};
    constants_info_[724].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[724].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias";
    constants_info_[725].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b";
    constants_info_[725].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[725].offset = 0;
    constants_info_[725].data_size = 1920;
    constants_info_[725].from_folded = true;
    constants_info_[725].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[725].shape = {960};
    constants_info_[725].stride = {1};
    constants_info_[725].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[725].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b";
    constants_info_[726].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b";
    constants_info_[726].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[726].offset = 0;
    constants_info_[726].data_size = 3072;
    constants_info_[726].from_folded = true;
    constants_info_[726].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[726].shape = {1536};
    constants_info_[726].stride = {1};
    constants_info_[726].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[726].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b";
    constants_info_[727].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb";
    constants_info_[727].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[727].offset = 0;
    constants_info_[727].data_size = 25600;
    constants_info_[727].from_folded = true;
    constants_info_[727].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[727].shape = {1, 200, 64};
    constants_info_[727].stride = {12800, 64, 1};
    constants_info_[727].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[727].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb";
    constants_info_[728].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb";
    constants_info_[728].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[728].offset = 0;
    constants_info_[728].data_size = 4096;
    constants_info_[728].from_folded = true;
    constants_info_[728].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[728].shape = {1, 32, 64};
    constants_info_[728].stride = {2048, 64, 1};
    constants_info_[728].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[728].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb";
    constants_info_[729].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight";
    constants_info_[729].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[729].offset = 0;
    constants_info_[729].data_size = 128;
    constants_info_[729].from_folded = true;
    constants_info_[729].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[729].shape = {64};
    constants_info_[729].stride = {1};
    constants_info_[729].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[729].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight";
    constants_info_[730].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias";
    constants_info_[730].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[730].offset = 0;
    constants_info_[730].data_size = 128;
    constants_info_[730].from_folded = true;
    constants_info_[730].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[730].shape = {64};
    constants_info_[730].stride = {1};
    constants_info_[730].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[730].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias";
    constants_info_[731].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias";
    constants_info_[731].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[731].offset = 0;
    constants_info_[731].data_size = 128;
    constants_info_[731].from_folded = true;
    constants_info_[731].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[731].shape = {64};
    constants_info_[731].stride = {1};
    constants_info_[731].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[731].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias";
    constants_info_[732].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight";
    constants_info_[732].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[732].offset = 0;
    constants_info_[732].data_size = 128;
    constants_info_[732].from_folded = true;
    constants_info_[732].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[732].shape = {64};
    constants_info_[732].stride = {1};
    constants_info_[732].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[732].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight";
    constants_info_[733].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias";
    constants_info_[733].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[733].offset = 0;
    constants_info_[733].data_size = 128;
    constants_info_[733].from_folded = true;
    constants_info_[733].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[733].shape = {64};
    constants_info_[733].stride = {1};
    constants_info_[733].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[733].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias";
    constants_info_[734].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight";
    constants_info_[734].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[734].offset = 0;
    constants_info_[734].data_size = 128;
    constants_info_[734].from_folded = true;
    constants_info_[734].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[734].shape = {64};
    constants_info_[734].stride = {1};
    constants_info_[734].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[734].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight";
    constants_info_[735].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias";
    constants_info_[735].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[735].offset = 0;
    constants_info_[735].data_size = 128;
    constants_info_[735].from_folded = true;
    constants_info_[735].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[735].shape = {64};
    constants_info_[735].stride = {1};
    constants_info_[735].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[735].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias";
    constants_info_[736].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias";
    constants_info_[736].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[736].offset = 0;
    constants_info_[736].data_size = 256;
    constants_info_[736].from_folded = true;
    constants_info_[736].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[736].shape = {128};
    constants_info_[736].stride = {1};
    constants_info_[736].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[736].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias";
    constants_info_[737].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias";
    constants_info_[737].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[737].offset = 0;
    constants_info_[737].data_size = 128;
    constants_info_[737].from_folded = true;
    constants_info_[737].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[737].shape = {64};
    constants_info_[737].stride = {1};
    constants_info_[737].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[737].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias";
    constants_info_[738].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb";
    constants_info_[738].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[738].offset = 0;
    constants_info_[738].data_size = 25600;
    constants_info_[738].from_folded = true;
    constants_info_[738].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[738].shape = {1, 200, 64};
    constants_info_[738].stride = {12800, 64, 1};
    constants_info_[738].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[738].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb";
    constants_info_[739].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb";
    constants_info_[739].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[739].offset = 0;
    constants_info_[739].data_size = 4096;
    constants_info_[739].from_folded = true;
    constants_info_[739].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[739].shape = {1, 32, 64};
    constants_info_[739].stride = {2048, 64, 1};
    constants_info_[739].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[739].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb";
    constants_info_[740].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight";
    constants_info_[740].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[740].offset = 0;
    constants_info_[740].data_size = 128;
    constants_info_[740].from_folded = true;
    constants_info_[740].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[740].shape = {64};
    constants_info_[740].stride = {1};
    constants_info_[740].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[740].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight";
    constants_info_[741].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias";
    constants_info_[741].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[741].offset = 0;
    constants_info_[741].data_size = 128;
    constants_info_[741].from_folded = true;
    constants_info_[741].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[741].shape = {64};
    constants_info_[741].stride = {1};
    constants_info_[741].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[741].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias";
    constants_info_[742].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias";
    constants_info_[742].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[742].offset = 0;
    constants_info_[742].data_size = 128;
    constants_info_[742].from_folded = true;
    constants_info_[742].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[742].shape = {64};
    constants_info_[742].stride = {1};
    constants_info_[742].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[742].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias";
    constants_info_[743].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight";
    constants_info_[743].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[743].offset = 0;
    constants_info_[743].data_size = 128;
    constants_info_[743].from_folded = true;
    constants_info_[743].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[743].shape = {64};
    constants_info_[743].stride = {1};
    constants_info_[743].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[743].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight";
    constants_info_[744].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias";
    constants_info_[744].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[744].offset = 0;
    constants_info_[744].data_size = 128;
    constants_info_[744].from_folded = true;
    constants_info_[744].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[744].shape = {64};
    constants_info_[744].stride = {1};
    constants_info_[744].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[744].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias";
    constants_info_[745].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight";
    constants_info_[745].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[745].offset = 0;
    constants_info_[745].data_size = 128;
    constants_info_[745].from_folded = true;
    constants_info_[745].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[745].shape = {64};
    constants_info_[745].stride = {1};
    constants_info_[745].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[745].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight";
    constants_info_[746].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias";
    constants_info_[746].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[746].offset = 0;
    constants_info_[746].data_size = 128;
    constants_info_[746].from_folded = true;
    constants_info_[746].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[746].shape = {64};
    constants_info_[746].stride = {1};
    constants_info_[746].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[746].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias";
    constants_info_[747].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias";
    constants_info_[747].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[747].offset = 0;
    constants_info_[747].data_size = 256;
    constants_info_[747].from_folded = true;
    constants_info_[747].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[747].shape = {128};
    constants_info_[747].stride = {1};
    constants_info_[747].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[747].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias";
    constants_info_[748].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias";
    constants_info_[748].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[748].offset = 0;
    constants_info_[748].data_size = 128;
    constants_info_[748].from_folded = true;
    constants_info_[748].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[748].shape = {64};
    constants_info_[748].stride = {1};
    constants_info_[748].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[748].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias";
    constants_info_[749].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias";
    constants_info_[749].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[749].offset = 0;
    constants_info_[749].data_size = 24576;
    constants_info_[749].from_folded = true;
    constants_info_[749].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[749].shape = {64, 1, 192};
    constants_info_[749].stride = {192, 192, 1};
    constants_info_[749].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[749].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias";
    constants_info_[750].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight";
    constants_info_[750].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[750].offset = 0;
    constants_info_[750].data_size = 1572864;
    constants_info_[750].from_folded = true;
    constants_info_[750].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[750].shape = {64, 64, 192};
    constants_info_[750].stride = {12288, 192, 1};
    constants_info_[750].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[750].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight";
    constants_info_[751].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w";
    constants_info_[751].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[751].offset = 0;
    constants_info_[751].data_size = 159384;
    constants_info_[751].from_folded = true;
    constants_info_[751].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[751].shape = {174, 458};
    constants_info_[751].stride = {458, 1};
    constants_info_[751].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[751].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w";
    constants_info_[752].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b";
    constants_info_[752].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[752].offset = 0;
    constants_info_[752].data_size = 348;
    constants_info_[752].from_folded = true;
    constants_info_[752].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[752].shape = {174, 1};
    constants_info_[752].stride = {1, 1};
    constants_info_[752].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[752].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b";
    constants_info_[753].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w";
    constants_info_[753].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[753].offset = 0;
    constants_info_[753].data_size = 384;
    constants_info_[753].from_folded = true;
    constants_info_[753].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[753].shape = {192};
    constants_info_[753].stride = {1};
    constants_info_[753].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[753].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w";
    constants_info_[754].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b";
    constants_info_[754].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[754].offset = 0;
    constants_info_[754].data_size = 384;
    constants_info_[754].from_folded = true;
    constants_info_[754].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[754].shape = {192};
    constants_info_[754].stride = {1};
    constants_info_[754].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[754].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b";
    constants_info_[755].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[755].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[755].offset = 0;
    constants_info_[755].data_size = 1536;
    constants_info_[755].from_folded = true;
    constants_info_[755].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[755].shape = {768};
    constants_info_[755].stride = {1};
    constants_info_[755].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[755].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[756].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[756].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[756].offset = 0;
    constants_info_[756].data_size = 1536;
    constants_info_[756].from_folded = true;
    constants_info_[756].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[756].shape = {768};
    constants_info_[756].stride = {1};
    constants_info_[756].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[756].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[757].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[757].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[757].offset = 0;
    constants_info_[757].data_size = 1536;
    constants_info_[757].from_folded = true;
    constants_info_[757].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[757].shape = {768};
    constants_info_[757].stride = {1};
    constants_info_[757].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[757].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[758].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[758].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[758].offset = 0;
    constants_info_[758].data_size = 1536;
    constants_info_[758].from_folded = true;
    constants_info_[758].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[758].shape = {768};
    constants_info_[758].stride = {1};
    constants_info_[758].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[758].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[759].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[759].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[759].offset = 0;
    constants_info_[759].data_size = 1536;
    constants_info_[759].from_folded = true;
    constants_info_[759].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[759].shape = {768};
    constants_info_[759].stride = {1};
    constants_info_[759].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[759].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[760].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[760].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[760].offset = 0;
    constants_info_[760].data_size = 1536;
    constants_info_[760].from_folded = true;
    constants_info_[760].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[760].shape = {768};
    constants_info_[760].stride = {1};
    constants_info_[760].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[760].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[761].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[761].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[761].offset = 0;
    constants_info_[761].data_size = 1536;
    constants_info_[761].from_folded = true;
    constants_info_[761].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[761].shape = {768};
    constants_info_[761].stride = {1};
    constants_info_[761].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[761].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[762].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[762].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[762].offset = 0;
    constants_info_[762].data_size = 1536;
    constants_info_[762].from_folded = true;
    constants_info_[762].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[762].shape = {768};
    constants_info_[762].stride = {1};
    constants_info_[762].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[762].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[763].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[763].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[763].offset = 0;
    constants_info_[763].data_size = 1536;
    constants_info_[763].from_folded = true;
    constants_info_[763].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[763].shape = {768};
    constants_info_[763].stride = {1};
    constants_info_[763].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[763].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[764].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[764].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[764].offset = 0;
    constants_info_[764].data_size = 1536;
    constants_info_[764].from_folded = true;
    constants_info_[764].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[764].shape = {768};
    constants_info_[764].stride = {1};
    constants_info_[764].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[764].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[765].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[765].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[765].offset = 0;
    constants_info_[765].data_size = 1536;
    constants_info_[765].from_folded = true;
    constants_info_[765].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[765].shape = {768};
    constants_info_[765].stride = {1};
    constants_info_[765].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[765].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[766].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[766].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[766].offset = 0;
    constants_info_[766].data_size = 1536;
    constants_info_[766].from_folded = true;
    constants_info_[766].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[766].shape = {768};
    constants_info_[766].stride = {1};
    constants_info_[766].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[766].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[767].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[767].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[767].offset = 0;
    constants_info_[767].data_size = 1536;
    constants_info_[767].from_folded = true;
    constants_info_[767].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[767].shape = {768};
    constants_info_[767].stride = {1};
    constants_info_[767].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[767].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[768].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[768].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[768].offset = 0;
    constants_info_[768].data_size = 1536;
    constants_info_[768].from_folded = true;
    constants_info_[768].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[768].shape = {768};
    constants_info_[768].stride = {1};
    constants_info_[768].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[768].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[769].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[769].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[769].offset = 0;
    constants_info_[769].data_size = 1536;
    constants_info_[769].from_folded = true;
    constants_info_[769].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[769].shape = {768};
    constants_info_[769].stride = {1};
    constants_info_[769].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[769].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[770].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[770].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[770].offset = 0;
    constants_info_[770].data_size = 1536;
    constants_info_[770].from_folded = true;
    constants_info_[770].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[770].shape = {768};
    constants_info_[770].stride = {1};
    constants_info_[770].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[770].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[771].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[771].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[771].offset = 0;
    constants_info_[771].data_size = 1536;
    constants_info_[771].from_folded = true;
    constants_info_[771].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[771].shape = {768};
    constants_info_[771].stride = {1};
    constants_info_[771].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[771].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[772].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[772].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[772].offset = 0;
    constants_info_[772].data_size = 1536;
    constants_info_[772].from_folded = true;
    constants_info_[772].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[772].shape = {768};
    constants_info_[772].stride = {1};
    constants_info_[772].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[772].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[773].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[773].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[773].offset = 0;
    constants_info_[773].data_size = 43968;
    constants_info_[773].from_folded = true;
    constants_info_[773].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[773].shape = {21984};
    constants_info_[773].stride = {1};
    constants_info_[773].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[773].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[774].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[774].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[774].offset = 0;
    constants_info_[774].data_size = 43968;
    constants_info_[774].from_folded = true;
    constants_info_[774].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[774].shape = {21984};
    constants_info_[774].stride = {1};
    constants_info_[774].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[774].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[775].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[775].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[775].offset = 0;
    constants_info_[775].data_size = 43968;
    constants_info_[775].from_folded = true;
    constants_info_[775].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[775].shape = {21984};
    constants_info_[775].stride = {1};
    constants_info_[775].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[775].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[776].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[776].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[776].offset = 0;
    constants_info_[776].data_size = 18432;
    constants_info_[776].from_folded = true;
    constants_info_[776].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[776].shape = {9216};
    constants_info_[776].stride = {1};
    constants_info_[776].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[776].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[777].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[777].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[777].offset = 0;
    constants_info_[777].data_size = 18432;
    constants_info_[777].from_folded = true;
    constants_info_[777].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[777].shape = {9216};
    constants_info_[777].stride = {1};
    constants_info_[777].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[777].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[778].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[778].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[778].offset = 0;
    constants_info_[778].data_size = 18432;
    constants_info_[778].from_folded = true;
    constants_info_[778].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[778].shape = {9216};
    constants_info_[778].stride = {1};
    constants_info_[778].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[778].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[779].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w";
    constants_info_[779].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[779].offset = 0;
    constants_info_[779].data_size = 96;
    constants_info_[779].from_folded = true;
    constants_info_[779].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[779].shape = {48};
    constants_info_[779].stride = {1};
    constants_info_[779].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[779].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w";
    constants_info_[780].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b";
    constants_info_[780].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[780].offset = 0;
    constants_info_[780].data_size = 96;
    constants_info_[780].from_folded = true;
    constants_info_[780].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[780].shape = {48};
    constants_info_[780].stride = {1};
    constants_info_[780].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[780].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b";
    constants_info_[781].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w";
    constants_info_[781].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[781].offset = 0;
    constants_info_[781].data_size = 43968;
    constants_info_[781].from_folded = true;
    constants_info_[781].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[781].shape = {21984};
    constants_info_[781].stride = {1};
    constants_info_[781].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[781].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w";
    constants_info_[782].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b";
    constants_info_[782].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[782].offset = 0;
    constants_info_[782].data_size = 43968;
    constants_info_[782].from_folded = true;
    constants_info_[782].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[782].shape = {21984};
    constants_info_[782].stride = {1};
    constants_info_[782].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[782].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b";
    constants_info_[783].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[783].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[783].offset = 0;
    constants_info_[783].data_size = 4096;
    constants_info_[783].from_folded = true;
    constants_info_[783].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[783].shape = {2048};
    constants_info_[783].stride = {1};
    constants_info_[783].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[783].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[784].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[784].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[784].offset = 0;
    constants_info_[784].data_size = 4096;
    constants_info_[784].from_folded = true;
    constants_info_[784].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[784].shape = {2048};
    constants_info_[784].stride = {1};
    constants_info_[784].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[784].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[785].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[785].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[785].offset = 0;
    constants_info_[785].data_size = 4096;
    constants_info_[785].from_folded = true;
    constants_info_[785].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[785].shape = {2048};
    constants_info_[785].stride = {1};
    constants_info_[785].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[785].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[786].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[786].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[786].offset = 0;
    constants_info_[786].data_size = 4096;
    constants_info_[786].from_folded = true;
    constants_info_[786].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[786].shape = {2048};
    constants_info_[786].stride = {1};
    constants_info_[786].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[786].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[787].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[787].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[787].offset = 0;
    constants_info_[787].data_size = 4096;
    constants_info_[787].from_folded = true;
    constants_info_[787].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[787].shape = {2048};
    constants_info_[787].stride = {1};
    constants_info_[787].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[787].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[788].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w";
    constants_info_[788].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[788].offset = 0;
    constants_info_[788].data_size = 12708;
    constants_info_[788].from_folded = true;
    constants_info_[788].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[788].shape = {6354};
    constants_info_[788].stride = {1};
    constants_info_[788].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[788].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w";
    constants_info_[789].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b";
    constants_info_[789].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[789].offset = 0;
    constants_info_[789].data_size = 12708;
    constants_info_[789].from_folded = true;
    constants_info_[789].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[789].shape = {6354};
    constants_info_[789].stride = {1};
    constants_info_[789].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[789].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b";
    constants_info_[790].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[790].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[790].offset = 0;
    constants_info_[790].data_size = 768;
    constants_info_[790].from_folded = true;
    constants_info_[790].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[790].shape = {384};
    constants_info_[790].stride = {1};
    constants_info_[790].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[790].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[791].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[791].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[791].offset = 0;
    constants_info_[791].data_size = 768;
    constants_info_[791].from_folded = true;
    constants_info_[791].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[791].shape = {384};
    constants_info_[791].stride = {1};
    constants_info_[791].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[791].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[792].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[792].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[792].offset = 0;
    constants_info_[792].data_size = 768;
    constants_info_[792].from_folded = true;
    constants_info_[792].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[792].shape = {384};
    constants_info_[792].stride = {1};
    constants_info_[792].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[792].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[793].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[793].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[793].offset = 0;
    constants_info_[793].data_size = 12708;
    constants_info_[793].from_folded = true;
    constants_info_[793].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[793].shape = {6354};
    constants_info_[793].stride = {1};
    constants_info_[793].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[793].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[794].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[794].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[794].offset = 0;
    constants_info_[794].data_size = 12708;
    constants_info_[794].from_folded = true;
    constants_info_[794].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[794].shape = {6354};
    constants_info_[794].stride = {1};
    constants_info_[794].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[794].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[795].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[795].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[795].offset = 0;
    constants_info_[795].data_size = 12708;
    constants_info_[795].from_folded = true;
    constants_info_[795].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[795].shape = {6354};
    constants_info_[795].stride = {1};
    constants_info_[795].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[795].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[796].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w";
    constants_info_[796].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[796].offset = 0;
    constants_info_[796].data_size = 12708;
    constants_info_[796].from_folded = true;
    constants_info_[796].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[796].shape = {6354};
    constants_info_[796].stride = {1};
    constants_info_[796].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[796].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w";
    constants_info_[797].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b";
    constants_info_[797].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[797].offset = 0;
    constants_info_[797].data_size = 12708;
    constants_info_[797].from_folded = true;
    constants_info_[797].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[797].shape = {6354};
    constants_info_[797].stride = {1};
    constants_info_[797].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[797].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b";
    constants_info_[798].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[798].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[798].offset = 0;
    constants_info_[798].data_size = 6144;
    constants_info_[798].from_folded = true;
    constants_info_[798].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[798].shape = {3072};
    constants_info_[798].stride = {1};
    constants_info_[798].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[798].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[799].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[799].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[799].offset = 0;
    constants_info_[799].data_size = 6144;
    constants_info_[799].from_folded = true;
    constants_info_[799].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[799].shape = {3072};
    constants_info_[799].stride = {1};
    constants_info_[799].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[799].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[800].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[800].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[800].offset = 0;
    constants_info_[800].data_size = 6144;
    constants_info_[800].from_folded = true;
    constants_info_[800].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[800].shape = {3072};
    constants_info_[800].stride = {1};
    constants_info_[800].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[800].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[801].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[801].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[801].offset = 0;
    constants_info_[801].data_size = 6144;
    constants_info_[801].from_folded = true;
    constants_info_[801].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[801].shape = {3072};
    constants_info_[801].stride = {1};
    constants_info_[801].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[801].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[802].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[802].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[802].offset = 0;
    constants_info_[802].data_size = 6144;
    constants_info_[802].from_folded = true;
    constants_info_[802].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[802].shape = {3072};
    constants_info_[802].stride = {1};
    constants_info_[802].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[802].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[803].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[803].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[803].offset = 0;
    constants_info_[803].data_size = 3072;
    constants_info_[803].from_folded = true;
    constants_info_[803].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[803].shape = {1536};
    constants_info_[803].stride = {1};
    constants_info_[803].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[803].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[804].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[804].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[804].offset = 0;
    constants_info_[804].data_size = 3072;
    constants_info_[804].from_folded = true;
    constants_info_[804].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[804].shape = {1536};
    constants_info_[804].stride = {1};
    constants_info_[804].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[804].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[805].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[805].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[805].offset = 0;
    constants_info_[805].data_size = 3072;
    constants_info_[805].from_folded = true;
    constants_info_[805].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[805].shape = {1536};
    constants_info_[805].stride = {1};
    constants_info_[805].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[805].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[806].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[806].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[806].offset = 0;
    constants_info_[806].data_size = 3072;
    constants_info_[806].from_folded = true;
    constants_info_[806].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[806].shape = {1536};
    constants_info_[806].stride = {1};
    constants_info_[806].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[806].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[807].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[807].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[807].offset = 0;
    constants_info_[807].data_size = 3072;
    constants_info_[807].from_folded = true;
    constants_info_[807].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[807].shape = {1536};
    constants_info_[807].stride = {1};
    constants_info_[807].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[807].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[808].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[808].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[808].offset = 0;
    constants_info_[808].data_size = 6144;
    constants_info_[808].from_folded = true;
    constants_info_[808].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[808].shape = {3072};
    constants_info_[808].stride = {1};
    constants_info_[808].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[808].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[809].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[809].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[809].offset = 0;
    constants_info_[809].data_size = 6144;
    constants_info_[809].from_folded = true;
    constants_info_[809].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[809].shape = {3072};
    constants_info_[809].stride = {1};
    constants_info_[809].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[809].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[810].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[810].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[810].offset = 0;
    constants_info_[810].data_size = 6144;
    constants_info_[810].from_folded = true;
    constants_info_[810].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[810].shape = {3072};
    constants_info_[810].stride = {1};
    constants_info_[810].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[810].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[811].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[811].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[811].offset = 0;
    constants_info_[811].data_size = 3072;
    constants_info_[811].from_folded = true;
    constants_info_[811].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[811].shape = {1536};
    constants_info_[811].stride = {1};
    constants_info_[811].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[811].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[812].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[812].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[812].offset = 0;
    constants_info_[812].data_size = 3072;
    constants_info_[812].from_folded = true;
    constants_info_[812].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[812].shape = {1536};
    constants_info_[812].stride = {1};
    constants_info_[812].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[812].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[813].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[813].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[813].offset = 0;
    constants_info_[813].data_size = 3072;
    constants_info_[813].from_folded = true;
    constants_info_[813].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[813].shape = {1536};
    constants_info_[813].stride = {1};
    constants_info_[813].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[813].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[814].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[814].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[814].offset = 0;
    constants_info_[814].data_size = 3072;
    constants_info_[814].from_folded = true;
    constants_info_[814].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[814].shape = {1536};
    constants_info_[814].stride = {1};
    constants_info_[814].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[814].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[815].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[815].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[815].offset = 0;
    constants_info_[815].data_size = 3072;
    constants_info_[815].from_folded = true;
    constants_info_[815].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[815].shape = {1536};
    constants_info_[815].stride = {1};
    constants_info_[815].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[815].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[816].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[816].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[816].offset = 0;
    constants_info_[816].data_size = 6144;
    constants_info_[816].from_folded = true;
    constants_info_[816].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[816].shape = {3072};
    constants_info_[816].stride = {1};
    constants_info_[816].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[816].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[817].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[817].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[817].offset = 0;
    constants_info_[817].data_size = 6144;
    constants_info_[817].from_folded = true;
    constants_info_[817].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[817].shape = {3072};
    constants_info_[817].stride = {1};
    constants_info_[817].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[817].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[818].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[818].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[818].offset = 0;
    constants_info_[818].data_size = 6144;
    constants_info_[818].from_folded = true;
    constants_info_[818].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[818].shape = {3072};
    constants_info_[818].stride = {1};
    constants_info_[818].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[818].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[819].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[819].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[819].offset = 0;
    constants_info_[819].data_size = 6144;
    constants_info_[819].from_folded = true;
    constants_info_[819].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[819].shape = {3072};
    constants_info_[819].stride = {1};
    constants_info_[819].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[819].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[820].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[820].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[820].offset = 0;
    constants_info_[820].data_size = 6144;
    constants_info_[820].from_folded = true;
    constants_info_[820].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[820].shape = {3072};
    constants_info_[820].stride = {1};
    constants_info_[820].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[820].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[821].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[821].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[821].offset = 0;
    constants_info_[821].data_size = 6144;
    constants_info_[821].from_folded = true;
    constants_info_[821].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[821].shape = {3072};
    constants_info_[821].stride = {1};
    constants_info_[821].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[821].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[822].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[822].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[822].offset = 0;
    constants_info_[822].data_size = 6144;
    constants_info_[822].from_folded = true;
    constants_info_[822].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[822].shape = {3072};
    constants_info_[822].stride = {1};
    constants_info_[822].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[822].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[823].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias";
    constants_info_[823].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[823].offset = 0;
    constants_info_[823].data_size = 18432;
    constants_info_[823].from_folded = true;
    constants_info_[823].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[823].shape = {9216};
    constants_info_[823].stride = {1};
    constants_info_[823].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[823].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias";
    constants_info_[824].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w";
    constants_info_[824].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[824].offset = 0;
    constants_info_[824].data_size = 384;
    constants_info_[824].from_folded = true;
    constants_info_[824].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[824].shape = {192};
    constants_info_[824].stride = {1};
    constants_info_[824].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[824].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w";
    constants_info_[825].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b";
    constants_info_[825].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[825].offset = 0;
    constants_info_[825].data_size = 384;
    constants_info_[825].from_folded = true;
    constants_info_[825].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[825].shape = {192};
    constants_info_[825].stride = {1};
    constants_info_[825].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[825].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b";
    constants_info_[826].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w";
    constants_info_[826].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[826].offset = 0;
    constants_info_[826].data_size = 14688;
    constants_info_[826].from_folded = true;
    constants_info_[826].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[826].shape = {72, 102};
    constants_info_[826].stride = {102, 1};
    constants_info_[826].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[826].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w";
    constants_info_[827].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b";
    constants_info_[827].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[827].offset = 0;
    constants_info_[827].data_size = 144;
    constants_info_[827].from_folded = true;
    constants_info_[827].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[827].shape = {72, 1};
    constants_info_[827].stride = {1, 1};
    constants_info_[827].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[827].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b";
    constants_info_[828].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w";
    constants_info_[828].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[828].offset = 0;
    constants_info_[828].data_size = 384;
    constants_info_[828].from_folded = true;
    constants_info_[828].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[828].shape = {192};
    constants_info_[828].stride = {1};
    constants_info_[828].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[828].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w";
    constants_info_[829].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b";
    constants_info_[829].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[829].offset = 0;
    constants_info_[829].data_size = 384;
    constants_info_[829].from_folded = true;
    constants_info_[829].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[829].shape = {192};
    constants_info_[829].stride = {1};
    constants_info_[829].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[829].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b";
    constants_info_[830].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[830].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[830].offset = 0;
    constants_info_[830].data_size = 1536;
    constants_info_[830].from_folded = true;
    constants_info_[830].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[830].shape = {768};
    constants_info_[830].stride = {1};
    constants_info_[830].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[830].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[831].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[831].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[831].offset = 0;
    constants_info_[831].data_size = 1536;
    constants_info_[831].from_folded = true;
    constants_info_[831].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[831].shape = {768};
    constants_info_[831].stride = {1};
    constants_info_[831].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[831].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[832].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[832].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[832].offset = 0;
    constants_info_[832].data_size = 1536;
    constants_info_[832].from_folded = true;
    constants_info_[832].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[832].shape = {768};
    constants_info_[832].stride = {1};
    constants_info_[832].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[832].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[833].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[833].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[833].offset = 0;
    constants_info_[833].data_size = 1536;
    constants_info_[833].from_folded = true;
    constants_info_[833].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[833].shape = {768};
    constants_info_[833].stride = {1};
    constants_info_[833].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[833].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[834].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[834].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[834].offset = 0;
    constants_info_[834].data_size = 1536;
    constants_info_[834].from_folded = true;
    constants_info_[834].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[834].shape = {768};
    constants_info_[834].stride = {1};
    constants_info_[834].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[834].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[835].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[835].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[835].offset = 0;
    constants_info_[835].data_size = 1536;
    constants_info_[835].from_folded = true;
    constants_info_[835].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[835].shape = {768};
    constants_info_[835].stride = {1};
    constants_info_[835].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[835].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[836].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[836].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[836].offset = 0;
    constants_info_[836].data_size = 1536;
    constants_info_[836].from_folded = true;
    constants_info_[836].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[836].shape = {768};
    constants_info_[836].stride = {1};
    constants_info_[836].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[836].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[837].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[837].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[837].offset = 0;
    constants_info_[837].data_size = 1536;
    constants_info_[837].from_folded = true;
    constants_info_[837].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[837].shape = {768};
    constants_info_[837].stride = {1};
    constants_info_[837].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[837].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[838].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[838].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[838].offset = 0;
    constants_info_[838].data_size = 1536;
    constants_info_[838].from_folded = true;
    constants_info_[838].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[838].shape = {768};
    constants_info_[838].stride = {1};
    constants_info_[838].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[838].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[839].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[839].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[839].offset = 0;
    constants_info_[839].data_size = 1536;
    constants_info_[839].from_folded = true;
    constants_info_[839].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[839].shape = {768};
    constants_info_[839].stride = {1};
    constants_info_[839].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[839].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[840].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[840].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[840].offset = 0;
    constants_info_[840].data_size = 1536;
    constants_info_[840].from_folded = true;
    constants_info_[840].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[840].shape = {768};
    constants_info_[840].stride = {1};
    constants_info_[840].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[840].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[841].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[841].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[841].offset = 0;
    constants_info_[841].data_size = 1536;
    constants_info_[841].from_folded = true;
    constants_info_[841].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[841].shape = {768};
    constants_info_[841].stride = {1};
    constants_info_[841].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[841].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[842].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[842].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[842].offset = 0;
    constants_info_[842].data_size = 1536;
    constants_info_[842].from_folded = true;
    constants_info_[842].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[842].shape = {768};
    constants_info_[842].stride = {1};
    constants_info_[842].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[842].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[843].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[843].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[843].offset = 0;
    constants_info_[843].data_size = 1536;
    constants_info_[843].from_folded = true;
    constants_info_[843].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[843].shape = {768};
    constants_info_[843].stride = {1};
    constants_info_[843].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[843].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[844].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[844].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[844].offset = 0;
    constants_info_[844].data_size = 1536;
    constants_info_[844].from_folded = true;
    constants_info_[844].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[844].shape = {768};
    constants_info_[844].stride = {1};
    constants_info_[844].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[844].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[845].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[845].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[845].offset = 0;
    constants_info_[845].data_size = 1536;
    constants_info_[845].from_folded = true;
    constants_info_[845].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[845].shape = {768};
    constants_info_[845].stride = {1};
    constants_info_[845].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[845].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[846].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[846].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[846].offset = 0;
    constants_info_[846].data_size = 1536;
    constants_info_[846].from_folded = true;
    constants_info_[846].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[846].shape = {768};
    constants_info_[846].stride = {1};
    constants_info_[846].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[846].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[847].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[847].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[847].offset = 0;
    constants_info_[847].data_size = 1536;
    constants_info_[847].from_folded = true;
    constants_info_[847].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[847].shape = {768};
    constants_info_[847].stride = {1};
    constants_info_[847].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[847].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[848].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[848].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[848].offset = 0;
    constants_info_[848].data_size = 9792;
    constants_info_[848].from_folded = true;
    constants_info_[848].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[848].shape = {4896};
    constants_info_[848].stride = {1};
    constants_info_[848].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[848].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[849].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[849].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[849].offset = 0;
    constants_info_[849].data_size = 9792;
    constants_info_[849].from_folded = true;
    constants_info_[849].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[849].shape = {4896};
    constants_info_[849].stride = {1};
    constants_info_[849].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[849].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[850].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[850].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[850].offset = 0;
    constants_info_[850].data_size = 9792;
    constants_info_[850].from_folded = true;
    constants_info_[850].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[850].shape = {4896};
    constants_info_[850].stride = {1};
    constants_info_[850].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[850].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[851].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[851].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[851].offset = 0;
    constants_info_[851].data_size = 18432;
    constants_info_[851].from_folded = true;
    constants_info_[851].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[851].shape = {9216};
    constants_info_[851].stride = {1};
    constants_info_[851].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[851].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[852].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[852].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[852].offset = 0;
    constants_info_[852].data_size = 18432;
    constants_info_[852].from_folded = true;
    constants_info_[852].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[852].shape = {9216};
    constants_info_[852].stride = {1};
    constants_info_[852].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[852].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[853].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[853].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[853].offset = 0;
    constants_info_[853].data_size = 18432;
    constants_info_[853].from_folded = true;
    constants_info_[853].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[853].shape = {9216};
    constants_info_[853].stride = {1};
    constants_info_[853].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[853].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[854].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w";
    constants_info_[854].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[854].offset = 0;
    constants_info_[854].data_size = 96;
    constants_info_[854].from_folded = true;
    constants_info_[854].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[854].shape = {48};
    constants_info_[854].stride = {1};
    constants_info_[854].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[854].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w";
    constants_info_[855].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b";
    constants_info_[855].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[855].offset = 0;
    constants_info_[855].data_size = 96;
    constants_info_[855].from_folded = true;
    constants_info_[855].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[855].shape = {48};
    constants_info_[855].stride = {1};
    constants_info_[855].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[855].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b";
    constants_info_[856].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w";
    constants_info_[856].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[856].offset = 0;
    constants_info_[856].data_size = 9792;
    constants_info_[856].from_folded = true;
    constants_info_[856].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[856].shape = {4896};
    constants_info_[856].stride = {1};
    constants_info_[856].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[856].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w";
    constants_info_[857].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b";
    constants_info_[857].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[857].offset = 0;
    constants_info_[857].data_size = 9792;
    constants_info_[857].from_folded = true;
    constants_info_[857].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[857].shape = {4896};
    constants_info_[857].stride = {1};
    constants_info_[857].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[857].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b";
    constants_info_[858].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[858].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[858].offset = 0;
    constants_info_[858].data_size = 4096;
    constants_info_[858].from_folded = true;
    constants_info_[858].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[858].shape = {2048};
    constants_info_[858].stride = {1};
    constants_info_[858].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[858].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[859].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[859].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[859].offset = 0;
    constants_info_[859].data_size = 4096;
    constants_info_[859].from_folded = true;
    constants_info_[859].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[859].shape = {2048};
    constants_info_[859].stride = {1};
    constants_info_[859].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[859].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[860].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[860].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[860].offset = 0;
    constants_info_[860].data_size = 4096;
    constants_info_[860].from_folded = true;
    constants_info_[860].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[860].shape = {2048};
    constants_info_[860].stride = {1};
    constants_info_[860].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[860].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[861].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[861].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[861].offset = 0;
    constants_info_[861].data_size = 4096;
    constants_info_[861].from_folded = true;
    constants_info_[861].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[861].shape = {2048};
    constants_info_[861].stride = {1};
    constants_info_[861].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[861].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[862].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[862].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[862].offset = 0;
    constants_info_[862].data_size = 4096;
    constants_info_[862].from_folded = true;
    constants_info_[862].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[862].shape = {2048};
    constants_info_[862].stride = {1};
    constants_info_[862].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[862].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[863].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w";
    constants_info_[863].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[863].offset = 0;
    constants_info_[863].data_size = 12708;
    constants_info_[863].from_folded = true;
    constants_info_[863].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[863].shape = {6354};
    constants_info_[863].stride = {1};
    constants_info_[863].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[863].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w";
    constants_info_[864].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b";
    constants_info_[864].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[864].offset = 0;
    constants_info_[864].data_size = 12708;
    constants_info_[864].from_folded = true;
    constants_info_[864].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[864].shape = {6354};
    constants_info_[864].stride = {1};
    constants_info_[864].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[864].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b";
    constants_info_[865].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[865].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[865].offset = 0;
    constants_info_[865].data_size = 768;
    constants_info_[865].from_folded = true;
    constants_info_[865].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[865].shape = {384};
    constants_info_[865].stride = {1};
    constants_info_[865].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[865].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[866].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[866].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[866].offset = 0;
    constants_info_[866].data_size = 768;
    constants_info_[866].from_folded = true;
    constants_info_[866].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[866].shape = {384};
    constants_info_[866].stride = {1};
    constants_info_[866].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[866].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[867].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[867].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[867].offset = 0;
    constants_info_[867].data_size = 768;
    constants_info_[867].from_folded = true;
    constants_info_[867].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[867].shape = {384};
    constants_info_[867].stride = {1};
    constants_info_[867].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[867].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[868].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[868].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[868].offset = 0;
    constants_info_[868].data_size = 12708;
    constants_info_[868].from_folded = true;
    constants_info_[868].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[868].shape = {6354};
    constants_info_[868].stride = {1};
    constants_info_[868].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[868].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[869].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[869].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[869].offset = 0;
    constants_info_[869].data_size = 12708;
    constants_info_[869].from_folded = true;
    constants_info_[869].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[869].shape = {6354};
    constants_info_[869].stride = {1};
    constants_info_[869].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[869].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[870].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[870].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[870].offset = 0;
    constants_info_[870].data_size = 12708;
    constants_info_[870].from_folded = true;
    constants_info_[870].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[870].shape = {6354};
    constants_info_[870].stride = {1};
    constants_info_[870].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[870].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[871].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w";
    constants_info_[871].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[871].offset = 0;
    constants_info_[871].data_size = 12708;
    constants_info_[871].from_folded = true;
    constants_info_[871].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[871].shape = {6354};
    constants_info_[871].stride = {1};
    constants_info_[871].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[871].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w";
    constants_info_[872].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b";
    constants_info_[872].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[872].offset = 0;
    constants_info_[872].data_size = 12708;
    constants_info_[872].from_folded = true;
    constants_info_[872].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[872].shape = {6354};
    constants_info_[872].stride = {1};
    constants_info_[872].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[872].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b";
    constants_info_[873].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[873].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[873].offset = 0;
    constants_info_[873].data_size = 6144;
    constants_info_[873].from_folded = true;
    constants_info_[873].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[873].shape = {3072};
    constants_info_[873].stride = {1};
    constants_info_[873].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[873].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[874].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[874].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[874].offset = 0;
    constants_info_[874].data_size = 6144;
    constants_info_[874].from_folded = true;
    constants_info_[874].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[874].shape = {3072};
    constants_info_[874].stride = {1};
    constants_info_[874].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[874].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[875].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[875].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[875].offset = 0;
    constants_info_[875].data_size = 6144;
    constants_info_[875].from_folded = true;
    constants_info_[875].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[875].shape = {3072};
    constants_info_[875].stride = {1};
    constants_info_[875].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[875].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[876].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[876].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[876].offset = 0;
    constants_info_[876].data_size = 6144;
    constants_info_[876].from_folded = true;
    constants_info_[876].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[876].shape = {3072};
    constants_info_[876].stride = {1};
    constants_info_[876].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[876].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[877].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[877].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[877].offset = 0;
    constants_info_[877].data_size = 6144;
    constants_info_[877].from_folded = true;
    constants_info_[877].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[877].shape = {3072};
    constants_info_[877].stride = {1};
    constants_info_[877].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[877].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[878].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[878].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[878].offset = 0;
    constants_info_[878].data_size = 3072;
    constants_info_[878].from_folded = true;
    constants_info_[878].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[878].shape = {1536};
    constants_info_[878].stride = {1};
    constants_info_[878].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[878].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[879].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[879].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[879].offset = 0;
    constants_info_[879].data_size = 3072;
    constants_info_[879].from_folded = true;
    constants_info_[879].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[879].shape = {1536};
    constants_info_[879].stride = {1};
    constants_info_[879].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[879].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[880].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[880].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[880].offset = 0;
    constants_info_[880].data_size = 3072;
    constants_info_[880].from_folded = true;
    constants_info_[880].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[880].shape = {1536};
    constants_info_[880].stride = {1};
    constants_info_[880].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[880].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[881].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[881].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[881].offset = 0;
    constants_info_[881].data_size = 3072;
    constants_info_[881].from_folded = true;
    constants_info_[881].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[881].shape = {1536};
    constants_info_[881].stride = {1};
    constants_info_[881].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[881].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[882].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[882].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[882].offset = 0;
    constants_info_[882].data_size = 3072;
    constants_info_[882].from_folded = true;
    constants_info_[882].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[882].shape = {1536};
    constants_info_[882].stride = {1};
    constants_info_[882].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[882].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[883].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[883].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[883].offset = 0;
    constants_info_[883].data_size = 6144;
    constants_info_[883].from_folded = true;
    constants_info_[883].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[883].shape = {3072};
    constants_info_[883].stride = {1};
    constants_info_[883].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[883].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[884].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[884].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[884].offset = 0;
    constants_info_[884].data_size = 6144;
    constants_info_[884].from_folded = true;
    constants_info_[884].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[884].shape = {3072};
    constants_info_[884].stride = {1};
    constants_info_[884].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[884].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[885].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[885].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[885].offset = 0;
    constants_info_[885].data_size = 6144;
    constants_info_[885].from_folded = true;
    constants_info_[885].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[885].shape = {3072};
    constants_info_[885].stride = {1};
    constants_info_[885].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[885].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[886].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[886].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[886].offset = 0;
    constants_info_[886].data_size = 3072;
    constants_info_[886].from_folded = true;
    constants_info_[886].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[886].shape = {1536};
    constants_info_[886].stride = {1};
    constants_info_[886].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[886].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[887].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[887].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[887].offset = 0;
    constants_info_[887].data_size = 3072;
    constants_info_[887].from_folded = true;
    constants_info_[887].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[887].shape = {1536};
    constants_info_[887].stride = {1};
    constants_info_[887].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[887].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[888].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[888].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[888].offset = 0;
    constants_info_[888].data_size = 3072;
    constants_info_[888].from_folded = true;
    constants_info_[888].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[888].shape = {1536};
    constants_info_[888].stride = {1};
    constants_info_[888].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[888].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[889].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[889].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[889].offset = 0;
    constants_info_[889].data_size = 3072;
    constants_info_[889].from_folded = true;
    constants_info_[889].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[889].shape = {1536};
    constants_info_[889].stride = {1};
    constants_info_[889].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[889].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[890].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[890].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[890].offset = 0;
    constants_info_[890].data_size = 3072;
    constants_info_[890].from_folded = true;
    constants_info_[890].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[890].shape = {1536};
    constants_info_[890].stride = {1};
    constants_info_[890].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[890].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[891].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[891].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[891].offset = 0;
    constants_info_[891].data_size = 6144;
    constants_info_[891].from_folded = true;
    constants_info_[891].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[891].shape = {3072};
    constants_info_[891].stride = {1};
    constants_info_[891].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[891].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[892].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[892].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[892].offset = 0;
    constants_info_[892].data_size = 6144;
    constants_info_[892].from_folded = true;
    constants_info_[892].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[892].shape = {3072};
    constants_info_[892].stride = {1};
    constants_info_[892].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[892].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[893].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[893].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[893].offset = 0;
    constants_info_[893].data_size = 6144;
    constants_info_[893].from_folded = true;
    constants_info_[893].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[893].shape = {3072};
    constants_info_[893].stride = {1};
    constants_info_[893].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[893].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[894].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[894].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[894].offset = 0;
    constants_info_[894].data_size = 6144;
    constants_info_[894].from_folded = true;
    constants_info_[894].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[894].shape = {3072};
    constants_info_[894].stride = {1};
    constants_info_[894].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[894].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[895].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[895].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[895].offset = 0;
    constants_info_[895].data_size = 6144;
    constants_info_[895].from_folded = true;
    constants_info_[895].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[895].shape = {3072};
    constants_info_[895].stride = {1};
    constants_info_[895].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[895].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[896].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[896].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[896].offset = 0;
    constants_info_[896].data_size = 6144;
    constants_info_[896].from_folded = true;
    constants_info_[896].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[896].shape = {3072};
    constants_info_[896].stride = {1};
    constants_info_[896].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[896].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[897].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[897].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[897].offset = 0;
    constants_info_[897].data_size = 6144;
    constants_info_[897].from_folded = true;
    constants_info_[897].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[897].shape = {3072};
    constants_info_[897].stride = {1};
    constants_info_[897].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[897].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[898].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias";
    constants_info_[898].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[898].offset = 0;
    constants_info_[898].data_size = 18432;
    constants_info_[898].from_folded = true;
    constants_info_[898].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[898].shape = {9216};
    constants_info_[898].stride = {1};
    constants_info_[898].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[898].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias";
    constants_info_[899].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w";
    constants_info_[899].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[899].offset = 0;
    constants_info_[899].data_size = 384;
    constants_info_[899].from_folded = true;
    constants_info_[899].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[899].shape = {192};
    constants_info_[899].stride = {1};
    constants_info_[899].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[899].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w";
    constants_info_[900].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b";
    constants_info_[900].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[900].offset = 0;
    constants_info_[900].data_size = 384;
    constants_info_[900].from_folded = true;
    constants_info_[900].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[900].shape = {192};
    constants_info_[900].stride = {1};
    constants_info_[900].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[900].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b";
    constants_info_[901].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w";
    constants_info_[901].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[901].offset = 0;
    constants_info_[901].data_size = 14688;
    constants_info_[901].from_folded = true;
    constants_info_[901].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[901].shape = {72, 102};
    constants_info_[901].stride = {102, 1};
    constants_info_[901].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[901].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w";
    constants_info_[902].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b";
    constants_info_[902].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[902].offset = 0;
    constants_info_[902].data_size = 144;
    constants_info_[902].from_folded = true;
    constants_info_[902].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[902].shape = {72, 1};
    constants_info_[902].stride = {1, 1};
    constants_info_[902].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[902].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b";
    constants_info_[903].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w";
    constants_info_[903].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[903].offset = 0;
    constants_info_[903].data_size = 384;
    constants_info_[903].from_folded = true;
    constants_info_[903].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[903].shape = {192};
    constants_info_[903].stride = {1};
    constants_info_[903].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[903].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w";
    constants_info_[904].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b";
    constants_info_[904].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[904].offset = 0;
    constants_info_[904].data_size = 384;
    constants_info_[904].from_folded = true;
    constants_info_[904].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[904].shape = {192};
    constants_info_[904].stride = {1};
    constants_info_[904].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[904].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b";
    constants_info_[905].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[905].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[905].offset = 0;
    constants_info_[905].data_size = 1536;
    constants_info_[905].from_folded = true;
    constants_info_[905].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[905].shape = {768};
    constants_info_[905].stride = {1};
    constants_info_[905].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[905].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[906].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[906].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[906].offset = 0;
    constants_info_[906].data_size = 1536;
    constants_info_[906].from_folded = true;
    constants_info_[906].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[906].shape = {768};
    constants_info_[906].stride = {1};
    constants_info_[906].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[906].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[907].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[907].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[907].offset = 0;
    constants_info_[907].data_size = 1536;
    constants_info_[907].from_folded = true;
    constants_info_[907].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[907].shape = {768};
    constants_info_[907].stride = {1};
    constants_info_[907].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[907].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[908].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[908].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[908].offset = 0;
    constants_info_[908].data_size = 1536;
    constants_info_[908].from_folded = true;
    constants_info_[908].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[908].shape = {768};
    constants_info_[908].stride = {1};
    constants_info_[908].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[908].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[909].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[909].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[909].offset = 0;
    constants_info_[909].data_size = 1536;
    constants_info_[909].from_folded = true;
    constants_info_[909].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[909].shape = {768};
    constants_info_[909].stride = {1};
    constants_info_[909].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[909].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[910].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[910].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[910].offset = 0;
    constants_info_[910].data_size = 1536;
    constants_info_[910].from_folded = true;
    constants_info_[910].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[910].shape = {768};
    constants_info_[910].stride = {1};
    constants_info_[910].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[910].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[911].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[911].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[911].offset = 0;
    constants_info_[911].data_size = 1536;
    constants_info_[911].from_folded = true;
    constants_info_[911].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[911].shape = {768};
    constants_info_[911].stride = {1};
    constants_info_[911].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[911].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[912].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[912].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[912].offset = 0;
    constants_info_[912].data_size = 1536;
    constants_info_[912].from_folded = true;
    constants_info_[912].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[912].shape = {768};
    constants_info_[912].stride = {1};
    constants_info_[912].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[912].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[913].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[913].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[913].offset = 0;
    constants_info_[913].data_size = 1536;
    constants_info_[913].from_folded = true;
    constants_info_[913].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[913].shape = {768};
    constants_info_[913].stride = {1};
    constants_info_[913].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[913].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[914].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[914].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[914].offset = 0;
    constants_info_[914].data_size = 1536;
    constants_info_[914].from_folded = true;
    constants_info_[914].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[914].shape = {768};
    constants_info_[914].stride = {1};
    constants_info_[914].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[914].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[915].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[915].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[915].offset = 0;
    constants_info_[915].data_size = 1536;
    constants_info_[915].from_folded = true;
    constants_info_[915].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[915].shape = {768};
    constants_info_[915].stride = {1};
    constants_info_[915].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[915].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[916].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[916].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[916].offset = 0;
    constants_info_[916].data_size = 1536;
    constants_info_[916].from_folded = true;
    constants_info_[916].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[916].shape = {768};
    constants_info_[916].stride = {1};
    constants_info_[916].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[916].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[917].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[917].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[917].offset = 0;
    constants_info_[917].data_size = 1536;
    constants_info_[917].from_folded = true;
    constants_info_[917].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[917].shape = {768};
    constants_info_[917].stride = {1};
    constants_info_[917].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[917].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[918].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[918].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[918].offset = 0;
    constants_info_[918].data_size = 1536;
    constants_info_[918].from_folded = true;
    constants_info_[918].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[918].shape = {768};
    constants_info_[918].stride = {1};
    constants_info_[918].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[918].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[919].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[919].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[919].offset = 0;
    constants_info_[919].data_size = 1536;
    constants_info_[919].from_folded = true;
    constants_info_[919].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[919].shape = {768};
    constants_info_[919].stride = {1};
    constants_info_[919].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[919].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[920].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[920].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[920].offset = 0;
    constants_info_[920].data_size = 1536;
    constants_info_[920].from_folded = true;
    constants_info_[920].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[920].shape = {768};
    constants_info_[920].stride = {1};
    constants_info_[920].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[920].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[921].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[921].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[921].offset = 0;
    constants_info_[921].data_size = 1536;
    constants_info_[921].from_folded = true;
    constants_info_[921].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[921].shape = {768};
    constants_info_[921].stride = {1};
    constants_info_[921].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[921].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[922].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[922].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[922].offset = 0;
    constants_info_[922].data_size = 1536;
    constants_info_[922].from_folded = true;
    constants_info_[922].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[922].shape = {768};
    constants_info_[922].stride = {1};
    constants_info_[922].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[922].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[923].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[923].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[923].offset = 0;
    constants_info_[923].data_size = 9792;
    constants_info_[923].from_folded = true;
    constants_info_[923].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[923].shape = {4896};
    constants_info_[923].stride = {1};
    constants_info_[923].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[923].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[924].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[924].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[924].offset = 0;
    constants_info_[924].data_size = 9792;
    constants_info_[924].from_folded = true;
    constants_info_[924].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[924].shape = {4896};
    constants_info_[924].stride = {1};
    constants_info_[924].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[924].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[925].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[925].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[925].offset = 0;
    constants_info_[925].data_size = 9792;
    constants_info_[925].from_folded = true;
    constants_info_[925].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[925].shape = {4896};
    constants_info_[925].stride = {1};
    constants_info_[925].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[925].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[926].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[926].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[926].offset = 0;
    constants_info_[926].data_size = 18432;
    constants_info_[926].from_folded = true;
    constants_info_[926].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[926].shape = {9216};
    constants_info_[926].stride = {1};
    constants_info_[926].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[926].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[927].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[927].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[927].offset = 0;
    constants_info_[927].data_size = 18432;
    constants_info_[927].from_folded = true;
    constants_info_[927].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[927].shape = {9216};
    constants_info_[927].stride = {1};
    constants_info_[927].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[927].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[928].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[928].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[928].offset = 0;
    constants_info_[928].data_size = 18432;
    constants_info_[928].from_folded = true;
    constants_info_[928].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[928].shape = {9216};
    constants_info_[928].stride = {1};
    constants_info_[928].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[928].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[929].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w";
    constants_info_[929].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[929].offset = 0;
    constants_info_[929].data_size = 96;
    constants_info_[929].from_folded = true;
    constants_info_[929].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[929].shape = {48};
    constants_info_[929].stride = {1};
    constants_info_[929].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[929].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w";
    constants_info_[930].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b";
    constants_info_[930].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[930].offset = 0;
    constants_info_[930].data_size = 96;
    constants_info_[930].from_folded = true;
    constants_info_[930].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[930].shape = {48};
    constants_info_[930].stride = {1};
    constants_info_[930].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[930].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b";
    constants_info_[931].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w";
    constants_info_[931].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[931].offset = 0;
    constants_info_[931].data_size = 9792;
    constants_info_[931].from_folded = true;
    constants_info_[931].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[931].shape = {4896};
    constants_info_[931].stride = {1};
    constants_info_[931].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[931].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w";
    constants_info_[932].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b";
    constants_info_[932].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[932].offset = 0;
    constants_info_[932].data_size = 9792;
    constants_info_[932].from_folded = true;
    constants_info_[932].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[932].shape = {4896};
    constants_info_[932].stride = {1};
    constants_info_[932].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[932].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b";
    constants_info_[933].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[933].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[933].offset = 0;
    constants_info_[933].data_size = 4096;
    constants_info_[933].from_folded = true;
    constants_info_[933].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[933].shape = {2048};
    constants_info_[933].stride = {1};
    constants_info_[933].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[933].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[934].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[934].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[934].offset = 0;
    constants_info_[934].data_size = 4096;
    constants_info_[934].from_folded = true;
    constants_info_[934].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[934].shape = {2048};
    constants_info_[934].stride = {1};
    constants_info_[934].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[934].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[935].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[935].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[935].offset = 0;
    constants_info_[935].data_size = 4096;
    constants_info_[935].from_folded = true;
    constants_info_[935].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[935].shape = {2048};
    constants_info_[935].stride = {1};
    constants_info_[935].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[935].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[936].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[936].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[936].offset = 0;
    constants_info_[936].data_size = 4096;
    constants_info_[936].from_folded = true;
    constants_info_[936].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[936].shape = {2048};
    constants_info_[936].stride = {1};
    constants_info_[936].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[936].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[937].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[937].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[937].offset = 0;
    constants_info_[937].data_size = 4096;
    constants_info_[937].from_folded = true;
    constants_info_[937].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[937].shape = {2048};
    constants_info_[937].stride = {1};
    constants_info_[937].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[937].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[938].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w";
    constants_info_[938].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[938].offset = 0;
    constants_info_[938].data_size = 12708;
    constants_info_[938].from_folded = true;
    constants_info_[938].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[938].shape = {6354};
    constants_info_[938].stride = {1};
    constants_info_[938].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[938].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w";
    constants_info_[939].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b";
    constants_info_[939].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[939].offset = 0;
    constants_info_[939].data_size = 12708;
    constants_info_[939].from_folded = true;
    constants_info_[939].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[939].shape = {6354};
    constants_info_[939].stride = {1};
    constants_info_[939].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[939].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b";
    constants_info_[940].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[940].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[940].offset = 0;
    constants_info_[940].data_size = 768;
    constants_info_[940].from_folded = true;
    constants_info_[940].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[940].shape = {384};
    constants_info_[940].stride = {1};
    constants_info_[940].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[940].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[941].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[941].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[941].offset = 0;
    constants_info_[941].data_size = 768;
    constants_info_[941].from_folded = true;
    constants_info_[941].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[941].shape = {384};
    constants_info_[941].stride = {1};
    constants_info_[941].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[941].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[942].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[942].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[942].offset = 0;
    constants_info_[942].data_size = 768;
    constants_info_[942].from_folded = true;
    constants_info_[942].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[942].shape = {384};
    constants_info_[942].stride = {1};
    constants_info_[942].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[942].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[943].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[943].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[943].offset = 0;
    constants_info_[943].data_size = 12708;
    constants_info_[943].from_folded = true;
    constants_info_[943].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[943].shape = {6354};
    constants_info_[943].stride = {1};
    constants_info_[943].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[943].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[944].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[944].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[944].offset = 0;
    constants_info_[944].data_size = 12708;
    constants_info_[944].from_folded = true;
    constants_info_[944].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[944].shape = {6354};
    constants_info_[944].stride = {1};
    constants_info_[944].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[944].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[945].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[945].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[945].offset = 0;
    constants_info_[945].data_size = 12708;
    constants_info_[945].from_folded = true;
    constants_info_[945].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[945].shape = {6354};
    constants_info_[945].stride = {1};
    constants_info_[945].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[945].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[946].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w";
    constants_info_[946].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[946].offset = 0;
    constants_info_[946].data_size = 12708;
    constants_info_[946].from_folded = true;
    constants_info_[946].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[946].shape = {6354};
    constants_info_[946].stride = {1};
    constants_info_[946].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[946].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w";
    constants_info_[947].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b";
    constants_info_[947].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[947].offset = 0;
    constants_info_[947].data_size = 12708;
    constants_info_[947].from_folded = true;
    constants_info_[947].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[947].shape = {6354};
    constants_info_[947].stride = {1};
    constants_info_[947].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[947].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b";
    constants_info_[948].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[948].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[948].offset = 0;
    constants_info_[948].data_size = 6144;
    constants_info_[948].from_folded = true;
    constants_info_[948].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[948].shape = {3072};
    constants_info_[948].stride = {1};
    constants_info_[948].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[948].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[949].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[949].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[949].offset = 0;
    constants_info_[949].data_size = 6144;
    constants_info_[949].from_folded = true;
    constants_info_[949].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[949].shape = {3072};
    constants_info_[949].stride = {1};
    constants_info_[949].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[949].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[950].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[950].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[950].offset = 0;
    constants_info_[950].data_size = 6144;
    constants_info_[950].from_folded = true;
    constants_info_[950].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[950].shape = {3072};
    constants_info_[950].stride = {1};
    constants_info_[950].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[950].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[951].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[951].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[951].offset = 0;
    constants_info_[951].data_size = 6144;
    constants_info_[951].from_folded = true;
    constants_info_[951].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[951].shape = {3072};
    constants_info_[951].stride = {1};
    constants_info_[951].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[951].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[952].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[952].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[952].offset = 0;
    constants_info_[952].data_size = 6144;
    constants_info_[952].from_folded = true;
    constants_info_[952].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[952].shape = {3072};
    constants_info_[952].stride = {1};
    constants_info_[952].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[952].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[953].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[953].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[953].offset = 0;
    constants_info_[953].data_size = 3072;
    constants_info_[953].from_folded = true;
    constants_info_[953].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[953].shape = {1536};
    constants_info_[953].stride = {1};
    constants_info_[953].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[953].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[954].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[954].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[954].offset = 0;
    constants_info_[954].data_size = 3072;
    constants_info_[954].from_folded = true;
    constants_info_[954].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[954].shape = {1536};
    constants_info_[954].stride = {1};
    constants_info_[954].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[954].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[955].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[955].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[955].offset = 0;
    constants_info_[955].data_size = 3072;
    constants_info_[955].from_folded = true;
    constants_info_[955].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[955].shape = {1536};
    constants_info_[955].stride = {1};
    constants_info_[955].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[955].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[956].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[956].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[956].offset = 0;
    constants_info_[956].data_size = 3072;
    constants_info_[956].from_folded = true;
    constants_info_[956].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[956].shape = {1536};
    constants_info_[956].stride = {1};
    constants_info_[956].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[956].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[957].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[957].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[957].offset = 0;
    constants_info_[957].data_size = 3072;
    constants_info_[957].from_folded = true;
    constants_info_[957].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[957].shape = {1536};
    constants_info_[957].stride = {1};
    constants_info_[957].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[957].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[958].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[958].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[958].offset = 0;
    constants_info_[958].data_size = 6144;
    constants_info_[958].from_folded = true;
    constants_info_[958].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[958].shape = {3072};
    constants_info_[958].stride = {1};
    constants_info_[958].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[958].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[959].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[959].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[959].offset = 0;
    constants_info_[959].data_size = 6144;
    constants_info_[959].from_folded = true;
    constants_info_[959].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[959].shape = {3072};
    constants_info_[959].stride = {1};
    constants_info_[959].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[959].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[960].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[960].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[960].offset = 0;
    constants_info_[960].data_size = 6144;
    constants_info_[960].from_folded = true;
    constants_info_[960].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[960].shape = {3072};
    constants_info_[960].stride = {1};
    constants_info_[960].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[960].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[961].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[961].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[961].offset = 0;
    constants_info_[961].data_size = 3072;
    constants_info_[961].from_folded = true;
    constants_info_[961].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[961].shape = {1536};
    constants_info_[961].stride = {1};
    constants_info_[961].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[961].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[962].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[962].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[962].offset = 0;
    constants_info_[962].data_size = 3072;
    constants_info_[962].from_folded = true;
    constants_info_[962].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[962].shape = {1536};
    constants_info_[962].stride = {1};
    constants_info_[962].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[962].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[963].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[963].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[963].offset = 0;
    constants_info_[963].data_size = 3072;
    constants_info_[963].from_folded = true;
    constants_info_[963].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[963].shape = {1536};
    constants_info_[963].stride = {1};
    constants_info_[963].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[963].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[964].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[964].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[964].offset = 0;
    constants_info_[964].data_size = 3072;
    constants_info_[964].from_folded = true;
    constants_info_[964].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[964].shape = {1536};
    constants_info_[964].stride = {1};
    constants_info_[964].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[964].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[965].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[965].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[965].offset = 0;
    constants_info_[965].data_size = 3072;
    constants_info_[965].from_folded = true;
    constants_info_[965].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[965].shape = {1536};
    constants_info_[965].stride = {1};
    constants_info_[965].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[965].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[966].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[966].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[966].offset = 0;
    constants_info_[966].data_size = 6144;
    constants_info_[966].from_folded = true;
    constants_info_[966].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[966].shape = {3072};
    constants_info_[966].stride = {1};
    constants_info_[966].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[966].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[967].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[967].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[967].offset = 0;
    constants_info_[967].data_size = 6144;
    constants_info_[967].from_folded = true;
    constants_info_[967].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[967].shape = {3072};
    constants_info_[967].stride = {1};
    constants_info_[967].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[967].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[968].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[968].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[968].offset = 0;
    constants_info_[968].data_size = 6144;
    constants_info_[968].from_folded = true;
    constants_info_[968].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[968].shape = {3072};
    constants_info_[968].stride = {1};
    constants_info_[968].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[968].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[969].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[969].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[969].offset = 0;
    constants_info_[969].data_size = 6144;
    constants_info_[969].from_folded = true;
    constants_info_[969].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[969].shape = {3072};
    constants_info_[969].stride = {1};
    constants_info_[969].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[969].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[970].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[970].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[970].offset = 0;
    constants_info_[970].data_size = 6144;
    constants_info_[970].from_folded = true;
    constants_info_[970].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[970].shape = {3072};
    constants_info_[970].stride = {1};
    constants_info_[970].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[970].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[971].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[971].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[971].offset = 0;
    constants_info_[971].data_size = 6144;
    constants_info_[971].from_folded = true;
    constants_info_[971].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[971].shape = {3072};
    constants_info_[971].stride = {1};
    constants_info_[971].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[971].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[972].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[972].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[972].offset = 0;
    constants_info_[972].data_size = 6144;
    constants_info_[972].from_folded = true;
    constants_info_[972].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[972].shape = {3072};
    constants_info_[972].stride = {1};
    constants_info_[972].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[972].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[973].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias";
    constants_info_[973].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[973].offset = 0;
    constants_info_[973].data_size = 18432;
    constants_info_[973].from_folded = true;
    constants_info_[973].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[973].shape = {9216};
    constants_info_[973].stride = {1};
    constants_info_[973].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[973].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias";
    constants_info_[974].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w";
    constants_info_[974].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[974].offset = 0;
    constants_info_[974].data_size = 384;
    constants_info_[974].from_folded = true;
    constants_info_[974].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[974].shape = {192};
    constants_info_[974].stride = {1};
    constants_info_[974].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[974].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w";
    constants_info_[975].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b";
    constants_info_[975].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[975].offset = 0;
    constants_info_[975].data_size = 384;
    constants_info_[975].from_folded = true;
    constants_info_[975].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[975].shape = {192};
    constants_info_[975].stride = {1};
    constants_info_[975].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[975].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b";
    constants_info_[976].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w";
    constants_info_[976].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[976].offset = 0;
    constants_info_[976].data_size = 4896;
    constants_info_[976].from_folded = true;
    constants_info_[976].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[976].shape = {24, 102};
    constants_info_[976].stride = {102, 1};
    constants_info_[976].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[976].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w";
    constants_info_[977].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b";
    constants_info_[977].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[977].offset = 0;
    constants_info_[977].data_size = 48;
    constants_info_[977].from_folded = true;
    constants_info_[977].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[977].shape = {24, 1};
    constants_info_[977].stride = {1, 1};
    constants_info_[977].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[977].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b";
    constants_info_[978].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w";
    constants_info_[978].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[978].offset = 0;
    constants_info_[978].data_size = 384;
    constants_info_[978].from_folded = true;
    constants_info_[978].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[978].shape = {192};
    constants_info_[978].stride = {1};
    constants_info_[978].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[978].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w";
    constants_info_[979].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b";
    constants_info_[979].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[979].offset = 0;
    constants_info_[979].data_size = 384;
    constants_info_[979].from_folded = true;
    constants_info_[979].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[979].shape = {192};
    constants_info_[979].stride = {1};
    constants_info_[979].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[979].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b";
    constants_info_[980].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[980].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[980].offset = 0;
    constants_info_[980].data_size = 1536;
    constants_info_[980].from_folded = true;
    constants_info_[980].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[980].shape = {768};
    constants_info_[980].stride = {1};
    constants_info_[980].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[980].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[981].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[981].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[981].offset = 0;
    constants_info_[981].data_size = 1536;
    constants_info_[981].from_folded = true;
    constants_info_[981].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[981].shape = {768};
    constants_info_[981].stride = {1};
    constants_info_[981].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[981].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[982].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[982].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[982].offset = 0;
    constants_info_[982].data_size = 1536;
    constants_info_[982].from_folded = true;
    constants_info_[982].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[982].shape = {768};
    constants_info_[982].stride = {1};
    constants_info_[982].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[982].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w";
    constants_info_[983].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[983].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[983].offset = 0;
    constants_info_[983].data_size = 1536;
    constants_info_[983].from_folded = true;
    constants_info_[983].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[983].shape = {768};
    constants_info_[983].stride = {1};
    constants_info_[983].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[983].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b";
    constants_info_[984].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[984].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[984].offset = 0;
    constants_info_[984].data_size = 1536;
    constants_info_[984].from_folded = true;
    constants_info_[984].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[984].shape = {768};
    constants_info_[984].stride = {1};
    constants_info_[984].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[984].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias";
    constants_info_[985].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[985].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[985].offset = 0;
    constants_info_[985].data_size = 1536;
    constants_info_[985].from_folded = true;
    constants_info_[985].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[985].shape = {768};
    constants_info_[985].stride = {1};
    constants_info_[985].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[985].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[986].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[986].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[986].offset = 0;
    constants_info_[986].data_size = 1536;
    constants_info_[986].from_folded = true;
    constants_info_[986].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[986].shape = {768};
    constants_info_[986].stride = {1};
    constants_info_[986].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[986].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[987].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[987].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[987].offset = 0;
    constants_info_[987].data_size = 1536;
    constants_info_[987].from_folded = true;
    constants_info_[987].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[987].shape = {768};
    constants_info_[987].stride = {1};
    constants_info_[987].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[987].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w";
    constants_info_[988].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[988].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[988].offset = 0;
    constants_info_[988].data_size = 1536;
    constants_info_[988].from_folded = true;
    constants_info_[988].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[988].shape = {768};
    constants_info_[988].stride = {1};
    constants_info_[988].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[988].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b";
    constants_info_[989].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[989].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[989].offset = 0;
    constants_info_[989].data_size = 1536;
    constants_info_[989].from_folded = true;
    constants_info_[989].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[989].shape = {768};
    constants_info_[989].stride = {1};
    constants_info_[989].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[989].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight";
    constants_info_[990].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[990].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[990].offset = 0;
    constants_info_[990].data_size = 1536;
    constants_info_[990].from_folded = true;
    constants_info_[990].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[990].shape = {768};
    constants_info_[990].stride = {1};
    constants_info_[990].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[990].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias";
    constants_info_[991].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[991].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[991].offset = 0;
    constants_info_[991].data_size = 1536;
    constants_info_[991].from_folded = true;
    constants_info_[991].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[991].shape = {768};
    constants_info_[991].stride = {1};
    constants_info_[991].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[991].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w";
    constants_info_[992].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[992].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[992].offset = 0;
    constants_info_[992].data_size = 1536;
    constants_info_[992].from_folded = true;
    constants_info_[992].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[992].shape = {768};
    constants_info_[992].stride = {1};
    constants_info_[992].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[992].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b";
    constants_info_[993].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[993].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[993].offset = 0;
    constants_info_[993].data_size = 1536;
    constants_info_[993].from_folded = true;
    constants_info_[993].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[993].shape = {768};
    constants_info_[993].stride = {1};
    constants_info_[993].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[993].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias";
    constants_info_[994].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[994].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[994].offset = 0;
    constants_info_[994].data_size = 1536;
    constants_info_[994].from_folded = true;
    constants_info_[994].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[994].shape = {768};
    constants_info_[994].stride = {1};
    constants_info_[994].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[994].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight";
    constants_info_[995].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[995].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[995].offset = 0;
    constants_info_[995].data_size = 1536;
    constants_info_[995].from_folded = true;
    constants_info_[995].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[995].shape = {768};
    constants_info_[995].stride = {1};
    constants_info_[995].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[995].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias";
    constants_info_[996].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[996].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[996].offset = 0;
    constants_info_[996].data_size = 1536;
    constants_info_[996].from_folded = true;
    constants_info_[996].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[996].shape = {768};
    constants_info_[996].stride = {1};
    constants_info_[996].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[996].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w";
    constants_info_[997].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[997].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[997].offset = 0;
    constants_info_[997].data_size = 1536;
    constants_info_[997].from_folded = true;
    constants_info_[997].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[997].shape = {768};
    constants_info_[997].stride = {1};
    constants_info_[997].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[997].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b";
    constants_info_[998].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[998].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[998].offset = 0;
    constants_info_[998].data_size = 9792;
    constants_info_[998].from_folded = true;
    constants_info_[998].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[998].shape = {4896};
    constants_info_[998].stride = {1};
    constants_info_[998].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[998].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[999].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[999].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[999].offset = 0;
    constants_info_[999].data_size = 9792;
    constants_info_[999].from_folded = true;
    constants_info_[999].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[999].shape = {4896};
    constants_info_[999].stride = {1};
    constants_info_[999].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[999].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[1000].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[1000].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1000].offset = 0;
    constants_info_[1000].data_size = 9792;
    constants_info_[1000].from_folded = true;
    constants_info_[1000].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1000].shape = {4896};
    constants_info_[1000].stride = {1};
    constants_info_[1000].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1000].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[1001].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[1001].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1001].offset = 0;
    constants_info_[1001].data_size = 18432;
    constants_info_[1001].from_folded = true;
    constants_info_[1001].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1001].shape = {9216};
    constants_info_[1001].stride = {1};
    constants_info_[1001].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1001].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias";
    constants_info_[1002].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[1002].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1002].offset = 0;
    constants_info_[1002].data_size = 18432;
    constants_info_[1002].from_folded = true;
    constants_info_[1002].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1002].shape = {9216};
    constants_info_[1002].stride = {1};
    constants_info_[1002].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1002].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w";
    constants_info_[1003].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[1003].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1003].offset = 0;
    constants_info_[1003].data_size = 18432;
    constants_info_[1003].from_folded = true;
    constants_info_[1003].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1003].shape = {9216};
    constants_info_[1003].stride = {1};
    constants_info_[1003].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1003].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b";
    constants_info_[1004].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w";
    constants_info_[1004].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1004].offset = 0;
    constants_info_[1004].data_size = 96;
    constants_info_[1004].from_folded = true;
    constants_info_[1004].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1004].shape = {48};
    constants_info_[1004].stride = {1};
    constants_info_[1004].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1004].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w";
    constants_info_[1005].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b";
    constants_info_[1005].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1005].offset = 0;
    constants_info_[1005].data_size = 96;
    constants_info_[1005].from_folded = true;
    constants_info_[1005].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1005].shape = {48};
    constants_info_[1005].stride = {1};
    constants_info_[1005].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1005].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b";
    constants_info_[1006].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w";
    constants_info_[1006].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1006].offset = 0;
    constants_info_[1006].data_size = 9792;
    constants_info_[1006].from_folded = true;
    constants_info_[1006].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1006].shape = {4896};
    constants_info_[1006].stride = {1};
    constants_info_[1006].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1006].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w";
    constants_info_[1007].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b";
    constants_info_[1007].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1007].offset = 0;
    constants_info_[1007].data_size = 9792;
    constants_info_[1007].from_folded = true;
    constants_info_[1007].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1007].shape = {4896};
    constants_info_[1007].stride = {1};
    constants_info_[1007].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1007].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b";
    constants_info_[1008].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[1008].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1008].offset = 0;
    constants_info_[1008].data_size = 4096;
    constants_info_[1008].from_folded = true;
    constants_info_[1008].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1008].shape = {2048};
    constants_info_[1008].stride = {1};
    constants_info_[1008].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1008].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias";
    constants_info_[1009].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[1009].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1009].offset = 0;
    constants_info_[1009].data_size = 4096;
    constants_info_[1009].from_folded = true;
    constants_info_[1009].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1009].shape = {2048};
    constants_info_[1009].stride = {1};
    constants_info_[1009].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1009].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[1010].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[1010].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1010].offset = 0;
    constants_info_[1010].data_size = 4096;
    constants_info_[1010].from_folded = true;
    constants_info_[1010].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1010].shape = {2048};
    constants_info_[1010].stride = {1};
    constants_info_[1010].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1010].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[1011].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[1011].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1011].offset = 0;
    constants_info_[1011].data_size = 4096;
    constants_info_[1011].from_folded = true;
    constants_info_[1011].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1011].shape = {2048};
    constants_info_[1011].stride = {1};
    constants_info_[1011].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1011].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w";
    constants_info_[1012].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[1012].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1012].offset = 0;
    constants_info_[1012].data_size = 4096;
    constants_info_[1012].from_folded = true;
    constants_info_[1012].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1012].shape = {2048};
    constants_info_[1012].stride = {1};
    constants_info_[1012].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1012].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b";
    constants_info_[1013].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w";
    constants_info_[1013].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1013].offset = 0;
    constants_info_[1013].data_size = 12708;
    constants_info_[1013].from_folded = true;
    constants_info_[1013].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1013].shape = {6354};
    constants_info_[1013].stride = {1};
    constants_info_[1013].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1013].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w";
    constants_info_[1014].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b";
    constants_info_[1014].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1014].offset = 0;
    constants_info_[1014].data_size = 12708;
    constants_info_[1014].from_folded = true;
    constants_info_[1014].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1014].shape = {6354};
    constants_info_[1014].stride = {1};
    constants_info_[1014].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1014].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b";
    constants_info_[1015].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[1015].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1015].offset = 0;
    constants_info_[1015].data_size = 768;
    constants_info_[1015].from_folded = true;
    constants_info_[1015].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1015].shape = {384};
    constants_info_[1015].stride = {1};
    constants_info_[1015].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1015].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias";
    constants_info_[1016].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[1016].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1016].offset = 0;
    constants_info_[1016].data_size = 768;
    constants_info_[1016].from_folded = true;
    constants_info_[1016].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1016].shape = {384};
    constants_info_[1016].stride = {1};
    constants_info_[1016].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1016].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w";
    constants_info_[1017].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[1017].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1017].offset = 0;
    constants_info_[1017].data_size = 768;
    constants_info_[1017].from_folded = true;
    constants_info_[1017].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1017].shape = {384};
    constants_info_[1017].stride = {1};
    constants_info_[1017].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1017].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b";
    constants_info_[1018].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[1018].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1018].offset = 0;
    constants_info_[1018].data_size = 12708;
    constants_info_[1018].from_folded = true;
    constants_info_[1018].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1018].shape = {6354};
    constants_info_[1018].stride = {1};
    constants_info_[1018].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1018].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias";
    constants_info_[1019].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[1019].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1019].offset = 0;
    constants_info_[1019].data_size = 12708;
    constants_info_[1019].from_folded = true;
    constants_info_[1019].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1019].shape = {6354};
    constants_info_[1019].stride = {1};
    constants_info_[1019].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1019].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w";
    constants_info_[1020].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[1020].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1020].offset = 0;
    constants_info_[1020].data_size = 12708;
    constants_info_[1020].from_folded = true;
    constants_info_[1020].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1020].shape = {6354};
    constants_info_[1020].stride = {1};
    constants_info_[1020].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1020].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b";
    constants_info_[1021].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w";
    constants_info_[1021].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1021].offset = 0;
    constants_info_[1021].data_size = 12708;
    constants_info_[1021].from_folded = true;
    constants_info_[1021].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1021].shape = {6354};
    constants_info_[1021].stride = {1};
    constants_info_[1021].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1021].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w";
    constants_info_[1022].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b";
    constants_info_[1022].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1022].offset = 0;
    constants_info_[1022].data_size = 12708;
    constants_info_[1022].from_folded = true;
    constants_info_[1022].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1022].shape = {6354};
    constants_info_[1022].stride = {1};
    constants_info_[1022].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1022].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b";
    constants_info_[1023].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[1023].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1023].offset = 0;
    constants_info_[1023].data_size = 6144;
    constants_info_[1023].from_folded = true;
    constants_info_[1023].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1023].shape = {3072};
    constants_info_[1023].stride = {1};
    constants_info_[1023].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1023].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias";
    constants_info_[1024].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[1024].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1024].offset = 0;
    constants_info_[1024].data_size = 6144;
    constants_info_[1024].from_folded = true;
    constants_info_[1024].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1024].shape = {3072};
    constants_info_[1024].stride = {1};
    constants_info_[1024].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1024].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight";
    constants_info_[1025].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[1025].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1025].offset = 0;
    constants_info_[1025].data_size = 6144;
    constants_info_[1025].from_folded = true;
    constants_info_[1025].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1025].shape = {3072};
    constants_info_[1025].stride = {1};
    constants_info_[1025].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1025].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias";
    constants_info_[1026].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[1026].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1026].offset = 0;
    constants_info_[1026].data_size = 6144;
    constants_info_[1026].from_folded = true;
    constants_info_[1026].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1026].shape = {3072};
    constants_info_[1026].stride = {1};
    constants_info_[1026].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1026].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w";
    constants_info_[1027].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[1027].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1027].offset = 0;
    constants_info_[1027].data_size = 6144;
    constants_info_[1027].from_folded = true;
    constants_info_[1027].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1027].shape = {3072};
    constants_info_[1027].stride = {1};
    constants_info_[1027].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1027].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b";
    constants_info_[1028].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[1028].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1028].offset = 0;
    constants_info_[1028].data_size = 3072;
    constants_info_[1028].from_folded = true;
    constants_info_[1028].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1028].shape = {1536};
    constants_info_[1028].stride = {1};
    constants_info_[1028].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1028].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias";
    constants_info_[1029].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[1029].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1029].offset = 0;
    constants_info_[1029].data_size = 3072;
    constants_info_[1029].from_folded = true;
    constants_info_[1029].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1029].shape = {1536};
    constants_info_[1029].stride = {1};
    constants_info_[1029].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1029].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight";
    constants_info_[1030].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[1030].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1030].offset = 0;
    constants_info_[1030].data_size = 3072;
    constants_info_[1030].from_folded = true;
    constants_info_[1030].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1030].shape = {1536};
    constants_info_[1030].stride = {1};
    constants_info_[1030].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1030].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias";
    constants_info_[1031].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[1031].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1031].offset = 0;
    constants_info_[1031].data_size = 3072;
    constants_info_[1031].from_folded = true;
    constants_info_[1031].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1031].shape = {1536};
    constants_info_[1031].stride = {1};
    constants_info_[1031].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1031].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w";
    constants_info_[1032].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[1032].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1032].offset = 0;
    constants_info_[1032].data_size = 3072;
    constants_info_[1032].from_folded = true;
    constants_info_[1032].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1032].shape = {1536};
    constants_info_[1032].stride = {1};
    constants_info_[1032].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1032].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b";
    constants_info_[1033].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[1033].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1033].offset = 0;
    constants_info_[1033].data_size = 6144;
    constants_info_[1033].from_folded = true;
    constants_info_[1033].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1033].shape = {3072};
    constants_info_[1033].stride = {1};
    constants_info_[1033].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1033].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias";
    constants_info_[1034].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[1034].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1034].offset = 0;
    constants_info_[1034].data_size = 6144;
    constants_info_[1034].from_folded = true;
    constants_info_[1034].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1034].shape = {3072};
    constants_info_[1034].stride = {1};
    constants_info_[1034].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1034].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w";
    constants_info_[1035].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[1035].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1035].offset = 0;
    constants_info_[1035].data_size = 6144;
    constants_info_[1035].from_folded = true;
    constants_info_[1035].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1035].shape = {3072};
    constants_info_[1035].stride = {1};
    constants_info_[1035].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1035].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b";
    constants_info_[1036].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[1036].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1036].offset = 0;
    constants_info_[1036].data_size = 3072;
    constants_info_[1036].from_folded = true;
    constants_info_[1036].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1036].shape = {1536};
    constants_info_[1036].stride = {1};
    constants_info_[1036].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1036].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias";
    constants_info_[1037].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[1037].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1037].offset = 0;
    constants_info_[1037].data_size = 3072;
    constants_info_[1037].from_folded = true;
    constants_info_[1037].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1037].shape = {1536};
    constants_info_[1037].stride = {1};
    constants_info_[1037].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1037].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight";
    constants_info_[1038].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[1038].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1038].offset = 0;
    constants_info_[1038].data_size = 3072;
    constants_info_[1038].from_folded = true;
    constants_info_[1038].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1038].shape = {1536};
    constants_info_[1038].stride = {1};
    constants_info_[1038].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1038].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias";
    constants_info_[1039].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[1039].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1039].offset = 0;
    constants_info_[1039].data_size = 3072;
    constants_info_[1039].from_folded = true;
    constants_info_[1039].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1039].shape = {1536};
    constants_info_[1039].stride = {1};
    constants_info_[1039].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1039].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w";
    constants_info_[1040].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[1040].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1040].offset = 0;
    constants_info_[1040].data_size = 3072;
    constants_info_[1040].from_folded = true;
    constants_info_[1040].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1040].shape = {1536};
    constants_info_[1040].stride = {1};
    constants_info_[1040].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1040].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b";
    constants_info_[1041].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[1041].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1041].offset = 0;
    constants_info_[1041].data_size = 6144;
    constants_info_[1041].from_folded = true;
    constants_info_[1041].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1041].shape = {3072};
    constants_info_[1041].stride = {1};
    constants_info_[1041].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1041].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias";
    constants_info_[1042].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[1042].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1042].offset = 0;
    constants_info_[1042].data_size = 6144;
    constants_info_[1042].from_folded = true;
    constants_info_[1042].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1042].shape = {3072};
    constants_info_[1042].stride = {1};
    constants_info_[1042].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1042].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w";
    constants_info_[1043].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[1043].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1043].offset = 0;
    constants_info_[1043].data_size = 6144;
    constants_info_[1043].from_folded = true;
    constants_info_[1043].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1043].shape = {3072};
    constants_info_[1043].stride = {1};
    constants_info_[1043].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1043].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b";
    constants_info_[1044].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[1044].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1044].offset = 0;
    constants_info_[1044].data_size = 6144;
    constants_info_[1044].from_folded = true;
    constants_info_[1044].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1044].shape = {3072};
    constants_info_[1044].stride = {1};
    constants_info_[1044].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1044].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight";
    constants_info_[1045].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[1045].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1045].offset = 0;
    constants_info_[1045].data_size = 6144;
    constants_info_[1045].from_folded = true;
    constants_info_[1045].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1045].shape = {3072};
    constants_info_[1045].stride = {1};
    constants_info_[1045].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1045].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias";
    constants_info_[1046].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[1046].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1046].offset = 0;
    constants_info_[1046].data_size = 6144;
    constants_info_[1046].from_folded = true;
    constants_info_[1046].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1046].shape = {3072};
    constants_info_[1046].stride = {1};
    constants_info_[1046].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1046].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight";
    constants_info_[1047].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[1047].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1047].offset = 0;
    constants_info_[1047].data_size = 6144;
    constants_info_[1047].from_folded = true;
    constants_info_[1047].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1047].shape = {3072};
    constants_info_[1047].stride = {1};
    constants_info_[1047].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1047].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias";
    constants_info_[1048].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b";
    constants_info_[1048].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1048].offset = 0;
    constants_info_[1048].data_size = 1024;
    constants_info_[1048].from_folded = true;
    constants_info_[1048].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1048].shape = {512};
    constants_info_[1048].stride = {1};
    constants_info_[1048].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1048].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b";
    constants_info_[1049].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b";
    constants_info_[1049].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1049].offset = 0;
    constants_info_[1049].data_size = 6144;
    constants_info_[1049].from_folded = true;
    constants_info_[1049].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1049].shape = {3072};
    constants_info_[1049].stride = {1};
    constants_info_[1049].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1049].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b";
    constants_info_[1050].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b";
    constants_info_[1050].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1050].offset = 0;
    constants_info_[1050].data_size = 1024;
    constants_info_[1050].from_folded = true;
    constants_info_[1050].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1050].shape = {512};
    constants_info_[1050].stride = {1};
    constants_info_[1050].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1050].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b";
    constants_info_[1051].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b";
    constants_info_[1051].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1051].offset = 0;
    constants_info_[1051].data_size = 6144;
    constants_info_[1051].from_folded = true;
    constants_info_[1051].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1051].shape = {3072};
    constants_info_[1051].stride = {1};
    constants_info_[1051].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1051].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b";
    constants_info_[1052].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias";
    constants_info_[1052].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1052].offset = 0;
    constants_info_[1052].data_size = 2;
    constants_info_[1052].from_folded = true;
    constants_info_[1052].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1052].shape = {1};
    constants_info_[1052].stride = {1};
    constants_info_[1052].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1052].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias";
    constants_info_[1053].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b";
    constants_info_[1053].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1053].offset = 0;
    constants_info_[1053].data_size = 6144;
    constants_info_[1053].from_folded = true;
    constants_info_[1053].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1053].shape = {3072};
    constants_info_[1053].stride = {1};
    constants_info_[1053].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1053].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b";
    constants_info_[1054].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b";
    constants_info_[1054].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1054].offset = 0;
    constants_info_[1054].data_size = 1024;
    constants_info_[1054].from_folded = true;
    constants_info_[1054].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1054].shape = {512};
    constants_info_[1054].stride = {1};
    constants_info_[1054].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1054].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b";
    constants_info_[1055].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b";
    constants_info_[1055].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1055].offset = 0;
    constants_info_[1055].data_size = 2;
    constants_info_[1055].from_folded = true;
    constants_info_[1055].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1055].shape = {1};
    constants_info_[1055].stride = {1};
    constants_info_[1055].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1055].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b";
    constants_info_[1056].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale";
    constants_info_[1056].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1056].offset = 0;
    constants_info_[1056].data_size = 1024;
    constants_info_[1056].from_folded = true;
    constants_info_[1056].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1056].shape = {512};
    constants_info_[1056].stride = {1};
    constants_info_[1056].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1056].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale";
    constants_info_[1057].name = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias";
    constants_info_[1057].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1057].offset = 0;
    constants_info_[1057].data_size = 1024;
    constants_info_[1057].from_folded = true;
    constants_info_[1057].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1057].shape = {512};
    constants_info_[1057].stride = {1};
    constants_info_[1057].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1057].original_fqn = "_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias";
    constants_info_[1058].name = "_FOLDED_CONST__tensor_constant2";
    constants_info_[1058].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1058].offset = 0;
    constants_info_[1058].data_size = 2;
    constants_info_[1058].from_folded = true;
    constants_info_[1058].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1058].shape = {1};
    constants_info_[1058].stride = {1};
    constants_info_[1058].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1058].original_fqn = "_FOLDED_CONST__tensor_constant2";
    constants_info_[1059].name = "_FOLDED_CONST_submod_0_cat_fusion_gpu__offset_dim_list";
    constants_info_[1059].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[1059].offset = 0;
    constants_info_[1059].data_size = 2216;
    constants_info_[1059].from_folded = true;
    constants_info_[1059].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1059].shape = {277};
    constants_info_[1059].stride = {1};
    constants_info_[1059].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1059].original_fqn = "_FOLDED_CONST_submod_0_cat_fusion_gpu__offset_dim_list";
    constants_info_[1060].name = "_FOLDED_CONST_submod_0_cat_fusion_gpu__permute";
    constants_info_[1060].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[1060].offset = 0;
    constants_info_[1060].data_size = 2208;
    constants_info_[1060].from_folded = true;
    constants_info_[1060].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1060].shape = {276};
    constants_info_[1060].stride = {1};
    constants_info_[1060].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1060].original_fqn = "_FOLDED_CONST_submod_0_cat_fusion_gpu__permute";
    constants_info_[1061].name = "_FOLDED_CONST_submod_0_cat_fusion_gpu__inv_permute";
    constants_info_[1061].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[1061].offset = 0;
    constants_info_[1061].data_size = 2208;
    constants_info_[1061].from_folded = true;
    constants_info_[1061].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1061].shape = {276};
    constants_info_[1061].stride = {1};
    constants_info_[1061].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1061].original_fqn = "_FOLDED_CONST_submod_0_cat_fusion_gpu__inv_permute";
    constants_info_[1062].name = "_FOLDED_CONST_submod_0_cat_fusion_gpu__inv_offset_dim_list";
    constants_info_[1062].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[1062].offset = 0;
    constants_info_[1062].data_size = 2216;
    constants_info_[1062].from_folded = true;
    constants_info_[1062].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1062].shape = {277};
    constants_info_[1062].stride = {1};
    constants_info_[1062].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1062].original_fqn = "_FOLDED_CONST_submod_0_cat_fusion_gpu__inv_offset_dim_list";
    constants_info_[1063].name = "_FOLDED_CONST_submod_0_cat_fusion_cpu__offset_dim_list";
    constants_info_[1063].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[1063].offset = 0;
    constants_info_[1063].data_size = 1464;
    constants_info_[1063].from_folded = true;
    constants_info_[1063].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1063].shape = {183};
    constants_info_[1063].stride = {1};
    constants_info_[1063].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1063].original_fqn = "_FOLDED_CONST_submod_0_cat_fusion_cpu__offset_dim_list";
    constants_info_[1064].name = "_FOLDED_CONST_submod_0_cat_fusion_cpu__permute";
    constants_info_[1064].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[1064].offset = 0;
    constants_info_[1064].data_size = 1456;
    constants_info_[1064].from_folded = true;
    constants_info_[1064].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1064].shape = {182};
    constants_info_[1064].stride = {1};
    constants_info_[1064].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1064].original_fqn = "_FOLDED_CONST_submod_0_cat_fusion_cpu__permute";
    constants_info_[1065].name = "_FOLDED_CONST_submod_0_cat_fusion_cpu__inv_permute";
    constants_info_[1065].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[1065].offset = 0;
    constants_info_[1065].data_size = 1456;
    constants_info_[1065].from_folded = true;
    constants_info_[1065].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1065].shape = {182};
    constants_info_[1065].stride = {1};
    constants_info_[1065].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1065].original_fqn = "_FOLDED_CONST_submod_0_cat_fusion_cpu__inv_permute";
    constants_info_[1066].name = "_FOLDED_CONST_submod_0_cat_fusion_cpu__inv_offset_dim_list";
    constants_info_[1066].dtype = static_cast<int32_t>(cached_torch_dtype_int64);
    constants_info_[1066].offset = 0;
    constants_info_[1066].data_size = 1464;
    constants_info_[1066].from_folded = true;
    constants_info_[1066].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1066].shape = {183};
    constants_info_[1066].stride = {1};
    constants_info_[1066].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1066].original_fqn = "_FOLDED_CONST_submod_0_cat_fusion_cpu__inv_offset_dim_list";
    constants_info_[1067].name = "_FOLDED_CONST_submod_1__tensor_constant1";
    constants_info_[1067].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1067].offset = 0;
    constants_info_[1067].data_size = 2;
    constants_info_[1067].from_folded = true;
    constants_info_[1067].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1067].shape = {};
    constants_info_[1067].stride = {};
    constants_info_[1067].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1067].original_fqn = "_FOLDED_CONST_submod_1__tensor_constant1";
    constants_info_[1068].name = "_FOLDED_CONST_submod_1_main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_positive_weight_calibration_bias";
    constants_info_[1068].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1068].offset = 0;
    constants_info_[1068].data_size = 2;
    constants_info_[1068].from_folded = true;
    constants_info_[1068].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1068].shape = {1};
    constants_info_[1068].stride = {1};
    constants_info_[1068].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1068].original_fqn = "_FOLDED_CONST_submod_1_main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_positive_weight_calibration_bias";
    constants_info_[1069].name = "_FOLDED_CONST_permute";
    constants_info_[1069].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1069].offset = 0;
    constants_info_[1069].data_size = 92160;
    constants_info_[1069].from_folded = true;
    constants_info_[1069].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1069].shape = {240, 192};
    constants_info_[1069].stride = {1, 240};
    constants_info_[1069].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1069].original_fqn = "_FOLDED_CONST_permute";
    constants_info_[1070].name = "_FOLDED_CONST_permute_1";
    constants_info_[1070].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1070].offset = 0;
    constants_info_[1070].data_size = 92160;
    constants_info_[1070].from_folded = true;
    constants_info_[1070].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1070].shape = {240, 192};
    constants_info_[1070].stride = {1, 240};
    constants_info_[1070].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1070].original_fqn = "_FOLDED_CONST_permute_1";
    constants_info_[1071].name = "_FOLDED_CONST_permute_2";
    constants_info_[1071].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1071].offset = 0;
    constants_info_[1071].data_size = 73728;
    constants_info_[1071].from_folded = true;
    constants_info_[1071].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1071].shape = {192, 192};
    constants_info_[1071].stride = {1, 192};
    constants_info_[1071].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1071].original_fqn = "_FOLDED_CONST_permute_2";
    constants_info_[1072].name = "_FOLDED_CONST_permute_3";
    constants_info_[1072].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1072].offset = 0;
    constants_info_[1072].data_size = 73728;
    constants_info_[1072].from_folded = true;
    constants_info_[1072].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1072].shape = {192, 192};
    constants_info_[1072].stride = {1, 192};
    constants_info_[1072].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1072].original_fqn = "_FOLDED_CONST_permute_3";
    constants_info_[1073].name = "_FOLDED_CONST_permute_4";
    constants_info_[1073].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1073].offset = 0;
    constants_info_[1073].data_size = 36864;
    constants_info_[1073].from_folded = true;
    constants_info_[1073].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1073].shape = {96, 192};
    constants_info_[1073].stride = {1, 96};
    constants_info_[1073].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1073].original_fqn = "_FOLDED_CONST_permute_4";
    constants_info_[1074].name = "_FOLDED_CONST_permute_5";
    constants_info_[1074].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1074].offset = 0;
    constants_info_[1074].data_size = 27648;
    constants_info_[1074].from_folded = true;
    constants_info_[1074].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1074].shape = {72, 192};
    constants_info_[1074].stride = {1, 72};
    constants_info_[1074].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1074].original_fqn = "_FOLDED_CONST_permute_5";
    constants_info_[1075].name = "_FOLDED_CONST_permute_6";
    constants_info_[1075].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1075].offset = 0;
    constants_info_[1075].data_size = 36864;
    constants_info_[1075].from_folded = true;
    constants_info_[1075].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1075].shape = {96, 192};
    constants_info_[1075].stride = {1, 96};
    constants_info_[1075].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1075].original_fqn = "_FOLDED_CONST_permute_6";
    constants_info_[1076].name = "_FOLDED_CONST_permute_7";
    constants_info_[1076].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1076].offset = 0;
    constants_info_[1076].data_size = 36864;
    constants_info_[1076].from_folded = true;
    constants_info_[1076].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1076].shape = {96, 192};
    constants_info_[1076].stride = {1, 96};
    constants_info_[1076].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1076].original_fqn = "_FOLDED_CONST_permute_7";
    constants_info_[1077].name = "_FOLDED_CONST_permute_8";
    constants_info_[1077].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1077].offset = 0;
    constants_info_[1077].data_size = 36864;
    constants_info_[1077].from_folded = true;
    constants_info_[1077].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1077].shape = {96, 192};
    constants_info_[1077].stride = {1, 96};
    constants_info_[1077].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1077].original_fqn = "_FOLDED_CONST_permute_8";
    constants_info_[1078].name = "_FOLDED_CONST_permute_9";
    constants_info_[1078].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1078].offset = 0;
    constants_info_[1078].data_size = 36864;
    constants_info_[1078].from_folded = true;
    constants_info_[1078].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1078].shape = {96, 192};
    constants_info_[1078].stride = {1, 96};
    constants_info_[1078].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1078].original_fqn = "_FOLDED_CONST_permute_9";
    constants_info_[1079].name = "_FOLDED_CONST_permute_10";
    constants_info_[1079].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1079].offset = 0;
    constants_info_[1079].data_size = 27648;
    constants_info_[1079].from_folded = true;
    constants_info_[1079].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1079].shape = {72, 192};
    constants_info_[1079].stride = {1, 72};
    constants_info_[1079].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1079].original_fqn = "_FOLDED_CONST_permute_10";
    constants_info_[1080].name = "_FOLDED_CONST_permute_11";
    constants_info_[1080].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1080].offset = 0;
    constants_info_[1080].data_size = 36864;
    constants_info_[1080].from_folded = true;
    constants_info_[1080].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1080].shape = {96, 192};
    constants_info_[1080].stride = {1, 96};
    constants_info_[1080].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1080].original_fqn = "_FOLDED_CONST_permute_11";
    constants_info_[1081].name = "_FOLDED_CONST_permute_12";
    constants_info_[1081].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1081].offset = 0;
    constants_info_[1081].data_size = 36864;
    constants_info_[1081].from_folded = true;
    constants_info_[1081].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1081].shape = {96, 192};
    constants_info_[1081].stride = {1, 96};
    constants_info_[1081].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1081].original_fqn = "_FOLDED_CONST_permute_12";
    constants_info_[1082].name = "_FOLDED_CONST_permute_13";
    constants_info_[1082].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1082].offset = 0;
    constants_info_[1082].data_size = 36864;
    constants_info_[1082].from_folded = true;
    constants_info_[1082].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1082].shape = {96, 192};
    constants_info_[1082].stride = {1, 96};
    constants_info_[1082].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1082].original_fqn = "_FOLDED_CONST_permute_13";
    constants_info_[1083].name = "_FOLDED_CONST_permute_14";
    constants_info_[1083].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1083].offset = 0;
    constants_info_[1083].data_size = 27648;
    constants_info_[1083].from_folded = true;
    constants_info_[1083].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1083].shape = {72, 192};
    constants_info_[1083].stride = {1, 72};
    constants_info_[1083].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1083].original_fqn = "_FOLDED_CONST_permute_14";
    constants_info_[1084].name = "_FOLDED_CONST_permute_15";
    constants_info_[1084].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1084].offset = 0;
    constants_info_[1084].data_size = 36864;
    constants_info_[1084].from_folded = true;
    constants_info_[1084].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1084].shape = {96, 192};
    constants_info_[1084].stride = {1, 96};
    constants_info_[1084].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1084].original_fqn = "_FOLDED_CONST_permute_15";
    constants_info_[1085].name = "_FOLDED_CONST_permute_16";
    constants_info_[1085].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1085].offset = 0;
    constants_info_[1085].data_size = 24576;
    constants_info_[1085].from_folded = true;
    constants_info_[1085].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1085].shape = {64, 192};
    constants_info_[1085].stride = {1, 64};
    constants_info_[1085].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1085].original_fqn = "_FOLDED_CONST_permute_16";
    constants_info_[1086].name = "_FOLDED_CONST_permute_17";
    constants_info_[1086].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1086].offset = 0;
    constants_info_[1086].data_size = 36864;
    constants_info_[1086].from_folded = true;
    constants_info_[1086].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1086].shape = {96, 192};
    constants_info_[1086].stride = {1, 96};
    constants_info_[1086].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1086].original_fqn = "_FOLDED_CONST_permute_17";
    constants_info_[1087].name = "_FOLDED_CONST_permute_18";
    constants_info_[1087].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1087].offset = 0;
    constants_info_[1087].data_size = 24576;
    constants_info_[1087].from_folded = true;
    constants_info_[1087].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1087].shape = {64, 192};
    constants_info_[1087].stride = {1, 64};
    constants_info_[1087].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1087].original_fqn = "_FOLDED_CONST_permute_18";
    constants_info_[1088].name = "_FOLDED_CONST_permute_19";
    constants_info_[1088].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1088].offset = 0;
    constants_info_[1088].data_size = 27648;
    constants_info_[1088].from_folded = true;
    constants_info_[1088].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1088].shape = {72, 192};
    constants_info_[1088].stride = {1, 72};
    constants_info_[1088].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1088].original_fqn = "_FOLDED_CONST_permute_19";
    constants_info_[1089].name = "_FOLDED_CONST_permute_20";
    constants_info_[1089].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1089].offset = 0;
    constants_info_[1089].data_size = 27648;
    constants_info_[1089].from_folded = true;
    constants_info_[1089].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1089].shape = {72, 192};
    constants_info_[1089].stride = {1, 72};
    constants_info_[1089].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1089].original_fqn = "_FOLDED_CONST_permute_20";
    constants_info_[1090].name = "_FOLDED_CONST_permute_21";
    constants_info_[1090].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1090].offset = 0;
    constants_info_[1090].data_size = 36864;
    constants_info_[1090].from_folded = true;
    constants_info_[1090].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1090].shape = {96, 192};
    constants_info_[1090].stride = {1, 96};
    constants_info_[1090].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1090].original_fqn = "_FOLDED_CONST_permute_21";
    constants_info_[1091].name = "_FOLDED_CONST_permute_22";
    constants_info_[1091].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1091].offset = 0;
    constants_info_[1091].data_size = 24576;
    constants_info_[1091].from_folded = true;
    constants_info_[1091].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1091].shape = {64, 192};
    constants_info_[1091].stride = {1, 64};
    constants_info_[1091].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1091].original_fqn = "_FOLDED_CONST_permute_22";
    constants_info_[1092].name = "_FOLDED_CONST_permute_23";
    constants_info_[1092].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1092].offset = 0;
    constants_info_[1092].data_size = 27648;
    constants_info_[1092].from_folded = true;
    constants_info_[1092].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1092].shape = {72, 192};
    constants_info_[1092].stride = {1, 72};
    constants_info_[1092].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1092].original_fqn = "_FOLDED_CONST_permute_23";
    constants_info_[1093].name = "_FOLDED_CONST_permute_24";
    constants_info_[1093].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1093].offset = 0;
    constants_info_[1093].data_size = 27648;
    constants_info_[1093].from_folded = true;
    constants_info_[1093].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1093].shape = {72, 192};
    constants_info_[1093].stride = {1, 72};
    constants_info_[1093].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1093].original_fqn = "_FOLDED_CONST_permute_24";
    constants_info_[1094].name = "_FOLDED_CONST_permute_25";
    constants_info_[1094].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1094].offset = 0;
    constants_info_[1094].data_size = 27648;
    constants_info_[1094].from_folded = true;
    constants_info_[1094].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1094].shape = {72, 192};
    constants_info_[1094].stride = {1, 72};
    constants_info_[1094].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1094].original_fqn = "_FOLDED_CONST_permute_25";
    constants_info_[1095].name = "_FOLDED_CONST_permute_26";
    constants_info_[1095].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1095].offset = 0;
    constants_info_[1095].data_size = 24576;
    constants_info_[1095].from_folded = true;
    constants_info_[1095].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1095].shape = {64, 192};
    constants_info_[1095].stride = {1, 64};
    constants_info_[1095].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1095].original_fqn = "_FOLDED_CONST_permute_26";
    constants_info_[1096].name = "_FOLDED_CONST_permute_27";
    constants_info_[1096].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1096].offset = 0;
    constants_info_[1096].data_size = 24576;
    constants_info_[1096].from_folded = true;
    constants_info_[1096].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1096].shape = {64, 192};
    constants_info_[1096].stride = {1, 64};
    constants_info_[1096].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1096].original_fqn = "_FOLDED_CONST_permute_27";
    constants_info_[1097].name = "_FOLDED_CONST_permute_28";
    constants_info_[1097].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1097].offset = 0;
    constants_info_[1097].data_size = 24576;
    constants_info_[1097].from_folded = true;
    constants_info_[1097].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1097].shape = {64, 192};
    constants_info_[1097].stride = {1, 64};
    constants_info_[1097].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1097].original_fqn = "_FOLDED_CONST_permute_28";
    constants_info_[1098].name = "_FOLDED_CONST_permute_29";
    constants_info_[1098].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1098].offset = 0;
    constants_info_[1098].data_size = 55296;
    constants_info_[1098].from_folded = true;
    constants_info_[1098].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1098].shape = {144, 192};
    constants_info_[1098].stride = {1, 144};
    constants_info_[1098].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1098].original_fqn = "_FOLDED_CONST_permute_29";
    constants_info_[1099].name = "_FOLDED_CONST_permute_30";
    constants_info_[1099].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1099].offset = 0;
    constants_info_[1099].data_size = 55296;
    constants_info_[1099].from_folded = true;
    constants_info_[1099].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1099].shape = {144, 192};
    constants_info_[1099].stride = {1, 144};
    constants_info_[1099].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1099].original_fqn = "_FOLDED_CONST_permute_30";
    constants_info_[1100].name = "_FOLDED_CONST_permute_31";
    constants_info_[1100].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1100].offset = 0;
    constants_info_[1100].data_size = 24576;
    constants_info_[1100].from_folded = true;
    constants_info_[1100].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1100].shape = {64, 192};
    constants_info_[1100].stride = {1, 64};
    constants_info_[1100].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1100].original_fqn = "_FOLDED_CONST_permute_31";
    constants_info_[1101].name = "_FOLDED_CONST_permute_32";
    constants_info_[1101].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1101].offset = 0;
    constants_info_[1101].data_size = 24576;
    constants_info_[1101].from_folded = true;
    constants_info_[1101].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1101].shape = {64, 192};
    constants_info_[1101].stride = {1, 64};
    constants_info_[1101].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1101].original_fqn = "_FOLDED_CONST_permute_32";
    constants_info_[1102].name = "_FOLDED_CONST_permute_33";
    constants_info_[1102].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1102].offset = 0;
    constants_info_[1102].data_size = 24576;
    constants_info_[1102].from_folded = true;
    constants_info_[1102].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1102].shape = {64, 192};
    constants_info_[1102].stride = {1, 64};
    constants_info_[1102].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1102].original_fqn = "_FOLDED_CONST_permute_33";
    constants_info_[1103].name = "_FOLDED_CONST_permute_34";
    constants_info_[1103].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1103].offset = 0;
    constants_info_[1103].data_size = 36864;
    constants_info_[1103].from_folded = true;
    constants_info_[1103].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1103].shape = {96, 192};
    constants_info_[1103].stride = {1, 96};
    constants_info_[1103].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1103].original_fqn = "_FOLDED_CONST_permute_34";
    constants_info_[1104].name = "_FOLDED_CONST_permute_35";
    constants_info_[1104].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1104].offset = 0;
    constants_info_[1104].data_size = 36864;
    constants_info_[1104].from_folded = true;
    constants_info_[1104].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1104].shape = {96, 192};
    constants_info_[1104].stride = {1, 96};
    constants_info_[1104].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1104].original_fqn = "_FOLDED_CONST_permute_35";
    constants_info_[1105].name = "_FOLDED_CONST_cat_3";
    constants_info_[1105].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1105].offset = 0;
    constants_info_[1105].data_size = 512;
    constants_info_[1105].from_folded = true;
    constants_info_[1105].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1105].shape = {256};
    constants_info_[1105].stride = {1};
    constants_info_[1105].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1105].original_fqn = "_FOLDED_CONST_cat_3";
    constants_info_[1106].name = "_FOLDED_CONST_constant_pad_nd_default_23";
    constants_info_[1106].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1106].offset = 0;
    constants_info_[1106].data_size = 3100672;
    constants_info_[1106].from_folded = true;
    constants_info_[1106].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1106].shape = {6056, 256};
    constants_info_[1106].stride = {256, 1};
    constants_info_[1106].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1106].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_23";
    constants_info_[1107].name = "_FOLDED_CONST_cat_6";
    constants_info_[1107].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1107].offset = 0;
    constants_info_[1107].data_size = 1024;
    constants_info_[1107].from_folded = true;
    constants_info_[1107].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1107].shape = {512};
    constants_info_[1107].stride = {1};
    constants_info_[1107].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1107].original_fqn = "_FOLDED_CONST_cat_6";
    constants_info_[1108].name = "_FOLDED_CONST_permute_37";
    constants_info_[1108].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1108].offset = 0;
    constants_info_[1108].data_size = 716800;
    constants_info_[1108].from_folded = true;
    constants_info_[1108].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1108].shape = {700, 512};
    constants_info_[1108].stride = {1, 700};
    constants_info_[1108].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1108].original_fqn = "_FOLDED_CONST_permute_37";
    constants_info_[1109].name = "_FOLDED_CONST_permute_40";
    constants_info_[1109].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1109].offset = 0;
    constants_info_[1109].data_size = 1549312;
    constants_info_[1109].from_folded = true;
    constants_info_[1109].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1109].shape = {256, 3026};
    constants_info_[1109].stride = {1, 256};
    constants_info_[1109].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1109].original_fqn = "_FOLDED_CONST_permute_40";
    constants_info_[1110].name = "_FOLDED_CONST_permute_41";
    constants_info_[1110].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1110].offset = 0;
    constants_info_[1110].data_size = 1549312;
    constants_info_[1110].from_folded = true;
    constants_info_[1110].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1110].shape = {3026, 256};
    constants_info_[1110].stride = {1, 3026};
    constants_info_[1110].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1110].original_fqn = "_FOLDED_CONST_permute_41";
    constants_info_[1111].name = "_FOLDED_CONST_permute_44";
    constants_info_[1111].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1111].offset = 0;
    constants_info_[1111].data_size = 524288;
    constants_info_[1111].from_folded = true;
    constants_info_[1111].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1111].shape = {256, 1024};
    constants_info_[1111].stride = {1, 256};
    constants_info_[1111].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1111].original_fqn = "_FOLDED_CONST_permute_44";
    constants_info_[1112].name = "_FOLDED_CONST_permute_45";
    constants_info_[1112].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1112].offset = 0;
    constants_info_[1112].data_size = 8192;
    constants_info_[1112].from_folded = true;
    constants_info_[1112].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1112].shape = {64, 64};
    constants_info_[1112].stride = {1, 64};
    constants_info_[1112].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1112].original_fqn = "_FOLDED_CONST_permute_45";
    constants_info_[1113].name = "_FOLDED_CONST_permute_42";
    constants_info_[1113].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1113].offset = 0;
    constants_info_[1113].data_size = 8192;
    constants_info_[1113].from_folded = true;
    constants_info_[1113].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1113].shape = {64, 64};
    constants_info_[1113].stride = {1, 64};
    constants_info_[1113].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1113].original_fqn = "_FOLDED_CONST_permute_42";
    constants_info_[1114].name = "_FOLDED_CONST_permute_46";
    constants_info_[1114].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1114].offset = 0;
    constants_info_[1114].data_size = 8192;
    constants_info_[1114].from_folded = true;
    constants_info_[1114].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1114].shape = {64, 64};
    constants_info_[1114].stride = {1, 64};
    constants_info_[1114].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1114].original_fqn = "_FOLDED_CONST_permute_46";
    constants_info_[1115].name = "_FOLDED_CONST_permute_43";
    constants_info_[1115].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1115].offset = 0;
    constants_info_[1115].data_size = 8192;
    constants_info_[1115].from_folded = true;
    constants_info_[1115].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1115].shape = {64, 64};
    constants_info_[1115].stride = {1, 64};
    constants_info_[1115].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1115].original_fqn = "_FOLDED_CONST_permute_43";
    constants_info_[1116].name = "_FOLDED_CONST_permute_57";
    constants_info_[1116].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1116].offset = 0;
    constants_info_[1116].data_size = 16384;
    constants_info_[1116].from_folded = true;
    constants_info_[1116].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1116].shape = {64, 128};
    constants_info_[1116].stride = {1, 64};
    constants_info_[1116].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1116].original_fqn = "_FOLDED_CONST_permute_57";
    constants_info_[1117].name = "_FOLDED_CONST_permute_59";
    constants_info_[1117].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1117].offset = 0;
    constants_info_[1117].data_size = 16384;
    constants_info_[1117].from_folded = true;
    constants_info_[1117].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1117].shape = {128, 64};
    constants_info_[1117].stride = {1, 128};
    constants_info_[1117].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1117].original_fqn = "_FOLDED_CONST_permute_59";
    constants_info_[1118].name = "_FOLDED_CONST_cat_9";
    constants_info_[1118].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1118].offset = 0;
    constants_info_[1118].data_size = 2304;
    constants_info_[1118].from_folded = true;
    constants_info_[1118].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1118].shape = {1152};
    constants_info_[1118].stride = {1};
    constants_info_[1118].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1118].original_fqn = "_FOLDED_CONST_cat_9";
    constants_info_[1119].name = "_FOLDED_CONST_constant_pad_nd_default_21";
    constants_info_[1119].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1119].offset = 0;
    constants_info_[1119].data_size = 7575552;
    constants_info_[1119].from_folded = true;
    constants_info_[1119].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1119].shape = {3288, 1152};
    constants_info_[1119].stride = {1152, 1};
    constants_info_[1119].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1119].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_21";
    constants_info_[1120].name = "_FOLDED_CONST_permute_38";
    constants_info_[1120].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1120].offset = 0;
    constants_info_[1120].data_size = 491520;
    constants_info_[1120].from_folded = true;
    constants_info_[1120].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1120].shape = {256, 960};
    constants_info_[1120].stride = {1, 256};
    constants_info_[1120].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1120].original_fqn = "_FOLDED_CONST_permute_38";
    constants_info_[1121].name = "_FOLDED_CONST_permute_39";
    constants_info_[1121].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1121].offset = 0;
    constants_info_[1121].data_size = 2949120;
    constants_info_[1121].from_folded = true;
    constants_info_[1121].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1121].shape = {960, 1536};
    constants_info_[1121].stride = {1, 960};
    constants_info_[1121].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1121].original_fqn = "_FOLDED_CONST_permute_39";
    constants_info_[1122].name = "_FOLDED_CONST_permute_56";
    constants_info_[1122].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1122].offset = 0;
    constants_info_[1122].data_size = 16384;
    constants_info_[1122].from_folded = true;
    constants_info_[1122].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1122].shape = {64, 128};
    constants_info_[1122].stride = {1, 64};
    constants_info_[1122].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1122].original_fqn = "_FOLDED_CONST_permute_56";
    constants_info_[1123].name = "_FOLDED_CONST_permute_58";
    constants_info_[1123].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1123].offset = 0;
    constants_info_[1123].data_size = 16384;
    constants_info_[1123].from_folded = true;
    constants_info_[1123].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1123].shape = {128, 64};
    constants_info_[1123].stride = {1, 128};
    constants_info_[1123].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1123].original_fqn = "_FOLDED_CONST_permute_58";
    constants_info_[1124].name = "_FOLDED_CONST_cat_13";
    constants_info_[1124].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1124].offset = 0;
    constants_info_[1124].data_size = 3072;
    constants_info_[1124].from_folded = true;
    constants_info_[1124].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1124].shape = {1536};
    constants_info_[1124].stride = {1};
    constants_info_[1124].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1124].original_fqn = "_FOLDED_CONST_cat_13";
    constants_info_[1125].name = "_FOLDED_CONST_permute_63";
    constants_info_[1125].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1125].offset = 0;
    constants_info_[1125].data_size = 14155776;
    constants_info_[1125].from_folded = true;
    constants_info_[1125].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1125].shape = {4608, 1536};
    constants_info_[1125].stride = {1, 4608};
    constants_info_[1125].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1125].original_fqn = "_FOLDED_CONST_permute_63";
    constants_info_[1126].name = "_FOLDED_CONST_permute_64";
    constants_info_[1126].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1126].offset = 0;
    constants_info_[1126].data_size = 1179648;
    constants_info_[1126].from_folded = true;
    constants_info_[1126].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1126].shape = {768, 768};
    constants_info_[1126].stride = {1, 768};
    constants_info_[1126].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1126].original_fqn = "_FOLDED_CONST_permute_64";
    constants_info_[1127].name = "_FOLDED_CONST_permute_65";
    constants_info_[1127].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1127].offset = 0;
    constants_info_[1127].data_size = 1179648;
    constants_info_[1127].from_folded = true;
    constants_info_[1127].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1127].shape = {768, 768};
    constants_info_[1127].stride = {1, 768};
    constants_info_[1127].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1127].original_fqn = "_FOLDED_CONST_permute_65";
    constants_info_[1128].name = "_FOLDED_CONST_permute_66";
    constants_info_[1128].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1128].offset = 0;
    constants_info_[1128].data_size = 33767424;
    constants_info_[1128].from_folded = true;
    constants_info_[1128].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1128].shape = {768, 21984};
    constants_info_[1128].stride = {1, 768};
    constants_info_[1128].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1128].original_fqn = "_FOLDED_CONST_permute_66";
    constants_info_[1129].name = "_FOLDED_CONST_permute_67";
    constants_info_[1129].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1129].offset = 0;
    constants_info_[1129].data_size = 14155776;
    constants_info_[1129].from_folded = true;
    constants_info_[1129].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1129].shape = {768, 9216};
    constants_info_[1129].stride = {1, 768};
    constants_info_[1129].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1129].original_fqn = "_FOLDED_CONST_permute_67";
    constants_info_[1130].name = "_FOLDED_CONST_permute_68";
    constants_info_[1130].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1130].offset = 0;
    constants_info_[1130].data_size = 90046464;
    constants_info_[1130].from_folded = true;
    constants_info_[1130].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1130].shape = {21984, 2048};
    constants_info_[1130].stride = {1, 21984};
    constants_info_[1130].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1130].original_fqn = "_FOLDED_CONST_permute_68";
    constants_info_[1131].name = "_FOLDED_CONST_constant_pad_nd_default_19";
    constants_info_[1131].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1131].offset = 0;
    constants_info_[1131].data_size = 4884480;
    constants_info_[1131].from_folded = true;
    constants_info_[1131].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1131].shape = {6360, 384};
    constants_info_[1131].stride = {384, 1};
    constants_info_[1131].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1131].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_19";
    constants_info_[1132].name = "_FOLDED_CONST_permute_70";
    constants_info_[1132].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1132].offset = 0;
    constants_info_[1132].data_size = 4879872;
    constants_info_[1132].from_folded = true;
    constants_info_[1132].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1132].shape = {384, 6354};
    constants_info_[1132].stride = {1, 384};
    constants_info_[1132].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1132].original_fqn = "_FOLDED_CONST_permute_70";
    constants_info_[1133].name = "_FOLDED_CONST_constant_pad_nd_default_17";
    constants_info_[1133].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1133].offset = 0;
    constants_info_[1133].data_size = 39075840;
    constants_info_[1133].from_folded = true;
    constants_info_[1133].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1133].shape = {6360, 3072};
    constants_info_[1133].stride = {3072, 1};
    constants_info_[1133].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1133].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_17";
    constants_info_[1134].name = "_FOLDED_CONST_permute_72";
    constants_info_[1134].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1134].offset = 0;
    constants_info_[1134].data_size = 9437184;
    constants_info_[1134].from_folded = true;
    constants_info_[1134].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1134].shape = {3072, 1536};
    constants_info_[1134].stride = {1, 3072};
    constants_info_[1134].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1134].original_fqn = "_FOLDED_CONST_permute_72";
    constants_info_[1135].name = "_FOLDED_CONST_permute_73";
    constants_info_[1135].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1135].offset = 0;
    constants_info_[1135].data_size = 9437184;
    constants_info_[1135].from_folded = true;
    constants_info_[1135].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1135].shape = {1536, 3072};
    constants_info_[1135].stride = {1, 1536};
    constants_info_[1135].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1135].original_fqn = "_FOLDED_CONST_permute_73";
    constants_info_[1136].name = "_FOLDED_CONST_permute_74";
    constants_info_[1136].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1136].offset = 0;
    constants_info_[1136].data_size = 9437184;
    constants_info_[1136].from_folded = true;
    constants_info_[1136].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1136].shape = {3072, 1536};
    constants_info_[1136].stride = {1, 3072};
    constants_info_[1136].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1136].original_fqn = "_FOLDED_CONST_permute_74";
    constants_info_[1137].name = "_FOLDED_CONST_permute_75";
    constants_info_[1137].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1137].offset = 0;
    constants_info_[1137].data_size = 9437184;
    constants_info_[1137].from_folded = true;
    constants_info_[1137].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1137].shape = {1536, 3072};
    constants_info_[1137].stride = {1, 1536};
    constants_info_[1137].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1137].original_fqn = "_FOLDED_CONST_permute_75";
    constants_info_[1138].name = "_FOLDED_CONST_permute_76";
    constants_info_[1138].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1138].offset = 0;
    constants_info_[1138].data_size = 56623104;
    constants_info_[1138].from_folded = true;
    constants_info_[1138].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1138].shape = {3072, 9216};
    constants_info_[1138].stride = {1, 3072};
    constants_info_[1138].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1138].original_fqn = "_FOLDED_CONST_permute_76";
    constants_info_[1139].name = "_FOLDED_CONST_cat_17";
    constants_info_[1139].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1139].offset = 0;
    constants_info_[1139].data_size = 3072;
    constants_info_[1139].from_folded = true;
    constants_info_[1139].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1139].shape = {1536};
    constants_info_[1139].stride = {1};
    constants_info_[1139].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1139].original_fqn = "_FOLDED_CONST_cat_17";
    constants_info_[1140].name = "_FOLDED_CONST_permute_78";
    constants_info_[1140].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1140].offset = 0;
    constants_info_[1140].data_size = 14155776;
    constants_info_[1140].from_folded = true;
    constants_info_[1140].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1140].shape = {4608, 1536};
    constants_info_[1140].stride = {1, 4608};
    constants_info_[1140].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1140].original_fqn = "_FOLDED_CONST_permute_78";
    constants_info_[1141].name = "_FOLDED_CONST_permute_79";
    constants_info_[1141].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1141].offset = 0;
    constants_info_[1141].data_size = 1179648;
    constants_info_[1141].from_folded = true;
    constants_info_[1141].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1141].shape = {768, 768};
    constants_info_[1141].stride = {1, 768};
    constants_info_[1141].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1141].original_fqn = "_FOLDED_CONST_permute_79";
    constants_info_[1142].name = "_FOLDED_CONST_permute_80";
    constants_info_[1142].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1142].offset = 0;
    constants_info_[1142].data_size = 1179648;
    constants_info_[1142].from_folded = true;
    constants_info_[1142].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1142].shape = {768, 768};
    constants_info_[1142].stride = {1, 768};
    constants_info_[1142].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1142].original_fqn = "_FOLDED_CONST_permute_80";
    constants_info_[1143].name = "_FOLDED_CONST_permute_81";
    constants_info_[1143].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1143].offset = 0;
    constants_info_[1143].data_size = 7520256;
    constants_info_[1143].from_folded = true;
    constants_info_[1143].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1143].shape = {768, 4896};
    constants_info_[1143].stride = {1, 768};
    constants_info_[1143].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1143].original_fqn = "_FOLDED_CONST_permute_81";
    constants_info_[1144].name = "_FOLDED_CONST_permute_82";
    constants_info_[1144].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1144].offset = 0;
    constants_info_[1144].data_size = 14155776;
    constants_info_[1144].from_folded = true;
    constants_info_[1144].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1144].shape = {768, 9216};
    constants_info_[1144].stride = {1, 768};
    constants_info_[1144].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1144].original_fqn = "_FOLDED_CONST_permute_82";
    constants_info_[1145].name = "_FOLDED_CONST_permute_83";
    constants_info_[1145].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1145].offset = 0;
    constants_info_[1145].data_size = 20054016;
    constants_info_[1145].from_folded = true;
    constants_info_[1145].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1145].shape = {4896, 2048};
    constants_info_[1145].stride = {1, 4896};
    constants_info_[1145].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1145].original_fqn = "_FOLDED_CONST_permute_83";
    constants_info_[1146].name = "_FOLDED_CONST_constant_pad_nd_default_13";
    constants_info_[1146].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1146].offset = 0;
    constants_info_[1146].data_size = 4884480;
    constants_info_[1146].from_folded = true;
    constants_info_[1146].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1146].shape = {6360, 384};
    constants_info_[1146].stride = {384, 1};
    constants_info_[1146].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1146].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_13";
    constants_info_[1147].name = "_FOLDED_CONST_permute_85";
    constants_info_[1147].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1147].offset = 0;
    constants_info_[1147].data_size = 4879872;
    constants_info_[1147].from_folded = true;
    constants_info_[1147].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1147].shape = {384, 6354};
    constants_info_[1147].stride = {1, 384};
    constants_info_[1147].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1147].original_fqn = "_FOLDED_CONST_permute_85";
    constants_info_[1148].name = "_FOLDED_CONST_constant_pad_nd_default_11";
    constants_info_[1148].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1148].offset = 0;
    constants_info_[1148].data_size = 39075840;
    constants_info_[1148].from_folded = true;
    constants_info_[1148].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1148].shape = {6360, 3072};
    constants_info_[1148].stride = {3072, 1};
    constants_info_[1148].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1148].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_11";
    constants_info_[1149].name = "_FOLDED_CONST_permute_87";
    constants_info_[1149].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1149].offset = 0;
    constants_info_[1149].data_size = 9437184;
    constants_info_[1149].from_folded = true;
    constants_info_[1149].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1149].shape = {3072, 1536};
    constants_info_[1149].stride = {1, 3072};
    constants_info_[1149].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1149].original_fqn = "_FOLDED_CONST_permute_87";
    constants_info_[1150].name = "_FOLDED_CONST_permute_88";
    constants_info_[1150].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1150].offset = 0;
    constants_info_[1150].data_size = 9437184;
    constants_info_[1150].from_folded = true;
    constants_info_[1150].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1150].shape = {1536, 3072};
    constants_info_[1150].stride = {1, 1536};
    constants_info_[1150].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1150].original_fqn = "_FOLDED_CONST_permute_88";
    constants_info_[1151].name = "_FOLDED_CONST_permute_89";
    constants_info_[1151].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1151].offset = 0;
    constants_info_[1151].data_size = 9437184;
    constants_info_[1151].from_folded = true;
    constants_info_[1151].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1151].shape = {3072, 1536};
    constants_info_[1151].stride = {1, 3072};
    constants_info_[1151].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1151].original_fqn = "_FOLDED_CONST_permute_89";
    constants_info_[1152].name = "_FOLDED_CONST_permute_90";
    constants_info_[1152].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1152].offset = 0;
    constants_info_[1152].data_size = 9437184;
    constants_info_[1152].from_folded = true;
    constants_info_[1152].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1152].shape = {1536, 3072};
    constants_info_[1152].stride = {1, 1536};
    constants_info_[1152].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1152].original_fqn = "_FOLDED_CONST_permute_90";
    constants_info_[1153].name = "_FOLDED_CONST_permute_91";
    constants_info_[1153].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1153].offset = 0;
    constants_info_[1153].data_size = 56623104;
    constants_info_[1153].from_folded = true;
    constants_info_[1153].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1153].shape = {3072, 9216};
    constants_info_[1153].stride = {1, 3072};
    constants_info_[1153].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1153].original_fqn = "_FOLDED_CONST_permute_91";
    constants_info_[1154].name = "_FOLDED_CONST_cat_21";
    constants_info_[1154].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1154].offset = 0;
    constants_info_[1154].data_size = 3072;
    constants_info_[1154].from_folded = true;
    constants_info_[1154].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1154].shape = {1536};
    constants_info_[1154].stride = {1};
    constants_info_[1154].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1154].original_fqn = "_FOLDED_CONST_cat_21";
    constants_info_[1155].name = "_FOLDED_CONST_permute_93";
    constants_info_[1155].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1155].offset = 0;
    constants_info_[1155].data_size = 14155776;
    constants_info_[1155].from_folded = true;
    constants_info_[1155].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1155].shape = {4608, 1536};
    constants_info_[1155].stride = {1, 4608};
    constants_info_[1155].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1155].original_fqn = "_FOLDED_CONST_permute_93";
    constants_info_[1156].name = "_FOLDED_CONST_permute_94";
    constants_info_[1156].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1156].offset = 0;
    constants_info_[1156].data_size = 1179648;
    constants_info_[1156].from_folded = true;
    constants_info_[1156].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1156].shape = {768, 768};
    constants_info_[1156].stride = {1, 768};
    constants_info_[1156].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1156].original_fqn = "_FOLDED_CONST_permute_94";
    constants_info_[1157].name = "_FOLDED_CONST_permute_95";
    constants_info_[1157].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1157].offset = 0;
    constants_info_[1157].data_size = 1179648;
    constants_info_[1157].from_folded = true;
    constants_info_[1157].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1157].shape = {768, 768};
    constants_info_[1157].stride = {1, 768};
    constants_info_[1157].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1157].original_fqn = "_FOLDED_CONST_permute_95";
    constants_info_[1158].name = "_FOLDED_CONST_permute_96";
    constants_info_[1158].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1158].offset = 0;
    constants_info_[1158].data_size = 7520256;
    constants_info_[1158].from_folded = true;
    constants_info_[1158].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1158].shape = {768, 4896};
    constants_info_[1158].stride = {1, 768};
    constants_info_[1158].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1158].original_fqn = "_FOLDED_CONST_permute_96";
    constants_info_[1159].name = "_FOLDED_CONST_permute_97";
    constants_info_[1159].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1159].offset = 0;
    constants_info_[1159].data_size = 14155776;
    constants_info_[1159].from_folded = true;
    constants_info_[1159].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1159].shape = {768, 9216};
    constants_info_[1159].stride = {1, 768};
    constants_info_[1159].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1159].original_fqn = "_FOLDED_CONST_permute_97";
    constants_info_[1160].name = "_FOLDED_CONST_permute_98";
    constants_info_[1160].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1160].offset = 0;
    constants_info_[1160].data_size = 20054016;
    constants_info_[1160].from_folded = true;
    constants_info_[1160].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1160].shape = {4896, 2048};
    constants_info_[1160].stride = {1, 4896};
    constants_info_[1160].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1160].original_fqn = "_FOLDED_CONST_permute_98";
    constants_info_[1161].name = "_FOLDED_CONST_constant_pad_nd_default_7";
    constants_info_[1161].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1161].offset = 0;
    constants_info_[1161].data_size = 4884480;
    constants_info_[1161].from_folded = true;
    constants_info_[1161].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1161].shape = {6360, 384};
    constants_info_[1161].stride = {384, 1};
    constants_info_[1161].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1161].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_7";
    constants_info_[1162].name = "_FOLDED_CONST_permute_100";
    constants_info_[1162].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1162].offset = 0;
    constants_info_[1162].data_size = 4879872;
    constants_info_[1162].from_folded = true;
    constants_info_[1162].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1162].shape = {384, 6354};
    constants_info_[1162].stride = {1, 384};
    constants_info_[1162].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1162].original_fqn = "_FOLDED_CONST_permute_100";
    constants_info_[1163].name = "_FOLDED_CONST_constant_pad_nd_default_5";
    constants_info_[1163].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1163].offset = 0;
    constants_info_[1163].data_size = 39075840;
    constants_info_[1163].from_folded = true;
    constants_info_[1163].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1163].shape = {6360, 3072};
    constants_info_[1163].stride = {3072, 1};
    constants_info_[1163].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1163].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_5";
    constants_info_[1164].name = "_FOLDED_CONST_permute_102";
    constants_info_[1164].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1164].offset = 0;
    constants_info_[1164].data_size = 9437184;
    constants_info_[1164].from_folded = true;
    constants_info_[1164].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1164].shape = {3072, 1536};
    constants_info_[1164].stride = {1, 3072};
    constants_info_[1164].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1164].original_fqn = "_FOLDED_CONST_permute_102";
    constants_info_[1165].name = "_FOLDED_CONST_permute_103";
    constants_info_[1165].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1165].offset = 0;
    constants_info_[1165].data_size = 9437184;
    constants_info_[1165].from_folded = true;
    constants_info_[1165].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1165].shape = {1536, 3072};
    constants_info_[1165].stride = {1, 1536};
    constants_info_[1165].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1165].original_fqn = "_FOLDED_CONST_permute_103";
    constants_info_[1166].name = "_FOLDED_CONST_permute_104";
    constants_info_[1166].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1166].offset = 0;
    constants_info_[1166].data_size = 9437184;
    constants_info_[1166].from_folded = true;
    constants_info_[1166].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1166].shape = {3072, 1536};
    constants_info_[1166].stride = {1, 3072};
    constants_info_[1166].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1166].original_fqn = "_FOLDED_CONST_permute_104";
    constants_info_[1167].name = "_FOLDED_CONST_permute_105";
    constants_info_[1167].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1167].offset = 0;
    constants_info_[1167].data_size = 9437184;
    constants_info_[1167].from_folded = true;
    constants_info_[1167].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1167].shape = {1536, 3072};
    constants_info_[1167].stride = {1, 1536};
    constants_info_[1167].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1167].original_fqn = "_FOLDED_CONST_permute_105";
    constants_info_[1168].name = "_FOLDED_CONST_permute_106";
    constants_info_[1168].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1168].offset = 0;
    constants_info_[1168].data_size = 56623104;
    constants_info_[1168].from_folded = true;
    constants_info_[1168].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1168].shape = {3072, 9216};
    constants_info_[1168].stride = {1, 3072};
    constants_info_[1168].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1168].original_fqn = "_FOLDED_CONST_permute_106";
    constants_info_[1169].name = "_FOLDED_CONST_cat_25";
    constants_info_[1169].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1169].offset = 0;
    constants_info_[1169].data_size = 3072;
    constants_info_[1169].from_folded = true;
    constants_info_[1169].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1169].shape = {1536};
    constants_info_[1169].stride = {1};
    constants_info_[1169].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1169].original_fqn = "_FOLDED_CONST_cat_25";
    constants_info_[1170].name = "_FOLDED_CONST_permute_108";
    constants_info_[1170].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1170].offset = 0;
    constants_info_[1170].data_size = 14155776;
    constants_info_[1170].from_folded = true;
    constants_info_[1170].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1170].shape = {4608, 1536};
    constants_info_[1170].stride = {1, 4608};
    constants_info_[1170].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1170].original_fqn = "_FOLDED_CONST_permute_108";
    constants_info_[1171].name = "_FOLDED_CONST_permute_109";
    constants_info_[1171].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1171].offset = 0;
    constants_info_[1171].data_size = 1179648;
    constants_info_[1171].from_folded = true;
    constants_info_[1171].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1171].shape = {768, 768};
    constants_info_[1171].stride = {1, 768};
    constants_info_[1171].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1171].original_fqn = "_FOLDED_CONST_permute_109";
    constants_info_[1172].name = "_FOLDED_CONST_permute_110";
    constants_info_[1172].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1172].offset = 0;
    constants_info_[1172].data_size = 1179648;
    constants_info_[1172].from_folded = true;
    constants_info_[1172].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1172].shape = {768, 768};
    constants_info_[1172].stride = {1, 768};
    constants_info_[1172].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1172].original_fqn = "_FOLDED_CONST_permute_110";
    constants_info_[1173].name = "_FOLDED_CONST_permute_111";
    constants_info_[1173].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1173].offset = 0;
    constants_info_[1173].data_size = 7520256;
    constants_info_[1173].from_folded = true;
    constants_info_[1173].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1173].shape = {768, 4896};
    constants_info_[1173].stride = {1, 768};
    constants_info_[1173].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1173].original_fqn = "_FOLDED_CONST_permute_111";
    constants_info_[1174].name = "_FOLDED_CONST_permute_112";
    constants_info_[1174].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1174].offset = 0;
    constants_info_[1174].data_size = 14155776;
    constants_info_[1174].from_folded = true;
    constants_info_[1174].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1174].shape = {768, 9216};
    constants_info_[1174].stride = {1, 768};
    constants_info_[1174].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1174].original_fqn = "_FOLDED_CONST_permute_112";
    constants_info_[1175].name = "_FOLDED_CONST_permute_113";
    constants_info_[1175].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1175].offset = 0;
    constants_info_[1175].data_size = 20054016;
    constants_info_[1175].from_folded = true;
    constants_info_[1175].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1175].shape = {4896, 2048};
    constants_info_[1175].stride = {1, 4896};
    constants_info_[1175].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1175].original_fqn = "_FOLDED_CONST_permute_113";
    constants_info_[1176].name = "_FOLDED_CONST_constant_pad_nd_default_3";
    constants_info_[1176].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1176].offset = 0;
    constants_info_[1176].data_size = 4884480;
    constants_info_[1176].from_folded = true;
    constants_info_[1176].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1176].shape = {6360, 384};
    constants_info_[1176].stride = {384, 1};
    constants_info_[1176].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1176].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_3";
    constants_info_[1177].name = "_FOLDED_CONST_permute_115";
    constants_info_[1177].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1177].offset = 0;
    constants_info_[1177].data_size = 4879872;
    constants_info_[1177].from_folded = true;
    constants_info_[1177].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1177].shape = {384, 6354};
    constants_info_[1177].stride = {1, 384};
    constants_info_[1177].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1177].original_fqn = "_FOLDED_CONST_permute_115";
    constants_info_[1178].name = "_FOLDED_CONST_constant_pad_nd_default_1";
    constants_info_[1178].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1178].offset = 0;
    constants_info_[1178].data_size = 39075840;
    constants_info_[1178].from_folded = true;
    constants_info_[1178].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1178].shape = {6360, 3072};
    constants_info_[1178].stride = {3072, 1};
    constants_info_[1178].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1178].original_fqn = "_FOLDED_CONST_constant_pad_nd_default_1";
    constants_info_[1179].name = "_FOLDED_CONST_permute_117";
    constants_info_[1179].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1179].offset = 0;
    constants_info_[1179].data_size = 9437184;
    constants_info_[1179].from_folded = true;
    constants_info_[1179].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1179].shape = {3072, 1536};
    constants_info_[1179].stride = {1, 3072};
    constants_info_[1179].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1179].original_fqn = "_FOLDED_CONST_permute_117";
    constants_info_[1180].name = "_FOLDED_CONST_permute_118";
    constants_info_[1180].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1180].offset = 0;
    constants_info_[1180].data_size = 9437184;
    constants_info_[1180].from_folded = true;
    constants_info_[1180].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1180].shape = {1536, 3072};
    constants_info_[1180].stride = {1, 1536};
    constants_info_[1180].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1180].original_fqn = "_FOLDED_CONST_permute_118";
    constants_info_[1181].name = "_FOLDED_CONST_permute_119";
    constants_info_[1181].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1181].offset = 0;
    constants_info_[1181].data_size = 9437184;
    constants_info_[1181].from_folded = true;
    constants_info_[1181].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1181].shape = {3072, 1536};
    constants_info_[1181].stride = {1, 3072};
    constants_info_[1181].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1181].original_fqn = "_FOLDED_CONST_permute_119";
    constants_info_[1182].name = "_FOLDED_CONST_permute_120";
    constants_info_[1182].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1182].offset = 0;
    constants_info_[1182].data_size = 9437184;
    constants_info_[1182].from_folded = true;
    constants_info_[1182].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1182].shape = {1536, 3072};
    constants_info_[1182].stride = {1, 1536};
    constants_info_[1182].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1182].original_fqn = "_FOLDED_CONST_permute_120";
    constants_info_[1183].name = "_FOLDED_CONST_permute_121";
    constants_info_[1183].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1183].offset = 0;
    constants_info_[1183].data_size = 3145728;
    constants_info_[1183].from_folded = true;
    constants_info_[1183].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1183].shape = {3072, 512};
    constants_info_[1183].stride = {1, 3072};
    constants_info_[1183].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1183].original_fqn = "_FOLDED_CONST_permute_121";
    constants_info_[1184].name = "_FOLDED_CONST_permute_122";
    constants_info_[1184].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1184].offset = 0;
    constants_info_[1184].data_size = 3145728;
    constants_info_[1184].from_folded = true;
    constants_info_[1184].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1184].shape = {512, 3072};
    constants_info_[1184].stride = {1, 512};
    constants_info_[1184].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1184].original_fqn = "_FOLDED_CONST_permute_122";
    constants_info_[1185].name = "_FOLDED_CONST_permute_123";
    constants_info_[1185].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1185].offset = 0;
    constants_info_[1185].data_size = 3145728;
    constants_info_[1185].from_folded = true;
    constants_info_[1185].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1185].shape = {3072, 512};
    constants_info_[1185].stride = {1, 3072};
    constants_info_[1185].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1185].original_fqn = "_FOLDED_CONST_permute_123";
    constants_info_[1186].name = "_FOLDED_CONST_permute_124";
    constants_info_[1186].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1186].offset = 0;
    constants_info_[1186].data_size = 3145728;
    constants_info_[1186].from_folded = true;
    constants_info_[1186].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1186].shape = {512, 3072};
    constants_info_[1186].stride = {1, 512};
    constants_info_[1186].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1186].original_fqn = "_FOLDED_CONST_permute_124";
    constants_info_[1187].name = "_FOLDED_CONST_permute_125";
    constants_info_[1187].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1187].offset = 0;
    constants_info_[1187].data_size = 18874368;
    constants_info_[1187].from_folded = true;
    constants_info_[1187].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1187].shape = {3072, 3072};
    constants_info_[1187].stride = {1, 3072};
    constants_info_[1187].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1187].original_fqn = "_FOLDED_CONST_permute_125";
    constants_info_[1188].name = "_FOLDED_CONST_permute_126";
    constants_info_[1188].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1188].offset = 0;
    constants_info_[1188].data_size = 3145728;
    constants_info_[1188].from_folded = true;
    constants_info_[1188].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1188].shape = {3072, 512};
    constants_info_[1188].stride = {1, 3072};
    constants_info_[1188].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1188].original_fqn = "_FOLDED_CONST_permute_126";
    constants_info_[1189].name = "_FOLDED_CONST_permute_127";
    constants_info_[1189].dtype = static_cast<int32_t>(cached_torch_dtype_float16);
    constants_info_[1189].offset = 0;
    constants_info_[1189].data_size = 1024;
    constants_info_[1189].from_folded = true;
    constants_info_[1189].type = static_cast<int32_t>(torch::aot_inductor::ConstantType::FoldedConstant);
    constants_info_[1189].shape = {512, 1};
    constants_info_[1189].stride = {1, 512};
    constants_info_[1189].layout = static_cast<int32_t>(cached_torch_layout_strided);
    constants_info_[1189].original_fqn = "_FOLDED_CONST_permute_127";
    update_constants_map(std::move(constants_map));
    update_constants_array(std::move(constants_array));
    in_spec_ = "[1, {\"type\": \"builtins.tuple\", \"context\": \"null\", \"children_spec\": [{\"type\": \"builtins.tuple\", \"context\": \"null\", \"children_spec\": [{\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}]}, {\"type\": \"builtins.dict\", \"context\": \"[]\", \"children_spec\": []}]}]";
    out_spec_ = "[1, {\"type\": \"torch.fx.immutable_collections.immutable_dict\", \"context\": \"[\\\"prediction_SALR_STANDALONE\\\"]\", \"children_spec\": [{\"type\": \"builtins.tuple\", \"context\": \"null\", \"children_spec\": [{\"type\": null, \"context\": null, \"children_spec\": []}, {\"type\": null, \"context\": null, \"children_spec\": []}]}]}]";
    outputs_info_[0].name = "output0";
    outputs_info_[1].name = "output1";
    this->kernels_ = std::make_unique<AOTInductorModelKernels>();
}

std::unordered_map<std::string, AtenTensorHandle> AOTInductorModel::const_run_impl(
    DeviceStreamType stream,
    AOTIProxyExecutorHandle proxy_executor,
    bool initialization
) {

                std::unordered_map<std::string, AtenTensorHandle> folded_constants_map;
                folded_constants_map.reserve(584);
                std::vector<AtenTensorHandle> output_handles(584);


    // The below assignment of output_handles to constants is not used directly.
    // It's only used to memo the correspondence of handle and constants.
    output_handles[0] = constants_->at(606);
    output_handles[1] = constants_->at(607);
    output_handles[2] = constants_->at(608);
    output_handles[3] = constants_->at(609);
    output_handles[4] = constants_->at(610);
    output_handles[5] = constants_->at(611);
    output_handles[6] = constants_->at(612);
    output_handles[7] = constants_->at(613);
    output_handles[8] = constants_->at(614);
    output_handles[9] = constants_->at(615);
    output_handles[10] = constants_->at(616);
    output_handles[11] = constants_->at(617);
    output_handles[12] = constants_->at(618);
    output_handles[13] = constants_->at(619);
    output_handles[14] = constants_->at(620);
    output_handles[15] = constants_->at(621);
    output_handles[16] = constants_->at(622);
    output_handles[17] = constants_->at(623);
    output_handles[18] = constants_->at(624);
    output_handles[19] = constants_->at(625);
    output_handles[20] = constants_->at(626);
    output_handles[21] = constants_->at(627);
    output_handles[22] = constants_->at(628);
    output_handles[23] = constants_->at(629);
    output_handles[24] = constants_->at(630);
    output_handles[25] = constants_->at(631);
    output_handles[26] = constants_->at(632);
    output_handles[27] = constants_->at(633);
    output_handles[28] = constants_->at(634);
    output_handles[29] = constants_->at(635);
    output_handles[30] = constants_->at(636);
    output_handles[31] = constants_->at(637);
    output_handles[32] = constants_->at(638);
    output_handles[33] = constants_->at(639);
    output_handles[34] = constants_->at(640);
    output_handles[35] = constants_->at(641);
    output_handles[36] = constants_->at(642);
    output_handles[37] = constants_->at(643);
    output_handles[38] = constants_->at(644);
    output_handles[39] = constants_->at(645);
    output_handles[40] = constants_->at(646);
    output_handles[41] = constants_->at(647);
    output_handles[42] = constants_->at(648);
    output_handles[43] = constants_->at(649);
    output_handles[44] = constants_->at(650);
    output_handles[45] = constants_->at(651);
    output_handles[46] = constants_->at(652);
    output_handles[47] = constants_->at(653);
    output_handles[48] = constants_->at(654);
    output_handles[49] = constants_->at(655);
    output_handles[50] = constants_->at(656);
    output_handles[51] = constants_->at(657);
    output_handles[52] = constants_->at(658);
    output_handles[53] = constants_->at(659);
    output_handles[54] = constants_->at(660);
    output_handles[55] = constants_->at(661);
    output_handles[56] = constants_->at(662);
    output_handles[57] = constants_->at(663);
    output_handles[58] = constants_->at(664);
    output_handles[59] = constants_->at(665);
    output_handles[60] = constants_->at(666);
    output_handles[61] = constants_->at(667);
    output_handles[62] = constants_->at(668);
    output_handles[63] = constants_->at(669);
    output_handles[64] = constants_->at(670);
    output_handles[65] = constants_->at(671);
    output_handles[66] = constants_->at(672);
    output_handles[67] = constants_->at(673);
    output_handles[68] = constants_->at(674);
    output_handles[69] = constants_->at(675);
    output_handles[70] = constants_->at(676);
    output_handles[71] = constants_->at(677);
    output_handles[72] = constants_->at(678);
    output_handles[73] = constants_->at(679);
    output_handles[74] = constants_->at(680);
    output_handles[75] = constants_->at(681);
    output_handles[76] = constants_->at(682);
    output_handles[77] = constants_->at(683);
    output_handles[78] = constants_->at(684);
    output_handles[79] = constants_->at(685);
    output_handles[80] = constants_->at(686);
    output_handles[81] = constants_->at(687);
    output_handles[82] = constants_->at(688);
    output_handles[83] = constants_->at(689);
    output_handles[84] = constants_->at(690);
    output_handles[85] = constants_->at(691);
    output_handles[86] = constants_->at(692);
    output_handles[87] = constants_->at(693);
    output_handles[88] = constants_->at(694);
    output_handles[89] = constants_->at(695);
    output_handles[90] = constants_->at(696);
    output_handles[91] = constants_->at(697);
    output_handles[92] = constants_->at(698);
    output_handles[93] = constants_->at(699);
    output_handles[94] = constants_->at(700);
    output_handles[95] = constants_->at(701);
    output_handles[96] = constants_->at(702);
    output_handles[97] = constants_->at(703);
    output_handles[98] = constants_->at(704);
    output_handles[99] = constants_->at(705);
    output_handles[100] = constants_->at(706);
    output_handles[101] = constants_->at(707);
    output_handles[102] = constants_->at(708);
    output_handles[103] = constants_->at(709);
    output_handles[104] = constants_->at(710);
    output_handles[105] = constants_->at(711);
    output_handles[106] = constants_->at(712);
    output_handles[107] = constants_->at(713);
    output_handles[108] = constants_->at(714);
    output_handles[109] = constants_->at(715);
    output_handles[110] = constants_->at(716);
    output_handles[111] = constants_->at(717);
    output_handles[112] = constants_->at(718);
    output_handles[113] = constants_->at(719);
    output_handles[114] = constants_->at(720);
    output_handles[115] = constants_->at(721);
    output_handles[116] = constants_->at(722);
    output_handles[117] = constants_->at(723);
    output_handles[118] = constants_->at(724);
    output_handles[119] = constants_->at(725);
    output_handles[120] = constants_->at(726);
    output_handles[121] = constants_->at(727);
    output_handles[122] = constants_->at(728);
    output_handles[123] = constants_->at(729);
    output_handles[124] = constants_->at(730);
    output_handles[125] = constants_->at(731);
    output_handles[126] = constants_->at(732);
    output_handles[127] = constants_->at(733);
    output_handles[128] = constants_->at(734);
    output_handles[129] = constants_->at(735);
    output_handles[130] = constants_->at(736);
    output_handles[131] = constants_->at(737);
    output_handles[132] = constants_->at(738);
    output_handles[133] = constants_->at(739);
    output_handles[134] = constants_->at(740);
    output_handles[135] = constants_->at(741);
    output_handles[136] = constants_->at(742);
    output_handles[137] = constants_->at(743);
    output_handles[138] = constants_->at(744);
    output_handles[139] = constants_->at(745);
    output_handles[140] = constants_->at(746);
    output_handles[141] = constants_->at(747);
    output_handles[142] = constants_->at(748);
    output_handles[143] = constants_->at(749);
    output_handles[144] = constants_->at(750);
    output_handles[145] = constants_->at(751);
    output_handles[146] = constants_->at(752);
    output_handles[147] = constants_->at(753);
    output_handles[148] = constants_->at(754);
    output_handles[149] = constants_->at(755);
    output_handles[150] = constants_->at(756);
    output_handles[151] = constants_->at(757);
    output_handles[152] = constants_->at(758);
    output_handles[153] = constants_->at(759);
    output_handles[154] = constants_->at(760);
    output_handles[155] = constants_->at(761);
    output_handles[156] = constants_->at(762);
    output_handles[157] = constants_->at(763);
    output_handles[158] = constants_->at(764);
    output_handles[159] = constants_->at(765);
    output_handles[160] = constants_->at(766);
    output_handles[161] = constants_->at(767);
    output_handles[162] = constants_->at(768);
    output_handles[163] = constants_->at(769);
    output_handles[164] = constants_->at(770);
    output_handles[165] = constants_->at(771);
    output_handles[166] = constants_->at(772);
    output_handles[167] = constants_->at(773);
    output_handles[168] = constants_->at(774);
    output_handles[169] = constants_->at(775);
    output_handles[170] = constants_->at(776);
    output_handles[171] = constants_->at(777);
    output_handles[172] = constants_->at(778);
    output_handles[173] = constants_->at(779);
    output_handles[174] = constants_->at(780);
    output_handles[175] = constants_->at(781);
    output_handles[176] = constants_->at(782);
    output_handles[177] = constants_->at(783);
    output_handles[178] = constants_->at(784);
    output_handles[179] = constants_->at(785);
    output_handles[180] = constants_->at(786);
    output_handles[181] = constants_->at(787);
    output_handles[182] = constants_->at(788);
    output_handles[183] = constants_->at(789);
    output_handles[184] = constants_->at(790);
    output_handles[185] = constants_->at(791);
    output_handles[186] = constants_->at(792);
    output_handles[187] = constants_->at(793);
    output_handles[188] = constants_->at(794);
    output_handles[189] = constants_->at(795);
    output_handles[190] = constants_->at(796);
    output_handles[191] = constants_->at(797);
    output_handles[192] = constants_->at(798);
    output_handles[193] = constants_->at(799);
    output_handles[194] = constants_->at(800);
    output_handles[195] = constants_->at(801);
    output_handles[196] = constants_->at(802);
    output_handles[197] = constants_->at(803);
    output_handles[198] = constants_->at(804);
    output_handles[199] = constants_->at(805);
    output_handles[200] = constants_->at(806);
    output_handles[201] = constants_->at(807);
    output_handles[202] = constants_->at(808);
    output_handles[203] = constants_->at(809);
    output_handles[204] = constants_->at(810);
    output_handles[205] = constants_->at(811);
    output_handles[206] = constants_->at(812);
    output_handles[207] = constants_->at(813);
    output_handles[208] = constants_->at(814);
    output_handles[209] = constants_->at(815);
    output_handles[210] = constants_->at(816);
    output_handles[211] = constants_->at(817);
    output_handles[212] = constants_->at(818);
    output_handles[213] = constants_->at(819);
    output_handles[214] = constants_->at(820);
    output_handles[215] = constants_->at(821);
    output_handles[216] = constants_->at(822);
    output_handles[217] = constants_->at(823);
    output_handles[218] = constants_->at(824);
    output_handles[219] = constants_->at(825);
    output_handles[220] = constants_->at(826);
    output_handles[221] = constants_->at(827);
    output_handles[222] = constants_->at(828);
    output_handles[223] = constants_->at(829);
    output_handles[224] = constants_->at(830);
    output_handles[225] = constants_->at(831);
    output_handles[226] = constants_->at(832);
    output_handles[227] = constants_->at(833);
    output_handles[228] = constants_->at(834);
    output_handles[229] = constants_->at(835);
    output_handles[230] = constants_->at(836);
    output_handles[231] = constants_->at(837);
    output_handles[232] = constants_->at(838);
    output_handles[233] = constants_->at(839);
    output_handles[234] = constants_->at(840);
    output_handles[235] = constants_->at(841);
    output_handles[236] = constants_->at(842);
    output_handles[237] = constants_->at(843);
    output_handles[238] = constants_->at(844);
    output_handles[239] = constants_->at(845);
    output_handles[240] = constants_->at(846);
    output_handles[241] = constants_->at(847);
    output_handles[242] = constants_->at(848);
    output_handles[243] = constants_->at(849);
    output_handles[244] = constants_->at(850);
    output_handles[245] = constants_->at(851);
    output_handles[246] = constants_->at(852);
    output_handles[247] = constants_->at(853);
    output_handles[248] = constants_->at(854);
    output_handles[249] = constants_->at(855);
    output_handles[250] = constants_->at(856);
    output_handles[251] = constants_->at(857);
    output_handles[252] = constants_->at(858);
    output_handles[253] = constants_->at(859);
    output_handles[254] = constants_->at(860);
    output_handles[255] = constants_->at(861);
    output_handles[256] = constants_->at(862);
    output_handles[257] = constants_->at(863);
    output_handles[258] = constants_->at(864);
    output_handles[259] = constants_->at(865);
    output_handles[260] = constants_->at(866);
    output_handles[261] = constants_->at(867);
    output_handles[262] = constants_->at(868);
    output_handles[263] = constants_->at(869);
    output_handles[264] = constants_->at(870);
    output_handles[265] = constants_->at(871);
    output_handles[266] = constants_->at(872);
    output_handles[267] = constants_->at(873);
    output_handles[268] = constants_->at(874);
    output_handles[269] = constants_->at(875);
    output_handles[270] = constants_->at(876);
    output_handles[271] = constants_->at(877);
    output_handles[272] = constants_->at(878);
    output_handles[273] = constants_->at(879);
    output_handles[274] = constants_->at(880);
    output_handles[275] = constants_->at(881);
    output_handles[276] = constants_->at(882);
    output_handles[277] = constants_->at(883);
    output_handles[278] = constants_->at(884);
    output_handles[279] = constants_->at(885);
    output_handles[280] = constants_->at(886);
    output_handles[281] = constants_->at(887);
    output_handles[282] = constants_->at(888);
    output_handles[283] = constants_->at(889);
    output_handles[284] = constants_->at(890);
    output_handles[285] = constants_->at(891);
    output_handles[286] = constants_->at(892);
    output_handles[287] = constants_->at(893);
    output_handles[288] = constants_->at(894);
    output_handles[289] = constants_->at(895);
    output_handles[290] = constants_->at(896);
    output_handles[291] = constants_->at(897);
    output_handles[292] = constants_->at(898);
    output_handles[293] = constants_->at(899);
    output_handles[294] = constants_->at(900);
    output_handles[295] = constants_->at(901);
    output_handles[296] = constants_->at(902);
    output_handles[297] = constants_->at(903);
    output_handles[298] = constants_->at(904);
    output_handles[299] = constants_->at(905);
    output_handles[300] = constants_->at(906);
    output_handles[301] = constants_->at(907);
    output_handles[302] = constants_->at(908);
    output_handles[303] = constants_->at(909);
    output_handles[304] = constants_->at(910);
    output_handles[305] = constants_->at(911);
    output_handles[306] = constants_->at(912);
    output_handles[307] = constants_->at(913);
    output_handles[308] = constants_->at(914);
    output_handles[309] = constants_->at(915);
    output_handles[310] = constants_->at(916);
    output_handles[311] = constants_->at(917);
    output_handles[312] = constants_->at(918);
    output_handles[313] = constants_->at(919);
    output_handles[314] = constants_->at(920);
    output_handles[315] = constants_->at(921);
    output_handles[316] = constants_->at(922);
    output_handles[317] = constants_->at(923);
    output_handles[318] = constants_->at(924);
    output_handles[319] = constants_->at(925);
    output_handles[320] = constants_->at(926);
    output_handles[321] = constants_->at(927);
    output_handles[322] = constants_->at(928);
    output_handles[323] = constants_->at(929);
    output_handles[324] = constants_->at(930);
    output_handles[325] = constants_->at(931);
    output_handles[326] = constants_->at(932);
    output_handles[327] = constants_->at(933);
    output_handles[328] = constants_->at(934);
    output_handles[329] = constants_->at(935);
    output_handles[330] = constants_->at(936);
    output_handles[331] = constants_->at(937);
    output_handles[332] = constants_->at(938);
    output_handles[333] = constants_->at(939);
    output_handles[334] = constants_->at(940);
    output_handles[335] = constants_->at(941);
    output_handles[336] = constants_->at(942);
    output_handles[337] = constants_->at(943);
    output_handles[338] = constants_->at(944);
    output_handles[339] = constants_->at(945);
    output_handles[340] = constants_->at(946);
    output_handles[341] = constants_->at(947);
    output_handles[342] = constants_->at(948);
    output_handles[343] = constants_->at(949);
    output_handles[344] = constants_->at(950);
    output_handles[345] = constants_->at(951);
    output_handles[346] = constants_->at(952);
    output_handles[347] = constants_->at(953);
    output_handles[348] = constants_->at(954);
    output_handles[349] = constants_->at(955);
    output_handles[350] = constants_->at(956);
    output_handles[351] = constants_->at(957);
    output_handles[352] = constants_->at(958);
    output_handles[353] = constants_->at(959);
    output_handles[354] = constants_->at(960);
    output_handles[355] = constants_->at(961);
    output_handles[356] = constants_->at(962);
    output_handles[357] = constants_->at(963);
    output_handles[358] = constants_->at(964);
    output_handles[359] = constants_->at(965);
    output_handles[360] = constants_->at(966);
    output_handles[361] = constants_->at(967);
    output_handles[362] = constants_->at(968);
    output_handles[363] = constants_->at(969);
    output_handles[364] = constants_->at(970);
    output_handles[365] = constants_->at(971);
    output_handles[366] = constants_->at(972);
    output_handles[367] = constants_->at(973);
    output_handles[368] = constants_->at(974);
    output_handles[369] = constants_->at(975);
    output_handles[370] = constants_->at(976);
    output_handles[371] = constants_->at(977);
    output_handles[372] = constants_->at(978);
    output_handles[373] = constants_->at(979);
    output_handles[374] = constants_->at(980);
    output_handles[375] = constants_->at(981);
    output_handles[376] = constants_->at(982);
    output_handles[377] = constants_->at(983);
    output_handles[378] = constants_->at(984);
    output_handles[379] = constants_->at(985);
    output_handles[380] = constants_->at(986);
    output_handles[381] = constants_->at(987);
    output_handles[382] = constants_->at(988);
    output_handles[383] = constants_->at(989);
    output_handles[384] = constants_->at(990);
    output_handles[385] = constants_->at(991);
    output_handles[386] = constants_->at(992);
    output_handles[387] = constants_->at(993);
    output_handles[388] = constants_->at(994);
    output_handles[389] = constants_->at(995);
    output_handles[390] = constants_->at(996);
    output_handles[391] = constants_->at(997);
    output_handles[392] = constants_->at(998);
    output_handles[393] = constants_->at(999);
    output_handles[394] = constants_->at(1000);
    output_handles[395] = constants_->at(1001);
    output_handles[396] = constants_->at(1002);
    output_handles[397] = constants_->at(1003);
    output_handles[398] = constants_->at(1004);
    output_handles[399] = constants_->at(1005);
    output_handles[400] = constants_->at(1006);
    output_handles[401] = constants_->at(1007);
    output_handles[402] = constants_->at(1008);
    output_handles[403] = constants_->at(1009);
    output_handles[404] = constants_->at(1010);
    output_handles[405] = constants_->at(1011);
    output_handles[406] = constants_->at(1012);
    output_handles[407] = constants_->at(1013);
    output_handles[408] = constants_->at(1014);
    output_handles[409] = constants_->at(1015);
    output_handles[410] = constants_->at(1016);
    output_handles[411] = constants_->at(1017);
    output_handles[412] = constants_->at(1018);
    output_handles[413] = constants_->at(1019);
    output_handles[414] = constants_->at(1020);
    output_handles[415] = constants_->at(1021);
    output_handles[416] = constants_->at(1022);
    output_handles[417] = constants_->at(1023);
    output_handles[418] = constants_->at(1024);
    output_handles[419] = constants_->at(1025);
    output_handles[420] = constants_->at(1026);
    output_handles[421] = constants_->at(1027);
    output_handles[422] = constants_->at(1028);
    output_handles[423] = constants_->at(1029);
    output_handles[424] = constants_->at(1030);
    output_handles[425] = constants_->at(1031);
    output_handles[426] = constants_->at(1032);
    output_handles[427] = constants_->at(1033);
    output_handles[428] = constants_->at(1034);
    output_handles[429] = constants_->at(1035);
    output_handles[430] = constants_->at(1036);
    output_handles[431] = constants_->at(1037);
    output_handles[432] = constants_->at(1038);
    output_handles[433] = constants_->at(1039);
    output_handles[434] = constants_->at(1040);
    output_handles[435] = constants_->at(1041);
    output_handles[436] = constants_->at(1042);
    output_handles[437] = constants_->at(1043);
    output_handles[438] = constants_->at(1044);
    output_handles[439] = constants_->at(1045);
    output_handles[440] = constants_->at(1046);
    output_handles[441] = constants_->at(1047);
    output_handles[442] = constants_->at(1048);
    output_handles[443] = constants_->at(1049);
    output_handles[444] = constants_->at(1050);
    output_handles[445] = constants_->at(1051);
    output_handles[446] = constants_->at(1052);
    output_handles[447] = constants_->at(1053);
    output_handles[448] = constants_->at(1054);
    output_handles[449] = constants_->at(1055);
    output_handles[450] = constants_->at(1056);
    output_handles[451] = constants_->at(1057);
    output_handles[452] = constants_->at(1058);
    output_handles[453] = constants_->at(1059);
    output_handles[454] = constants_->at(1060);
    output_handles[455] = constants_->at(1061);
    output_handles[456] = constants_->at(1062);
    output_handles[457] = constants_->at(1063);
    output_handles[458] = constants_->at(1064);
    output_handles[459] = constants_->at(1065);
    output_handles[460] = constants_->at(1066);
    output_handles[461] = constants_->at(1067);
    output_handles[462] = constants_->at(1068);
    output_handles[463] = constants_->at(1069);
    output_handles[464] = constants_->at(1070);
    output_handles[465] = constants_->at(1071);
    output_handles[466] = constants_->at(1072);
    output_handles[467] = constants_->at(1073);
    output_handles[468] = constants_->at(1074);
    output_handles[469] = constants_->at(1075);
    output_handles[470] = constants_->at(1076);
    output_handles[471] = constants_->at(1077);
    output_handles[472] = constants_->at(1078);
    output_handles[473] = constants_->at(1079);
    output_handles[474] = constants_->at(1080);
    output_handles[475] = constants_->at(1081);
    output_handles[476] = constants_->at(1082);
    output_handles[477] = constants_->at(1083);
    output_handles[478] = constants_->at(1084);
    output_handles[479] = constants_->at(1085);
    output_handles[480] = constants_->at(1086);
    output_handles[481] = constants_->at(1087);
    output_handles[482] = constants_->at(1088);
    output_handles[483] = constants_->at(1089);
    output_handles[484] = constants_->at(1090);
    output_handles[485] = constants_->at(1091);
    output_handles[486] = constants_->at(1092);
    output_handles[487] = constants_->at(1093);
    output_handles[488] = constants_->at(1094);
    output_handles[489] = constants_->at(1095);
    output_handles[490] = constants_->at(1096);
    output_handles[491] = constants_->at(1097);
    output_handles[492] = constants_->at(1098);
    output_handles[493] = constants_->at(1099);
    output_handles[494] = constants_->at(1100);
    output_handles[495] = constants_->at(1101);
    output_handles[496] = constants_->at(1102);
    output_handles[497] = constants_->at(1103);
    output_handles[498] = constants_->at(1104);
    output_handles[499] = constants_->at(1105);
    output_handles[500] = constants_->at(1106);
    output_handles[501] = constants_->at(1107);
    output_handles[502] = constants_->at(1108);
    output_handles[503] = constants_->at(1109);
    output_handles[504] = constants_->at(1110);
    output_handles[505] = constants_->at(1111);
    output_handles[506] = constants_->at(1112);
    output_handles[507] = constants_->at(1113);
    output_handles[508] = constants_->at(1114);
    output_handles[509] = constants_->at(1115);
    output_handles[510] = constants_->at(1116);
    output_handles[511] = constants_->at(1117);
    output_handles[512] = constants_->at(1118);
    output_handles[513] = constants_->at(1119);
    output_handles[514] = constants_->at(1120);
    output_handles[515] = constants_->at(1121);
    output_handles[516] = constants_->at(1122);
    output_handles[517] = constants_->at(1123);
    output_handles[518] = constants_->at(1124);
    output_handles[519] = constants_->at(1125);
    output_handles[520] = constants_->at(1126);
    output_handles[521] = constants_->at(1127);
    output_handles[522] = constants_->at(1128);
    output_handles[523] = constants_->at(1129);
    output_handles[524] = constants_->at(1130);
    output_handles[525] = constants_->at(1131);
    output_handles[526] = constants_->at(1132);
    output_handles[527] = constants_->at(1133);
    output_handles[528] = constants_->at(1134);
    output_handles[529] = constants_->at(1135);
    output_handles[530] = constants_->at(1136);
    output_handles[531] = constants_->at(1137);
    output_handles[532] = constants_->at(1138);
    output_handles[533] = constants_->at(1139);
    output_handles[534] = constants_->at(1140);
    output_handles[535] = constants_->at(1141);
    output_handles[536] = constants_->at(1142);
    output_handles[537] = constants_->at(1143);
    output_handles[538] = constants_->at(1144);
    output_handles[539] = constants_->at(1145);
    output_handles[540] = constants_->at(1146);
    output_handles[541] = constants_->at(1147);
    output_handles[542] = constants_->at(1148);
    output_handles[543] = constants_->at(1149);
    output_handles[544] = constants_->at(1150);
    output_handles[545] = constants_->at(1151);
    output_handles[546] = constants_->at(1152);
    output_handles[547] = constants_->at(1153);
    output_handles[548] = constants_->at(1154);
    output_handles[549] = constants_->at(1155);
    output_handles[550] = constants_->at(1156);
    output_handles[551] = constants_->at(1157);
    output_handles[552] = constants_->at(1158);
    output_handles[553] = constants_->at(1159);
    output_handles[554] = constants_->at(1160);
    output_handles[555] = constants_->at(1161);
    output_handles[556] = constants_->at(1162);
    output_handles[557] = constants_->at(1163);
    output_handles[558] = constants_->at(1164);
    output_handles[559] = constants_->at(1165);
    output_handles[560] = constants_->at(1166);
    output_handles[561] = constants_->at(1167);
    output_handles[562] = constants_->at(1168);
    output_handles[563] = constants_->at(1169);
    output_handles[564] = constants_->at(1170);
    output_handles[565] = constants_->at(1171);
    output_handles[566] = constants_->at(1172);
    output_handles[567] = constants_->at(1173);
    output_handles[568] = constants_->at(1174);
    output_handles[569] = constants_->at(1175);
    output_handles[570] = constants_->at(1176);
    output_handles[571] = constants_->at(1177);
    output_handles[572] = constants_->at(1178);
    output_handles[573] = constants_->at(1179);
    output_handles[574] = constants_->at(1180);
    output_handles[575] = constants_->at(1181);
    output_handles[576] = constants_->at(1182);
    output_handles[577] = constants_->at(1183);
    output_handles[578] = constants_->at(1184);
    output_handles[579] = constants_->at(1185);
    output_handles[580] = constants_->at(1186);
    output_handles[581] = constants_->at(1187);
    output_handles[582] = constants_->at(1188);
    output_handles[583] = constants_->at(1189);
    _const_run_impl(output_handles, stream, proxy_executor);
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[0];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale"] = output_handles[1];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias"] = output_handles[2];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[3];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale"] = output_handles[4];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias"] = output_handles[5];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[6];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale"] = output_handles[7];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias"] = output_handles[8];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[9];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale"] = output_handles[10];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias"] = output_handles[11];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[12];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale"] = output_handles[13];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias"] = output_handles[14];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[15];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale"] = output_handles[16];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias"] = output_handles[17];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[18];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale"] = output_handles[19];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias"] = output_handles[20];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[21];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale"] = output_handles[22];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias"] = output_handles[23];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[24];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale"] = output_handles[25];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias"] = output_handles[26];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[27];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale"] = output_handles[28];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias"] = output_handles[29];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[30];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale"] = output_handles[31];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias"] = output_handles[32];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[33];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale"] = output_handles[34];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias"] = output_handles[35];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[36];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale"] = output_handles[37];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias"] = output_handles[38];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[39];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale"] = output_handles[40];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias"] = output_handles[41];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[42];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale"] = output_handles[43];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias"] = output_handles[44];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[45];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale"] = output_handles[46];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias"] = output_handles[47];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[48];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale"] = output_handles[49];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias"] = output_handles[50];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[51];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale"] = output_handles[52];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias"] = output_handles[53];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[54];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale"] = output_handles[55];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias"] = output_handles[56];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[57];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale"] = output_handles[58];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias"] = output_handles[59];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[60];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale"] = output_handles[61];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias"] = output_handles[62];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[63];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale"] = output_handles[64];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias"] = output_handles[65];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[66];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale"] = output_handles[67];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias"] = output_handles[68];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[69];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale"] = output_handles[70];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias"] = output_handles[71];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[72];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale"] = output_handles[73];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias"] = output_handles[74];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[75];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale"] = output_handles[76];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias"] = output_handles[77];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[78];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale"] = output_handles[79];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias"] = output_handles[80];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[81];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale"] = output_handles[82];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias"] = output_handles[83];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[84];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale"] = output_handles[85];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias"] = output_handles[86];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[87];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale"] = output_handles[88];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias"] = output_handles[89];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[90];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale"] = output_handles[91];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias"] = output_handles[92];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[93];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale"] = output_handles[94];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias"] = output_handles[95];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[96];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale"] = output_handles[97];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias"] = output_handles[98];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[99];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale"] = output_handles[100];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias"] = output_handles[101];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[102];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale"] = output_handles[103];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias"] = output_handles[104];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b"] = output_handles[105];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale"] = output_handles[106];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias"] = output_handles[107];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale"] = output_handles[108];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias"] = output_handles[109];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b"] = output_handles[110];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b"] = output_handles[111];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale"] = output_handles[112];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias"] = output_handles[113];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale"] = output_handles[114];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias"] = output_handles[115];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b"] = output_handles[116];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale"] = output_handles[117];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias"] = output_handles[118];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b"] = output_handles[119];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b"] = output_handles[120];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb"] = output_handles[121];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb"] = output_handles[122];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight"] = output_handles[123];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias"] = output_handles[124];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias"] = output_handles[125];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight"] = output_handles[126];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias"] = output_handles[127];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight"] = output_handles[128];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias"] = output_handles[129];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias"] = output_handles[130];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias"] = output_handles[131];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb"] = output_handles[132];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb"] = output_handles[133];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight"] = output_handles[134];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias"] = output_handles[135];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias"] = output_handles[136];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight"] = output_handles[137];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias"] = output_handles[138];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight"] = output_handles[139];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias"] = output_handles[140];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias"] = output_handles[141];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias"] = output_handles[142];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias"] = output_handles[143];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight"] = output_handles[144];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w"] = output_handles[145];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b"] = output_handles[146];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w"] = output_handles[147];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b"] = output_handles[148];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight"] = output_handles[149];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias"] = output_handles[150];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w"] = output_handles[151];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b"] = output_handles[152];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias"] = output_handles[153];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight"] = output_handles[154];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias"] = output_handles[155];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w"] = output_handles[156];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b"] = output_handles[157];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight"] = output_handles[158];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias"] = output_handles[159];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w"] = output_handles[160];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b"] = output_handles[161];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias"] = output_handles[162];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight"] = output_handles[163];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias"] = output_handles[164];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w"] = output_handles[165];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b"] = output_handles[166];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias"] = output_handles[167];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w"] = output_handles[168];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b"] = output_handles[169];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias"] = output_handles[170];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w"] = output_handles[171];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b"] = output_handles[172];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w"] = output_handles[173];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b"] = output_handles[174];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w"] = output_handles[175];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b"] = output_handles[176];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias"] = output_handles[177];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight"] = output_handles[178];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias"] = output_handles[179];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w"] = output_handles[180];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b"] = output_handles[181];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w"] = output_handles[182];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b"] = output_handles[183];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias"] = output_handles[184];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w"] = output_handles[185];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b"] = output_handles[186];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias"] = output_handles[187];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w"] = output_handles[188];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b"] = output_handles[189];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w"] = output_handles[190];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b"] = output_handles[191];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias"] = output_handles[192];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight"] = output_handles[193];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias"] = output_handles[194];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w"] = output_handles[195];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b"] = output_handles[196];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias"] = output_handles[197];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight"] = output_handles[198];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias"] = output_handles[199];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w"] = output_handles[200];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b"] = output_handles[201];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias"] = output_handles[202];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w"] = output_handles[203];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b"] = output_handles[204];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias"] = output_handles[205];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight"] = output_handles[206];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias"] = output_handles[207];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w"] = output_handles[208];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b"] = output_handles[209];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias"] = output_handles[210];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w"] = output_handles[211];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b"] = output_handles[212];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight"] = output_handles[213];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias"] = output_handles[214];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight"] = output_handles[215];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias"] = output_handles[216];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias"] = output_handles[217];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w"] = output_handles[218];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b"] = output_handles[219];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w"] = output_handles[220];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b"] = output_handles[221];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w"] = output_handles[222];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b"] = output_handles[223];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight"] = output_handles[224];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias"] = output_handles[225];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w"] = output_handles[226];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b"] = output_handles[227];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias"] = output_handles[228];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight"] = output_handles[229];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias"] = output_handles[230];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w"] = output_handles[231];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b"] = output_handles[232];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight"] = output_handles[233];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias"] = output_handles[234];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w"] = output_handles[235];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b"] = output_handles[236];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias"] = output_handles[237];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight"] = output_handles[238];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias"] = output_handles[239];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w"] = output_handles[240];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b"] = output_handles[241];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias"] = output_handles[242];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w"] = output_handles[243];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b"] = output_handles[244];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias"] = output_handles[245];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w"] = output_handles[246];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b"] = output_handles[247];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w"] = output_handles[248];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b"] = output_handles[249];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w"] = output_handles[250];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b"] = output_handles[251];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias"] = output_handles[252];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight"] = output_handles[253];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias"] = output_handles[254];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w"] = output_handles[255];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b"] = output_handles[256];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w"] = output_handles[257];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b"] = output_handles[258];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias"] = output_handles[259];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w"] = output_handles[260];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b"] = output_handles[261];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias"] = output_handles[262];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w"] = output_handles[263];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b"] = output_handles[264];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w"] = output_handles[265];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b"] = output_handles[266];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias"] = output_handles[267];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight"] = output_handles[268];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias"] = output_handles[269];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w"] = output_handles[270];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b"] = output_handles[271];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias"] = output_handles[272];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight"] = output_handles[273];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias"] = output_handles[274];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w"] = output_handles[275];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b"] = output_handles[276];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias"] = output_handles[277];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w"] = output_handles[278];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b"] = output_handles[279];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias"] = output_handles[280];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight"] = output_handles[281];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias"] = output_handles[282];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w"] = output_handles[283];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b"] = output_handles[284];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias"] = output_handles[285];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w"] = output_handles[286];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b"] = output_handles[287];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight"] = output_handles[288];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias"] = output_handles[289];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight"] = output_handles[290];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias"] = output_handles[291];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias"] = output_handles[292];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w"] = output_handles[293];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b"] = output_handles[294];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w"] = output_handles[295];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b"] = output_handles[296];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w"] = output_handles[297];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b"] = output_handles[298];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight"] = output_handles[299];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias"] = output_handles[300];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w"] = output_handles[301];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b"] = output_handles[302];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias"] = output_handles[303];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight"] = output_handles[304];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias"] = output_handles[305];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w"] = output_handles[306];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b"] = output_handles[307];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight"] = output_handles[308];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias"] = output_handles[309];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w"] = output_handles[310];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b"] = output_handles[311];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias"] = output_handles[312];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight"] = output_handles[313];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias"] = output_handles[314];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w"] = output_handles[315];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b"] = output_handles[316];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias"] = output_handles[317];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w"] = output_handles[318];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b"] = output_handles[319];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias"] = output_handles[320];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w"] = output_handles[321];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b"] = output_handles[322];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w"] = output_handles[323];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b"] = output_handles[324];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w"] = output_handles[325];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b"] = output_handles[326];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias"] = output_handles[327];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight"] = output_handles[328];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias"] = output_handles[329];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w"] = output_handles[330];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b"] = output_handles[331];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w"] = output_handles[332];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b"] = output_handles[333];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias"] = output_handles[334];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w"] = output_handles[335];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b"] = output_handles[336];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias"] = output_handles[337];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w"] = output_handles[338];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b"] = output_handles[339];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w"] = output_handles[340];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b"] = output_handles[341];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias"] = output_handles[342];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight"] = output_handles[343];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias"] = output_handles[344];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w"] = output_handles[345];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b"] = output_handles[346];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias"] = output_handles[347];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight"] = output_handles[348];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias"] = output_handles[349];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w"] = output_handles[350];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b"] = output_handles[351];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias"] = output_handles[352];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w"] = output_handles[353];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b"] = output_handles[354];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias"] = output_handles[355];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight"] = output_handles[356];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias"] = output_handles[357];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w"] = output_handles[358];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b"] = output_handles[359];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias"] = output_handles[360];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w"] = output_handles[361];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b"] = output_handles[362];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight"] = output_handles[363];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias"] = output_handles[364];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight"] = output_handles[365];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias"] = output_handles[366];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias"] = output_handles[367];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w"] = output_handles[368];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b"] = output_handles[369];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w"] = output_handles[370];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b"] = output_handles[371];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w"] = output_handles[372];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b"] = output_handles[373];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight"] = output_handles[374];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias"] = output_handles[375];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w"] = output_handles[376];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b"] = output_handles[377];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias"] = output_handles[378];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight"] = output_handles[379];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias"] = output_handles[380];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w"] = output_handles[381];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b"] = output_handles[382];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight"] = output_handles[383];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias"] = output_handles[384];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w"] = output_handles[385];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b"] = output_handles[386];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias"] = output_handles[387];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight"] = output_handles[388];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias"] = output_handles[389];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w"] = output_handles[390];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b"] = output_handles[391];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias"] = output_handles[392];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w"] = output_handles[393];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b"] = output_handles[394];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias"] = output_handles[395];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w"] = output_handles[396];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b"] = output_handles[397];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w"] = output_handles[398];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b"] = output_handles[399];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w"] = output_handles[400];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b"] = output_handles[401];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias"] = output_handles[402];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight"] = output_handles[403];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias"] = output_handles[404];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w"] = output_handles[405];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b"] = output_handles[406];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w"] = output_handles[407];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b"] = output_handles[408];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias"] = output_handles[409];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w"] = output_handles[410];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b"] = output_handles[411];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias"] = output_handles[412];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w"] = output_handles[413];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b"] = output_handles[414];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w"] = output_handles[415];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b"] = output_handles[416];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias"] = output_handles[417];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight"] = output_handles[418];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias"] = output_handles[419];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w"] = output_handles[420];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b"] = output_handles[421];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias"] = output_handles[422];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight"] = output_handles[423];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias"] = output_handles[424];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w"] = output_handles[425];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b"] = output_handles[426];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias"] = output_handles[427];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w"] = output_handles[428];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b"] = output_handles[429];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias"] = output_handles[430];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight"] = output_handles[431];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias"] = output_handles[432];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w"] = output_handles[433];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b"] = output_handles[434];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias"] = output_handles[435];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w"] = output_handles[436];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b"] = output_handles[437];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight"] = output_handles[438];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias"] = output_handles[439];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight"] = output_handles[440];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias"] = output_handles[441];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b"] = output_handles[442];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b"] = output_handles[443];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b"] = output_handles[444];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b"] = output_handles[445];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias"] = output_handles[446];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b"] = output_handles[447];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b"] = output_handles[448];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b"] = output_handles[449];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale"] = output_handles[450];
    folded_constants_map["_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias"] = output_handles[451];
    folded_constants_map["_FOLDED_CONST__tensor_constant2"] = output_handles[452];
    folded_constants_map["_FOLDED_CONST_submod_0_cat_fusion_gpu__offset_dim_list"] = output_handles[453];
    folded_constants_map["_FOLDED_CONST_submod_0_cat_fusion_gpu__permute"] = output_handles[454];
    folded_constants_map["_FOLDED_CONST_submod_0_cat_fusion_gpu__inv_permute"] = output_handles[455];
    folded_constants_map["_FOLDED_CONST_submod_0_cat_fusion_gpu__inv_offset_dim_list"] = output_handles[456];
    folded_constants_map["_FOLDED_CONST_submod_0_cat_fusion_cpu__offset_dim_list"] = output_handles[457];
    folded_constants_map["_FOLDED_CONST_submod_0_cat_fusion_cpu__permute"] = output_handles[458];
    folded_constants_map["_FOLDED_CONST_submod_0_cat_fusion_cpu__inv_permute"] = output_handles[459];
    folded_constants_map["_FOLDED_CONST_submod_0_cat_fusion_cpu__inv_offset_dim_list"] = output_handles[460];
    folded_constants_map["_FOLDED_CONST_submod_1__tensor_constant1"] = output_handles[461];
    folded_constants_map["_FOLDED_CONST_submod_1_main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_positive_weight_calibration_bias"] = output_handles[462];
    folded_constants_map["_FOLDED_CONST_permute"] = output_handles[463];
    folded_constants_map["_FOLDED_CONST_permute_1"] = output_handles[464];
    folded_constants_map["_FOLDED_CONST_permute_2"] = output_handles[465];
    folded_constants_map["_FOLDED_CONST_permute_3"] = output_handles[466];
    folded_constants_map["_FOLDED_CONST_permute_4"] = output_handles[467];
    folded_constants_map["_FOLDED_CONST_permute_5"] = output_handles[468];
    folded_constants_map["_FOLDED_CONST_permute_6"] = output_handles[469];
    folded_constants_map["_FOLDED_CONST_permute_7"] = output_handles[470];
    folded_constants_map["_FOLDED_CONST_permute_8"] = output_handles[471];
    folded_constants_map["_FOLDED_CONST_permute_9"] = output_handles[472];
    folded_constants_map["_FOLDED_CONST_permute_10"] = output_handles[473];
    folded_constants_map["_FOLDED_CONST_permute_11"] = output_handles[474];
    folded_constants_map["_FOLDED_CONST_permute_12"] = output_handles[475];
    folded_constants_map["_FOLDED_CONST_permute_13"] = output_handles[476];
    folded_constants_map["_FOLDED_CONST_permute_14"] = output_handles[477];
    folded_constants_map["_FOLDED_CONST_permute_15"] = output_handles[478];
    folded_constants_map["_FOLDED_CONST_permute_16"] = output_handles[479];
    folded_constants_map["_FOLDED_CONST_permute_17"] = output_handles[480];
    folded_constants_map["_FOLDED_CONST_permute_18"] = output_handles[481];
    folded_constants_map["_FOLDED_CONST_permute_19"] = output_handles[482];
    folded_constants_map["_FOLDED_CONST_permute_20"] = output_handles[483];
    folded_constants_map["_FOLDED_CONST_permute_21"] = output_handles[484];
    folded_constants_map["_FOLDED_CONST_permute_22"] = output_handles[485];
    folded_constants_map["_FOLDED_CONST_permute_23"] = output_handles[486];
    folded_constants_map["_FOLDED_CONST_permute_24"] = output_handles[487];
    folded_constants_map["_FOLDED_CONST_permute_25"] = output_handles[488];
    folded_constants_map["_FOLDED_CONST_permute_26"] = output_handles[489];
    folded_constants_map["_FOLDED_CONST_permute_27"] = output_handles[490];
    folded_constants_map["_FOLDED_CONST_permute_28"] = output_handles[491];
    folded_constants_map["_FOLDED_CONST_permute_29"] = output_handles[492];
    folded_constants_map["_FOLDED_CONST_permute_30"] = output_handles[493];
    folded_constants_map["_FOLDED_CONST_permute_31"] = output_handles[494];
    folded_constants_map["_FOLDED_CONST_permute_32"] = output_handles[495];
    folded_constants_map["_FOLDED_CONST_permute_33"] = output_handles[496];
    folded_constants_map["_FOLDED_CONST_permute_34"] = output_handles[497];
    folded_constants_map["_FOLDED_CONST_permute_35"] = output_handles[498];
    folded_constants_map["_FOLDED_CONST_cat_3"] = output_handles[499];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_23"] = output_handles[500];
    folded_constants_map["_FOLDED_CONST_cat_6"] = output_handles[501];
    folded_constants_map["_FOLDED_CONST_permute_37"] = output_handles[502];
    folded_constants_map["_FOLDED_CONST_permute_40"] = output_handles[503];
    folded_constants_map["_FOLDED_CONST_permute_41"] = output_handles[504];
    folded_constants_map["_FOLDED_CONST_permute_44"] = output_handles[505];
    folded_constants_map["_FOLDED_CONST_permute_45"] = output_handles[506];
    folded_constants_map["_FOLDED_CONST_permute_42"] = output_handles[507];
    folded_constants_map["_FOLDED_CONST_permute_46"] = output_handles[508];
    folded_constants_map["_FOLDED_CONST_permute_43"] = output_handles[509];
    folded_constants_map["_FOLDED_CONST_permute_57"] = output_handles[510];
    folded_constants_map["_FOLDED_CONST_permute_59"] = output_handles[511];
    folded_constants_map["_FOLDED_CONST_cat_9"] = output_handles[512];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_21"] = output_handles[513];
    folded_constants_map["_FOLDED_CONST_permute_38"] = output_handles[514];
    folded_constants_map["_FOLDED_CONST_permute_39"] = output_handles[515];
    folded_constants_map["_FOLDED_CONST_permute_56"] = output_handles[516];
    folded_constants_map["_FOLDED_CONST_permute_58"] = output_handles[517];
    folded_constants_map["_FOLDED_CONST_cat_13"] = output_handles[518];
    folded_constants_map["_FOLDED_CONST_permute_63"] = output_handles[519];
    folded_constants_map["_FOLDED_CONST_permute_64"] = output_handles[520];
    folded_constants_map["_FOLDED_CONST_permute_65"] = output_handles[521];
    folded_constants_map["_FOLDED_CONST_permute_66"] = output_handles[522];
    folded_constants_map["_FOLDED_CONST_permute_67"] = output_handles[523];
    folded_constants_map["_FOLDED_CONST_permute_68"] = output_handles[524];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_19"] = output_handles[525];
    folded_constants_map["_FOLDED_CONST_permute_70"] = output_handles[526];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_17"] = output_handles[527];
    folded_constants_map["_FOLDED_CONST_permute_72"] = output_handles[528];
    folded_constants_map["_FOLDED_CONST_permute_73"] = output_handles[529];
    folded_constants_map["_FOLDED_CONST_permute_74"] = output_handles[530];
    folded_constants_map["_FOLDED_CONST_permute_75"] = output_handles[531];
    folded_constants_map["_FOLDED_CONST_permute_76"] = output_handles[532];
    folded_constants_map["_FOLDED_CONST_cat_17"] = output_handles[533];
    folded_constants_map["_FOLDED_CONST_permute_78"] = output_handles[534];
    folded_constants_map["_FOLDED_CONST_permute_79"] = output_handles[535];
    folded_constants_map["_FOLDED_CONST_permute_80"] = output_handles[536];
    folded_constants_map["_FOLDED_CONST_permute_81"] = output_handles[537];
    folded_constants_map["_FOLDED_CONST_permute_82"] = output_handles[538];
    folded_constants_map["_FOLDED_CONST_permute_83"] = output_handles[539];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_13"] = output_handles[540];
    folded_constants_map["_FOLDED_CONST_permute_85"] = output_handles[541];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_11"] = output_handles[542];
    folded_constants_map["_FOLDED_CONST_permute_87"] = output_handles[543];
    folded_constants_map["_FOLDED_CONST_permute_88"] = output_handles[544];
    folded_constants_map["_FOLDED_CONST_permute_89"] = output_handles[545];
    folded_constants_map["_FOLDED_CONST_permute_90"] = output_handles[546];
    folded_constants_map["_FOLDED_CONST_permute_91"] = output_handles[547];
    folded_constants_map["_FOLDED_CONST_cat_21"] = output_handles[548];
    folded_constants_map["_FOLDED_CONST_permute_93"] = output_handles[549];
    folded_constants_map["_FOLDED_CONST_permute_94"] = output_handles[550];
    folded_constants_map["_FOLDED_CONST_permute_95"] = output_handles[551];
    folded_constants_map["_FOLDED_CONST_permute_96"] = output_handles[552];
    folded_constants_map["_FOLDED_CONST_permute_97"] = output_handles[553];
    folded_constants_map["_FOLDED_CONST_permute_98"] = output_handles[554];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_7"] = output_handles[555];
    folded_constants_map["_FOLDED_CONST_permute_100"] = output_handles[556];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_5"] = output_handles[557];
    folded_constants_map["_FOLDED_CONST_permute_102"] = output_handles[558];
    folded_constants_map["_FOLDED_CONST_permute_103"] = output_handles[559];
    folded_constants_map["_FOLDED_CONST_permute_104"] = output_handles[560];
    folded_constants_map["_FOLDED_CONST_permute_105"] = output_handles[561];
    folded_constants_map["_FOLDED_CONST_permute_106"] = output_handles[562];
    folded_constants_map["_FOLDED_CONST_cat_25"] = output_handles[563];
    folded_constants_map["_FOLDED_CONST_permute_108"] = output_handles[564];
    folded_constants_map["_FOLDED_CONST_permute_109"] = output_handles[565];
    folded_constants_map["_FOLDED_CONST_permute_110"] = output_handles[566];
    folded_constants_map["_FOLDED_CONST_permute_111"] = output_handles[567];
    folded_constants_map["_FOLDED_CONST_permute_112"] = output_handles[568];
    folded_constants_map["_FOLDED_CONST_permute_113"] = output_handles[569];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_3"] = output_handles[570];
    folded_constants_map["_FOLDED_CONST_permute_115"] = output_handles[571];
    folded_constants_map["_FOLDED_CONST_constant_pad_nd_default_1"] = output_handles[572];
    folded_constants_map["_FOLDED_CONST_permute_117"] = output_handles[573];
    folded_constants_map["_FOLDED_CONST_permute_118"] = output_handles[574];
    folded_constants_map["_FOLDED_CONST_permute_119"] = output_handles[575];
    folded_constants_map["_FOLDED_CONST_permute_120"] = output_handles[576];
    folded_constants_map["_FOLDED_CONST_permute_121"] = output_handles[577];
    folded_constants_map["_FOLDED_CONST_permute_122"] = output_handles[578];
    folded_constants_map["_FOLDED_CONST_permute_123"] = output_handles[579];
    folded_constants_map["_FOLDED_CONST_permute_124"] = output_handles[580];
    folded_constants_map["_FOLDED_CONST_permute_125"] = output_handles[581];
    folded_constants_map["_FOLDED_CONST_permute_126"] = output_handles[582];
    folded_constants_map["_FOLDED_CONST_permute_127"] = output_handles[583];
    return folded_constants_map;
}
CACHE_TORCH_DTYPE(float16);
CACHE_TORCH_DEVICE(cuda);


void AOTInductorModel::_const_run_impl(
    std::vector<AtenTensorHandle>& output_handles,
    DeviceStreamType stream,
    AOTIProxyExecutorHandle proxy_executor
) {
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(0);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(1);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_1_scale = constants_->at(2);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_1_bias = constants_->at(3);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(4);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(5);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_1_scale = constants_->at(6);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_1_bias = constants_->at(7);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(8);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(9);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_1_scale = constants_->at(10);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_1_bias = constants_->at(11);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(12);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(13);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_1_scale = constants_->at(14);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_1_bias = constants_->at(15);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(16);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(17);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(18);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(19);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(20);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(21);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(22);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(23);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(24);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(25);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(26);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(27);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(28);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(29);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(30);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(31);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(32);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(33);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_1_scale = constants_->at(34);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_1_bias = constants_->at(35);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(36);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(37);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(38);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(39);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(40);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(41);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(42);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(43);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(44);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(45);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(46);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(47);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(48);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(49);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_1_scale = constants_->at(50);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_1_bias = constants_->at(51);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(52);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(53);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(54);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(55);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(56);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(57);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(58);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(59);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(60);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(61);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(62);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(63);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(64);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(65);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(66);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(67);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(68);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(69);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(70);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(71);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(72);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(73);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(74);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(75);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(76);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(77);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(78);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(79);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(80);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(81);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(82);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(83);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(84);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(85);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(86);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(87);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(88);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(89);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_1_scale = constants_->at(90);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_1_bias = constants_->at(91);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(92);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(93);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(94);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(95);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(96);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(97);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_1_scale = constants_->at(98);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_1_bias = constants_->at(99);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(100);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(101);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(102);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(103);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(104);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(105);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(106);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(107);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(108);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(109);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(110);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(111);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(112);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(113);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(114);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(115);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(116);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(117);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_1_scale = constants_->at(118);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_1_bias = constants_->at(119);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(120);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(121);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_1_scale = constants_->at(122);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_1_bias = constants_->at(123);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(124);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(125);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(126);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(127);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(128);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(129);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(130);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(131);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(132);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(133);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(134);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(135);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(136);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(137);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(138);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(139);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(140);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(141);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(142);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(143);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(144);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(145);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_w = constants_->at(146);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_b = constants_->at(147);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = constants_->at(148);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = constants_->at(149);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w = constants_->at(150);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b = constants_->at(151);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w = constants_->at(152);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = constants_->at(153);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = constants_->at(154);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = constants_->at(155);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_w = constants_->at(156);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_b = constants_->at(157);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_w = constants_->at(158);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_b = constants_->at(159);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_w = constants_->at(160);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_b = constants_->at(161);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_w = constants_->at(162);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_b = constants_->at(163);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_w = constants_->at(164);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_b = constants_->at(165);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_w = constants_->at(166);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_b = constants_->at(167);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(168);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(169);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = constants_->at(170);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = constants_->at(171);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w = constants_->at(172);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b = constants_->at(173);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale = constants_->at(174);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias = constants_->at(175);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(176);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(177);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w = constants_->at(178);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b = constants_->at(179);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w = constants_->at(180);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b = constants_->at(181);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb = constants_->at(182);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb = constants_->at(183);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight = constants_->at(184);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias = constants_->at(185);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight = constants_->at(186);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight = constants_->at(187);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias = constants_->at(188);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight = constants_->at(189);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias = constants_->at(190);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight = constants_->at(191);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias = constants_->at(192);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_weight = constants_->at(193);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias = constants_->at(194);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_weight = constants_->at(195);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias = constants_->at(196);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb = constants_->at(197);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb = constants_->at(198);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight = constants_->at(199);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias = constants_->at(200);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight = constants_->at(201);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight = constants_->at(202);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias = constants_->at(203);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight = constants_->at(204);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias = constants_->at(205);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight = constants_->at(206);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias = constants_->at(207);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_weight = constants_->at(208);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias = constants_->at(209);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_weight = constants_->at(210);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias = constants_->at(211);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias = constants_->at(212);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight = constants_->at(213);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w = constants_->at(214);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b = constants_->at(215);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w = constants_->at(216);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b = constants_->at(217);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_weight = constants_->at(218);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_bias = constants_->at(219);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(220);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(221);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(222);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(223);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_weight = constants_->at(224);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(225);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(226);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(227);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(228);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(229);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_weight = constants_->at(230);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_bias = constants_->at(231);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(232);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(233);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(234);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(235);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_weight = constants_->at(236);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(237);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(238);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(239);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(240);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(241);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = constants_->at(242);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(243);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(244);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(245);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = constants_->at(246);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(247);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(248);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(249);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w = constants_->at(250);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b = constants_->at(251);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w = constants_->at(252);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b = constants_->at(253);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_weight = constants_->at(254);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(255);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(256);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(257);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(258);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(259);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w = constants_->at(260);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b = constants_->at(261);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = constants_->at(262);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(263);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(264);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(265);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_weight = constants_->at(266);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(267);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(268);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(269);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w = constants_->at(270);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b = constants_->at(271);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_weight = constants_->at(272);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(273);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(274);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(275);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(276);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(277);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_weight = constants_->at(278);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(279);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(280);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(281);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(282);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(283);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_weight = constants_->at(284);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(285);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(286);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(287);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_weight = constants_->at(288);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(289);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(290);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(291);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(292);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(293);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_weight = constants_->at(294);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(295);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(296);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(297);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(298);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(299);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(300);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(301);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_weight = constants_->at(302);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias = constants_->at(303);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w = constants_->at(304);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b = constants_->at(305);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w = constants_->at(306);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b = constants_->at(307);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w = constants_->at(308);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b = constants_->at(309);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_weight = constants_->at(310);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_bias = constants_->at(311);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(312);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(313);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(314);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(315);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_weight = constants_->at(316);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(317);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(318);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(319);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(320);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(321);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_weight = constants_->at(322);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_bias = constants_->at(323);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(324);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(325);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(326);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(327);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_weight = constants_->at(328);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(329);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(330);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(331);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(332);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(333);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = constants_->at(334);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(335);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(336);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(337);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = constants_->at(338);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(339);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(340);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(341);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w = constants_->at(342);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b = constants_->at(343);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w = constants_->at(344);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b = constants_->at(345);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_weight = constants_->at(346);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(347);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(348);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(349);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(350);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(351);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w = constants_->at(352);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b = constants_->at(353);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = constants_->at(354);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(355);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(356);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(357);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_weight = constants_->at(358);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(359);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(360);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(361);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w = constants_->at(362);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b = constants_->at(363);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_weight = constants_->at(364);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(365);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(366);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(367);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(368);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(369);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_weight = constants_->at(370);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(371);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(372);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(373);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(374);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(375);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_weight = constants_->at(376);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(377);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(378);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(379);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_weight = constants_->at(380);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(381);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(382);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(383);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(384);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(385);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_weight = constants_->at(386);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(387);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(388);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(389);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(390);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(391);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(392);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(393);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_weight = constants_->at(394);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias = constants_->at(395);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w = constants_->at(396);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b = constants_->at(397);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w = constants_->at(398);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b = constants_->at(399);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w = constants_->at(400);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b = constants_->at(401);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_weight = constants_->at(402);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_bias = constants_->at(403);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(404);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(405);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(406);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(407);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_weight = constants_->at(408);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(409);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(410);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(411);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(412);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(413);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_weight = constants_->at(414);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_bias = constants_->at(415);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(416);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(417);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(418);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(419);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_weight = constants_->at(420);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(421);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(422);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(423);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(424);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(425);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = constants_->at(426);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(427);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(428);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(429);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = constants_->at(430);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(431);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(432);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(433);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w = constants_->at(434);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b = constants_->at(435);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w = constants_->at(436);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b = constants_->at(437);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_weight = constants_->at(438);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(439);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(440);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(441);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(442);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(443);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w = constants_->at(444);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b = constants_->at(445);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = constants_->at(446);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(447);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(448);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(449);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_weight = constants_->at(450);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(451);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(452);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(453);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w = constants_->at(454);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b = constants_->at(455);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_weight = constants_->at(456);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(457);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(458);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(459);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(460);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(461);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_weight = constants_->at(462);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(463);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(464);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(465);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(466);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(467);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_weight = constants_->at(468);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(469);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(470);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(471);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_weight = constants_->at(472);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(473);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(474);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(475);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(476);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(477);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_weight = constants_->at(478);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(479);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(480);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(481);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(482);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(483);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(484);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(485);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_weight = constants_->at(486);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias = constants_->at(487);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w = constants_->at(488);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b = constants_->at(489);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w = constants_->at(490);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b = constants_->at(491);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w = constants_->at(492);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b = constants_->at(493);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_weight = constants_->at(494);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_bias = constants_->at(495);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(496);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(497);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(498);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(499);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_weight = constants_->at(500);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(501);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(502);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(503);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(504);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(505);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_weight = constants_->at(506);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_bias = constants_->at(507);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(508);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(509);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(510);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(511);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_weight = constants_->at(512);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(513);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(514);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(515);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(516);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(517);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = constants_->at(518);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(519);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(520);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(521);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = constants_->at(522);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(523);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(524);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(525);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w = constants_->at(526);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b = constants_->at(527);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w = constants_->at(528);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b = constants_->at(529);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_weight = constants_->at(530);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(531);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(532);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(533);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(534);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(535);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w = constants_->at(536);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b = constants_->at(537);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = constants_->at(538);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(539);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(540);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(541);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_weight = constants_->at(542);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(543);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(544);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(545);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w = constants_->at(546);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b = constants_->at(547);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_weight = constants_->at(548);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(549);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(550);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(551);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(552);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(553);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_weight = constants_->at(554);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(555);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(556);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(557);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(558);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(559);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_weight = constants_->at(560);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(561);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(562);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(563);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_weight = constants_->at(564);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(565);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(566);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(567);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(568);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(569);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_weight = constants_->at(570);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(571);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(572);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(573);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(574);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(575);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(576);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(577);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w = constants_->at(578);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b = constants_->at(579);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w = constants_->at(580);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b = constants_->at(581);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w = constants_->at(582);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b = constants_->at(583);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w = constants_->at(584);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b = constants_->at(585);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_dependent_tasks_1_SALR_STANDALONE_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias = constants_->at(586);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w = constants_->at(587);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b = constants_->at(588);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w = constants_->at(589);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = constants_->at(590);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w = constants_->at(591);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b = constants_->at(592);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = constants_->at(593);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = constants_->at(594);
    [[maybe_unused]] auto _tensor_constant2 = constants_->at(595);
    [[maybe_unused]] auto submod_0_cat_fusion_gpu__offset_dim_list = constants_->at(596);
    [[maybe_unused]] auto submod_0_cat_fusion_gpu__permute = constants_->at(597);
    [[maybe_unused]] auto submod_0_cat_fusion_gpu__inv_permute = constants_->at(598);
    [[maybe_unused]] auto submod_0_cat_fusion_gpu__inv_offset_dim_list = constants_->at(599);
    [[maybe_unused]] auto submod_0_cat_fusion_cpu__offset_dim_list = constants_->at(600);
    [[maybe_unused]] auto submod_0_cat_fusion_cpu__permute = constants_->at(601);
    [[maybe_unused]] auto submod_0_cat_fusion_cpu__inv_permute = constants_->at(602);
    [[maybe_unused]] auto submod_0_cat_fusion_cpu__inv_offset_dim_list = constants_->at(603);
    [[maybe_unused]] auto submod_1__tensor_constant1 = constants_->at(604);
    [[maybe_unused]] auto submod_1_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_calibration_positive_weight_calibration_bias = constants_->at(605);
    auto& kernels = static_cast<AOTInductorModelKernels&>(*this->kernels_.get());

    AOTICudaStreamGuard stream_guard(stream, this->device_idx_);
    static constexpr int64_t int_array_0[] = {256L, };
    static constexpr int64_t int_array_1[] = {1L, };
    AtenTensorHandle buf0_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(1, int_array_0, int_array_1, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf0_handle));
    RAIIAtenTensorHandle buf0(buf0_handle);
    // Topologically Sorted Source Nodes: [cat_default_14], Original ATen: [aten.cat]
    if (kernels.triton_poi_fused_cat_0 == nullptr) {
        kernels.triton_poi_fused_cat_0 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cpkq2p2hycw5573b4oc4lmf2ozjxie4evhb4azfb2lvj5bsujzcw.cubin", "triton_poi_fused_cat_0", 0, this->cubin_dir_);
    }
    CUdeviceptr var_0 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_1 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_b.data_ptr());
    CUdeviceptr var_2 = reinterpret_cast<CUdeviceptr>(buf0.data_ptr());
    int var_3 = 256L;
    void* kernel_args_var_0[] = {&var_0, &var_1, &var_2, &var_3};
    Grid triton_poi_fused_cat_0_grid_0 = Grid(2L, 1L, 1L);
    if (triton_poi_fused_cat_0_grid_0.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_0, triton_poi_fused_cat_0_grid_0.grid_x, triton_poi_fused_cat_0_grid_0.grid_y, triton_poi_fused_cat_0_grid_0.grid_z, 4, 0, kernel_args_var_0, stream);
    }
    static constexpr int64_t int_array_2[] = {6056L, 256L};
    static constexpr int64_t int_array_3[] = {256L, 1L};
    AtenTensorHandle buf1_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_2, int_array_3, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf1_handle));
    RAIIAtenTensorHandle buf1(buf1_handle);
    // Topologically Sorted Source Nodes: [linear_default], Original ATen: [aten.addmm]
    if (kernels.triton_poi_fused_addmm_1 == nullptr) {
        kernels.triton_poi_fused_addmm_1 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/czjsl7lff5ivjfcugcn7tyqam2ukgurv7q4i2doawkvccj4u6vo4.cubin", "triton_poi_fused_addmm_1", 0, this->cubin_dir_);
    }
    CUdeviceptr var_4 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_5 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_w.data_ptr());
    CUdeviceptr var_6 = reinterpret_cast<CUdeviceptr>(buf1.data_ptr());
    int var_7 = 1550336L;
    void* kernel_args_var_1[] = {&var_4, &var_5, &var_6, &var_7};
    Grid triton_poi_fused_addmm_1_grid_1 = Grid(1514L, 1L, 1L);
    if (triton_poi_fused_addmm_1_grid_1.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_1, triton_poi_fused_addmm_1_grid_1.grid_x, triton_poi_fused_addmm_1_grid_1.grid_y, triton_poi_fused_addmm_1_grid_1.grid_z, 4, 0, kernel_args_var_1, stream);
    }
    static constexpr int64_t int_array_4[] = {512L, };
    AtenTensorHandle buf2_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(1, int_array_4, int_array_1, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf2_handle));
    RAIIAtenTensorHandle buf2(buf2_handle);
    // Topologically Sorted Source Nodes: [cat_default_16], Original ATen: [aten.cat]
    if (kernels.triton_poi_fused_cat_2 == nullptr) {
        kernels.triton_poi_fused_cat_2 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c6evltjrmwgiom5litd3426munv66ti3xd7wiii4hnozwfsdsyem.cubin", "triton_poi_fused_cat_2", 0, this->cubin_dir_);
    }
    CUdeviceptr var_8 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_9 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_10 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    int var_11 = 512L;
    void* kernel_args_var_2[] = {&var_8, &var_9, &var_10, &var_11};
    Grid triton_poi_fused_cat_2_grid_2 = Grid(4L, 1L, 1L);
    if (triton_poi_fused_cat_2_grid_2.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_2, triton_poi_fused_cat_2_grid_2.grid_x, triton_poi_fused_cat_2_grid_2.grid_y, triton_poi_fused_cat_2_grid_2.grid_z, 4, 0, kernel_args_var_2, stream);
    }
    static constexpr int64_t int_array_5[] = {512L, 700L};
    static constexpr int64_t int_array_6[] = {700L, 1L};
    AtenTensorHandle buf3_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_5, int_array_6, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf3_handle));
    RAIIAtenTensorHandle buf3(buf3_handle);
    // Topologically Sorted Source Nodes: [cat_default_15], Original ATen: [aten.cat]
    if (kernels.triton_poi_fused_cat_3 == nullptr) {
        kernels.triton_poi_fused_cat_3 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cg535e4755mzocsmbnskq6mtbqsvxfnkrwbuuwpl3gevabeaecs3.cubin", "triton_poi_fused_cat_3", 0, this->cubin_dir_);
    }
    CUdeviceptr var_12 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_13 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_14 = reinterpret_cast<CUdeviceptr>(buf3.data_ptr());
    int var_15 = 358400L;
    void* kernel_args_var_3[] = {&var_12, &var_13, &var_14, &var_15};
    Grid triton_poi_fused_cat_3_grid_3 = Grid(700L, 1L, 1L);
    if (triton_poi_fused_cat_3_grid_3.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_3, triton_poi_fused_cat_3_grid_3.grid_x, triton_poi_fused_cat_3_grid_3.grid_y, triton_poi_fused_cat_3_grid_3.grid_z, 8, 0, kernel_args_var_3, stream);
    }
    static constexpr int64_t int_array_7[] = {1152L, };
    AtenTensorHandle buf4_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(1, int_array_7, int_array_1, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf4_handle));
    RAIIAtenTensorHandle buf4(buf4_handle);
    // Topologically Sorted Source Nodes: [cat_default_18], Original ATen: [aten.cat]
    if (kernels.triton_poi_fused_cat_4 == nullptr) {
        kernels.triton_poi_fused_cat_4 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cfawoj32ejwv352natrajujvn3sjvpuhmo66qydlssblp2xwgmtp.cubin", "triton_poi_fused_cat_4", 0, this->cubin_dir_);
    }
    CUdeviceptr var_16 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_17 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_18 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_19 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_20 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_21 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_22 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    int var_23 = 1152L;
    void* kernel_args_var_4[] = {&var_16, &var_17, &var_18, &var_19, &var_20, &var_21, &var_22, &var_23};
    Grid triton_poi_fused_cat_4_grid_4 = Grid(5L, 1L, 1L);
    if (triton_poi_fused_cat_4_grid_4.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_4, triton_poi_fused_cat_4_grid_4.grid_x, triton_poi_fused_cat_4_grid_4.grid_y, triton_poi_fused_cat_4_grid_4.grid_z, 4, 0, kernel_args_var_4, stream);
    }
    static constexpr int64_t int_array_8[] = {1152L, 3282L};
    static constexpr int64_t int_array_9[] = {3282L, 1L};
    AtenTensorHandle buf5_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_8, int_array_9, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf5_handle));
    RAIIAtenTensorHandle buf5(buf5_handle);
    // Topologically Sorted Source Nodes: [cat_default_17], Original ATen: [aten.cat]
    if (kernels.triton_poi_fused_cat_5 == nullptr) {
        kernels.triton_poi_fused_cat_5 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c2ahmc4dpvlsj6zi5oii767ghr5hi6k57xlumrfcpjghcwv7tg53.cubin", "triton_poi_fused_cat_5", 0, this->cubin_dir_);
    }
    CUdeviceptr var_24 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_25 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_26 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_27 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_28 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_29 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_w.data_ptr());
    CUdeviceptr var_30 = reinterpret_cast<CUdeviceptr>(buf5.data_ptr());
    int var_31 = 3780864L;
    void* kernel_args_var_5[] = {&var_24, &var_25, &var_26, &var_27, &var_28, &var_29, &var_30, &var_31};
    Grid triton_poi_fused_cat_5_grid_5 = Grid(3693L, 1L, 1L);
    if (triton_poi_fused_cat_5_grid_5.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_5, triton_poi_fused_cat_5_grid_5.grid_x, triton_poi_fused_cat_5_grid_5.grid_y, triton_poi_fused_cat_5_grid_5.grid_z, 4, 0, kernel_args_var_5, stream);
    }
    static constexpr int64_t int_array_10[] = {3288L, 1152L};
    static constexpr int64_t int_array_11[] = {1152L, 1L};
    AtenTensorHandle buf6_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_10, int_array_11, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf6_handle));
    RAIIAtenTensorHandle buf6(buf6_handle);
    // Topologically Sorted Source Nodes: [linear_default_2], Original ATen: [aten.addmm]
    if (kernels.triton_poi_fused_addmm_6 == nullptr) {
        kernels.triton_poi_fused_addmm_6 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/csp53dh2oafgqd3blorqb3ateh35ltze2s5cxthcnjqgwbtiq7ak.cubin", "triton_poi_fused_addmm_6", 8320, this->cubin_dir_);
    }
    CUdeviceptr var_32 = reinterpret_cast<CUdeviceptr>(buf5.data_ptr());
    CUdeviceptr var_33 = reinterpret_cast<CUdeviceptr>(buf6.data_ptr());
    int var_34 = 3288L;
    int var_35 = 1152L;
    void* kernel_args_var_6[] = {&var_32, &var_33, &var_34, &var_35};
    Grid triton_poi_fused_addmm_6_grid_6 = Grid(18L, 52L, 1L);
    if (triton_poi_fused_addmm_6_grid_6.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_6, triton_poi_fused_addmm_6_grid_6.grid_x, triton_poi_fused_addmm_6_grid_6.grid_y, triton_poi_fused_addmm_6_grid_6.grid_z, 8, 8320, kernel_args_var_6, stream);
    }
    buf5.reset();
    static constexpr int64_t int_array_12[] = {1536L, };
    AtenTensorHandle buf7_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(1, int_array_12, int_array_1, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf7_handle));
    RAIIAtenTensorHandle buf7(buf7_handle);
    // Topologically Sorted Source Nodes: [cat_default_20], Original ATen: [aten.cat]
    if (kernels.triton_poi_fused_cat_7 == nullptr) {
        kernels.triton_poi_fused_cat_7 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/celvitsau46njveywrpan6h3i7blyj3pe54rezxolno6hettlcyy.cubin", "triton_poi_fused_cat_7", 0, this->cubin_dir_);
    }
    CUdeviceptr var_36 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_37 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_38 = reinterpret_cast<CUdeviceptr>(buf7.data_ptr());
    int var_39 = 1536L;
    void* kernel_args_var_7[] = {&var_36, &var_37, &var_38, &var_39};
    Grid triton_poi_fused_cat_7_grid_7 = Grid(12L, 1L, 1L);
    if (triton_poi_fused_cat_7_grid_7.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_7, triton_poi_fused_cat_7_grid_7.grid_x, triton_poi_fused_cat_7_grid_7.grid_y, triton_poi_fused_cat_7_grid_7.grid_z, 4, 0, kernel_args_var_7, stream);
    }
    static constexpr int64_t int_array_13[] = {1536L, 4608L};
    static constexpr int64_t int_array_14[] = {4608L, 1L};
    AtenTensorHandle buf8_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_13, int_array_14, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf8_handle));
    RAIIAtenTensorHandle buf8(buf8_handle);
    // Topologically Sorted Source Nodes: [cat_default_19], Original ATen: [aten.cat]
    if (kernels.triton_poi_fused_cat_8 == nullptr) {
        kernels.triton_poi_fused_cat_8 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c53yaq6bh3z3ua6b7opweozpxykbi3myfu3qvdocy62honcujqho.cubin", "triton_poi_fused_cat_8", 0, this->cubin_dir_);
    }
    CUdeviceptr var_40 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_41 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_42 = reinterpret_cast<CUdeviceptr>(buf8.data_ptr());
    int var_43 = 7077888L;
    void* kernel_args_var_8[] = {&var_40, &var_41, &var_42, &var_43};
    Grid triton_poi_fused_cat_8_grid_8 = Grid(6912L, 1L, 1L);
    if (triton_poi_fused_cat_8_grid_8.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_8, triton_poi_fused_cat_8_grid_8.grid_x, triton_poi_fused_cat_8_grid_8.grid_y, triton_poi_fused_cat_8_grid_8.grid_z, 4, 0, kernel_args_var_8, stream);
    }
    static constexpr int64_t int_array_15[] = {6360L, 384L};
    static constexpr int64_t int_array_16[] = {384L, 1L};
    AtenTensorHandle buf9_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_15, int_array_16, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf9_handle));
    RAIIAtenTensorHandle buf9(buf9_handle);
    // Topologically Sorted Source Nodes: [linear_66], Original ATen: [aten.addmm]
    if (kernels.triton_poi_fused_addmm_9 == nullptr) {
        kernels.triton_poi_fused_addmm_9 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cp22sh2cunulnbuhdq4qqoleftxnnhwhrghjnbhzpnsdy4z3xh4d.cubin", "triton_poi_fused_addmm_9", 8320, this->cubin_dir_);
    }
    CUdeviceptr var_44 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_45 = reinterpret_cast<CUdeviceptr>(buf9.data_ptr());
    int var_46 = 6360L;
    int var_47 = 384L;
    void* kernel_args_var_9[] = {&var_44, &var_45, &var_46, &var_47};
    Grid triton_poi_fused_addmm_9_grid_9 = Grid(6L, 100L, 1L);
    if (triton_poi_fused_addmm_9_grid_9.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_9, triton_poi_fused_addmm_9_grid_9.grid_x, triton_poi_fused_addmm_9_grid_9.grid_y, triton_poi_fused_addmm_9_grid_9.grid_z, 8, 8320, kernel_args_var_9, stream);
    }
    static constexpr int64_t int_array_17[] = {6360L, 3072L};
    static constexpr int64_t int_array_18[] = {3072L, 1L};
    AtenTensorHandle buf10_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_17, int_array_18, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf10_handle));
    RAIIAtenTensorHandle buf10(buf10_handle);
    // Topologically Sorted Source Nodes: [linear_68], Original ATen: [aten.addmm]
    if (kernels.triton_poi_fused_addmm_10 == nullptr) {
        kernels.triton_poi_fused_addmm_10 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/csehwahvykdyevvubwrfgm3dwtn2zrqaegfoibjajlxalprkyiuc.cubin", "triton_poi_fused_addmm_10", 8320, this->cubin_dir_);
    }
    CUdeviceptr var_48 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_49 = reinterpret_cast<CUdeviceptr>(buf10.data_ptr());
    int var_50 = 6360L;
    int var_51 = 3072L;
    void* kernel_args_var_10[] = {&var_48, &var_49, &var_50, &var_51};
    Grid triton_poi_fused_addmm_10_grid_10 = Grid(48L, 100L, 1L);
    if (triton_poi_fused_addmm_10_grid_10.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_10, triton_poi_fused_addmm_10_grid_10.grid_x, triton_poi_fused_addmm_10_grid_10.grid_y, triton_poi_fused_addmm_10_grid_10.grid_z, 8, 8320, kernel_args_var_10, stream);
    }
    AtenTensorHandle buf11_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(1, int_array_12, int_array_1, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf11_handle));
    RAIIAtenTensorHandle buf11(buf11_handle);
    // Topologically Sorted Source Nodes: [cat_default_22], Original ATen: [aten.cat]
    CUdeviceptr var_52 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_53 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_54 = reinterpret_cast<CUdeviceptr>(buf11.data_ptr());
    int var_55 = 1536L;
    void* kernel_args_var_11[] = {&var_52, &var_53, &var_54, &var_55};
    Grid triton_poi_fused_cat_7_grid_11 = Grid(12L, 1L, 1L);
    if (triton_poi_fused_cat_7_grid_11.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_7, triton_poi_fused_cat_7_grid_11.grid_x, triton_poi_fused_cat_7_grid_11.grid_y, triton_poi_fused_cat_7_grid_11.grid_z, 4, 0, kernel_args_var_11, stream);
    }
    AtenTensorHandle buf12_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_13, int_array_14, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf12_handle));
    RAIIAtenTensorHandle buf12(buf12_handle);
    // Topologically Sorted Source Nodes: [cat_default_21], Original ATen: [aten.cat]
    CUdeviceptr var_56 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_57 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_58 = reinterpret_cast<CUdeviceptr>(buf12.data_ptr());
    int var_59 = 7077888L;
    void* kernel_args_var_12[] = {&var_56, &var_57, &var_58, &var_59};
    Grid triton_poi_fused_cat_8_grid_12 = Grid(6912L, 1L, 1L);
    if (triton_poi_fused_cat_8_grid_12.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_8, triton_poi_fused_cat_8_grid_12.grid_x, triton_poi_fused_cat_8_grid_12.grid_y, triton_poi_fused_cat_8_grid_12.grid_z, 4, 0, kernel_args_var_12, stream);
    }
    AtenTensorHandle buf13_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_15, int_array_16, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf13_handle));
    RAIIAtenTensorHandle buf13(buf13_handle);
    // Topologically Sorted Source Nodes: [linear_81], Original ATen: [aten.addmm]
    CUdeviceptr var_60 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_61 = reinterpret_cast<CUdeviceptr>(buf13.data_ptr());
    int var_62 = 6360L;
    int var_63 = 384L;
    void* kernel_args_var_13[] = {&var_60, &var_61, &var_62, &var_63};
    Grid triton_poi_fused_addmm_9_grid_13 = Grid(6L, 100L, 1L);
    if (triton_poi_fused_addmm_9_grid_13.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_9, triton_poi_fused_addmm_9_grid_13.grid_x, triton_poi_fused_addmm_9_grid_13.grid_y, triton_poi_fused_addmm_9_grid_13.grid_z, 8, 8320, kernel_args_var_13, stream);
    }
    AtenTensorHandle buf14_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_17, int_array_18, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf14_handle));
    RAIIAtenTensorHandle buf14(buf14_handle);
    // Topologically Sorted Source Nodes: [linear_83], Original ATen: [aten.addmm]
    CUdeviceptr var_64 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_65 = reinterpret_cast<CUdeviceptr>(buf14.data_ptr());
    int var_66 = 6360L;
    int var_67 = 3072L;
    void* kernel_args_var_14[] = {&var_64, &var_65, &var_66, &var_67};
    Grid triton_poi_fused_addmm_10_grid_14 = Grid(48L, 100L, 1L);
    if (triton_poi_fused_addmm_10_grid_14.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_10, triton_poi_fused_addmm_10_grid_14.grid_x, triton_poi_fused_addmm_10_grid_14.grid_y, triton_poi_fused_addmm_10_grid_14.grid_z, 8, 8320, kernel_args_var_14, stream);
    }
    AtenTensorHandle buf15_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(1, int_array_12, int_array_1, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf15_handle));
    RAIIAtenTensorHandle buf15(buf15_handle);
    // Topologically Sorted Source Nodes: [cat_default_24], Original ATen: [aten.cat]
    CUdeviceptr var_68 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_69 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_70 = reinterpret_cast<CUdeviceptr>(buf15.data_ptr());
    int var_71 = 1536L;
    void* kernel_args_var_15[] = {&var_68, &var_69, &var_70, &var_71};
    Grid triton_poi_fused_cat_7_grid_15 = Grid(12L, 1L, 1L);
    if (triton_poi_fused_cat_7_grid_15.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_7, triton_poi_fused_cat_7_grid_15.grid_x, triton_poi_fused_cat_7_grid_15.grid_y, triton_poi_fused_cat_7_grid_15.grid_z, 4, 0, kernel_args_var_15, stream);
    }
    AtenTensorHandle buf16_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_13, int_array_14, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf16_handle));
    RAIIAtenTensorHandle buf16(buf16_handle);
    // Topologically Sorted Source Nodes: [cat_default_23], Original ATen: [aten.cat]
    CUdeviceptr var_72 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_73 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_74 = reinterpret_cast<CUdeviceptr>(buf16.data_ptr());
    int var_75 = 7077888L;
    void* kernel_args_var_16[] = {&var_72, &var_73, &var_74, &var_75};
    Grid triton_poi_fused_cat_8_grid_16 = Grid(6912L, 1L, 1L);
    if (triton_poi_fused_cat_8_grid_16.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_8, triton_poi_fused_cat_8_grid_16.grid_x, triton_poi_fused_cat_8_grid_16.grid_y, triton_poi_fused_cat_8_grid_16.grid_z, 4, 0, kernel_args_var_16, stream);
    }
    AtenTensorHandle buf17_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_15, int_array_16, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf17_handle));
    RAIIAtenTensorHandle buf17(buf17_handle);
    // Topologically Sorted Source Nodes: [linear_96], Original ATen: [aten.addmm]
    CUdeviceptr var_76 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_77 = reinterpret_cast<CUdeviceptr>(buf17.data_ptr());
    int var_78 = 6360L;
    int var_79 = 384L;
    void* kernel_args_var_17[] = {&var_76, &var_77, &var_78, &var_79};
    Grid triton_poi_fused_addmm_9_grid_17 = Grid(6L, 100L, 1L);
    if (triton_poi_fused_addmm_9_grid_17.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_9, triton_poi_fused_addmm_9_grid_17.grid_x, triton_poi_fused_addmm_9_grid_17.grid_y, triton_poi_fused_addmm_9_grid_17.grid_z, 8, 8320, kernel_args_var_17, stream);
    }
    AtenTensorHandle buf18_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_17, int_array_18, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf18_handle));
    RAIIAtenTensorHandle buf18(buf18_handle);
    // Topologically Sorted Source Nodes: [linear_98], Original ATen: [aten.addmm]
    CUdeviceptr var_80 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_81 = reinterpret_cast<CUdeviceptr>(buf18.data_ptr());
    int var_82 = 6360L;
    int var_83 = 3072L;
    void* kernel_args_var_18[] = {&var_80, &var_81, &var_82, &var_83};
    Grid triton_poi_fused_addmm_10_grid_18 = Grid(48L, 100L, 1L);
    if (triton_poi_fused_addmm_10_grid_18.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_10, triton_poi_fused_addmm_10_grid_18.grid_x, triton_poi_fused_addmm_10_grid_18.grid_y, triton_poi_fused_addmm_10_grid_18.grid_z, 8, 8320, kernel_args_var_18, stream);
    }
    AtenTensorHandle buf19_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(1, int_array_12, int_array_1, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf19_handle));
    RAIIAtenTensorHandle buf19(buf19_handle);
    // Topologically Sorted Source Nodes: [cat_default_26], Original ATen: [aten.cat]
    CUdeviceptr var_84 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_85 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_86 = reinterpret_cast<CUdeviceptr>(buf19.data_ptr());
    int var_87 = 1536L;
    void* kernel_args_var_19[] = {&var_84, &var_85, &var_86, &var_87};
    Grid triton_poi_fused_cat_7_grid_19 = Grid(12L, 1L, 1L);
    if (triton_poi_fused_cat_7_grid_19.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_7, triton_poi_fused_cat_7_grid_19.grid_x, triton_poi_fused_cat_7_grid_19.grid_y, triton_poi_fused_cat_7_grid_19.grid_z, 4, 0, kernel_args_var_19, stream);
    }
    AtenTensorHandle buf20_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_13, int_array_14, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf20_handle));
    RAIIAtenTensorHandle buf20(buf20_handle);
    // Topologically Sorted Source Nodes: [cat_default_25], Original ATen: [aten.cat]
    CUdeviceptr var_88 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_89 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_90 = reinterpret_cast<CUdeviceptr>(buf20.data_ptr());
    int var_91 = 7077888L;
    void* kernel_args_var_20[] = {&var_88, &var_89, &var_90, &var_91};
    Grid triton_poi_fused_cat_8_grid_20 = Grid(6912L, 1L, 1L);
    if (triton_poi_fused_cat_8_grid_20.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_8, triton_poi_fused_cat_8_grid_20.grid_x, triton_poi_fused_cat_8_grid_20.grid_y, triton_poi_fused_cat_8_grid_20.grid_z, 4, 0, kernel_args_var_20, stream);
    }
    AtenTensorHandle buf21_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_15, int_array_16, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf21_handle));
    RAIIAtenTensorHandle buf21(buf21_handle);
    // Topologically Sorted Source Nodes: [linear_111], Original ATen: [aten.addmm]
    CUdeviceptr var_92 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_93 = reinterpret_cast<CUdeviceptr>(buf21.data_ptr());
    int var_94 = 6360L;
    int var_95 = 384L;
    void* kernel_args_var_21[] = {&var_92, &var_93, &var_94, &var_95};
    Grid triton_poi_fused_addmm_9_grid_21 = Grid(6L, 100L, 1L);
    if (triton_poi_fused_addmm_9_grid_21.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_9, triton_poi_fused_addmm_9_grid_21.grid_x, triton_poi_fused_addmm_9_grid_21.grid_y, triton_poi_fused_addmm_9_grid_21.grid_z, 8, 8320, kernel_args_var_21, stream);
    }
    AtenTensorHandle buf22_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_17, int_array_18, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf22_handle));
    RAIIAtenTensorHandle buf22(buf22_handle);
    // Topologically Sorted Source Nodes: [linear_113], Original ATen: [aten.addmm]
    CUdeviceptr var_96 = reinterpret_cast<CUdeviceptr>(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_97 = reinterpret_cast<CUdeviceptr>(buf22.data_ptr());
    int var_98 = 6360L;
    int var_99 = 3072L;
    void* kernel_args_var_22[] = {&var_96, &var_97, &var_98, &var_99};
    Grid triton_poi_fused_addmm_10_grid_22 = Grid(48L, 100L, 1L);
    if (triton_poi_fused_addmm_10_grid_22.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_10, triton_poi_fused_addmm_10_grid_22.grid_x, triton_poi_fused_addmm_10_grid_22.grid_y, triton_poi_fused_addmm_10_grid_22.grid_z, 8, 8320, kernel_args_var_22, stream);
    }
    static constexpr int64_t int_array_19[] = {240L, 192L};
    static constexpr int64_t int_array_20[] = {1L, 240L};
    auto tmp_tensor_handle_0 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_19, int_array_20, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_0_raii(tmp_tensor_handle_0);
    auto tmp_tensor_handle_1 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_19, int_array_20, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_1_raii(tmp_tensor_handle_1);
    static constexpr int64_t int_array_21[] = {192L, 192L};
    static constexpr int64_t int_array_22[] = {1L, 192L};
    auto tmp_tensor_handle_2 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_21, int_array_22, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_2_raii(tmp_tensor_handle_2);
    auto tmp_tensor_handle_3 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_21, int_array_22, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_3_raii(tmp_tensor_handle_3);
    static constexpr int64_t int_array_23[] = {96L, 192L};
    static constexpr int64_t int_array_24[] = {1L, 96L};
    auto tmp_tensor_handle_4 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_4_raii(tmp_tensor_handle_4);
    static constexpr int64_t int_array_25[] = {72L, 192L};
    static constexpr int64_t int_array_26[] = {1L, 72L};
    auto tmp_tensor_handle_5 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_25, int_array_26, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_5_raii(tmp_tensor_handle_5);
    auto tmp_tensor_handle_6 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_6_raii(tmp_tensor_handle_6);
    auto tmp_tensor_handle_7 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_7_raii(tmp_tensor_handle_7);
    auto tmp_tensor_handle_8 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_8_raii(tmp_tensor_handle_8);
    auto tmp_tensor_handle_9 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_9_raii(tmp_tensor_handle_9);
    auto tmp_tensor_handle_10 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_25, int_array_26, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_10_raii(tmp_tensor_handle_10);
    auto tmp_tensor_handle_11 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_11_raii(tmp_tensor_handle_11);
    auto tmp_tensor_handle_12 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_12_raii(tmp_tensor_handle_12);
    auto tmp_tensor_handle_13 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_13_raii(tmp_tensor_handle_13);
    auto tmp_tensor_handle_14 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_25, int_array_26, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_14_raii(tmp_tensor_handle_14);
    auto tmp_tensor_handle_15 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_15_raii(tmp_tensor_handle_15);
    static constexpr int64_t int_array_27[] = {64L, 192L};
    static constexpr int64_t int_array_28[] = {1L, 64L};
    auto tmp_tensor_handle_16 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_16_raii(tmp_tensor_handle_16);
    auto tmp_tensor_handle_17 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_17_raii(tmp_tensor_handle_17);
    auto tmp_tensor_handle_18 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_18_raii(tmp_tensor_handle_18);
    auto tmp_tensor_handle_19 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_25, int_array_26, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_19_raii(tmp_tensor_handle_19);
    auto tmp_tensor_handle_20 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_25, int_array_26, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_20_raii(tmp_tensor_handle_20);
    auto tmp_tensor_handle_21 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_21_raii(tmp_tensor_handle_21);
    auto tmp_tensor_handle_22 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_22_raii(tmp_tensor_handle_22);
    auto tmp_tensor_handle_23 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_25, int_array_26, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_23_raii(tmp_tensor_handle_23);
    auto tmp_tensor_handle_24 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_25, int_array_26, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_24_raii(tmp_tensor_handle_24);
    auto tmp_tensor_handle_25 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_25, int_array_26, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_25_raii(tmp_tensor_handle_25);
    auto tmp_tensor_handle_26 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_26_raii(tmp_tensor_handle_26);
    auto tmp_tensor_handle_27 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_27_raii(tmp_tensor_handle_27);
    auto tmp_tensor_handle_28 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_28_raii(tmp_tensor_handle_28);
    static constexpr int64_t int_array_29[] = {144L, 192L};
    static constexpr int64_t int_array_30[] = {1L, 144L};
    auto tmp_tensor_handle_29 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_29, int_array_30, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_29_raii(tmp_tensor_handle_29);
    auto tmp_tensor_handle_30 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_29, int_array_30, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_30_raii(tmp_tensor_handle_30);
    auto tmp_tensor_handle_31 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_31_raii(tmp_tensor_handle_31);
    auto tmp_tensor_handle_32 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_32_raii(tmp_tensor_handle_32);
    auto tmp_tensor_handle_33 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_27, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_33_raii(tmp_tensor_handle_33);
    auto tmp_tensor_handle_34 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_34_raii(tmp_tensor_handle_34);
    auto tmp_tensor_handle_35 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, 2, int_array_23, int_array_24, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_35_raii(tmp_tensor_handle_35);
    static constexpr int64_t int_array_31[] = {700L, 512L};
    static constexpr int64_t int_array_32[] = {1L, 700L};
    auto tmp_tensor_handle_36 = reinterpret_tensor_wrapper(buf3, 2, int_array_31, int_array_32, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_36_raii(tmp_tensor_handle_36);
    static constexpr int64_t int_array_33[] = {256L, 3026L};
    static constexpr int64_t int_array_34[] = {1L, 256L};
    auto tmp_tensor_handle_37 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w, 2, int_array_33, int_array_34, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_37_raii(tmp_tensor_handle_37);
    static constexpr int64_t int_array_35[] = {3026L, 256L};
    static constexpr int64_t int_array_36[] = {1L, 3026L};
    auto tmp_tensor_handle_38 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w, 2, int_array_35, int_array_36, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_38_raii(tmp_tensor_handle_38);
    static constexpr int64_t int_array_37[] = {256L, 1024L};
    auto tmp_tensor_handle_39 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w, 2, int_array_37, int_array_34, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_39_raii(tmp_tensor_handle_39);
    static constexpr int64_t int_array_38[] = {64L, 64L};
    auto tmp_tensor_handle_40 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight, 2, int_array_38, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_40_raii(tmp_tensor_handle_40);
    auto tmp_tensor_handle_41 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight, 2, int_array_38, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_41_raii(tmp_tensor_handle_41);
    auto tmp_tensor_handle_42 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight, 2, int_array_38, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_42_raii(tmp_tensor_handle_42);
    auto tmp_tensor_handle_43 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight, 2, int_array_38, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_43_raii(tmp_tensor_handle_43);
    static constexpr int64_t int_array_39[] = {64L, 128L};
    auto tmp_tensor_handle_44 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_weight, 2, int_array_39, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_44_raii(tmp_tensor_handle_44);
    static constexpr int64_t int_array_40[] = {128L, 64L};
    static constexpr int64_t int_array_41[] = {1L, 128L};
    auto tmp_tensor_handle_45 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_weight, 2, int_array_40, int_array_41, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_45_raii(tmp_tensor_handle_45);
    static constexpr int64_t int_array_42[] = {256L, 960L};
    auto tmp_tensor_handle_46 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w, 2, int_array_42, int_array_34, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_46_raii(tmp_tensor_handle_46);
    static constexpr int64_t int_array_43[] = {960L, 1536L};
    static constexpr int64_t int_array_44[] = {1L, 960L};
    auto tmp_tensor_handle_47 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w, 2, int_array_43, int_array_44, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_47_raii(tmp_tensor_handle_47);
    auto tmp_tensor_handle_48 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_weight, 2, int_array_39, int_array_28, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_48_raii(tmp_tensor_handle_48);
    auto tmp_tensor_handle_49 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_weight, 2, int_array_40, int_array_41, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_49_raii(tmp_tensor_handle_49);
    static constexpr int64_t int_array_45[] = {4608L, 1536L};
    static constexpr int64_t int_array_46[] = {1L, 4608L};
    auto tmp_tensor_handle_50 = reinterpret_tensor_wrapper(buf8, 2, int_array_45, int_array_46, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_50_raii(tmp_tensor_handle_50);
    static constexpr int64_t int_array_47[] = {768L, 768L};
    static constexpr int64_t int_array_48[] = {1L, 768L};
    auto tmp_tensor_handle_51 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_weight, 2, int_array_47, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_51_raii(tmp_tensor_handle_51);
    auto tmp_tensor_handle_52 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_weight, 2, int_array_47, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_52_raii(tmp_tensor_handle_52);
    static constexpr int64_t int_array_49[] = {768L, 21984L};
    auto tmp_tensor_handle_53 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight, 2, int_array_49, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_53_raii(tmp_tensor_handle_53);
    static constexpr int64_t int_array_50[] = {768L, 9216L};
    auto tmp_tensor_handle_54 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight, 2, int_array_50, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_54_raii(tmp_tensor_handle_54);
    static constexpr int64_t int_array_51[] = {21984L, 2048L};
    static constexpr int64_t int_array_52[] = {1L, 21984L};
    auto tmp_tensor_handle_55 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_weight, 2, int_array_51, int_array_52, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_55_raii(tmp_tensor_handle_55);
    static constexpr int64_t int_array_53[] = {384L, 6354L};
    static constexpr int64_t int_array_54[] = {1L, 384L};
    auto tmp_tensor_handle_56 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_weight, 2, int_array_53, int_array_54, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_56_raii(tmp_tensor_handle_56);
    static constexpr int64_t int_array_55[] = {3072L, 1536L};
    static constexpr int64_t int_array_56[] = {1L, 3072L};
    auto tmp_tensor_handle_57 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_weight, 2, int_array_55, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_57_raii(tmp_tensor_handle_57);
    static constexpr int64_t int_array_57[] = {1536L, 3072L};
    static constexpr int64_t int_array_58[] = {1L, 1536L};
    auto tmp_tensor_handle_58 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_weight, 2, int_array_57, int_array_58, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_58_raii(tmp_tensor_handle_58);
    auto tmp_tensor_handle_59 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_weight, 2, int_array_55, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_59_raii(tmp_tensor_handle_59);
    auto tmp_tensor_handle_60 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_weight, 2, int_array_57, int_array_58, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_60_raii(tmp_tensor_handle_60);
    static constexpr int64_t int_array_59[] = {3072L, 9216L};
    auto tmp_tensor_handle_61 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_weight, 2, int_array_59, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_61_raii(tmp_tensor_handle_61);
    auto tmp_tensor_handle_62 = reinterpret_tensor_wrapper(buf12, 2, int_array_45, int_array_46, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_62_raii(tmp_tensor_handle_62);
    auto tmp_tensor_handle_63 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_weight, 2, int_array_47, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_63_raii(tmp_tensor_handle_63);
    auto tmp_tensor_handle_64 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_weight, 2, int_array_47, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_64_raii(tmp_tensor_handle_64);
    static constexpr int64_t int_array_60[] = {768L, 4896L};
    auto tmp_tensor_handle_65 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight, 2, int_array_60, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_65_raii(tmp_tensor_handle_65);
    auto tmp_tensor_handle_66 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight, 2, int_array_50, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_66_raii(tmp_tensor_handle_66);
    static constexpr int64_t int_array_61[] = {4896L, 2048L};
    static constexpr int64_t int_array_62[] = {1L, 4896L};
    auto tmp_tensor_handle_67 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_weight, 2, int_array_61, int_array_62, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_67_raii(tmp_tensor_handle_67);
    auto tmp_tensor_handle_68 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_weight, 2, int_array_53, int_array_54, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_68_raii(tmp_tensor_handle_68);
    auto tmp_tensor_handle_69 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_weight, 2, int_array_55, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_69_raii(tmp_tensor_handle_69);
    auto tmp_tensor_handle_70 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_weight, 2, int_array_57, int_array_58, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_70_raii(tmp_tensor_handle_70);
    auto tmp_tensor_handle_71 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_weight, 2, int_array_55, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_71_raii(tmp_tensor_handle_71);
    auto tmp_tensor_handle_72 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_weight, 2, int_array_57, int_array_58, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_72_raii(tmp_tensor_handle_72);
    auto tmp_tensor_handle_73 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_weight, 2, int_array_59, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_73_raii(tmp_tensor_handle_73);
    auto tmp_tensor_handle_74 = reinterpret_tensor_wrapper(buf16, 2, int_array_45, int_array_46, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_74_raii(tmp_tensor_handle_74);
    auto tmp_tensor_handle_75 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_weight, 2, int_array_47, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_75_raii(tmp_tensor_handle_75);
    auto tmp_tensor_handle_76 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_weight, 2, int_array_47, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_76_raii(tmp_tensor_handle_76);
    auto tmp_tensor_handle_77 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight, 2, int_array_60, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_77_raii(tmp_tensor_handle_77);
    auto tmp_tensor_handle_78 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight, 2, int_array_50, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_78_raii(tmp_tensor_handle_78);
    auto tmp_tensor_handle_79 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_weight, 2, int_array_61, int_array_62, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_79_raii(tmp_tensor_handle_79);
    auto tmp_tensor_handle_80 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_weight, 2, int_array_53, int_array_54, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_80_raii(tmp_tensor_handle_80);
    auto tmp_tensor_handle_81 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_weight, 2, int_array_55, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_81_raii(tmp_tensor_handle_81);
    auto tmp_tensor_handle_82 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_weight, 2, int_array_57, int_array_58, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_82_raii(tmp_tensor_handle_82);
    auto tmp_tensor_handle_83 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_weight, 2, int_array_55, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_83_raii(tmp_tensor_handle_83);
    auto tmp_tensor_handle_84 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_weight, 2, int_array_57, int_array_58, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_84_raii(tmp_tensor_handle_84);
    auto tmp_tensor_handle_85 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_weight, 2, int_array_59, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_85_raii(tmp_tensor_handle_85);
    auto tmp_tensor_handle_86 = reinterpret_tensor_wrapper(buf20, 2, int_array_45, int_array_46, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_86_raii(tmp_tensor_handle_86);
    auto tmp_tensor_handle_87 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_weight, 2, int_array_47, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_87_raii(tmp_tensor_handle_87);
    auto tmp_tensor_handle_88 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_weight, 2, int_array_47, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_88_raii(tmp_tensor_handle_88);
    auto tmp_tensor_handle_89 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight, 2, int_array_60, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_89_raii(tmp_tensor_handle_89);
    auto tmp_tensor_handle_90 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight, 2, int_array_50, int_array_48, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_90_raii(tmp_tensor_handle_90);
    auto tmp_tensor_handle_91 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_weight, 2, int_array_61, int_array_62, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_91_raii(tmp_tensor_handle_91);
    auto tmp_tensor_handle_92 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_weight, 2, int_array_53, int_array_54, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_92_raii(tmp_tensor_handle_92);
    auto tmp_tensor_handle_93 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_weight, 2, int_array_55, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_93_raii(tmp_tensor_handle_93);
    auto tmp_tensor_handle_94 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_weight, 2, int_array_57, int_array_58, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_94_raii(tmp_tensor_handle_94);
    auto tmp_tensor_handle_95 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_weight, 2, int_array_55, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_95_raii(tmp_tensor_handle_95);
    auto tmp_tensor_handle_96 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_weight, 2, int_array_57, int_array_58, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_96_raii(tmp_tensor_handle_96);
    static constexpr int64_t int_array_63[] = {3072L, 512L};
    auto tmp_tensor_handle_97 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w, 2, int_array_63, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_97_raii(tmp_tensor_handle_97);
    static constexpr int64_t int_array_64[] = {512L, 3072L};
    static constexpr int64_t int_array_65[] = {1L, 512L};
    auto tmp_tensor_handle_98 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w, 2, int_array_64, int_array_65, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_98_raii(tmp_tensor_handle_98);
    auto tmp_tensor_handle_99 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w, 2, int_array_63, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_99_raii(tmp_tensor_handle_99);
    auto tmp_tensor_handle_100 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w, 2, int_array_64, int_array_65, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_100_raii(tmp_tensor_handle_100);
    static constexpr int64_t int_array_66[] = {3072L, 3072L};
    auto tmp_tensor_handle_101 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w, 2, int_array_66, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_101_raii(tmp_tensor_handle_101);
    auto tmp_tensor_handle_102 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w, 2, int_array_63, int_array_56, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_102_raii(tmp_tensor_handle_102);
    static constexpr int64_t int_array_67[] = {512L, 1L};
    auto tmp_tensor_handle_103 = reinterpret_tensor_wrapper(submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w, 2, int_array_67, int_array_65, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_103_raii(tmp_tensor_handle_103);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[0]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_1_scale, &output_handles[1]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_1_bias, &output_handles[2]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[3]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_1_scale, &output_handles[4]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_1_bias, &output_handles[5]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[6]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_1_scale, &output_handles[7]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_1_bias, &output_handles[8]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[9]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_1_scale, &output_handles[10]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_1_bias, &output_handles[11]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[12]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[13]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[14]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[15]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[16]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[17]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[18]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[19]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[20]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[21]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[22]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[23]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[24]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_1_scale, &output_handles[25]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_1_bias, &output_handles[26]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[27]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[28]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[29]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[30]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[31]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[32]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[33]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[34]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[35]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[36]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_1_scale, &output_handles[37]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_1_bias, &output_handles[38]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[39]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[40]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[41]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[42]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[43]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[44]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[45]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[46]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[47]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[48]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[49]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[50]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[51]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[52]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[53]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[54]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[55]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[56]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[57]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[58]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[59]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[60]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[61]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[62]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[63]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[64]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[65]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[66]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_1_scale, &output_handles[67]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_1_bias, &output_handles[68]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[69]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[70]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[71]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[72]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_1_scale, &output_handles[73]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_1_bias, &output_handles[74]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[75]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[76]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[77]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[78]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[79]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[80]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[81]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[82]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[83]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[84]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[85]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[86]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[87]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_1_scale, &output_handles[88]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_1_bias, &output_handles[89]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[90]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_1_scale, &output_handles[91]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_1_bias, &output_handles[92]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[93]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[94]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[95]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[96]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[97]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[98]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[99]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[100]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[101]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[102]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_1_scale, &output_handles[103]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_1_bias, &output_handles[104]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b, &output_handles[105]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_1_scale, &output_handles[106]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_1_bias, &output_handles[107]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale, &output_handles[108]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias, &output_handles[109]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b, &output_handles[110]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b, &output_handles[111]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale, &output_handles[112]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias, &output_handles[113]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale, &output_handles[114]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias, &output_handles[115]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b, &output_handles[116]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale, &output_handles[117]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias, &output_handles[118]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b, &output_handles[119]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b, &output_handles[120]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb, &output_handles[121]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb, &output_handles[122]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight, &output_handles[123]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias, &output_handles[124]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias, &output_handles[125]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight, &output_handles[126]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias, &output_handles[127]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight, &output_handles[128]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias, &output_handles[129]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias, &output_handles[130]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias, &output_handles[131]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb, &output_handles[132]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb, &output_handles[133]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight, &output_handles[134]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias, &output_handles[135]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias, &output_handles[136]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight, &output_handles[137]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias, &output_handles[138]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight, &output_handles[139]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias, &output_handles[140]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias, &output_handles[141]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias, &output_handles[142]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias, &output_handles[143]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight, &output_handles[144]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w, &output_handles[145]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b, &output_handles[146]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w, &output_handles[147]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b, &output_handles[148]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight, &output_handles[149]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias, &output_handles[150]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w, &output_handles[151]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b, &output_handles[152]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias, &output_handles[153]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight, &output_handles[154]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias, &output_handles[155]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w, &output_handles[156]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b, &output_handles[157]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight, &output_handles[158]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias, &output_handles[159]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w, &output_handles[160]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b, &output_handles[161]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias, &output_handles[162]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight, &output_handles[163]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias, &output_handles[164]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w, &output_handles[165]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b, &output_handles[166]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias, &output_handles[167]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, &output_handles[168]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, &output_handles[169]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias, &output_handles[170]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w, &output_handles[171]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b, &output_handles[172]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w, &output_handles[173]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b, &output_handles[174]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w, &output_handles[175]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b, &output_handles[176]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias, &output_handles[177]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight, &output_handles[178]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias, &output_handles[179]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w, &output_handles[180]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b, &output_handles[181]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w, &output_handles[182]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b, &output_handles[183]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias, &output_handles[184]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w, &output_handles[185]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b, &output_handles[186]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias, &output_handles[187]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w, &output_handles[188]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b, &output_handles[189]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w, &output_handles[190]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b, &output_handles[191]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias, &output_handles[192]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight, &output_handles[193]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias, &output_handles[194]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w, &output_handles[195]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b, &output_handles[196]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias, &output_handles[197]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight, &output_handles[198]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias, &output_handles[199]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w, &output_handles[200]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b, &output_handles[201]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias, &output_handles[202]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w, &output_handles[203]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b, &output_handles[204]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias, &output_handles[205]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight, &output_handles[206]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias, &output_handles[207]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w, &output_handles[208]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b, &output_handles[209]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias, &output_handles[210]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w, &output_handles[211]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b, &output_handles[212]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight, &output_handles[213]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias, &output_handles[214]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight, &output_handles[215]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias, &output_handles[216]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias, &output_handles[217]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w, &output_handles[218]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b, &output_handles[219]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w, &output_handles[220]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b, &output_handles[221]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w, &output_handles[222]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b, &output_handles[223]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight, &output_handles[224]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias, &output_handles[225]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w, &output_handles[226]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b, &output_handles[227]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias, &output_handles[228]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight, &output_handles[229]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias, &output_handles[230]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w, &output_handles[231]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b, &output_handles[232]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight, &output_handles[233]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias, &output_handles[234]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w, &output_handles[235]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b, &output_handles[236]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias, &output_handles[237]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight, &output_handles[238]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias, &output_handles[239]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w, &output_handles[240]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b, &output_handles[241]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias, &output_handles[242]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, &output_handles[243]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, &output_handles[244]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias, &output_handles[245]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w, &output_handles[246]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b, &output_handles[247]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w, &output_handles[248]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b, &output_handles[249]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w, &output_handles[250]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b, &output_handles[251]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias, &output_handles[252]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight, &output_handles[253]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias, &output_handles[254]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w, &output_handles[255]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b, &output_handles[256]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w, &output_handles[257]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b, &output_handles[258]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias, &output_handles[259]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w, &output_handles[260]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b, &output_handles[261]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias, &output_handles[262]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w, &output_handles[263]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b, &output_handles[264]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w, &output_handles[265]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b, &output_handles[266]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias, &output_handles[267]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight, &output_handles[268]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias, &output_handles[269]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w, &output_handles[270]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b, &output_handles[271]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias, &output_handles[272]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight, &output_handles[273]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias, &output_handles[274]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w, &output_handles[275]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b, &output_handles[276]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias, &output_handles[277]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w, &output_handles[278]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b, &output_handles[279]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias, &output_handles[280]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight, &output_handles[281]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias, &output_handles[282]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w, &output_handles[283]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b, &output_handles[284]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias, &output_handles[285]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w, &output_handles[286]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b, &output_handles[287]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight, &output_handles[288]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias, &output_handles[289]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight, &output_handles[290]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias, &output_handles[291]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias, &output_handles[292]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w, &output_handles[293]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b, &output_handles[294]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w, &output_handles[295]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b, &output_handles[296]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w, &output_handles[297]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b, &output_handles[298]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight, &output_handles[299]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias, &output_handles[300]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w, &output_handles[301]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b, &output_handles[302]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias, &output_handles[303]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight, &output_handles[304]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias, &output_handles[305]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w, &output_handles[306]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b, &output_handles[307]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight, &output_handles[308]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias, &output_handles[309]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w, &output_handles[310]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b, &output_handles[311]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias, &output_handles[312]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight, &output_handles[313]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias, &output_handles[314]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w, &output_handles[315]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b, &output_handles[316]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias, &output_handles[317]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, &output_handles[318]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, &output_handles[319]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias, &output_handles[320]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w, &output_handles[321]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b, &output_handles[322]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w, &output_handles[323]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b, &output_handles[324]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w, &output_handles[325]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b, &output_handles[326]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias, &output_handles[327]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight, &output_handles[328]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias, &output_handles[329]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w, &output_handles[330]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b, &output_handles[331]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w, &output_handles[332]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b, &output_handles[333]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias, &output_handles[334]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w, &output_handles[335]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b, &output_handles[336]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias, &output_handles[337]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w, &output_handles[338]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b, &output_handles[339]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w, &output_handles[340]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b, &output_handles[341]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias, &output_handles[342]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight, &output_handles[343]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias, &output_handles[344]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w, &output_handles[345]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b, &output_handles[346]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias, &output_handles[347]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight, &output_handles[348]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias, &output_handles[349]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w, &output_handles[350]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b, &output_handles[351]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias, &output_handles[352]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w, &output_handles[353]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b, &output_handles[354]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias, &output_handles[355]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight, &output_handles[356]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias, &output_handles[357]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w, &output_handles[358]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b, &output_handles[359]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias, &output_handles[360]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w, &output_handles[361]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b, &output_handles[362]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight, &output_handles[363]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias, &output_handles[364]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight, &output_handles[365]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias, &output_handles[366]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias, &output_handles[367]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w, &output_handles[368]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b, &output_handles[369]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w, &output_handles[370]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b, &output_handles[371]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w, &output_handles[372]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b, &output_handles[373]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight, &output_handles[374]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias, &output_handles[375]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w, &output_handles[376]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b, &output_handles[377]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias, &output_handles[378]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight, &output_handles[379]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias, &output_handles[380]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w, &output_handles[381]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b, &output_handles[382]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight, &output_handles[383]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias, &output_handles[384]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w, &output_handles[385]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b, &output_handles[386]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias, &output_handles[387]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight, &output_handles[388]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias, &output_handles[389]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w, &output_handles[390]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b, &output_handles[391]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias, &output_handles[392]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, &output_handles[393]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, &output_handles[394]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias, &output_handles[395]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w, &output_handles[396]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b, &output_handles[397]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w, &output_handles[398]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b, &output_handles[399]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w, &output_handles[400]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b, &output_handles[401]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias, &output_handles[402]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight, &output_handles[403]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias, &output_handles[404]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w, &output_handles[405]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b, &output_handles[406]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w, &output_handles[407]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b, &output_handles[408]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias, &output_handles[409]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w, &output_handles[410]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b, &output_handles[411]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias, &output_handles[412]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w, &output_handles[413]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b, &output_handles[414]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w, &output_handles[415]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b, &output_handles[416]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias, &output_handles[417]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight, &output_handles[418]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias, &output_handles[419]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w, &output_handles[420]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b, &output_handles[421]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias, &output_handles[422]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight, &output_handles[423]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias, &output_handles[424]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w, &output_handles[425]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b, &output_handles[426]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias, &output_handles[427]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w, &output_handles[428]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b, &output_handles[429]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias, &output_handles[430]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight, &output_handles[431]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias, &output_handles[432]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w, &output_handles[433]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b, &output_handles[434]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias, &output_handles[435]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w, &output_handles[436]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b, &output_handles[437]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight, &output_handles[438]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias, &output_handles[439]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight, &output_handles[440]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias, &output_handles[441]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b, &output_handles[442]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b, &output_handles[443]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b, &output_handles[444]);
    aoti_torch_clone(submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b, &output_handles[445]);
    aoti_torch_clone(submod_0_main_module_impl_impl_dependent_tasks_1_SALR_STANDALONE_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias, &output_handles[446]);
    aoti_torch_clone(submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b, &output_handles[447]);
    aoti_torch_clone(submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b, &output_handles[448]);
    aoti_torch_clone(submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b, &output_handles[449]);
    aoti_torch_clone(submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale, &output_handles[450]);
    aoti_torch_clone(submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias, &output_handles[451]);
    aoti_torch_clone(_tensor_constant2, &output_handles[452]);
    aoti_torch_clone(submod_0_cat_fusion_gpu__offset_dim_list, &output_handles[453]);
    aoti_torch_clone(submod_0_cat_fusion_gpu__permute, &output_handles[454]);
    aoti_torch_clone(submod_0_cat_fusion_gpu__inv_permute, &output_handles[455]);
    aoti_torch_clone(submod_0_cat_fusion_gpu__inv_offset_dim_list, &output_handles[456]);
    aoti_torch_clone(submod_0_cat_fusion_cpu__offset_dim_list, &output_handles[457]);
    aoti_torch_clone(submod_0_cat_fusion_cpu__permute, &output_handles[458]);
    aoti_torch_clone(submod_0_cat_fusion_cpu__inv_permute, &output_handles[459]);
    aoti_torch_clone(submod_0_cat_fusion_cpu__inv_offset_dim_list, &output_handles[460]);
    aoti_torch_clone(submod_1__tensor_constant1, &output_handles[461]);
    aoti_torch_clone(submod_1_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_calibration_positive_weight_calibration_bias, &output_handles[462]);
    aoti_torch_clone(tmp_tensor_handle_0_raii, &output_handles[463]);
    aoti_torch_clone(tmp_tensor_handle_1_raii, &output_handles[464]);
    aoti_torch_clone(tmp_tensor_handle_2_raii, &output_handles[465]);
    aoti_torch_clone(tmp_tensor_handle_3_raii, &output_handles[466]);
    aoti_torch_clone(tmp_tensor_handle_4_raii, &output_handles[467]);
    aoti_torch_clone(tmp_tensor_handle_5_raii, &output_handles[468]);
    aoti_torch_clone(tmp_tensor_handle_6_raii, &output_handles[469]);
    aoti_torch_clone(tmp_tensor_handle_7_raii, &output_handles[470]);
    aoti_torch_clone(tmp_tensor_handle_8_raii, &output_handles[471]);
    aoti_torch_clone(tmp_tensor_handle_9_raii, &output_handles[472]);
    aoti_torch_clone(tmp_tensor_handle_10_raii, &output_handles[473]);
    aoti_torch_clone(tmp_tensor_handle_11_raii, &output_handles[474]);
    aoti_torch_clone(tmp_tensor_handle_12_raii, &output_handles[475]);
    aoti_torch_clone(tmp_tensor_handle_13_raii, &output_handles[476]);
    aoti_torch_clone(tmp_tensor_handle_14_raii, &output_handles[477]);
    aoti_torch_clone(tmp_tensor_handle_15_raii, &output_handles[478]);
    aoti_torch_clone(tmp_tensor_handle_16_raii, &output_handles[479]);
    aoti_torch_clone(tmp_tensor_handle_17_raii, &output_handles[480]);
    aoti_torch_clone(tmp_tensor_handle_18_raii, &output_handles[481]);
    aoti_torch_clone(tmp_tensor_handle_19_raii, &output_handles[482]);
    aoti_torch_clone(tmp_tensor_handle_20_raii, &output_handles[483]);
    aoti_torch_clone(tmp_tensor_handle_21_raii, &output_handles[484]);
    aoti_torch_clone(tmp_tensor_handle_22_raii, &output_handles[485]);
    aoti_torch_clone(tmp_tensor_handle_23_raii, &output_handles[486]);
    aoti_torch_clone(tmp_tensor_handle_24_raii, &output_handles[487]);
    aoti_torch_clone(tmp_tensor_handle_25_raii, &output_handles[488]);
    aoti_torch_clone(tmp_tensor_handle_26_raii, &output_handles[489]);
    aoti_torch_clone(tmp_tensor_handle_27_raii, &output_handles[490]);
    aoti_torch_clone(tmp_tensor_handle_28_raii, &output_handles[491]);
    aoti_torch_clone(tmp_tensor_handle_29_raii, &output_handles[492]);
    aoti_torch_clone(tmp_tensor_handle_30_raii, &output_handles[493]);
    aoti_torch_clone(tmp_tensor_handle_31_raii, &output_handles[494]);
    aoti_torch_clone(tmp_tensor_handle_32_raii, &output_handles[495]);
    aoti_torch_clone(tmp_tensor_handle_33_raii, &output_handles[496]);
    aoti_torch_clone(tmp_tensor_handle_34_raii, &output_handles[497]);
    aoti_torch_clone(tmp_tensor_handle_35_raii, &output_handles[498]);
    output_handles[499] = buf0.release();
    output_handles[500] = buf1.release();
    output_handles[501] = buf2.release();
    output_handles[502] = tmp_tensor_handle_36_raii.release();
    aoti_torch_clone(tmp_tensor_handle_37_raii, &output_handles[503]);
    aoti_torch_clone(tmp_tensor_handle_38_raii, &output_handles[504]);
    aoti_torch_clone(tmp_tensor_handle_39_raii, &output_handles[505]);
    aoti_torch_clone(tmp_tensor_handle_40_raii, &output_handles[506]);
    aoti_torch_clone(tmp_tensor_handle_41_raii, &output_handles[507]);
    aoti_torch_clone(tmp_tensor_handle_42_raii, &output_handles[508]);
    aoti_torch_clone(tmp_tensor_handle_43_raii, &output_handles[509]);
    aoti_torch_clone(tmp_tensor_handle_44_raii, &output_handles[510]);
    aoti_torch_clone(tmp_tensor_handle_45_raii, &output_handles[511]);
    output_handles[512] = buf4.release();
    output_handles[513] = buf6.release();
    aoti_torch_clone(tmp_tensor_handle_46_raii, &output_handles[514]);
    aoti_torch_clone(tmp_tensor_handle_47_raii, &output_handles[515]);
    aoti_torch_clone(tmp_tensor_handle_48_raii, &output_handles[516]);
    aoti_torch_clone(tmp_tensor_handle_49_raii, &output_handles[517]);
    output_handles[518] = buf7.release();
    output_handles[519] = tmp_tensor_handle_50_raii.release();
    aoti_torch_clone(tmp_tensor_handle_51_raii, &output_handles[520]);
    aoti_torch_clone(tmp_tensor_handle_52_raii, &output_handles[521]);
    aoti_torch_clone(tmp_tensor_handle_53_raii, &output_handles[522]);
    aoti_torch_clone(tmp_tensor_handle_54_raii, &output_handles[523]);
    aoti_torch_clone(tmp_tensor_handle_55_raii, &output_handles[524]);
    output_handles[525] = buf9.release();
    aoti_torch_clone(tmp_tensor_handle_56_raii, &output_handles[526]);
    output_handles[527] = buf10.release();
    aoti_torch_clone(tmp_tensor_handle_57_raii, &output_handles[528]);
    aoti_torch_clone(tmp_tensor_handle_58_raii, &output_handles[529]);
    aoti_torch_clone(tmp_tensor_handle_59_raii, &output_handles[530]);
    aoti_torch_clone(tmp_tensor_handle_60_raii, &output_handles[531]);
    aoti_torch_clone(tmp_tensor_handle_61_raii, &output_handles[532]);
    output_handles[533] = buf11.release();
    output_handles[534] = tmp_tensor_handle_62_raii.release();
    aoti_torch_clone(tmp_tensor_handle_63_raii, &output_handles[535]);
    aoti_torch_clone(tmp_tensor_handle_64_raii, &output_handles[536]);
    aoti_torch_clone(tmp_tensor_handle_65_raii, &output_handles[537]);
    aoti_torch_clone(tmp_tensor_handle_66_raii, &output_handles[538]);
    aoti_torch_clone(tmp_tensor_handle_67_raii, &output_handles[539]);
    output_handles[540] = buf13.release();
    aoti_torch_clone(tmp_tensor_handle_68_raii, &output_handles[541]);
    output_handles[542] = buf14.release();
    aoti_torch_clone(tmp_tensor_handle_69_raii, &output_handles[543]);
    aoti_torch_clone(tmp_tensor_handle_70_raii, &output_handles[544]);
    aoti_torch_clone(tmp_tensor_handle_71_raii, &output_handles[545]);
    aoti_torch_clone(tmp_tensor_handle_72_raii, &output_handles[546]);
    aoti_torch_clone(tmp_tensor_handle_73_raii, &output_handles[547]);
    output_handles[548] = buf15.release();
    output_handles[549] = tmp_tensor_handle_74_raii.release();
    aoti_torch_clone(tmp_tensor_handle_75_raii, &output_handles[550]);
    aoti_torch_clone(tmp_tensor_handle_76_raii, &output_handles[551]);
    aoti_torch_clone(tmp_tensor_handle_77_raii, &output_handles[552]);
    aoti_torch_clone(tmp_tensor_handle_78_raii, &output_handles[553]);
    aoti_torch_clone(tmp_tensor_handle_79_raii, &output_handles[554]);
    output_handles[555] = buf17.release();
    aoti_torch_clone(tmp_tensor_handle_80_raii, &output_handles[556]);
    output_handles[557] = buf18.release();
    aoti_torch_clone(tmp_tensor_handle_81_raii, &output_handles[558]);
    aoti_torch_clone(tmp_tensor_handle_82_raii, &output_handles[559]);
    aoti_torch_clone(tmp_tensor_handle_83_raii, &output_handles[560]);
    aoti_torch_clone(tmp_tensor_handle_84_raii, &output_handles[561]);
    aoti_torch_clone(tmp_tensor_handle_85_raii, &output_handles[562]);
    output_handles[563] = buf19.release();
    output_handles[564] = tmp_tensor_handle_86_raii.release();
    aoti_torch_clone(tmp_tensor_handle_87_raii, &output_handles[565]);
    aoti_torch_clone(tmp_tensor_handle_88_raii, &output_handles[566]);
    aoti_torch_clone(tmp_tensor_handle_89_raii, &output_handles[567]);
    aoti_torch_clone(tmp_tensor_handle_90_raii, &output_handles[568]);
    aoti_torch_clone(tmp_tensor_handle_91_raii, &output_handles[569]);
    output_handles[570] = buf21.release();
    aoti_torch_clone(tmp_tensor_handle_92_raii, &output_handles[571]);
    output_handles[572] = buf22.release();
    aoti_torch_clone(tmp_tensor_handle_93_raii, &output_handles[573]);
    aoti_torch_clone(tmp_tensor_handle_94_raii, &output_handles[574]);
    aoti_torch_clone(tmp_tensor_handle_95_raii, &output_handles[575]);
    aoti_torch_clone(tmp_tensor_handle_96_raii, &output_handles[576]);
    aoti_torch_clone(tmp_tensor_handle_97_raii, &output_handles[577]);
    aoti_torch_clone(tmp_tensor_handle_98_raii, &output_handles[578]);
    aoti_torch_clone(tmp_tensor_handle_99_raii, &output_handles[579]);
    aoti_torch_clone(tmp_tensor_handle_100_raii, &output_handles[580]);
    aoti_torch_clone(tmp_tensor_handle_101_raii, &output_handles[581]);
    aoti_torch_clone(tmp_tensor_handle_102_raii, &output_handles[582]);
    aoti_torch_clone(tmp_tensor_handle_103_raii, &output_handles[583]);
} // AOTInductorModel::_const_run_impl

void AOTInductorModel::run_impl(
    AtenTensorHandle*
        input_handles, // array of input AtenTensorHandle; handles
                        // are stolen; the array itself is borrowed
    AtenTensorHandle*
        output_handles, // array for writing output AtenTensorHandle; handles
                        // will be stolen by the caller; the array itself is
                        // borrowed
    DeviceStreamType stream,
    AOTIProxyExecutorHandle proxy_executor
) {

    auto inputs = steal_from_raw_handles_to_raii_handles(input_handles, 9);
    auto arg606_1 = std::move(inputs[0]);
    auto arg607_1 = std::move(inputs[1]);
    auto arg608_1 = std::move(inputs[2]);
    auto arg609_1 = std::move(inputs[3]);
    auto arg610_1 = std::move(inputs[4]);
    auto arg611_1 = std::move(inputs[5]);
    auto arg612_1 = std::move(inputs[6]);
    auto arg613_1 = std::move(inputs[7]);
    auto arg614_1 = std::move(inputs[8]);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(0);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(1);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_1_scale = constants_->at(2);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3_submodules_1_bias = constants_->at(3);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(4);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(5);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_1_scale = constants_->at(6);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2_submodules_1_bias = constants_->at(7);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(8);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(9);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_1_scale = constants_->at(10);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1_submodules_1_bias = constants_->at(11);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(12);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(13);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_1_scale = constants_->at(14);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0_submodules_1_bias = constants_->at(15);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(16);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(17);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(18);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(19);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(20);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(21);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(22);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(23);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(24);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(25);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(26);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(27);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(28);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(29);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(30);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(31);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(32);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(33);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_1_scale = constants_->at(34);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3_submodules_1_bias = constants_->at(35);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(36);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(37);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(38);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(39);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(40);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(41);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(42);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(43);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(44);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(45);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(46);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(47);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(48);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(49);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_1_scale = constants_->at(50);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3_submodules_1_bias = constants_->at(51);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(52);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(53);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(54);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(55);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(56);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(57);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(58);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(59);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(60);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(61);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(62);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(63);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(64);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(65);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(66);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(67);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(68);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(69);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(70);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(71);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(72);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(73);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(74);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(75);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(76);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(77);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(78);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(79);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(80);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(81);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(82);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(83);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(84);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(85);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(86);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(87);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(88);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(89);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_1_scale = constants_->at(90);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR_submodules_1_bias = constants_->at(91);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(92);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(93);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(94);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(95);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(96);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(97);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_1_scale = constants_->at(98);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2_submodules_1_bias = constants_->at(99);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(100);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(101);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(102);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(103);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(104);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(105);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(106);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(107);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(108);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(109);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(110);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(111);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(112);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(113);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(114);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(115);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(116);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(117);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_1_scale = constants_->at(118);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0_submodules_1_bias = constants_->at(119);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(120);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(121);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_1_scale = constants_->at(122);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1_submodules_1_bias = constants_->at(123);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(124);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(125);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(126);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(127);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(128);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(129);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(130);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(131);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(132);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(133);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(134);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(135);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(136);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(137);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_1_scale = constants_->at(138);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3_submodules_1_bias = constants_->at(139);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(140);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(141);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_1_scale = constants_->at(142);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3_submodules_1_bias = constants_->at(143);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(144);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(145);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_w = constants_->at(146);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_b = constants_->at(147);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = constants_->at(148);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = constants_->at(149);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w = constants_->at(150);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b = constants_->at(151);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w = constants_->at(152);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = constants_->at(153);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = constants_->at(154);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = constants_->at(155);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_w = constants_->at(156);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_b = constants_->at(157);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_w = constants_->at(158);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_b = constants_->at(159);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_w = constants_->at(160);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_b = constants_->at(161);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_w = constants_->at(162);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_b = constants_->at(163);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_w = constants_->at(164);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_b = constants_->at(165);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_w = constants_->at(166);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_b = constants_->at(167);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(168);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(169);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = constants_->at(170);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = constants_->at(171);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w = constants_->at(172);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b = constants_->at(173);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale = constants_->at(174);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias = constants_->at(175);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_w = constants_->at(176);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(177);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w = constants_->at(178);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b = constants_->at(179);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w = constants_->at(180);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b = constants_->at(181);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb = constants_->at(182);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb = constants_->at(183);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight = constants_->at(184);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias = constants_->at(185);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight = constants_->at(186);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight = constants_->at(187);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias = constants_->at(188);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight = constants_->at(189);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias = constants_->at(190);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight = constants_->at(191);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias = constants_->at(192);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_weight = constants_->at(193);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias = constants_->at(194);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_weight = constants_->at(195);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias = constants_->at(196);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb = constants_->at(197);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb = constants_->at(198);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight = constants_->at(199);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias = constants_->at(200);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight = constants_->at(201);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight = constants_->at(202);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias = constants_->at(203);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight = constants_->at(204);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias = constants_->at(205);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight = constants_->at(206);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias = constants_->at(207);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_weight = constants_->at(208);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias = constants_->at(209);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_weight = constants_->at(210);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias = constants_->at(211);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias = constants_->at(212);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight = constants_->at(213);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w = constants_->at(214);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b = constants_->at(215);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w = constants_->at(216);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b = constants_->at(217);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_weight = constants_->at(218);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_bias = constants_->at(219);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(220);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(221);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(222);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(223);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_weight = constants_->at(224);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(225);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(226);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(227);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(228);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(229);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_weight = constants_->at(230);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_bias = constants_->at(231);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(232);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(233);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(234);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(235);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_weight = constants_->at(236);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(237);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(238);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(239);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(240);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(241);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = constants_->at(242);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(243);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(244);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(245);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = constants_->at(246);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(247);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(248);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(249);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w = constants_->at(250);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b = constants_->at(251);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w = constants_->at(252);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b = constants_->at(253);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_weight = constants_->at(254);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(255);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(256);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(257);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(258);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(259);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w = constants_->at(260);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b = constants_->at(261);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = constants_->at(262);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(263);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(264);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(265);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_weight = constants_->at(266);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(267);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(268);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(269);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w = constants_->at(270);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b = constants_->at(271);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_weight = constants_->at(272);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(273);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(274);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(275);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(276);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(277);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_weight = constants_->at(278);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(279);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(280);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(281);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(282);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(283);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_weight = constants_->at(284);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(285);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(286);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(287);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_weight = constants_->at(288);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(289);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(290);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(291);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(292);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(293);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_weight = constants_->at(294);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(295);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(296);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(297);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(298);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(299);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(300);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(301);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_weight = constants_->at(302);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias = constants_->at(303);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w = constants_->at(304);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b = constants_->at(305);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w = constants_->at(306);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b = constants_->at(307);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w = constants_->at(308);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b = constants_->at(309);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_weight = constants_->at(310);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_bias = constants_->at(311);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(312);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(313);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(314);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(315);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_weight = constants_->at(316);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(317);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(318);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(319);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(320);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(321);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_weight = constants_->at(322);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_bias = constants_->at(323);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(324);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(325);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(326);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(327);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_weight = constants_->at(328);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(329);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(330);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(331);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(332);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(333);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = constants_->at(334);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(335);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(336);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(337);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = constants_->at(338);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(339);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(340);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(341);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w = constants_->at(342);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b = constants_->at(343);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w = constants_->at(344);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b = constants_->at(345);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_weight = constants_->at(346);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(347);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(348);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(349);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(350);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(351);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w = constants_->at(352);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b = constants_->at(353);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = constants_->at(354);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(355);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(356);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(357);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_weight = constants_->at(358);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(359);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(360);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(361);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w = constants_->at(362);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b = constants_->at(363);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_weight = constants_->at(364);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(365);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(366);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(367);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(368);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(369);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_weight = constants_->at(370);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(371);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(372);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(373);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(374);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(375);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_weight = constants_->at(376);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(377);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(378);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(379);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_weight = constants_->at(380);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(381);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(382);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(383);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(384);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(385);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_weight = constants_->at(386);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(387);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(388);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(389);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(390);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(391);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(392);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(393);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_weight = constants_->at(394);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias = constants_->at(395);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w = constants_->at(396);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b = constants_->at(397);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w = constants_->at(398);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b = constants_->at(399);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w = constants_->at(400);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b = constants_->at(401);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_weight = constants_->at(402);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_bias = constants_->at(403);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(404);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(405);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(406);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(407);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_weight = constants_->at(408);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(409);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(410);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(411);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(412);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(413);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_weight = constants_->at(414);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_bias = constants_->at(415);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(416);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(417);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(418);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(419);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_weight = constants_->at(420);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(421);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(422);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(423);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(424);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(425);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = constants_->at(426);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(427);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(428);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(429);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = constants_->at(430);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(431);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(432);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(433);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w = constants_->at(434);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b = constants_->at(435);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w = constants_->at(436);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b = constants_->at(437);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_weight = constants_->at(438);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(439);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(440);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(441);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(442);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(443);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w = constants_->at(444);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b = constants_->at(445);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = constants_->at(446);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(447);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(448);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(449);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_weight = constants_->at(450);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(451);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(452);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(453);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w = constants_->at(454);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b = constants_->at(455);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_weight = constants_->at(456);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(457);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(458);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(459);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(460);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(461);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_weight = constants_->at(462);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(463);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(464);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(465);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(466);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(467);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_weight = constants_->at(468);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(469);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(470);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(471);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_weight = constants_->at(472);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(473);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(474);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(475);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(476);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(477);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_weight = constants_->at(478);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(479);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(480);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(481);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(482);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(483);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(484);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(485);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_weight = constants_->at(486);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias = constants_->at(487);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w = constants_->at(488);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b = constants_->at(489);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w = constants_->at(490);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b = constants_->at(491);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w = constants_->at(492);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b = constants_->at(493);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_weight = constants_->at(494);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_bias = constants_->at(495);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(496);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(497);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(498);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(499);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_weight = constants_->at(500);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(501);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(502);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(503);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(504);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(505);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_weight = constants_->at(506);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_bias = constants_->at(507);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(508);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(509);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(510);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(511);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_weight = constants_->at(512);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(513);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(514);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(515);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(516);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(517);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = constants_->at(518);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(519);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(520);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(521);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = constants_->at(522);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(523);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(524);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(525);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w = constants_->at(526);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b = constants_->at(527);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w = constants_->at(528);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b = constants_->at(529);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_weight = constants_->at(530);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(531);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(532);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(533);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(534);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(535);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w = constants_->at(536);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b = constants_->at(537);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = constants_->at(538);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(539);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(540);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(541);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_weight = constants_->at(542);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(543);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(544);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(545);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w = constants_->at(546);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b = constants_->at(547);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_weight = constants_->at(548);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(549);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(550);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(551);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(552);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(553);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_weight = constants_->at(554);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(555);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(556);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(557);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(558);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(559);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_weight = constants_->at(560);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(561);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(562);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(563);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_weight = constants_->at(564);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(565);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(566);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(567);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(568);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(569);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_weight = constants_->at(570);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(571);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(572);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(573);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(574);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(575);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(576);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(577);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w = constants_->at(578);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b = constants_->at(579);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w = constants_->at(580);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b = constants_->at(581);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w = constants_->at(582);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b = constants_->at(583);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w = constants_->at(584);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b = constants_->at(585);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_dependent_tasks_1_SALR_STANDALONE_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias = constants_->at(586);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w = constants_->at(587);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b = constants_->at(588);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w = constants_->at(589);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = constants_->at(590);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w = constants_->at(591);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b = constants_->at(592);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = constants_->at(593);
    [[maybe_unused]] auto submod_0_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = constants_->at(594);
    [[maybe_unused]] auto _tensor_constant2 = constants_->at(595);
    [[maybe_unused]] auto submod_0_cat_fusion_gpu__offset_dim_list = constants_->at(596);
    [[maybe_unused]] auto submod_0_cat_fusion_gpu__permute = constants_->at(597);
    [[maybe_unused]] auto submod_0_cat_fusion_gpu__inv_permute = constants_->at(598);
    [[maybe_unused]] auto submod_0_cat_fusion_gpu__inv_offset_dim_list = constants_->at(599);
    [[maybe_unused]] auto submod_0_cat_fusion_cpu__offset_dim_list = constants_->at(600);
    [[maybe_unused]] auto submod_0_cat_fusion_cpu__permute = constants_->at(601);
    [[maybe_unused]] auto submod_0_cat_fusion_cpu__inv_permute = constants_->at(602);
    [[maybe_unused]] auto submod_0_cat_fusion_cpu__inv_offset_dim_list = constants_->at(603);
    [[maybe_unused]] auto submod_1__tensor_constant1 = constants_->at(604);
    [[maybe_unused]] auto submod_1_main_module_impl_impl_task_archs_1_Optimized_prediction_arch_calibration_positive_weight_calibration_bias = constants_->at(605);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(606);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale = constants_->at(607);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias = constants_->at(608);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(609);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale = constants_->at(610);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias = constants_->at(611);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(612);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale = constants_->at(613);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias = constants_->at(614);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(615);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale = constants_->at(616);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias = constants_->at(617);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(618);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale = constants_->at(619);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias = constants_->at(620);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(621);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale = constants_->at(622);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias = constants_->at(623);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(624);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale = constants_->at(625);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias = constants_->at(626);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(627);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale = constants_->at(628);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias = constants_->at(629);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(630);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale = constants_->at(631);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias = constants_->at(632);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(633);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale = constants_->at(634);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias = constants_->at(635);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(636);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale = constants_->at(637);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias = constants_->at(638);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(639);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale = constants_->at(640);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias = constants_->at(641);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(642);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale = constants_->at(643);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias = constants_->at(644);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(645);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale = constants_->at(646);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias = constants_->at(647);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(648);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale = constants_->at(649);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias = constants_->at(650);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(651);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale = constants_->at(652);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias = constants_->at(653);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(654);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale = constants_->at(655);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias = constants_->at(656);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(657);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale = constants_->at(658);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias = constants_->at(659);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(660);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale = constants_->at(661);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias = constants_->at(662);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(663);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale = constants_->at(664);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias = constants_->at(665);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(666);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale = constants_->at(667);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias = constants_->at(668);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(669);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale = constants_->at(670);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias = constants_->at(671);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(672);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale = constants_->at(673);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias = constants_->at(674);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(675);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale = constants_->at(676);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias = constants_->at(677);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(678);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale = constants_->at(679);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias = constants_->at(680);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(681);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale = constants_->at(682);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias = constants_->at(683);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(684);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale = constants_->at(685);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias = constants_->at(686);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(687);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale = constants_->at(688);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias = constants_->at(689);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(690);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale = constants_->at(691);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias = constants_->at(692);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(693);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale = constants_->at(694);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias = constants_->at(695);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(696);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale = constants_->at(697);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias = constants_->at(698);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(699);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale = constants_->at(700);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias = constants_->at(701);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(702);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale = constants_->at(703);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias = constants_->at(704);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(705);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale = constants_->at(706);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias = constants_->at(707);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(708);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale = constants_->at(709);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias = constants_->at(710);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = constants_->at(711);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale = constants_->at(712);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias = constants_->at(713);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = constants_->at(714);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = constants_->at(715);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b = constants_->at(716);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = constants_->at(717);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = constants_->at(718);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = constants_->at(719);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = constants_->at(720);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = constants_->at(721);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b = constants_->at(722);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale = constants_->at(723);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias = constants_->at(724);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b = constants_->at(725);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b = constants_->at(726);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb = constants_->at(727);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb = constants_->at(728);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight = constants_->at(729);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias = constants_->at(730);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias = constants_->at(731);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight = constants_->at(732);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias = constants_->at(733);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight = constants_->at(734);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias = constants_->at(735);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias = constants_->at(736);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias = constants_->at(737);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb = constants_->at(738);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb = constants_->at(739);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight = constants_->at(740);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias = constants_->at(741);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias = constants_->at(742);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight = constants_->at(743);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias = constants_->at(744);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight = constants_->at(745);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias = constants_->at(746);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias = constants_->at(747);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias = constants_->at(748);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias = constants_->at(749);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight = constants_->at(750);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w = constants_->at(751);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b = constants_->at(752);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w = constants_->at(753);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b = constants_->at(754);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(755);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(756);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(757);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(758);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(759);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(760);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(761);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(762);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(763);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(764);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(765);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(766);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(767);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(768);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(769);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(770);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(771);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(772);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(773);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(774);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(775);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(776);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(777);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(778);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w = constants_->at(779);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b = constants_->at(780);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w = constants_->at(781);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b = constants_->at(782);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(783);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(784);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(785);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(786);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(787);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w = constants_->at(788);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b = constants_->at(789);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(790);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(791);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(792);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(793);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(794);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(795);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w = constants_->at(796);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b = constants_->at(797);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(798);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(799);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(800);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(801);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(802);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(803);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(804);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(805);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(806);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(807);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(808);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(809);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(810);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(811);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(812);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(813);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(814);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(815);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(816);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(817);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(818);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(819);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(820);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(821);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(822);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias = constants_->at(823);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w = constants_->at(824);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b = constants_->at(825);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w = constants_->at(826);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b = constants_->at(827);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w = constants_->at(828);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b = constants_->at(829);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(830);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(831);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(832);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(833);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(834);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(835);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(836);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(837);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(838);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(839);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(840);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(841);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(842);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(843);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(844);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(845);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(846);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(847);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(848);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(849);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(850);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(851);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(852);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(853);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w = constants_->at(854);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b = constants_->at(855);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w = constants_->at(856);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b = constants_->at(857);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(858);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(859);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(860);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(861);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(862);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w = constants_->at(863);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b = constants_->at(864);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(865);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(866);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(867);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(868);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(869);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(870);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w = constants_->at(871);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b = constants_->at(872);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(873);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(874);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(875);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(876);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(877);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(878);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(879);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(880);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(881);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(882);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(883);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(884);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(885);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(886);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(887);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(888);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(889);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(890);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(891);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(892);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(893);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(894);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(895);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(896);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(897);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias = constants_->at(898);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w = constants_->at(899);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b = constants_->at(900);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w = constants_->at(901);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b = constants_->at(902);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w = constants_->at(903);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b = constants_->at(904);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(905);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(906);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(907);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(908);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(909);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(910);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(911);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(912);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(913);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(914);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(915);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(916);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(917);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(918);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(919);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(920);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(921);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(922);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(923);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(924);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(925);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(926);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(927);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(928);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w = constants_->at(929);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b = constants_->at(930);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w = constants_->at(931);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b = constants_->at(932);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(933);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(934);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(935);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(936);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(937);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w = constants_->at(938);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b = constants_->at(939);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(940);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(941);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(942);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(943);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(944);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(945);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w = constants_->at(946);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b = constants_->at(947);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(948);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(949);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(950);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(951);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(952);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(953);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(954);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(955);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(956);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(957);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(958);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(959);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(960);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(961);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(962);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(963);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(964);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(965);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(966);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(967);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(968);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(969);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(970);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(971);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(972);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias = constants_->at(973);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w = constants_->at(974);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b = constants_->at(975);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w = constants_->at(976);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b = constants_->at(977);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w = constants_->at(978);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b = constants_->at(979);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(980);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(981);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w = constants_->at(982);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b = constants_->at(983);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias = constants_->at(984);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(985);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(986);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w = constants_->at(987);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b = constants_->at(988);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = constants_->at(989);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = constants_->at(990);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w = constants_->at(991);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b = constants_->at(992);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias = constants_->at(993);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = constants_->at(994);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = constants_->at(995);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w = constants_->at(996);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b = constants_->at(997);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = constants_->at(998);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(999);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(1000);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = constants_->at(1001);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = constants_->at(1002);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = constants_->at(1003);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w = constants_->at(1004);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b = constants_->at(1005);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w = constants_->at(1006);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b = constants_->at(1007);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias = constants_->at(1008);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = constants_->at(1009);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = constants_->at(1010);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w = constants_->at(1011);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b = constants_->at(1012);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w = constants_->at(1013);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b = constants_->at(1014);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = constants_->at(1015);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = constants_->at(1016);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = constants_->at(1017);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias = constants_->at(1018);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w = constants_->at(1019);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b = constants_->at(1020);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w = constants_->at(1021);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b = constants_->at(1022);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias = constants_->at(1023);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = constants_->at(1024);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = constants_->at(1025);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w = constants_->at(1026);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b = constants_->at(1027);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias = constants_->at(1028);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = constants_->at(1029);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = constants_->at(1030);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w = constants_->at(1031);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b = constants_->at(1032);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias = constants_->at(1033);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w = constants_->at(1034);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b = constants_->at(1035);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias = constants_->at(1036);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = constants_->at(1037);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = constants_->at(1038);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w = constants_->at(1039);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b = constants_->at(1040);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias = constants_->at(1041);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w = constants_->at(1042);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b = constants_->at(1043);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight = constants_->at(1044);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias = constants_->at(1045);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight = constants_->at(1046);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias = constants_->at(1047);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b = constants_->at(1048);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b = constants_->at(1049);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b = constants_->at(1050);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b = constants_->at(1051);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias = constants_->at(1052);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b = constants_->at(1053);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = constants_->at(1054);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b = constants_->at(1055);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = constants_->at(1056);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = constants_->at(1057);
    [[maybe_unused]] auto _FOLDED_CONST__tensor_constant2 = constants_->at(1058);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_cat_fusion_gpu__offset_dim_list = constants_->at(1059);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_cat_fusion_gpu__permute = constants_->at(1060);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_cat_fusion_gpu__inv_permute = constants_->at(1061);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_cat_fusion_gpu__inv_offset_dim_list = constants_->at(1062);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_cat_fusion_cpu__offset_dim_list = constants_->at(1063);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_cat_fusion_cpu__permute = constants_->at(1064);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_cat_fusion_cpu__inv_permute = constants_->at(1065);
    [[maybe_unused]] auto _FOLDED_CONST_submod_0_cat_fusion_cpu__inv_offset_dim_list = constants_->at(1066);
    [[maybe_unused]] auto _FOLDED_CONST_submod_1__tensor_constant1 = constants_->at(1067);
    [[maybe_unused]] auto _FOLDED_CONST_submod_1_main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_positive_weight_calibration_bias = constants_->at(1068);
    [[maybe_unused]] auto _FOLDED_CONST_permute = constants_->at(1069);
    [[maybe_unused]] auto _FOLDED_CONST_permute_1 = constants_->at(1070);
    [[maybe_unused]] auto _FOLDED_CONST_permute_2 = constants_->at(1071);
    [[maybe_unused]] auto _FOLDED_CONST_permute_3 = constants_->at(1072);
    [[maybe_unused]] auto _FOLDED_CONST_permute_4 = constants_->at(1073);
    [[maybe_unused]] auto _FOLDED_CONST_permute_5 = constants_->at(1074);
    [[maybe_unused]] auto _FOLDED_CONST_permute_6 = constants_->at(1075);
    [[maybe_unused]] auto _FOLDED_CONST_permute_7 = constants_->at(1076);
    [[maybe_unused]] auto _FOLDED_CONST_permute_8 = constants_->at(1077);
    [[maybe_unused]] auto _FOLDED_CONST_permute_9 = constants_->at(1078);
    [[maybe_unused]] auto _FOLDED_CONST_permute_10 = constants_->at(1079);
    [[maybe_unused]] auto _FOLDED_CONST_permute_11 = constants_->at(1080);
    [[maybe_unused]] auto _FOLDED_CONST_permute_12 = constants_->at(1081);
    [[maybe_unused]] auto _FOLDED_CONST_permute_13 = constants_->at(1082);
    [[maybe_unused]] auto _FOLDED_CONST_permute_14 = constants_->at(1083);
    [[maybe_unused]] auto _FOLDED_CONST_permute_15 = constants_->at(1084);
    [[maybe_unused]] auto _FOLDED_CONST_permute_16 = constants_->at(1085);
    [[maybe_unused]] auto _FOLDED_CONST_permute_17 = constants_->at(1086);
    [[maybe_unused]] auto _FOLDED_CONST_permute_18 = constants_->at(1087);
    [[maybe_unused]] auto _FOLDED_CONST_permute_19 = constants_->at(1088);
    [[maybe_unused]] auto _FOLDED_CONST_permute_20 = constants_->at(1089);
    [[maybe_unused]] auto _FOLDED_CONST_permute_21 = constants_->at(1090);
    [[maybe_unused]] auto _FOLDED_CONST_permute_22 = constants_->at(1091);
    [[maybe_unused]] auto _FOLDED_CONST_permute_23 = constants_->at(1092);
    [[maybe_unused]] auto _FOLDED_CONST_permute_24 = constants_->at(1093);
    [[maybe_unused]] auto _FOLDED_CONST_permute_25 = constants_->at(1094);
    [[maybe_unused]] auto _FOLDED_CONST_permute_26 = constants_->at(1095);
    [[maybe_unused]] auto _FOLDED_CONST_permute_27 = constants_->at(1096);
    [[maybe_unused]] auto _FOLDED_CONST_permute_28 = constants_->at(1097);
    [[maybe_unused]] auto _FOLDED_CONST_permute_29 = constants_->at(1098);
    [[maybe_unused]] auto _FOLDED_CONST_permute_30 = constants_->at(1099);
    [[maybe_unused]] auto _FOLDED_CONST_permute_31 = constants_->at(1100);
    [[maybe_unused]] auto _FOLDED_CONST_permute_32 = constants_->at(1101);
    [[maybe_unused]] auto _FOLDED_CONST_permute_33 = constants_->at(1102);
    [[maybe_unused]] auto _FOLDED_CONST_permute_34 = constants_->at(1103);
    [[maybe_unused]] auto _FOLDED_CONST_permute_35 = constants_->at(1104);
    [[maybe_unused]] auto _FOLDED_CONST_cat_3 = constants_->at(1105);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_23 = constants_->at(1106);
    [[maybe_unused]] auto _FOLDED_CONST_cat_6 = constants_->at(1107);
    [[maybe_unused]] auto _FOLDED_CONST_permute_37 = constants_->at(1108);
    [[maybe_unused]] auto _FOLDED_CONST_permute_40 = constants_->at(1109);
    [[maybe_unused]] auto _FOLDED_CONST_permute_41 = constants_->at(1110);
    [[maybe_unused]] auto _FOLDED_CONST_permute_44 = constants_->at(1111);
    [[maybe_unused]] auto _FOLDED_CONST_permute_45 = constants_->at(1112);
    [[maybe_unused]] auto _FOLDED_CONST_permute_42 = constants_->at(1113);
    [[maybe_unused]] auto _FOLDED_CONST_permute_46 = constants_->at(1114);
    [[maybe_unused]] auto _FOLDED_CONST_permute_43 = constants_->at(1115);
    [[maybe_unused]] auto _FOLDED_CONST_permute_57 = constants_->at(1116);
    [[maybe_unused]] auto _FOLDED_CONST_permute_59 = constants_->at(1117);
    [[maybe_unused]] auto _FOLDED_CONST_cat_9 = constants_->at(1118);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_21 = constants_->at(1119);
    [[maybe_unused]] auto _FOLDED_CONST_permute_38 = constants_->at(1120);
    [[maybe_unused]] auto _FOLDED_CONST_permute_39 = constants_->at(1121);
    [[maybe_unused]] auto _FOLDED_CONST_permute_56 = constants_->at(1122);
    [[maybe_unused]] auto _FOLDED_CONST_permute_58 = constants_->at(1123);
    [[maybe_unused]] auto _FOLDED_CONST_cat_13 = constants_->at(1124);
    [[maybe_unused]] auto _FOLDED_CONST_permute_63 = constants_->at(1125);
    [[maybe_unused]] auto _FOLDED_CONST_permute_64 = constants_->at(1126);
    [[maybe_unused]] auto _FOLDED_CONST_permute_65 = constants_->at(1127);
    [[maybe_unused]] auto _FOLDED_CONST_permute_66 = constants_->at(1128);
    [[maybe_unused]] auto _FOLDED_CONST_permute_67 = constants_->at(1129);
    [[maybe_unused]] auto _FOLDED_CONST_permute_68 = constants_->at(1130);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_19 = constants_->at(1131);
    [[maybe_unused]] auto _FOLDED_CONST_permute_70 = constants_->at(1132);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_17 = constants_->at(1133);
    [[maybe_unused]] auto _FOLDED_CONST_permute_72 = constants_->at(1134);
    [[maybe_unused]] auto _FOLDED_CONST_permute_73 = constants_->at(1135);
    [[maybe_unused]] auto _FOLDED_CONST_permute_74 = constants_->at(1136);
    [[maybe_unused]] auto _FOLDED_CONST_permute_75 = constants_->at(1137);
    [[maybe_unused]] auto _FOLDED_CONST_permute_76 = constants_->at(1138);
    [[maybe_unused]] auto _FOLDED_CONST_cat_17 = constants_->at(1139);
    [[maybe_unused]] auto _FOLDED_CONST_permute_78 = constants_->at(1140);
    [[maybe_unused]] auto _FOLDED_CONST_permute_79 = constants_->at(1141);
    [[maybe_unused]] auto _FOLDED_CONST_permute_80 = constants_->at(1142);
    [[maybe_unused]] auto _FOLDED_CONST_permute_81 = constants_->at(1143);
    [[maybe_unused]] auto _FOLDED_CONST_permute_82 = constants_->at(1144);
    [[maybe_unused]] auto _FOLDED_CONST_permute_83 = constants_->at(1145);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_13 = constants_->at(1146);
    [[maybe_unused]] auto _FOLDED_CONST_permute_85 = constants_->at(1147);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_11 = constants_->at(1148);
    [[maybe_unused]] auto _FOLDED_CONST_permute_87 = constants_->at(1149);
    [[maybe_unused]] auto _FOLDED_CONST_permute_88 = constants_->at(1150);
    [[maybe_unused]] auto _FOLDED_CONST_permute_89 = constants_->at(1151);
    [[maybe_unused]] auto _FOLDED_CONST_permute_90 = constants_->at(1152);
    [[maybe_unused]] auto _FOLDED_CONST_permute_91 = constants_->at(1153);
    [[maybe_unused]] auto _FOLDED_CONST_cat_21 = constants_->at(1154);
    [[maybe_unused]] auto _FOLDED_CONST_permute_93 = constants_->at(1155);
    [[maybe_unused]] auto _FOLDED_CONST_permute_94 = constants_->at(1156);
    [[maybe_unused]] auto _FOLDED_CONST_permute_95 = constants_->at(1157);
    [[maybe_unused]] auto _FOLDED_CONST_permute_96 = constants_->at(1158);
    [[maybe_unused]] auto _FOLDED_CONST_permute_97 = constants_->at(1159);
    [[maybe_unused]] auto _FOLDED_CONST_permute_98 = constants_->at(1160);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_7 = constants_->at(1161);
    [[maybe_unused]] auto _FOLDED_CONST_permute_100 = constants_->at(1162);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_5 = constants_->at(1163);
    [[maybe_unused]] auto _FOLDED_CONST_permute_102 = constants_->at(1164);
    [[maybe_unused]] auto _FOLDED_CONST_permute_103 = constants_->at(1165);
    [[maybe_unused]] auto _FOLDED_CONST_permute_104 = constants_->at(1166);
    [[maybe_unused]] auto _FOLDED_CONST_permute_105 = constants_->at(1167);
    [[maybe_unused]] auto _FOLDED_CONST_permute_106 = constants_->at(1168);
    [[maybe_unused]] auto _FOLDED_CONST_cat_25 = constants_->at(1169);
    [[maybe_unused]] auto _FOLDED_CONST_permute_108 = constants_->at(1170);
    [[maybe_unused]] auto _FOLDED_CONST_permute_109 = constants_->at(1171);
    [[maybe_unused]] auto _FOLDED_CONST_permute_110 = constants_->at(1172);
    [[maybe_unused]] auto _FOLDED_CONST_permute_111 = constants_->at(1173);
    [[maybe_unused]] auto _FOLDED_CONST_permute_112 = constants_->at(1174);
    [[maybe_unused]] auto _FOLDED_CONST_permute_113 = constants_->at(1175);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_3 = constants_->at(1176);
    [[maybe_unused]] auto _FOLDED_CONST_permute_115 = constants_->at(1177);
    [[maybe_unused]] auto _FOLDED_CONST_constant_pad_nd_default_1 = constants_->at(1178);
    [[maybe_unused]] auto _FOLDED_CONST_permute_117 = constants_->at(1179);
    [[maybe_unused]] auto _FOLDED_CONST_permute_118 = constants_->at(1180);
    [[maybe_unused]] auto _FOLDED_CONST_permute_119 = constants_->at(1181);
    [[maybe_unused]] auto _FOLDED_CONST_permute_120 = constants_->at(1182);
    [[maybe_unused]] auto _FOLDED_CONST_permute_121 = constants_->at(1183);
    [[maybe_unused]] auto _FOLDED_CONST_permute_122 = constants_->at(1184);
    [[maybe_unused]] auto _FOLDED_CONST_permute_123 = constants_->at(1185);
    [[maybe_unused]] auto _FOLDED_CONST_permute_124 = constants_->at(1186);
    [[maybe_unused]] auto _FOLDED_CONST_permute_125 = constants_->at(1187);
    [[maybe_unused]] auto _FOLDED_CONST_permute_126 = constants_->at(1188);
    [[maybe_unused]] auto _FOLDED_CONST_permute_127 = constants_->at(1189);
    int64_t* arg606_1_size = arg606_1.sizes();
    int64_t s0 = arg606_1_size[0];
    inputs.clear();
    auto& kernels = static_cast<AOTInductorModelKernels&>(*this->kernels_.get());

    AOTICudaStreamGuard stream_guard(stream, this->device_idx_);
    const int64_t int_array_34[] = {s0, 36284L};
    static constexpr int64_t int_array_35[] = {36284L, 1L};
    AtenTensorHandle buf0_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_34, int_array_35, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf0_handle));
    RAIIAtenTensorHandle buf0(buf0_handle);
    // Topologically Sorted Source Nodes: [cat_default_12, permute_pooled_embs_auto_grad], Original ATen: [aten.cat, fbgemm.permute_pooled_embs_auto_grad]
    int64_t triton_poi_fused_cat_permute_pooled_embs_auto_grad_11_xnumel = 36284L*s0;
    if (kernels.triton_poi_fused_cat_permute_pooled_embs_auto_grad_11 == nullptr) {
        kernels.triton_poi_fused_cat_permute_pooled_embs_auto_grad_11 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c2bskoewa3qcqitxvglesiytinx5dxjiolu72htqvfz7i26hx5fx.cubin", "triton_poi_fused_cat_permute_pooled_embs_auto_grad_11", 0, this->cubin_dir_);
    }
    CUdeviceptr var_0 = reinterpret_cast<CUdeviceptr>(arg608_1.data_ptr());
    CUdeviceptr var_1 = reinterpret_cast<CUdeviceptr>(arg609_1.data_ptr());
    CUdeviceptr var_2 = reinterpret_cast<CUdeviceptr>(arg610_1.data_ptr());
    CUdeviceptr var_3 = reinterpret_cast<CUdeviceptr>(arg611_1.data_ptr());
    CUdeviceptr var_4 = reinterpret_cast<CUdeviceptr>(buf0.data_ptr());
    int32_t var_5 = triton_poi_fused_cat_permute_pooled_embs_auto_grad_11_xnumel;
    void* kernel_args_var_0[] = {&var_0, &var_1, &var_2, &var_3, &var_4, &var_5};
    Grid triton_poi_fused_cat_permute_pooled_embs_auto_grad_11_grid_0 = Grid((-1L)*static_cast<int64_t>(std::floor((-9071.0/256.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_permute_pooled_embs_auto_grad_11_grid_0.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_permute_pooled_embs_auto_grad_11, triton_poi_fused_cat_permute_pooled_embs_auto_grad_11_grid_0.grid_x, triton_poi_fused_cat_permute_pooled_embs_auto_grad_11_grid_0.grid_y, triton_poi_fused_cat_permute_pooled_embs_auto_grad_11_grid_0.grid_z, 4, 0, kernel_args_var_0, stream);
    }
    arg608_1.reset();
    arg609_1.reset();
    arg610_1.reset();
    arg611_1.reset();
    // Topologically Sorted Source Nodes: [cat_default_12, permute_pooled_embs_auto_grad], Original ATen: [aten.cat, fbgemm.permute_pooled_embs_auto_grad]
    AtenTensorHandle buf2_handle;  // output buffer
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_new_uninitialized_tensor(&buf2_handle));
    RAIIAtenTensorHandle buf2(buf2_handle);
    aoti_torch_proxy_executor_call_function(proxy_executor, 0, 0, std::vector<int64_t>{}.data(), 6, std::vector<AtenTensorHandle>{buf0, _FOLDED_CONST_submod_0_cat_fusion_gpu__offset_dim_list, _FOLDED_CONST_submod_0_cat_fusion_gpu__permute, _FOLDED_CONST_submod_0_cat_fusion_gpu__inv_offset_dim_list, _FOLDED_CONST_submod_0_cat_fusion_gpu__inv_permute, buf2}.data());
    buf0.reset();

    // Topologically Sorted Source Nodes: [permute_pooled_embs_auto_grad_1], Original ATen: [fbgemm.permute_pooled_embs_auto_grad]
    AtenTensorHandle buf4_handle;  // output buffer
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_new_uninitialized_tensor(&buf4_handle));
    RAIIAtenTensorHandle buf4(buf4_handle);
    aoti_torch_proxy_executor_call_function(proxy_executor, 1, 0, std::vector<int64_t>{}.data(), 6, std::vector<AtenTensorHandle>{arg612_1, _FOLDED_CONST_submod_0_cat_fusion_cpu__offset_dim_list, _FOLDED_CONST_submod_0_cat_fusion_cpu__permute, _FOLDED_CONST_submod_0_cat_fusion_cpu__inv_offset_dim_list, _FOLDED_CONST_submod_0_cat_fusion_cpu__inv_permute, buf4}.data());
    arg612_1.reset();

    const int64_t int_array_36[] = {s0, 192L};
    static constexpr int64_t int_array_37[] = {192L, 1L};
    AtenTensorHandle buf5_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_36, int_array_37, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf5_handle));
    RAIIAtenTensorHandle buf5(buf5_handle);
    // Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_12 == nullptr) {
        kernels.triton_tem_fused_addmm_12 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c547khxhgdkpnna5jhm3dkru5b6yjshojvu53dctlpj3lsofcdlc.cubin", "triton_tem_fused_addmm_12", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_6 = reinterpret_cast<CUdeviceptr>(arg606_1.data_ptr());
    CUdeviceptr var_7 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute.data_ptr());
    CUdeviceptr var_8 = reinterpret_cast<CUdeviceptr>(buf5.data_ptr());
    int32_t var_9 = s0;
    void* kernel_args_var_1[] = {&var_6, &var_7, &var_8, &var_9};
    Grid triton_tem_fused_addmm_12_grid_1 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_12_grid_1.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_12, triton_tem_fused_addmm_12_grid_1.grid_x, triton_tem_fused_addmm_12_grid_1.grid_y, triton_tem_fused_addmm_12_grid_1.grid_z, 8, 49152, kernel_args_var_1, stream);
    }
    const int64_t int_array_38[] = {s0, 87936L};
    static constexpr int64_t int_array_39[] = {87936L, 1L};
    AtenTensorHandle buf388_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_38, int_array_39, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf388_handle));
    RAIIAtenTensorHandle buf388(buf388_handle);
    const int64_t int_array_0[] = {s0, 192L};
    static constexpr int64_t int_array_1[] = {87936L, 1L};
    auto tmp_tensor_handle_0 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 69120L);
    RAIIAtenTensorHandle tmp_tensor_handle_0_raii(tmp_tensor_handle_0);
    decltype(auto) buf353 = std::move(tmp_tensor_handle_0_raii);  // alias
    // Topologically Sorted Source Nodes: [linear, layer_norm], Original ATen: [aten.addmm, aten.native_layer_norm]
    if (kernels.triton_per_fused_addmm_native_layer_norm_13 == nullptr) {
        kernels.triton_per_fused_addmm_native_layer_norm_13 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ceetflbbs4ly4lzn5pmvzffpbge3rrbww6w4v7tdeda653vdtnoi.cubin", "triton_per_fused_addmm_native_layer_norm_13", 8, this->cubin_dir_);
    }
    CUdeviceptr var_10 = reinterpret_cast<CUdeviceptr>(buf5.data_ptr());
    CUdeviceptr var_11 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_12 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_13 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_14 = reinterpret_cast<CUdeviceptr>(buf353.data_ptr());
    int32_t var_15 = s0;
    int var_16 = 192L;
    void* kernel_args_var_2[] = {&var_10, &var_11, &var_12, &var_13, &var_14, &var_15, &var_16};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_2 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_2.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_2.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_2.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_2.grid_z, 2, 8, kernel_args_var_2, stream);
    }
    auto buf9 = std::move(buf5);  // reuse
    // Topologically Sorted Source Nodes: [linear_1], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_14 == nullptr) {
        kernels.triton_tem_fused_addmm_14 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cesparzrjb7velt6ube6yjrqj4zrq4hcenb42omjduq5zacc6cel.cubin", "triton_tem_fused_addmm_14", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_17 = reinterpret_cast<CUdeviceptr>(arg606_1.data_ptr());
    CUdeviceptr var_18 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_1.data_ptr());
    CUdeviceptr var_19 = reinterpret_cast<CUdeviceptr>(buf9.data_ptr());
    int32_t var_20 = s0;
    void* kernel_args_var_3[] = {&var_17, &var_18, &var_19, &var_20};
    Grid triton_tem_fused_addmm_14_grid_3 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_14_grid_3.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_14, triton_tem_fused_addmm_14_grid_3.grid_x, triton_tem_fused_addmm_14_grid_3.grid_y, triton_tem_fused_addmm_14_grid_3.grid_z, 8, 49152, kernel_args_var_3, stream);
    }
    auto tmp_tensor_handle_1 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 69888L);
    RAIIAtenTensorHandle tmp_tensor_handle_1_raii(tmp_tensor_handle_1);
    decltype(auto) buf357 = std::move(tmp_tensor_handle_1_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_1, layer_norm_1], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_21 = reinterpret_cast<CUdeviceptr>(buf9.data_ptr());
    CUdeviceptr var_22 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_23 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale.data_ptr());
    CUdeviceptr var_24 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias.data_ptr());
    CUdeviceptr var_25 = reinterpret_cast<CUdeviceptr>(buf357.data_ptr());
    int32_t var_26 = s0;
    int var_27 = 192L;
    void* kernel_args_var_4[] = {&var_21, &var_22, &var_23, &var_24, &var_25, &var_26, &var_27};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_4 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_4.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_4.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_4.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_4.grid_z, 2, 8, kernel_args_var_4, stream);
    }
    auto buf13 = std::move(buf9);  // reuse
    // Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_15 == nullptr) {
        kernels.triton_tem_fused_addmm_15 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cahmekazgmvnae2eajtqaibxl6lsxfupshcpgsqmu6eawaxlssss.cubin", "triton_tem_fused_addmm_15", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_28 = reinterpret_cast<CUdeviceptr>(arg606_1.data_ptr());
    CUdeviceptr var_29 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_2.data_ptr());
    CUdeviceptr var_30 = reinterpret_cast<CUdeviceptr>(buf13.data_ptr());
    int32_t var_31 = s0;
    void* kernel_args_var_5[] = {&var_28, &var_29, &var_30, &var_31};
    Grid triton_tem_fused_addmm_15_grid_5 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_15_grid_5.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_15, triton_tem_fused_addmm_15_grid_5.grid_x, triton_tem_fused_addmm_15_grid_5.grid_y, triton_tem_fused_addmm_15_grid_5.grid_z, 8, 49152, kernel_args_var_5, stream);
    }
    auto tmp_tensor_handle_2 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 70656L);
    RAIIAtenTensorHandle tmp_tensor_handle_2_raii(tmp_tensor_handle_2);
    decltype(auto) buf361 = std::move(tmp_tensor_handle_2_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_2, layer_norm_2], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_32 = reinterpret_cast<CUdeviceptr>(buf13.data_ptr());
    CUdeviceptr var_33 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_34 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale.data_ptr());
    CUdeviceptr var_35 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias.data_ptr());
    CUdeviceptr var_36 = reinterpret_cast<CUdeviceptr>(buf361.data_ptr());
    int32_t var_37 = s0;
    int var_38 = 192L;
    void* kernel_args_var_6[] = {&var_32, &var_33, &var_34, &var_35, &var_36, &var_37, &var_38};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_6 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_6.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_6.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_6.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_6.grid_z, 2, 8, kernel_args_var_6, stream);
    }
    auto buf17 = std::move(buf13);  // reuse
    // Topologically Sorted Source Nodes: [linear_3], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_16 == nullptr) {
        kernels.triton_tem_fused_addmm_16 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/chdktc553rbpxwow555iabp54x5faylyao2xkynjyrqglk73b2hv.cubin", "triton_tem_fused_addmm_16", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_39 = reinterpret_cast<CUdeviceptr>(arg606_1.data_ptr());
    CUdeviceptr var_40 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_3.data_ptr());
    CUdeviceptr var_41 = reinterpret_cast<CUdeviceptr>(buf17.data_ptr());
    int32_t var_42 = s0;
    void* kernel_args_var_7[] = {&var_39, &var_40, &var_41, &var_42};
    Grid triton_tem_fused_addmm_16_grid_7 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_16_grid_7.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_16, triton_tem_fused_addmm_16_grid_7.grid_x, triton_tem_fused_addmm_16_grid_7.grid_y, triton_tem_fused_addmm_16_grid_7.grid_z, 8, 49152, kernel_args_var_7, stream);
    }
    auto tmp_tensor_handle_3 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 70848L);
    RAIIAtenTensorHandle tmp_tensor_handle_3_raii(tmp_tensor_handle_3);
    decltype(auto) buf362 = std::move(tmp_tensor_handle_3_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_3, layer_norm_3], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_43 = reinterpret_cast<CUdeviceptr>(buf17.data_ptr());
    CUdeviceptr var_44 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_45 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale.data_ptr());
    CUdeviceptr var_46 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias.data_ptr());
    CUdeviceptr var_47 = reinterpret_cast<CUdeviceptr>(buf362.data_ptr());
    int32_t var_48 = s0;
    int var_49 = 192L;
    void* kernel_args_var_8[] = {&var_43, &var_44, &var_45, &var_46, &var_47, &var_48, &var_49};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_8 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_8.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_8.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_8.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_8.grid_z, 2, 8, kernel_args_var_8, stream);
    }
    auto buf21 = std::move(buf17);  // reuse
    // Topologically Sorted Source Nodes: [linear_4], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_17 == nullptr) {
        kernels.triton_tem_fused_addmm_17 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c3wknol6gk2otqnjzwrfzwi4tg7wl3sd4zvwgb77hwafixbhdtg5.cubin", "triton_tem_fused_addmm_17", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_50 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_51 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_4.data_ptr());
    CUdeviceptr var_52 = reinterpret_cast<CUdeviceptr>(buf21.data_ptr());
    int32_t var_53 = s0;
    void* kernel_args_var_9[] = {&var_50, &var_51, &var_52, &var_53};
    Grid triton_tem_fused_addmm_17_grid_9 = Grid(2L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_17_grid_9.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_17, triton_tem_fused_addmm_17_grid_9.grid_x, triton_tem_fused_addmm_17_grid_9.grid_y, triton_tem_fused_addmm_17_grid_9.grid_z, 8, 49152, kernel_args_var_9, stream);
    }
    auto tmp_tensor_handle_4 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 68736L);
    RAIIAtenTensorHandle tmp_tensor_handle_4_raii(tmp_tensor_handle_4);
    decltype(auto) buf351 = std::move(tmp_tensor_handle_4_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_4, layer_norm_4], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_54 = reinterpret_cast<CUdeviceptr>(buf21.data_ptr());
    CUdeviceptr var_55 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_56 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_57 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_58 = reinterpret_cast<CUdeviceptr>(buf351.data_ptr());
    int32_t var_59 = s0;
    int var_60 = 192L;
    void* kernel_args_var_10[] = {&var_54, &var_55, &var_56, &var_57, &var_58, &var_59, &var_60};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_10 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_10.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_10.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_10.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_10.grid_z, 2, 8, kernel_args_var_10, stream);
    }
    auto buf25 = std::move(buf21);  // reuse
    // Topologically Sorted Source Nodes: [linear_5], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_18 == nullptr) {
        kernels.triton_tem_fused_addmm_18 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c7bkzjf5mm3eh7xst5v325w56hogg2xfxzloevnnfgxivdqesydo.cubin", "triton_tem_fused_addmm_18", 30720, this->cubin_dir_);
    }
    CUdeviceptr var_61 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_62 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_5.data_ptr());
    CUdeviceptr var_63 = reinterpret_cast<CUdeviceptr>(buf25.data_ptr());
    int32_t var_64 = s0;
    void* kernel_args_var_11[] = {&var_61, &var_62, &var_63, &var_64};
    Grid triton_tem_fused_addmm_18_grid_11 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_18_grid_11.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_18, triton_tem_fused_addmm_18_grid_11.grid_x, triton_tem_fused_addmm_18_grid_11.grid_y, triton_tem_fused_addmm_18_grid_11.grid_z, 8, 30720, kernel_args_var_11, stream);
    }
    auto tmp_tensor_handle_5 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 68928L);
    RAIIAtenTensorHandle tmp_tensor_handle_5_raii(tmp_tensor_handle_5);
    decltype(auto) buf352 = std::move(tmp_tensor_handle_5_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_5, layer_norm_5], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_65 = reinterpret_cast<CUdeviceptr>(buf25.data_ptr());
    CUdeviceptr var_66 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_67 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_68 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_69 = reinterpret_cast<CUdeviceptr>(buf352.data_ptr());
    int32_t var_70 = s0;
    int var_71 = 192L;
    void* kernel_args_var_12[] = {&var_65, &var_66, &var_67, &var_68, &var_69, &var_70, &var_71};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_12 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_12.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_12.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_12.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_12.grid_z, 2, 8, kernel_args_var_12, stream);
    }
    auto buf29 = std::move(buf25);  // reuse
    // Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_19 == nullptr) {
        kernels.triton_tem_fused_addmm_19 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ce4qzhwnhe22lh734i3lvs6vzbzfnzub5h4kvpk754nbgvn55g2k.cubin", "triton_tem_fused_addmm_19", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_72 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_73 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_6.data_ptr());
    CUdeviceptr var_74 = reinterpret_cast<CUdeviceptr>(buf29.data_ptr());
    int32_t var_75 = s0;
    void* kernel_args_var_13[] = {&var_72, &var_73, &var_74, &var_75};
    Grid triton_tem_fused_addmm_19_grid_13 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_19_grid_13.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_19, triton_tem_fused_addmm_19_grid_13.grid_x, triton_tem_fused_addmm_19_grid_13.grid_y, triton_tem_fused_addmm_19_grid_13.grid_z, 8, 49152, kernel_args_var_13, stream);
    }
    auto tmp_tensor_handle_6 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 69312L);
    RAIIAtenTensorHandle tmp_tensor_handle_6_raii(tmp_tensor_handle_6);
    decltype(auto) buf354 = std::move(tmp_tensor_handle_6_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_6, layer_norm_6], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_76 = reinterpret_cast<CUdeviceptr>(buf29.data_ptr());
    CUdeviceptr var_77 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_78 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_79 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_80 = reinterpret_cast<CUdeviceptr>(buf354.data_ptr());
    int32_t var_81 = s0;
    int var_82 = 192L;
    void* kernel_args_var_14[] = {&var_76, &var_77, &var_78, &var_79, &var_80, &var_81, &var_82};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_14 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_14.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_14.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_14.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_14.grid_z, 2, 8, kernel_args_var_14, stream);
    }
    auto buf33 = std::move(buf29);  // reuse
    // Topologically Sorted Source Nodes: [linear_7], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_20 == nullptr) {
        kernels.triton_tem_fused_addmm_20 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckml5lahy4pvjkow6n6j7app4ewa2dzihdzem3e4dcbeykksr42c.cubin", "triton_tem_fused_addmm_20", 24576, this->cubin_dir_);
    }
    CUdeviceptr var_83 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_84 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_7.data_ptr());
    CUdeviceptr var_85 = reinterpret_cast<CUdeviceptr>(buf33.data_ptr());
    int32_t var_86 = s0;
    void* kernel_args_var_15[] = {&var_83, &var_84, &var_85, &var_86};
    Grid triton_tem_fused_addmm_20_grid_15 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(31L + s0), static_cast<int64_t>(32L))), 1L, 1L);
    if (triton_tem_fused_addmm_20_grid_15.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_20, triton_tem_fused_addmm_20_grid_15.grid_x, triton_tem_fused_addmm_20_grid_15.grid_y, triton_tem_fused_addmm_20_grid_15.grid_z, 8, 24576, kernel_args_var_15, stream);
    }
    auto tmp_tensor_handle_7 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 69504L);
    RAIIAtenTensorHandle tmp_tensor_handle_7_raii(tmp_tensor_handle_7);
    decltype(auto) buf355 = std::move(tmp_tensor_handle_7_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_7, layer_norm_7], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_87 = reinterpret_cast<CUdeviceptr>(buf33.data_ptr());
    CUdeviceptr var_88 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_89 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_90 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_91 = reinterpret_cast<CUdeviceptr>(buf355.data_ptr());
    int32_t var_92 = s0;
    int var_93 = 192L;
    void* kernel_args_var_16[] = {&var_87, &var_88, &var_89, &var_90, &var_91, &var_92, &var_93};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_16 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_16.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_16.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_16.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_16.grid_z, 2, 8, kernel_args_var_16, stream);
    }
    auto buf37 = std::move(buf33);  // reuse
    // Topologically Sorted Source Nodes: [linear_8], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_21 == nullptr) {
        kernels.triton_tem_fused_addmm_21 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjcfjljsfirqzfvx2c3cwvvt4p37gf2lspra3igw67vtildefrrb.cubin", "triton_tem_fused_addmm_21", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_94 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_95 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_8.data_ptr());
    CUdeviceptr var_96 = reinterpret_cast<CUdeviceptr>(buf37.data_ptr());
    int32_t var_97 = s0;
    void* kernel_args_var_17[] = {&var_94, &var_95, &var_96, &var_97};
    Grid triton_tem_fused_addmm_21_grid_17 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_21_grid_17.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_21, triton_tem_fused_addmm_21_grid_17.grid_x, triton_tem_fused_addmm_21_grid_17.grid_y, triton_tem_fused_addmm_21_grid_17.grid_z, 8, 49152, kernel_args_var_17, stream);
    }
    auto tmp_tensor_handle_8 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 69696L);
    RAIIAtenTensorHandle tmp_tensor_handle_8_raii(tmp_tensor_handle_8);
    decltype(auto) buf356 = std::move(tmp_tensor_handle_8_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_8, layer_norm_8], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_98 = reinterpret_cast<CUdeviceptr>(buf37.data_ptr());
    CUdeviceptr var_99 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_100 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_101 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_102 = reinterpret_cast<CUdeviceptr>(buf356.data_ptr());
    int32_t var_103 = s0;
    int var_104 = 192L;
    void* kernel_args_var_18[] = {&var_98, &var_99, &var_100, &var_101, &var_102, &var_103, &var_104};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_18 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_18.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_18.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_18.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_18.grid_z, 2, 8, kernel_args_var_18, stream);
    }
    auto buf41 = std::move(buf37);  // reuse
    // Topologically Sorted Source Nodes: [linear_9], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_22 == nullptr) {
        kernels.triton_tem_fused_addmm_22 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckiaca6gmkyw6ehlmgjwzaw4oiiccysitnwr6hzetmdko6bygww5.cubin", "triton_tem_fused_addmm_22", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_105 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_106 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_9.data_ptr());
    CUdeviceptr var_107 = reinterpret_cast<CUdeviceptr>(buf41.data_ptr());
    int32_t var_108 = s0;
    void* kernel_args_var_19[] = {&var_105, &var_106, &var_107, &var_108};
    Grid triton_tem_fused_addmm_22_grid_19 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_22_grid_19.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_22, triton_tem_fused_addmm_22_grid_19.grid_x, triton_tem_fused_addmm_22_grid_19.grid_y, triton_tem_fused_addmm_22_grid_19.grid_z, 8, 49152, kernel_args_var_19, stream);
    }
    auto tmp_tensor_handle_9 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 70080L);
    RAIIAtenTensorHandle tmp_tensor_handle_9_raii(tmp_tensor_handle_9);
    decltype(auto) buf358 = std::move(tmp_tensor_handle_9_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_9, layer_norm_9], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_109 = reinterpret_cast<CUdeviceptr>(buf41.data_ptr());
    CUdeviceptr var_110 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_111 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_112 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_113 = reinterpret_cast<CUdeviceptr>(buf358.data_ptr());
    int32_t var_114 = s0;
    int var_115 = 192L;
    void* kernel_args_var_20[] = {&var_109, &var_110, &var_111, &var_112, &var_113, &var_114, &var_115};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_20 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_20.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_20.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_20.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_20.grid_z, 2, 8, kernel_args_var_20, stream);
    }
    auto buf45 = std::move(buf41);  // reuse
    // Topologically Sorted Source Nodes: [linear_10], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_23 == nullptr) {
        kernels.triton_tem_fused_addmm_23 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/crxbk5t43gxe73afeijvgu6a2oh77hmlhjf2gtcoqdehuzalkb4e.cubin", "triton_tem_fused_addmm_23", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_116 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_117 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_10.data_ptr());
    CUdeviceptr var_118 = reinterpret_cast<CUdeviceptr>(buf45.data_ptr());
    int32_t var_119 = s0;
    void* kernel_args_var_21[] = {&var_116, &var_117, &var_118, &var_119};
    Grid triton_tem_fused_addmm_23_grid_21 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_23_grid_21.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_23, triton_tem_fused_addmm_23_grid_21.grid_x, triton_tem_fused_addmm_23_grid_21.grid_y, triton_tem_fused_addmm_23_grid_21.grid_z, 8, 49152, kernel_args_var_21, stream);
    }
    auto tmp_tensor_handle_10 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 70272L);
    RAIIAtenTensorHandle tmp_tensor_handle_10_raii(tmp_tensor_handle_10);
    decltype(auto) buf359 = std::move(tmp_tensor_handle_10_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_10, layer_norm_10], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_120 = reinterpret_cast<CUdeviceptr>(buf45.data_ptr());
    CUdeviceptr var_121 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_122 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_123 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_124 = reinterpret_cast<CUdeviceptr>(buf359.data_ptr());
    int32_t var_125 = s0;
    int var_126 = 192L;
    void* kernel_args_var_22[] = {&var_120, &var_121, &var_122, &var_123, &var_124, &var_125, &var_126};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_22 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_22.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_22.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_22.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_22.grid_z, 2, 8, kernel_args_var_22, stream);
    }
    auto buf49 = std::move(buf45);  // reuse
    // Topologically Sorted Source Nodes: [linear_11], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_24 == nullptr) {
        kernels.triton_tem_fused_addmm_24 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cb72mgdc7onmotha3kkkktqepznlysrelm5xphf243gczmvwxury.cubin", "triton_tem_fused_addmm_24", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_127 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_128 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_11.data_ptr());
    CUdeviceptr var_129 = reinterpret_cast<CUdeviceptr>(buf49.data_ptr());
    int32_t var_130 = s0;
    void* kernel_args_var_23[] = {&var_127, &var_128, &var_129, &var_130};
    Grid triton_tem_fused_addmm_24_grid_23 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_24_grid_23.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_24, triton_tem_fused_addmm_24_grid_23.grid_x, triton_tem_fused_addmm_24_grid_23.grid_y, triton_tem_fused_addmm_24_grid_23.grid_z, 8, 49152, kernel_args_var_23, stream);
    }
    auto tmp_tensor_handle_11 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 70464L);
    RAIIAtenTensorHandle tmp_tensor_handle_11_raii(tmp_tensor_handle_11);
    decltype(auto) buf360 = std::move(tmp_tensor_handle_11_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_11, layer_norm_11], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_131 = reinterpret_cast<CUdeviceptr>(buf49.data_ptr());
    CUdeviceptr var_132 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_133 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_134 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_135 = reinterpret_cast<CUdeviceptr>(buf360.data_ptr());
    int32_t var_136 = s0;
    int var_137 = 192L;
    void* kernel_args_var_24[] = {&var_131, &var_132, &var_133, &var_134, &var_135, &var_136, &var_137};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_24 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_24.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_24.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_24.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_24.grid_z, 2, 8, kernel_args_var_24, stream);
    }
    auto buf53 = std::move(buf49);  // reuse
    // Topologically Sorted Source Nodes: [linear_12], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_25 == nullptr) {
        kernels.triton_tem_fused_addmm_25 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cvbz4q3yoyyk6wq76uf7laus6krjoscib3kmy4ruzgd5jj6yjb25.cubin", "triton_tem_fused_addmm_25", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_138 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_139 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_12.data_ptr());
    CUdeviceptr var_140 = reinterpret_cast<CUdeviceptr>(buf53.data_ptr());
    int32_t var_141 = s0;
    void* kernel_args_var_25[] = {&var_138, &var_139, &var_140, &var_141};
    Grid triton_tem_fused_addmm_25_grid_25 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_25_grid_25.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_25, triton_tem_fused_addmm_25_grid_25.grid_x, triton_tem_fused_addmm_25_grid_25.grid_y, triton_tem_fused_addmm_25_grid_25.grid_z, 8, 49152, kernel_args_var_25, stream);
    }
    auto tmp_tensor_handle_12 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 71040L);
    RAIIAtenTensorHandle tmp_tensor_handle_12_raii(tmp_tensor_handle_12);
    decltype(auto) buf363 = std::move(tmp_tensor_handle_12_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_12, layer_norm_12], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_142 = reinterpret_cast<CUdeviceptr>(buf53.data_ptr());
    CUdeviceptr var_143 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_144 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_145 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_146 = reinterpret_cast<CUdeviceptr>(buf363.data_ptr());
    int32_t var_147 = s0;
    int var_148 = 192L;
    void* kernel_args_var_26[] = {&var_142, &var_143, &var_144, &var_145, &var_146, &var_147, &var_148};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_26 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_26.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_26.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_26.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_26.grid_z, 2, 8, kernel_args_var_26, stream);
    }
    auto buf57 = std::move(buf53);  // reuse
    // Topologically Sorted Source Nodes: [linear_13], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_26 == nullptr) {
        kernels.triton_tem_fused_addmm_26 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cc3a4qoxlw2alxniwflchwvpdu56dlyynp6nzktpdpyjgrb2espv.cubin", "triton_tem_fused_addmm_26", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_149 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_150 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_13.data_ptr());
    CUdeviceptr var_151 = reinterpret_cast<CUdeviceptr>(buf57.data_ptr());
    int32_t var_152 = s0;
    void* kernel_args_var_27[] = {&var_149, &var_150, &var_151, &var_152};
    Grid triton_tem_fused_addmm_26_grid_27 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_26_grid_27.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_26, triton_tem_fused_addmm_26_grid_27.grid_x, triton_tem_fused_addmm_26_grid_27.grid_y, triton_tem_fused_addmm_26_grid_27.grid_z, 8, 49152, kernel_args_var_27, stream);
    }
    auto tmp_tensor_handle_13 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 71232L);
    RAIIAtenTensorHandle tmp_tensor_handle_13_raii(tmp_tensor_handle_13);
    decltype(auto) buf364 = std::move(tmp_tensor_handle_13_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_13, layer_norm_13], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_153 = reinterpret_cast<CUdeviceptr>(buf57.data_ptr());
    CUdeviceptr var_154 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_155 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_156 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_157 = reinterpret_cast<CUdeviceptr>(buf364.data_ptr());
    int32_t var_158 = s0;
    int var_159 = 192L;
    void* kernel_args_var_28[] = {&var_153, &var_154, &var_155, &var_156, &var_157, &var_158, &var_159};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_28 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_28.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_28.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_28.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_28.grid_z, 2, 8, kernel_args_var_28, stream);
    }
    auto buf61 = std::move(buf57);  // reuse
    // Topologically Sorted Source Nodes: [linear_14], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_27 == nullptr) {
        kernels.triton_tem_fused_addmm_27 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ctyv3iipgnngjwcspwl66rhygq4d342rzj4xppk2mjpypgpoy5e4.cubin", "triton_tem_fused_addmm_27", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_160 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_161 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_14.data_ptr());
    CUdeviceptr var_162 = reinterpret_cast<CUdeviceptr>(buf61.data_ptr());
    int32_t var_163 = s0;
    void* kernel_args_var_29[] = {&var_160, &var_161, &var_162, &var_163};
    Grid triton_tem_fused_addmm_27_grid_29 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_27_grid_29.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_27, triton_tem_fused_addmm_27_grid_29.grid_x, triton_tem_fused_addmm_27_grid_29.grid_y, triton_tem_fused_addmm_27_grid_29.grid_z, 8, 49152, kernel_args_var_29, stream);
    }
    auto tmp_tensor_handle_14 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 71424L);
    RAIIAtenTensorHandle tmp_tensor_handle_14_raii(tmp_tensor_handle_14);
    decltype(auto) buf365 = std::move(tmp_tensor_handle_14_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_14, layer_norm_14], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_164 = reinterpret_cast<CUdeviceptr>(buf61.data_ptr());
    CUdeviceptr var_165 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_166 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_167 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_168 = reinterpret_cast<CUdeviceptr>(buf365.data_ptr());
    int32_t var_169 = s0;
    int var_170 = 192L;
    void* kernel_args_var_30[] = {&var_164, &var_165, &var_166, &var_167, &var_168, &var_169, &var_170};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_30 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_30.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_30.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_30.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_30.grid_z, 2, 8, kernel_args_var_30, stream);
    }
    auto buf65 = std::move(buf61);  // reuse
    // Topologically Sorted Source Nodes: [linear_15], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_28 == nullptr) {
        kernels.triton_tem_fused_addmm_28 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c3t3gh6bafbqrecb6nfqbnrtt5v3fnp52cdbogtm5qwxcmq44txt.cubin", "triton_tem_fused_addmm_28", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_171 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_172 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_15.data_ptr());
    CUdeviceptr var_173 = reinterpret_cast<CUdeviceptr>(buf65.data_ptr());
    int32_t var_174 = s0;
    void* kernel_args_var_31[] = {&var_171, &var_172, &var_173, &var_174};
    Grid triton_tem_fused_addmm_28_grid_31 = Grid(2L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_28_grid_31.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_28, triton_tem_fused_addmm_28_grid_31.grid_x, triton_tem_fused_addmm_28_grid_31.grid_y, triton_tem_fused_addmm_28_grid_31.grid_z, 8, 49152, kernel_args_var_31, stream);
    }
    auto tmp_tensor_handle_15 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 71616L);
    RAIIAtenTensorHandle tmp_tensor_handle_15_raii(tmp_tensor_handle_15);
    decltype(auto) buf366 = std::move(tmp_tensor_handle_15_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_15, layer_norm_15], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_175 = reinterpret_cast<CUdeviceptr>(buf65.data_ptr());
    CUdeviceptr var_176 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_177 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_178 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_179 = reinterpret_cast<CUdeviceptr>(buf366.data_ptr());
    int32_t var_180 = s0;
    int var_181 = 192L;
    void* kernel_args_var_32[] = {&var_175, &var_176, &var_177, &var_178, &var_179, &var_180, &var_181};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_32 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_32.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_32.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_32.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_32.grid_z, 2, 8, kernel_args_var_32, stream);
    }
    auto buf69 = std::move(buf65);  // reuse
    // Topologically Sorted Source Nodes: [linear_16], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_29 == nullptr) {
        kernels.triton_tem_fused_addmm_29 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ccemvf34wigfqou6zcvln6vswdsgz3jm2hfngbym7na7ts5d5o3t.cubin", "triton_tem_fused_addmm_29", 8192, this->cubin_dir_);
    }
    CUdeviceptr var_182 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_183 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_16.data_ptr());
    CUdeviceptr var_184 = reinterpret_cast<CUdeviceptr>(buf69.data_ptr());
    int32_t var_185 = s0;
    void* kernel_args_var_33[] = {&var_182, &var_183, &var_184, &var_185};
    Grid triton_tem_fused_addmm_29_grid_33 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(31L + s0), static_cast<int64_t>(32L))), 1L, 1L);
    if (triton_tem_fused_addmm_29_grid_33.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_29, triton_tem_fused_addmm_29_grid_33.grid_x, triton_tem_fused_addmm_29_grid_33.grid_y, triton_tem_fused_addmm_29_grid_33.grid_z, 4, 8192, kernel_args_var_33, stream);
    }
    auto tmp_tensor_handle_16 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 71808L);
    RAIIAtenTensorHandle tmp_tensor_handle_16_raii(tmp_tensor_handle_16);
    decltype(auto) buf367 = std::move(tmp_tensor_handle_16_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_16, layer_norm_16], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_186 = reinterpret_cast<CUdeviceptr>(buf69.data_ptr());
    CUdeviceptr var_187 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_188 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_189 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_190 = reinterpret_cast<CUdeviceptr>(buf367.data_ptr());
    int32_t var_191 = s0;
    int var_192 = 192L;
    void* kernel_args_var_34[] = {&var_186, &var_187, &var_188, &var_189, &var_190, &var_191, &var_192};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_34 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_34.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_34.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_34.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_34.grid_z, 2, 8, kernel_args_var_34, stream);
    }
    auto buf73 = std::move(buf69);  // reuse
    // Topologically Sorted Source Nodes: [linear_17], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_30 == nullptr) {
        kernels.triton_tem_fused_addmm_30 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c5lvhwbkk5qpn6y3zw6f2naw7pz7ohkczxjngcmo7f6rxlprqvuc.cubin", "triton_tem_fused_addmm_30", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_193 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_194 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_17.data_ptr());
    CUdeviceptr var_195 = reinterpret_cast<CUdeviceptr>(buf73.data_ptr());
    int32_t var_196 = s0;
    void* kernel_args_var_35[] = {&var_193, &var_194, &var_195, &var_196};
    Grid triton_tem_fused_addmm_30_grid_35 = Grid(2L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_30_grid_35.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_30, triton_tem_fused_addmm_30_grid_35.grid_x, triton_tem_fused_addmm_30_grid_35.grid_y, triton_tem_fused_addmm_30_grid_35.grid_z, 8, 49152, kernel_args_var_35, stream);
    }
    auto tmp_tensor_handle_17 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 72000L);
    RAIIAtenTensorHandle tmp_tensor_handle_17_raii(tmp_tensor_handle_17);
    decltype(auto) buf368 = std::move(tmp_tensor_handle_17_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_17, layer_norm_17], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_197 = reinterpret_cast<CUdeviceptr>(buf73.data_ptr());
    CUdeviceptr var_198 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_199 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_200 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_201 = reinterpret_cast<CUdeviceptr>(buf368.data_ptr());
    int32_t var_202 = s0;
    int var_203 = 192L;
    void* kernel_args_var_36[] = {&var_197, &var_198, &var_199, &var_200, &var_201, &var_202, &var_203};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_36 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_36.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_36.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_36.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_36.grid_z, 2, 8, kernel_args_var_36, stream);
    }
    auto buf77 = std::move(buf73);  // reuse
    // Topologically Sorted Source Nodes: [linear_18], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_31 == nullptr) {
        kernels.triton_tem_fused_addmm_31 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/czesduhx3jujn3ljlhwtoh3ghogo6dphacn3lwrlyskxx6o7tpgl.cubin", "triton_tem_fused_addmm_31", 8192, this->cubin_dir_);
    }
    CUdeviceptr var_204 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_205 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_18.data_ptr());
    CUdeviceptr var_206 = reinterpret_cast<CUdeviceptr>(buf77.data_ptr());
    int32_t var_207 = s0;
    void* kernel_args_var_37[] = {&var_204, &var_205, &var_206, &var_207};
    Grid triton_tem_fused_addmm_31_grid_37 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(31L + s0), static_cast<int64_t>(32L))), 1L, 1L);
    if (triton_tem_fused_addmm_31_grid_37.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_31, triton_tem_fused_addmm_31_grid_37.grid_x, triton_tem_fused_addmm_31_grid_37.grid_y, triton_tem_fused_addmm_31_grid_37.grid_z, 4, 8192, kernel_args_var_37, stream);
    }
    auto tmp_tensor_handle_18 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 72192L);
    RAIIAtenTensorHandle tmp_tensor_handle_18_raii(tmp_tensor_handle_18);
    decltype(auto) buf369 = std::move(tmp_tensor_handle_18_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_18, layer_norm_18], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_208 = reinterpret_cast<CUdeviceptr>(buf77.data_ptr());
    CUdeviceptr var_209 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_210 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_211 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_212 = reinterpret_cast<CUdeviceptr>(buf369.data_ptr());
    int32_t var_213 = s0;
    int var_214 = 192L;
    void* kernel_args_var_38[] = {&var_208, &var_209, &var_210, &var_211, &var_212, &var_213, &var_214};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_38 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_38.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_38.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_38.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_38.grid_z, 2, 8, kernel_args_var_38, stream);
    }
    auto buf81 = std::move(buf77);  // reuse
    // Topologically Sorted Source Nodes: [linear_19], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_32 == nullptr) {
        kernels.triton_tem_fused_addmm_32 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cuxt3brluwqes7fdlucvz7dohkbmhbhltb5j7db6qt2cypifgyog.cubin", "triton_tem_fused_addmm_32", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_215 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_216 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_19.data_ptr());
    CUdeviceptr var_217 = reinterpret_cast<CUdeviceptr>(buf81.data_ptr());
    int32_t var_218 = s0;
    void* kernel_args_var_39[] = {&var_215, &var_216, &var_217, &var_218};
    Grid triton_tem_fused_addmm_32_grid_39 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_32_grid_39.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_32, triton_tem_fused_addmm_32_grid_39.grid_x, triton_tem_fused_addmm_32_grid_39.grid_y, triton_tem_fused_addmm_32_grid_39.grid_z, 8, 49152, kernel_args_var_39, stream);
    }
    auto tmp_tensor_handle_19 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 72384L);
    RAIIAtenTensorHandle tmp_tensor_handle_19_raii(tmp_tensor_handle_19);
    decltype(auto) buf370 = std::move(tmp_tensor_handle_19_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_19, layer_norm_19], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_219 = reinterpret_cast<CUdeviceptr>(buf81.data_ptr());
    CUdeviceptr var_220 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_221 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_222 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_223 = reinterpret_cast<CUdeviceptr>(buf370.data_ptr());
    int32_t var_224 = s0;
    int var_225 = 192L;
    void* kernel_args_var_40[] = {&var_219, &var_220, &var_221, &var_222, &var_223, &var_224, &var_225};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_40 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_40.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_40.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_40.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_40.grid_z, 2, 8, kernel_args_var_40, stream);
    }
    auto buf85 = std::move(buf81);  // reuse
    // Topologically Sorted Source Nodes: [linear_20], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_33 == nullptr) {
        kernels.triton_tem_fused_addmm_33 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c6lzkrruafiyjivrc2jchr4d6lsjubwddrx2pmvrxkjqnwovcnsw.cubin", "triton_tem_fused_addmm_33", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_226 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_227 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_20.data_ptr());
    CUdeviceptr var_228 = reinterpret_cast<CUdeviceptr>(buf85.data_ptr());
    int32_t var_229 = s0;
    void* kernel_args_var_41[] = {&var_226, &var_227, &var_228, &var_229};
    Grid triton_tem_fused_addmm_33_grid_41 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_33_grid_41.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_33, triton_tem_fused_addmm_33_grid_41.grid_x, triton_tem_fused_addmm_33_grid_41.grid_y, triton_tem_fused_addmm_33_grid_41.grid_z, 8, 49152, kernel_args_var_41, stream);
    }
    auto tmp_tensor_handle_20 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 72576L);
    RAIIAtenTensorHandle tmp_tensor_handle_20_raii(tmp_tensor_handle_20);
    decltype(auto) buf371 = std::move(tmp_tensor_handle_20_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_20, layer_norm_20], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_230 = reinterpret_cast<CUdeviceptr>(buf85.data_ptr());
    CUdeviceptr var_231 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_232 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_233 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_234 = reinterpret_cast<CUdeviceptr>(buf371.data_ptr());
    int32_t var_235 = s0;
    int var_236 = 192L;
    void* kernel_args_var_42[] = {&var_230, &var_231, &var_232, &var_233, &var_234, &var_235, &var_236};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_42 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_42.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_42.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_42.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_42.grid_z, 2, 8, kernel_args_var_42, stream);
    }
    auto buf89 = std::move(buf85);  // reuse
    // Topologically Sorted Source Nodes: [linear_21], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_34 == nullptr) {
        kernels.triton_tem_fused_addmm_34 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cs7fgbhbwh5anbhh7fhney5jzud6id3r4frzngsf2kfzushma6no.cubin", "triton_tem_fused_addmm_34", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_237 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_238 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_21.data_ptr());
    CUdeviceptr var_239 = reinterpret_cast<CUdeviceptr>(buf89.data_ptr());
    int32_t var_240 = s0;
    void* kernel_args_var_43[] = {&var_237, &var_238, &var_239, &var_240};
    Grid triton_tem_fused_addmm_34_grid_43 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_34_grid_43.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_34, triton_tem_fused_addmm_34_grid_43.grid_x, triton_tem_fused_addmm_34_grid_43.grid_y, triton_tem_fused_addmm_34_grid_43.grid_z, 8, 49152, kernel_args_var_43, stream);
    }
    auto tmp_tensor_handle_21 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 72768L);
    RAIIAtenTensorHandle tmp_tensor_handle_21_raii(tmp_tensor_handle_21);
    decltype(auto) buf372 = std::move(tmp_tensor_handle_21_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_21, layer_norm_21], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_241 = reinterpret_cast<CUdeviceptr>(buf89.data_ptr());
    CUdeviceptr var_242 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_243 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_244 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_245 = reinterpret_cast<CUdeviceptr>(buf372.data_ptr());
    int32_t var_246 = s0;
    int var_247 = 192L;
    void* kernel_args_var_44[] = {&var_241, &var_242, &var_243, &var_244, &var_245, &var_246, &var_247};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_44 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_44.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_44.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_44.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_44.grid_z, 2, 8, kernel_args_var_44, stream);
    }
    auto buf93 = std::move(buf89);  // reuse
    // Topologically Sorted Source Nodes: [linear_22], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_35 == nullptr) {
        kernels.triton_tem_fused_addmm_35 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c7nut5v23jzr5lbhsdt6i6k2gd4rp4slaxydyfpxoz5u75qc3dpt.cubin", "triton_tem_fused_addmm_35", 18432, this->cubin_dir_);
    }
    CUdeviceptr var_248 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_249 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_22.data_ptr());
    CUdeviceptr var_250 = reinterpret_cast<CUdeviceptr>(buf93.data_ptr());
    int32_t var_251 = s0;
    void* kernel_args_var_45[] = {&var_248, &var_249, &var_250, &var_251};
    Grid triton_tem_fused_addmm_35_grid_45 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_35_grid_45.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_35, triton_tem_fused_addmm_35_grid_45.grid_x, triton_tem_fused_addmm_35_grid_45.grid_y, triton_tem_fused_addmm_35_grid_45.grid_z, 8, 18432, kernel_args_var_45, stream);
    }
    auto tmp_tensor_handle_22 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 72960L);
    RAIIAtenTensorHandle tmp_tensor_handle_22_raii(tmp_tensor_handle_22);
    decltype(auto) buf373 = std::move(tmp_tensor_handle_22_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_22, layer_norm_22], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_252 = reinterpret_cast<CUdeviceptr>(buf93.data_ptr());
    CUdeviceptr var_253 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_254 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale.data_ptr());
    CUdeviceptr var_255 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias.data_ptr());
    CUdeviceptr var_256 = reinterpret_cast<CUdeviceptr>(buf373.data_ptr());
    int32_t var_257 = s0;
    int var_258 = 192L;
    void* kernel_args_var_46[] = {&var_252, &var_253, &var_254, &var_255, &var_256, &var_257, &var_258};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_46 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_46.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_46.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_46.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_46.grid_z, 2, 8, kernel_args_var_46, stream);
    }
    auto buf97 = std::move(buf93);  // reuse
    // Topologically Sorted Source Nodes: [linear_23], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_36 == nullptr) {
        kernels.triton_tem_fused_addmm_36 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cawwzof67rd2guo2ax6drufs7quhz5hfl6ygxadzbas6dirioxau.cubin", "triton_tem_fused_addmm_36", 36864, this->cubin_dir_);
    }
    CUdeviceptr var_259 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_260 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_23.data_ptr());
    CUdeviceptr var_261 = reinterpret_cast<CUdeviceptr>(buf97.data_ptr());
    int32_t var_262 = s0;
    void* kernel_args_var_47[] = {&var_259, &var_260, &var_261, &var_262};
    Grid triton_tem_fused_addmm_36_grid_47 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_36_grid_47.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_36, triton_tem_fused_addmm_36_grid_47.grid_x, triton_tem_fused_addmm_36_grid_47.grid_y, triton_tem_fused_addmm_36_grid_47.grid_z, 4, 36864, kernel_args_var_47, stream);
    }
    auto tmp_tensor_handle_23 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 73152L);
    RAIIAtenTensorHandle tmp_tensor_handle_23_raii(tmp_tensor_handle_23);
    decltype(auto) buf374 = std::move(tmp_tensor_handle_23_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_23, layer_norm_23], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_263 = reinterpret_cast<CUdeviceptr>(buf97.data_ptr());
    CUdeviceptr var_264 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_265 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_266 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_267 = reinterpret_cast<CUdeviceptr>(buf374.data_ptr());
    int32_t var_268 = s0;
    int var_269 = 192L;
    void* kernel_args_var_48[] = {&var_263, &var_264, &var_265, &var_266, &var_267, &var_268, &var_269};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_48 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_48.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_48.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_48.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_48.grid_z, 2, 8, kernel_args_var_48, stream);
    }
    auto buf101 = std::move(buf97);  // reuse
    // Topologically Sorted Source Nodes: [linear_24], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_37 == nullptr) {
        kernels.triton_tem_fused_addmm_37 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/csqr72xuap4jq27frglx473is5wwz4bocnc4b3fnvwkmnu6seqqn.cubin", "triton_tem_fused_addmm_37", 36864, this->cubin_dir_);
    }
    CUdeviceptr var_270 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_271 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_24.data_ptr());
    CUdeviceptr var_272 = reinterpret_cast<CUdeviceptr>(buf101.data_ptr());
    int32_t var_273 = s0;
    void* kernel_args_var_49[] = {&var_270, &var_271, &var_272, &var_273};
    Grid triton_tem_fused_addmm_37_grid_49 = Grid(2L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_37_grid_49.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_37, triton_tem_fused_addmm_37_grid_49.grid_x, triton_tem_fused_addmm_37_grid_49.grid_y, triton_tem_fused_addmm_37_grid_49.grid_z, 4, 36864, kernel_args_var_49, stream);
    }
    auto tmp_tensor_handle_24 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 73344L);
    RAIIAtenTensorHandle tmp_tensor_handle_24_raii(tmp_tensor_handle_24);
    decltype(auto) buf375 = std::move(tmp_tensor_handle_24_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_24, layer_norm_24], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_274 = reinterpret_cast<CUdeviceptr>(buf101.data_ptr());
    CUdeviceptr var_275 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_276 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale.data_ptr());
    CUdeviceptr var_277 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias.data_ptr());
    CUdeviceptr var_278 = reinterpret_cast<CUdeviceptr>(buf375.data_ptr());
    int32_t var_279 = s0;
    int var_280 = 192L;
    void* kernel_args_var_50[] = {&var_274, &var_275, &var_276, &var_277, &var_278, &var_279, &var_280};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_50 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_50.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_50.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_50.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_50.grid_z, 2, 8, kernel_args_var_50, stream);
    }
    auto buf105 = std::move(buf101);  // reuse
    // Topologically Sorted Source Nodes: [linear_25], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_38 == nullptr) {
        kernels.triton_tem_fused_addmm_38 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cw43puenvhjmo4sc3cufwn4t3xaq5fsnfkstu7y46t4mlq2azzdh.cubin", "triton_tem_fused_addmm_38", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_281 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_282 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_25.data_ptr());
    CUdeviceptr var_283 = reinterpret_cast<CUdeviceptr>(buf105.data_ptr());
    int32_t var_284 = s0;
    void* kernel_args_var_51[] = {&var_281, &var_282, &var_283, &var_284};
    Grid triton_tem_fused_addmm_38_grid_51 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_38_grid_51.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_38, triton_tem_fused_addmm_38_grid_51.grid_x, triton_tem_fused_addmm_38_grid_51.grid_y, triton_tem_fused_addmm_38_grid_51.grid_z, 8, 49152, kernel_args_var_51, stream);
    }
    auto tmp_tensor_handle_25 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 73536L);
    RAIIAtenTensorHandle tmp_tensor_handle_25_raii(tmp_tensor_handle_25);
    decltype(auto) buf376 = std::move(tmp_tensor_handle_25_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_25, layer_norm_25], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_285 = reinterpret_cast<CUdeviceptr>(buf105.data_ptr());
    CUdeviceptr var_286 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_287 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_288 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_289 = reinterpret_cast<CUdeviceptr>(buf376.data_ptr());
    int32_t var_290 = s0;
    int var_291 = 192L;
    void* kernel_args_var_52[] = {&var_285, &var_286, &var_287, &var_288, &var_289, &var_290, &var_291};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_52 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_52.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_52.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_52.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_52.grid_z, 2, 8, kernel_args_var_52, stream);
    }
    auto buf109 = std::move(buf105);  // reuse
    // Topologically Sorted Source Nodes: [linear_26], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_39 == nullptr) {
        kernels.triton_tem_fused_addmm_39 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cucr2djwcf4gzlinpprtinmdmvv6laqlqkifhimoeujfcapdjfqb.cubin", "triton_tem_fused_addmm_39", 8192, this->cubin_dir_);
    }
    CUdeviceptr var_292 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_293 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_26.data_ptr());
    CUdeviceptr var_294 = reinterpret_cast<CUdeviceptr>(buf109.data_ptr());
    int32_t var_295 = s0;
    void* kernel_args_var_53[] = {&var_292, &var_293, &var_294, &var_295};
    Grid triton_tem_fused_addmm_39_grid_53 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(31L + s0), static_cast<int64_t>(32L))), 1L, 1L);
    if (triton_tem_fused_addmm_39_grid_53.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_39, triton_tem_fused_addmm_39_grid_53.grid_x, triton_tem_fused_addmm_39_grid_53.grid_y, triton_tem_fused_addmm_39_grid_53.grid_z, 4, 8192, kernel_args_var_53, stream);
    }
    auto tmp_tensor_handle_26 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 73728L);
    RAIIAtenTensorHandle tmp_tensor_handle_26_raii(tmp_tensor_handle_26);
    decltype(auto) buf377 = std::move(tmp_tensor_handle_26_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_26, layer_norm_26], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_296 = reinterpret_cast<CUdeviceptr>(buf109.data_ptr());
    CUdeviceptr var_297 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_298 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_299 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_300 = reinterpret_cast<CUdeviceptr>(buf377.data_ptr());
    int32_t var_301 = s0;
    int var_302 = 192L;
    void* kernel_args_var_54[] = {&var_296, &var_297, &var_298, &var_299, &var_300, &var_301, &var_302};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_54 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_54.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_54.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_54.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_54.grid_z, 2, 8, kernel_args_var_54, stream);
    }
    auto buf113 = std::move(buf109);  // reuse
    // Topologically Sorted Source Nodes: [linear_27], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_40 == nullptr) {
        kernels.triton_tem_fused_addmm_40 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cdhzbfcp7x3fiu7n2uw456skvxe5xq6uikum6orfyckh7b6k4bxv.cubin", "triton_tem_fused_addmm_40", 8192, this->cubin_dir_);
    }
    CUdeviceptr var_303 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_304 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_27.data_ptr());
    CUdeviceptr var_305 = reinterpret_cast<CUdeviceptr>(buf113.data_ptr());
    int32_t var_306 = s0;
    void* kernel_args_var_55[] = {&var_303, &var_304, &var_305, &var_306};
    Grid triton_tem_fused_addmm_40_grid_55 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(31L + s0), static_cast<int64_t>(32L))), 1L, 1L);
    if (triton_tem_fused_addmm_40_grid_55.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_40, triton_tem_fused_addmm_40_grid_55.grid_x, triton_tem_fused_addmm_40_grid_55.grid_y, triton_tem_fused_addmm_40_grid_55.grid_z, 4, 8192, kernel_args_var_55, stream);
    }
    auto tmp_tensor_handle_27 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 73920L);
    RAIIAtenTensorHandle tmp_tensor_handle_27_raii(tmp_tensor_handle_27);
    decltype(auto) buf378 = std::move(tmp_tensor_handle_27_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_27, layer_norm_27], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_307 = reinterpret_cast<CUdeviceptr>(buf113.data_ptr());
    CUdeviceptr var_308 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_309 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_310 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_311 = reinterpret_cast<CUdeviceptr>(buf378.data_ptr());
    int32_t var_312 = s0;
    int var_313 = 192L;
    void* kernel_args_var_56[] = {&var_307, &var_308, &var_309, &var_310, &var_311, &var_312, &var_313};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_56 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_56.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_56.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_56.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_56.grid_z, 2, 8, kernel_args_var_56, stream);
    }
    auto buf117 = std::move(buf113);  // reuse
    // Topologically Sorted Source Nodes: [linear_28], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_41 == nullptr) {
        kernels.triton_tem_fused_addmm_41 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ccqthsy324gczv72a3wvdj326lmm2kyq5htpovoj23phqtibkipg.cubin", "triton_tem_fused_addmm_41", 24576, this->cubin_dir_);
    }
    CUdeviceptr var_314 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_315 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_28.data_ptr());
    CUdeviceptr var_316 = reinterpret_cast<CUdeviceptr>(buf117.data_ptr());
    int32_t var_317 = s0;
    void* kernel_args_var_57[] = {&var_314, &var_315, &var_316, &var_317};
    Grid triton_tem_fused_addmm_41_grid_57 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(31L + s0), static_cast<int64_t>(32L))), 1L, 1L);
    if (triton_tem_fused_addmm_41_grid_57.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_41, triton_tem_fused_addmm_41_grid_57.grid_x, triton_tem_fused_addmm_41_grid_57.grid_y, triton_tem_fused_addmm_41_grid_57.grid_z, 8, 24576, kernel_args_var_57, stream);
    }
    auto tmp_tensor_handle_28 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 74112L);
    RAIIAtenTensorHandle tmp_tensor_handle_28_raii(tmp_tensor_handle_28);
    decltype(auto) buf379 = std::move(tmp_tensor_handle_28_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_28, layer_norm_28], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_318 = reinterpret_cast<CUdeviceptr>(buf117.data_ptr());
    CUdeviceptr var_319 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_320 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_321 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_322 = reinterpret_cast<CUdeviceptr>(buf379.data_ptr());
    int32_t var_323 = s0;
    int var_324 = 192L;
    void* kernel_args_var_58[] = {&var_318, &var_319, &var_320, &var_321, &var_322, &var_323, &var_324};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_58 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_58.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_58.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_58.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_58.grid_z, 2, 8, kernel_args_var_58, stream);
    }
    auto buf121 = std::move(buf117);  // reuse
    // Topologically Sorted Source Nodes: [linear_29], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_42 == nullptr) {
        kernels.triton_tem_fused_addmm_42 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cuq7i2f4lwzbtmwuflkaearuxiarnkprnftwl7w2csopqacznqyd.cubin", "triton_tem_fused_addmm_42", 163840, this->cubin_dir_);
    }
    CUdeviceptr var_325 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_326 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_29.data_ptr());
    CUdeviceptr var_327 = reinterpret_cast<CUdeviceptr>(buf121.data_ptr());
    int32_t var_328 = s0;
    void* kernel_args_var_59[] = {&var_325, &var_326, &var_327, &var_328};
    Grid triton_tem_fused_addmm_42_grid_59 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_42_grid_59.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_42, triton_tem_fused_addmm_42_grid_59.grid_x, triton_tem_fused_addmm_42_grid_59.grid_y, triton_tem_fused_addmm_42_grid_59.grid_z, 4, 163840, kernel_args_var_59, stream);
    }
    auto tmp_tensor_handle_29 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 74304L);
    RAIIAtenTensorHandle tmp_tensor_handle_29_raii(tmp_tensor_handle_29);
    decltype(auto) buf380 = std::move(tmp_tensor_handle_29_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_29, layer_norm_29], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_329 = reinterpret_cast<CUdeviceptr>(buf121.data_ptr());
    CUdeviceptr var_330 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_331 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale.data_ptr());
    CUdeviceptr var_332 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias.data_ptr());
    CUdeviceptr var_333 = reinterpret_cast<CUdeviceptr>(buf380.data_ptr());
    int32_t var_334 = s0;
    int var_335 = 192L;
    void* kernel_args_var_60[] = {&var_329, &var_330, &var_331, &var_332, &var_333, &var_334, &var_335};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_60 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_60.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_60.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_60.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_60.grid_z, 2, 8, kernel_args_var_60, stream);
    }
    auto buf125 = std::move(buf121);  // reuse
    // Topologically Sorted Source Nodes: [linear_30], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_43 == nullptr) {
        kernels.triton_tem_fused_addmm_43 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cnuqru5bmqx6asigtlkfrefix4hmdcz5ykt563eqab3zsxffc57j.cubin", "triton_tem_fused_addmm_43", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_336 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_337 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_30.data_ptr());
    CUdeviceptr var_338 = reinterpret_cast<CUdeviceptr>(buf125.data_ptr());
    int32_t var_339 = s0;
    void* kernel_args_var_61[] = {&var_336, &var_337, &var_338, &var_339};
    Grid triton_tem_fused_addmm_43_grid_61 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_43_grid_61.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_43, triton_tem_fused_addmm_43_grid_61.grid_x, triton_tem_fused_addmm_43_grid_61.grid_y, triton_tem_fused_addmm_43_grid_61.grid_z, 8, 49152, kernel_args_var_61, stream);
    }
    auto tmp_tensor_handle_30 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 74496L);
    RAIIAtenTensorHandle tmp_tensor_handle_30_raii(tmp_tensor_handle_30);
    decltype(auto) buf381 = std::move(tmp_tensor_handle_30_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_30, layer_norm_30], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_340 = reinterpret_cast<CUdeviceptr>(buf125.data_ptr());
    CUdeviceptr var_341 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_342 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale.data_ptr());
    CUdeviceptr var_343 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias.data_ptr());
    CUdeviceptr var_344 = reinterpret_cast<CUdeviceptr>(buf381.data_ptr());
    int32_t var_345 = s0;
    int var_346 = 192L;
    void* kernel_args_var_62[] = {&var_340, &var_341, &var_342, &var_343, &var_344, &var_345, &var_346};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_62 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_62.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_62.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_62.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_62.grid_z, 2, 8, kernel_args_var_62, stream);
    }
    auto buf129 = std::move(buf125);  // reuse
    // Topologically Sorted Source Nodes: [linear_31], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_44 == nullptr) {
        kernels.triton_tem_fused_addmm_44 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cbbydhk3gwpah4ui2stxm6hvewbiwwehb4rx6dsvt7s7euryj6mh.cubin", "triton_tem_fused_addmm_44", 18432, this->cubin_dir_);
    }
    CUdeviceptr var_347 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_348 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_31.data_ptr());
    CUdeviceptr var_349 = reinterpret_cast<CUdeviceptr>(buf129.data_ptr());
    int32_t var_350 = s0;
    void* kernel_args_var_63[] = {&var_347, &var_348, &var_349, &var_350};
    Grid triton_tem_fused_addmm_44_grid_63 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_44_grid_63.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_44, triton_tem_fused_addmm_44_grid_63.grid_x, triton_tem_fused_addmm_44_grid_63.grid_y, triton_tem_fused_addmm_44_grid_63.grid_z, 4, 18432, kernel_args_var_63, stream);
    }
    auto tmp_tensor_handle_31 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 74688L);
    RAIIAtenTensorHandle tmp_tensor_handle_31_raii(tmp_tensor_handle_31);
    decltype(auto) buf382 = std::move(tmp_tensor_handle_31_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_31, layer_norm_31], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_351 = reinterpret_cast<CUdeviceptr>(buf129.data_ptr());
    CUdeviceptr var_352 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_353 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_354 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_355 = reinterpret_cast<CUdeviceptr>(buf382.data_ptr());
    int32_t var_356 = s0;
    int var_357 = 192L;
    void* kernel_args_var_64[] = {&var_351, &var_352, &var_353, &var_354, &var_355, &var_356, &var_357};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_64 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_64.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_64.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_64.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_64.grid_z, 2, 8, kernel_args_var_64, stream);
    }
    auto buf133 = std::move(buf129);  // reuse
    // Topologically Sorted Source Nodes: [linear_32], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_45 == nullptr) {
        kernels.triton_tem_fused_addmm_45 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cszfj4vbh6jcyntegsi3dylwdrlcxqnil7ak6xfx3rlz3zkzb73e.cubin", "triton_tem_fused_addmm_45", 18432, this->cubin_dir_);
    }
    CUdeviceptr var_358 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_359 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_32.data_ptr());
    CUdeviceptr var_360 = reinterpret_cast<CUdeviceptr>(buf133.data_ptr());
    int32_t var_361 = s0;
    void* kernel_args_var_65[] = {&var_358, &var_359, &var_360, &var_361};
    Grid triton_tem_fused_addmm_45_grid_65 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_45_grid_65.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_45, triton_tem_fused_addmm_45_grid_65.grid_x, triton_tem_fused_addmm_45_grid_65.grid_y, triton_tem_fused_addmm_45_grid_65.grid_z, 8, 18432, kernel_args_var_65, stream);
    }
    auto tmp_tensor_handle_32 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 74880L);
    RAIIAtenTensorHandle tmp_tensor_handle_32_raii(tmp_tensor_handle_32);
    decltype(auto) buf383 = std::move(tmp_tensor_handle_32_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_32, layer_norm_32], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_362 = reinterpret_cast<CUdeviceptr>(buf133.data_ptr());
    CUdeviceptr var_363 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_364 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_365 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_366 = reinterpret_cast<CUdeviceptr>(buf383.data_ptr());
    int32_t var_367 = s0;
    int var_368 = 192L;
    void* kernel_args_var_66[] = {&var_362, &var_363, &var_364, &var_365, &var_366, &var_367, &var_368};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_66 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_66.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_66.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_66.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_66.grid_z, 2, 8, kernel_args_var_66, stream);
    }
    auto buf137 = std::move(buf133);  // reuse
    // Topologically Sorted Source Nodes: [linear_33], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_46 == nullptr) {
        kernels.triton_tem_fused_addmm_46 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cv6hamlvd3nb7bszbdy5s5ybmsz2nwdnwrunns5ijeupgg6mewrp.cubin", "triton_tem_fused_addmm_46", 18432, this->cubin_dir_);
    }
    CUdeviceptr var_369 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_370 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_33.data_ptr());
    CUdeviceptr var_371 = reinterpret_cast<CUdeviceptr>(buf137.data_ptr());
    int32_t var_372 = s0;
    void* kernel_args_var_67[] = {&var_369, &var_370, &var_371, &var_372};
    Grid triton_tem_fused_addmm_46_grid_67 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_46_grid_67.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_46, triton_tem_fused_addmm_46_grid_67.grid_x, triton_tem_fused_addmm_46_grid_67.grid_y, triton_tem_fused_addmm_46_grid_67.grid_z, 8, 18432, kernel_args_var_67, stream);
    }
    auto tmp_tensor_handle_33 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 75072L);
    RAIIAtenTensorHandle tmp_tensor_handle_33_raii(tmp_tensor_handle_33);
    decltype(auto) buf384 = std::move(tmp_tensor_handle_33_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_33, layer_norm_33], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_373 = reinterpret_cast<CUdeviceptr>(buf137.data_ptr());
    CUdeviceptr var_374 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_375 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_376 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_377 = reinterpret_cast<CUdeviceptr>(buf384.data_ptr());
    int32_t var_378 = s0;
    int var_379 = 192L;
    void* kernel_args_var_68[] = {&var_373, &var_374, &var_375, &var_376, &var_377, &var_378, &var_379};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_68 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_68.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_68.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_68.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_68.grid_z, 2, 8, kernel_args_var_68, stream);
    }
    auto buf141 = std::move(buf137);  // reuse
    // Topologically Sorted Source Nodes: [linear_34], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_47 == nullptr) {
        kernels.triton_tem_fused_addmm_47 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cmr5rdw2vn2sc6kk3uqv6zv5gbmyeh27mvemrmaxrsh6bywnjyhk.cubin", "triton_tem_fused_addmm_47", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_380 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_381 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_34.data_ptr());
    CUdeviceptr var_382 = reinterpret_cast<CUdeviceptr>(buf141.data_ptr());
    int32_t var_383 = s0;
    void* kernel_args_var_69[] = {&var_380, &var_381, &var_382, &var_383};
    Grid triton_tem_fused_addmm_47_grid_69 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_47_grid_69.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_47, triton_tem_fused_addmm_47_grid_69.grid_x, triton_tem_fused_addmm_47_grid_69.grid_y, triton_tem_fused_addmm_47_grid_69.grid_z, 8, 49152, kernel_args_var_69, stream);
    }
    auto tmp_tensor_handle_34 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 75264L);
    RAIIAtenTensorHandle tmp_tensor_handle_34_raii(tmp_tensor_handle_34);
    decltype(auto) buf385 = std::move(tmp_tensor_handle_34_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_34, layer_norm_34], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_384 = reinterpret_cast<CUdeviceptr>(buf141.data_ptr());
    CUdeviceptr var_385 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_386 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_387 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_388 = reinterpret_cast<CUdeviceptr>(buf385.data_ptr());
    int32_t var_389 = s0;
    int var_390 = 192L;
    void* kernel_args_var_70[] = {&var_384, &var_385, &var_386, &var_387, &var_388, &var_389, &var_390};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_70 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_70.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_70.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_70.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_70.grid_z, 2, 8, kernel_args_var_70, stream);
    }
    auto buf145 = std::move(buf141);  // reuse
    // Topologically Sorted Source Nodes: [linear_35], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_48 == nullptr) {
        kernels.triton_tem_fused_addmm_48 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c662mjhi3tofty5drfqfhe56hgy3uxgbxz7mfhmimbk2rrgqct3i.cubin", "triton_tem_fused_addmm_48", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_391 = reinterpret_cast<CUdeviceptr>(arg607_1.data_ptr());
    CUdeviceptr var_392 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_35.data_ptr());
    CUdeviceptr var_393 = reinterpret_cast<CUdeviceptr>(buf145.data_ptr());
    int32_t var_394 = s0;
    void* kernel_args_var_71[] = {&var_391, &var_392, &var_393, &var_394};
    Grid triton_tem_fused_addmm_48_grid_71 = Grid(2L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_48_grid_71.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_48, triton_tem_fused_addmm_48_grid_71.grid_x, triton_tem_fused_addmm_48_grid_71.grid_y, triton_tem_fused_addmm_48_grid_71.grid_z, 8, 49152, kernel_args_var_71, stream);
    }
    arg607_1.reset();
    auto tmp_tensor_handle_35 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 75456L);
    RAIIAtenTensorHandle tmp_tensor_handle_35_raii(tmp_tensor_handle_35);
    decltype(auto) buf386 = std::move(tmp_tensor_handle_35_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_35, layer_norm_35], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_395 = reinterpret_cast<CUdeviceptr>(buf145.data_ptr());
    CUdeviceptr var_396 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_397 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale.data_ptr());
    CUdeviceptr var_398 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias.data_ptr());
    CUdeviceptr var_399 = reinterpret_cast<CUdeviceptr>(buf386.data_ptr());
    int32_t var_400 = s0;
    int var_401 = 192L;
    void* kernel_args_var_72[] = {&var_395, &var_396, &var_397, &var_398, &var_399, &var_400, &var_401};
    Grid triton_per_fused_addmm_native_layer_norm_13_grid_72 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_13_grid_72.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_13, triton_per_fused_addmm_native_layer_norm_13_grid_72.grid_x, triton_per_fused_addmm_native_layer_norm_13_grid_72.grid_y, triton_per_fused_addmm_native_layer_norm_13_grid_72.grid_z, 2, 8, kernel_args_var_72, stream);
    }
    buf145.reset();
    const int64_t int_array_40[] = {s0, 6056L};
    static constexpr int64_t int_array_41[] = {6056L, 1L};
    AtenTensorHandle buf149_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_40, int_array_41, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf149_handle));
    RAIIAtenTensorHandle buf149(buf149_handle);
    // Topologically Sorted Source Nodes: [cat_default_11, linear_default], Original ATen: [aten.cat, aten.addmm]
    int64_t triton_poi_fused_addmm_cat_49_xnumel = 6056L*s0;
    if (kernels.triton_poi_fused_addmm_cat_49 == nullptr) {
        kernels.triton_poi_fused_addmm_cat_49 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ct6nmg34pghh653tmbfrpkhlrijyb2k7f77wobsqcuiyvhqkxiag.cubin", "triton_poi_fused_addmm_cat_49", 0, this->cubin_dir_);
    }
    CUdeviceptr var_402 = reinterpret_cast<CUdeviceptr>(arg606_1.data_ptr());
    CUdeviceptr var_403 = reinterpret_cast<CUdeviceptr>(buf149.data_ptr());
    int32_t var_404 = triton_poi_fused_addmm_cat_49_xnumel;
    void* kernel_args_var_73[] = {&var_402, &var_403, &var_404};
    Grid triton_poi_fused_addmm_cat_49_grid_73 = Grid((-1L)*static_cast<int64_t>(std::floor((-757.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_cat_49_grid_73.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_cat_49, triton_poi_fused_addmm_cat_49_grid_73.grid_x, triton_poi_fused_addmm_cat_49_grid_73.grid_y, triton_poi_fused_addmm_cat_49_grid_73.grid_z, 8, 0, kernel_args_var_73, stream);
    }
    const int64_t int_array_42[] = {s0, 256L};
    static constexpr int64_t int_array_43[] = {256L, 1L};
    AtenTensorHandle buf150_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_42, int_array_43, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf150_handle));
    RAIIAtenTensorHandle buf150(buf150_handle);
    // Topologically Sorted Source Nodes: [cat_default_11, linear_default], Original ATen: [aten.cat, aten.addmm]
    if (kernels.triton_tem_fused_addmm_cat_50 == nullptr) {
        kernels.triton_tem_fused_addmm_cat_50 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cidwluuplfskjwz6entvkkttew4j2ogfmrhlejcvinhnfgugjtdj.cubin", "triton_tem_fused_addmm_cat_50", 163840, this->cubin_dir_);
    }
    CUdeviceptr var_405 = reinterpret_cast<CUdeviceptr>(buf149.data_ptr());
    CUdeviceptr var_406 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_constant_pad_nd_default_23.data_ptr());
    CUdeviceptr var_407 = reinterpret_cast<CUdeviceptr>(buf150.data_ptr());
    int32_t var_408 = s0;
    void* kernel_args_var_74[] = {&var_405, &var_406, &var_407, &var_408};
    Grid triton_tem_fused_addmm_cat_50_grid_74 = Grid(4L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_cat_50_grid_74.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_cat_50, triton_tem_fused_addmm_cat_50_grid_74.grid_x, triton_tem_fused_addmm_cat_50_grid_74.grid_y, triton_tem_fused_addmm_cat_50_grid_74.grid_z, 4, 163840, kernel_args_var_74, stream);
    }
    buf149.reset();
    auto buf186 = std::move(buf150);  // reuse
    // Topologically Sorted Source Nodes: [linear_default, layer_norm_36, sigmoid, mul_477], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51 == nullptr) {
        kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cberbyj3rezbo77kanr6dl7fayjhjytjxhoucbtt3kz7vgo6zbl4.cubin", "triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51", 8, this->cubin_dir_);
    }
    CUdeviceptr var_409 = reinterpret_cast<CUdeviceptr>(buf186.data_ptr());
    CUdeviceptr var_410 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_3.data_ptr());
    CUdeviceptr var_411 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale.data_ptr());
    CUdeviceptr var_412 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias.data_ptr());
    int32_t var_413 = s0;
    int var_414 = 256L;
    void* kernel_args_var_75[] = {&var_409, &var_410, &var_411, &var_412, &var_413, &var_414};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51_grid_75 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51_grid_75.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51_grid_75.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51_grid_75.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_51_grid_75.grid_z, 2, 8, kernel_args_var_75, stream);
    }
    const int64_t int_array_44[] = {s0, 700L};
    static constexpr int64_t int_array_45[] = {700L, 1L};
    AtenTensorHandle buf169_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_44, int_array_45, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf169_handle));
    RAIIAtenTensorHandle buf169(buf169_handle);
    const int64_t int_array_2[] = {s0, 36L};
    static constexpr int64_t int_array_3[] = {700L, 1L};
    auto tmp_tensor_handle_36 = reinterpret_tensor_wrapper(buf169, 2, int_array_2, int_array_3, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_36_raii(tmp_tensor_handle_36);
    decltype(auto) buf154 = std::move(tmp_tensor_handle_36_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_52_xnumel = 36L*s0;
    if (kernels.triton_poi_fused_cat_52 == nullptr) {
        kernels.triton_poi_fused_cat_52 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cogrle4vykpwbl4sqhza2qxdrrkaecp6t5ecxhl63lxzfpnft5dr.cubin", "triton_poi_fused_cat_52", 0, this->cubin_dir_);
    }
    CUdeviceptr var_415 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_416 = reinterpret_cast<CUdeviceptr>(buf154.data_ptr());
    int32_t var_417 = triton_poi_fused_cat_52_xnumel;
    void* kernel_args_var_76[] = {&var_415, &var_416, &var_417};
    Grid triton_poi_fused_cat_52_grid_76 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/128.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_52_grid_76.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_52, triton_poi_fused_cat_52_grid_76.grid_x, triton_poi_fused_cat_52_grid_76.grid_y, triton_poi_fused_cat_52_grid_76.grid_z, 8, 0, kernel_args_var_76, stream);
    }
    const int64_t int_array_4[] = {s0, 28L};
    auto tmp_tensor_handle_37 = reinterpret_tensor_wrapper(buf169, 2, int_array_4, int_array_3, 36L);
    RAIIAtenTensorHandle tmp_tensor_handle_37_raii(tmp_tensor_handle_37);
    decltype(auto) buf155 = std::move(tmp_tensor_handle_37_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_53_xnumel = 28L*s0;
    if (kernels.triton_poi_fused_cat_53 == nullptr) {
        kernels.triton_poi_fused_cat_53 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cn2przwxw334x7pbromibavklvixoptw5jamdixy7532t3nlszhx.cubin", "triton_poi_fused_cat_53", 1024, this->cubin_dir_);
    }
    CUdeviceptr var_418 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_419 = reinterpret_cast<CUdeviceptr>(buf155.data_ptr());
    int32_t var_420 = triton_poi_fused_cat_53_xnumel;
    void* kernel_args_var_77[] = {&var_418, &var_419, &var_420};
    Grid triton_poi_fused_cat_53_grid_77 = Grid((-1L)*static_cast<int64_t>(std::floor((-7.0/128.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_53_grid_77.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_53, triton_poi_fused_cat_53_grid_77.grid_x, triton_poi_fused_cat_53_grid_77.grid_y, triton_poi_fused_cat_53_grid_77.grid_z, 4, 1024, kernel_args_var_77, stream);
    }
    const int64_t int_array_5[] = {s0, 228L};
    auto tmp_tensor_handle_38 = reinterpret_tensor_wrapper(buf169, 2, int_array_5, int_array_3, 64L);
    RAIIAtenTensorHandle tmp_tensor_handle_38_raii(tmp_tensor_handle_38);
    decltype(auto) buf156 = std::move(tmp_tensor_handle_38_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_54_xnumel = 228L*s0;
    if (kernels.triton_poi_fused_cat_54 == nullptr) {
        kernels.triton_poi_fused_cat_54 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/czs7lrdsrtha5d3ajrm75l2njsu6rjjemqqyo2tzyyp5ggyzu47h.cubin", "triton_poi_fused_cat_54", 0, this->cubin_dir_);
    }
    CUdeviceptr var_421 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_422 = reinterpret_cast<CUdeviceptr>(buf156.data_ptr());
    int32_t var_423 = triton_poi_fused_cat_54_xnumel;
    void* kernel_args_var_78[] = {&var_421, &var_422, &var_423};
    Grid triton_poi_fused_cat_54_grid_78 = Grid((-1L)*static_cast<int64_t>(std::floor((-57.0/256.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_54_grid_78.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_54, triton_poi_fused_cat_54_grid_78.grid_x, triton_poi_fused_cat_54_grid_78.grid_y, triton_poi_fused_cat_54_grid_78.grid_z, 4, 0, kernel_args_var_78, stream);
    }
    const int64_t int_array_6[] = {s0, 16L};
    auto tmp_tensor_handle_39 = reinterpret_tensor_wrapper(buf169, 2, int_array_6, int_array_3, 292L);
    RAIIAtenTensorHandle tmp_tensor_handle_39_raii(tmp_tensor_handle_39);
    decltype(auto) buf157 = std::move(tmp_tensor_handle_39_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_55_xnumel = 16L*s0;
    if (kernels.triton_poi_fused_cat_55 == nullptr) {
        kernels.triton_poi_fused_cat_55 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ct7jbrnjqakgfco6m4zjg2jzwvsmrpbbdiwcyofckclhr424ho7r.cubin", "triton_poi_fused_cat_55", 0, this->cubin_dir_);
    }
    CUdeviceptr var_424 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_425 = reinterpret_cast<CUdeviceptr>(buf157.data_ptr());
    int32_t var_426 = triton_poi_fused_cat_55_xnumel;
    void* kernel_args_var_79[] = {&var_424, &var_425, &var_426};
    Grid triton_poi_fused_cat_55_grid_79 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_55_grid_79.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_55, triton_poi_fused_cat_55_grid_79.grid_x, triton_poi_fused_cat_55_grid_79.grid_y, triton_poi_fused_cat_55_grid_79.grid_z, 4, 0, kernel_args_var_79, stream);
    }
    const int64_t int_array_7[] = {s0, 32L};
    auto tmp_tensor_handle_40 = reinterpret_tensor_wrapper(buf169, 2, int_array_7, int_array_3, 308L);
    RAIIAtenTensorHandle tmp_tensor_handle_40_raii(tmp_tensor_handle_40);
    decltype(auto) buf158 = std::move(tmp_tensor_handle_40_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_56_xnumel = 32L*s0;
    if (kernels.triton_poi_fused_cat_56 == nullptr) {
        kernels.triton_poi_fused_cat_56 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cigpttxrldty67gkq4dgzvel7fb3lb7ukluqc7gxlbciyskxiu22.cubin", "triton_poi_fused_cat_56", 512, this->cubin_dir_);
    }
    CUdeviceptr var_427 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_428 = reinterpret_cast<CUdeviceptr>(buf158.data_ptr());
    int32_t var_429 = triton_poi_fused_cat_56_xnumel;
    void* kernel_args_var_80[] = {&var_427, &var_428, &var_429};
    Grid triton_poi_fused_cat_56_grid_80 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_56_grid_80.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_56, triton_poi_fused_cat_56_grid_80.grid_x, triton_poi_fused_cat_56_grid_80.grid_y, triton_poi_fused_cat_56_grid_80.grid_z, 4, 512, kernel_args_var_80, stream);
    }
    auto tmp_tensor_handle_41 = reinterpret_tensor_wrapper(buf169, 2, int_array_7, int_array_3, 340L);
    RAIIAtenTensorHandle tmp_tensor_handle_41_raii(tmp_tensor_handle_41);
    decltype(auto) buf159 = std::move(tmp_tensor_handle_41_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_57_xnumel = 32L*s0;
    if (kernels.triton_poi_fused_cat_57 == nullptr) {
        kernels.triton_poi_fused_cat_57 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/citwp5oyn3oaynxwzp6mzdjghragub577jzlzawq7o6qqjxtdhwc.cubin", "triton_poi_fused_cat_57", 512, this->cubin_dir_);
    }
    CUdeviceptr var_430 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_431 = reinterpret_cast<CUdeviceptr>(buf159.data_ptr());
    int32_t var_432 = triton_poi_fused_cat_57_xnumel;
    void* kernel_args_var_81[] = {&var_430, &var_431, &var_432};
    Grid triton_poi_fused_cat_57_grid_81 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_57_grid_81.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_57, triton_poi_fused_cat_57_grid_81.grid_x, triton_poi_fused_cat_57_grid_81.grid_y, triton_poi_fused_cat_57_grid_81.grid_z, 4, 512, kernel_args_var_81, stream);
    }
    auto tmp_tensor_handle_42 = reinterpret_tensor_wrapper(buf169, 2, int_array_7, int_array_3, 372L);
    RAIIAtenTensorHandle tmp_tensor_handle_42_raii(tmp_tensor_handle_42);
    decltype(auto) buf160 = std::move(tmp_tensor_handle_42_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_58_xnumel = 32L*s0;
    if (kernels.triton_poi_fused_cat_58 == nullptr) {
        kernels.triton_poi_fused_cat_58 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ctnwwibr5zzwcagukdzxug7e4pl2jef5q6ybbzj44ovxmuzppl63.cubin", "triton_poi_fused_cat_58", 512, this->cubin_dir_);
    }
    CUdeviceptr var_433 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_434 = reinterpret_cast<CUdeviceptr>(buf160.data_ptr());
    int32_t var_435 = triton_poi_fused_cat_58_xnumel;
    void* kernel_args_var_82[] = {&var_433, &var_434, &var_435};
    Grid triton_poi_fused_cat_58_grid_82 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_58_grid_82.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_58, triton_poi_fused_cat_58_grid_82.grid_x, triton_poi_fused_cat_58_grid_82.grid_y, triton_poi_fused_cat_58_grid_82.grid_z, 4, 512, kernel_args_var_82, stream);
    }
    auto tmp_tensor_handle_43 = reinterpret_tensor_wrapper(buf169, 2, int_array_7, int_array_3, 404L);
    RAIIAtenTensorHandle tmp_tensor_handle_43_raii(tmp_tensor_handle_43);
    decltype(auto) buf161 = std::move(tmp_tensor_handle_43_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_59_xnumel = 32L*s0;
    if (kernels.triton_poi_fused_cat_59 == nullptr) {
        kernels.triton_poi_fused_cat_59 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cgjcsgxmtetczvu5kei2ncnuxeasovcstbg7ooixhd3byo5cnk3y.cubin", "triton_poi_fused_cat_59", 512, this->cubin_dir_);
    }
    CUdeviceptr var_436 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_437 = reinterpret_cast<CUdeviceptr>(buf161.data_ptr());
    int32_t var_438 = triton_poi_fused_cat_59_xnumel;
    void* kernel_args_var_83[] = {&var_436, &var_437, &var_438};
    Grid triton_poi_fused_cat_59_grid_83 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_59_grid_83.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_59, triton_poi_fused_cat_59_grid_83.grid_x, triton_poi_fused_cat_59_grid_83.grid_y, triton_poi_fused_cat_59_grid_83.grid_z, 4, 512, kernel_args_var_83, stream);
    }
    const int64_t int_array_8[] = {s0, 80L};
    auto tmp_tensor_handle_44 = reinterpret_tensor_wrapper(buf169, 2, int_array_8, int_array_3, 436L);
    RAIIAtenTensorHandle tmp_tensor_handle_44_raii(tmp_tensor_handle_44);
    decltype(auto) buf162 = std::move(tmp_tensor_handle_44_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_60_xnumel = 80L*s0;
    if (kernels.triton_poi_fused_cat_60 == nullptr) {
        kernels.triton_poi_fused_cat_60 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/crywr7sjycwy7bgrfcv7uwreje25yxbwewkm7h2psufhuxfj3ryj.cubin", "triton_poi_fused_cat_60", 1024, this->cubin_dir_);
    }
    CUdeviceptr var_439 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_440 = reinterpret_cast<CUdeviceptr>(buf162.data_ptr());
    int32_t var_441 = triton_poi_fused_cat_60_xnumel;
    void* kernel_args_var_84[] = {&var_439, &var_440, &var_441};
    Grid triton_poi_fused_cat_60_grid_84 = Grid((-1L)*static_cast<int64_t>(std::floor((-5.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_60_grid_84.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_60, triton_poi_fused_cat_60_grid_84.grid_x, triton_poi_fused_cat_60_grid_84.grid_y, triton_poi_fused_cat_60_grid_84.grid_z, 4, 1024, kernel_args_var_84, stream);
    }
    auto tmp_tensor_handle_45 = reinterpret_tensor_wrapper(buf169, 2, int_array_6, int_array_3, 516L);
    RAIIAtenTensorHandle tmp_tensor_handle_45_raii(tmp_tensor_handle_45);
    decltype(auto) buf163 = std::move(tmp_tensor_handle_45_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_61_xnumel = 16L*s0;
    if (kernels.triton_poi_fused_cat_61 == nullptr) {
        kernels.triton_poi_fused_cat_61 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cwylyczaeafd7mlqkdaq2tjpkx5zs5fhnpprytng34oevppke6sp.cubin", "triton_poi_fused_cat_61", 512, this->cubin_dir_);
    }
    CUdeviceptr var_442 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_443 = reinterpret_cast<CUdeviceptr>(buf163.data_ptr());
    int32_t var_444 = triton_poi_fused_cat_61_xnumel;
    void* kernel_args_var_85[] = {&var_442, &var_443, &var_444};
    Grid triton_poi_fused_cat_61_grid_85 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_61_grid_85.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_61, triton_poi_fused_cat_61_grid_85.grid_x, triton_poi_fused_cat_61_grid_85.grid_y, triton_poi_fused_cat_61_grid_85.grid_z, 4, 512, kernel_args_var_85, stream);
    }
    auto tmp_tensor_handle_46 = reinterpret_tensor_wrapper(buf169, 2, int_array_7, int_array_3, 532L);
    RAIIAtenTensorHandle tmp_tensor_handle_46_raii(tmp_tensor_handle_46);
    decltype(auto) buf164 = std::move(tmp_tensor_handle_46_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_62_xnumel = 32L*s0;
    if (kernels.triton_poi_fused_cat_62 == nullptr) {
        kernels.triton_poi_fused_cat_62 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/czjmqnqbqy5ybu3mykbefwmacviswaeqspac36iguhsl5cvul5iu.cubin", "triton_poi_fused_cat_62", 512, this->cubin_dir_);
    }
    CUdeviceptr var_445 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_446 = reinterpret_cast<CUdeviceptr>(buf164.data_ptr());
    int32_t var_447 = triton_poi_fused_cat_62_xnumel;
    void* kernel_args_var_86[] = {&var_445, &var_446, &var_447};
    Grid triton_poi_fused_cat_62_grid_86 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_62_grid_86.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_62, triton_poi_fused_cat_62_grid_86.grid_x, triton_poi_fused_cat_62_grid_86.grid_y, triton_poi_fused_cat_62_grid_86.grid_z, 4, 512, kernel_args_var_86, stream);
    }
    auto tmp_tensor_handle_47 = reinterpret_tensor_wrapper(buf169, 2, int_array_7, int_array_3, 564L);
    RAIIAtenTensorHandle tmp_tensor_handle_47_raii(tmp_tensor_handle_47);
    decltype(auto) buf165 = std::move(tmp_tensor_handle_47_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_63_xnumel = 32L*s0;
    if (kernels.triton_poi_fused_cat_63 == nullptr) {
        kernels.triton_poi_fused_cat_63 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckpk4m33bvcwhftehyrxz6yaxelxqgxagra5wwkdo4ljjealg2z2.cubin", "triton_poi_fused_cat_63", 1024, this->cubin_dir_);
    }
    CUdeviceptr var_448 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_449 = reinterpret_cast<CUdeviceptr>(buf165.data_ptr());
    int32_t var_450 = triton_poi_fused_cat_63_xnumel;
    void* kernel_args_var_87[] = {&var_448, &var_449, &var_450};
    Grid triton_poi_fused_cat_63_grid_87 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_63_grid_87.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_63, triton_poi_fused_cat_63_grid_87.grid_x, triton_poi_fused_cat_63_grid_87.grid_y, triton_poi_fused_cat_63_grid_87.grid_z, 4, 1024, kernel_args_var_87, stream);
    }
    auto tmp_tensor_handle_48 = reinterpret_tensor_wrapper(buf169, 2, int_array_6, int_array_3, 596L);
    RAIIAtenTensorHandle tmp_tensor_handle_48_raii(tmp_tensor_handle_48);
    decltype(auto) buf166 = std::move(tmp_tensor_handle_48_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_64_xnumel = 16L*s0;
    if (kernels.triton_poi_fused_cat_64 == nullptr) {
        kernels.triton_poi_fused_cat_64 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cz36vljzz2qcq2bzovc3uei776mmsdcwnmnafv6crzcgp3f6iarm.cubin", "triton_poi_fused_cat_64", 0, this->cubin_dir_);
    }
    CUdeviceptr var_451 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_452 = reinterpret_cast<CUdeviceptr>(buf166.data_ptr());
    int32_t var_453 = triton_poi_fused_cat_64_xnumel;
    void* kernel_args_var_88[] = {&var_451, &var_452, &var_453};
    Grid triton_poi_fused_cat_64_grid_88 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_64_grid_88.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_64, triton_poi_fused_cat_64_grid_88.grid_x, triton_poi_fused_cat_64_grid_88.grid_y, triton_poi_fused_cat_64_grid_88.grid_z, 4, 0, kernel_args_var_88, stream);
    }
    auto tmp_tensor_handle_49 = reinterpret_tensor_wrapper(buf169, 2, int_array_6, int_array_3, 612L);
    RAIIAtenTensorHandle tmp_tensor_handle_49_raii(tmp_tensor_handle_49);
    decltype(auto) buf167 = std::move(tmp_tensor_handle_49_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_65_xnumel = 16L*s0;
    if (kernels.triton_poi_fused_cat_65 == nullptr) {
        kernels.triton_poi_fused_cat_65 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cd7ryofc2o2jxaq6iosfor5oqcmjrbbswndfnbix5lj434gzavva.cubin", "triton_poi_fused_cat_65", 512, this->cubin_dir_);
    }
    CUdeviceptr var_454 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_455 = reinterpret_cast<CUdeviceptr>(buf167.data_ptr());
    int32_t var_456 = triton_poi_fused_cat_65_xnumel;
    void* kernel_args_var_89[] = {&var_454, &var_455, &var_456};
    Grid triton_poi_fused_cat_65_grid_89 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_65_grid_89.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_65, triton_poi_fused_cat_65_grid_89.grid_x, triton_poi_fused_cat_65_grid_89.grid_y, triton_poi_fused_cat_65_grid_89.grid_z, 4, 512, kernel_args_var_89, stream);
    }
    const int64_t int_array_9[] = {s0, 72L};
    auto tmp_tensor_handle_50 = reinterpret_tensor_wrapper(buf169, 2, int_array_9, int_array_3, 628L);
    RAIIAtenTensorHandle tmp_tensor_handle_50_raii(tmp_tensor_handle_50);
    decltype(auto) buf168 = std::move(tmp_tensor_handle_50_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_9], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_66_xnumel = 72L*s0;
    if (kernels.triton_poi_fused_cat_66 == nullptr) {
        kernels.triton_poi_fused_cat_66 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/culjyrw6xf7r577gd6jkecvprzk5ocsfaj44gobar46cjx2v5wap.cubin", "triton_poi_fused_cat_66", 1024, this->cubin_dir_);
    }
    CUdeviceptr var_457 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_458 = reinterpret_cast<CUdeviceptr>(buf168.data_ptr());
    int32_t var_459 = triton_poi_fused_cat_66_xnumel;
    void* kernel_args_var_90[] = {&var_457, &var_458, &var_459};
    Grid triton_poi_fused_cat_66_grid_90 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/128.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_66_grid_90.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_66, triton_poi_fused_cat_66_grid_90.grid_x, triton_poi_fused_cat_66_grid_90.grid_y, triton_poi_fused_cat_66_grid_90.grid_z, 4, 1024, kernel_args_var_90, stream);
    }
    buf154.reset();
    buf155.reset();
    buf156.reset();
    buf157.reset();
    buf158.reset();
    buf159.reset();
    buf160.reset();
    buf161.reset();
    buf162.reset();
    buf163.reset();
    buf164.reset();
    buf165.reset();
    buf166.reset();
    buf167.reset();
    buf168.reset();
    const int64_t int_array_46[] = {s0, 512L};
    static constexpr int64_t int_array_47[] = {512L, 1L};
    AtenTensorHandle buf170_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_46, int_array_47, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf170_handle));
    RAIIAtenTensorHandle buf170(buf170_handle);
    // Topologically Sorted Source Nodes: [linear_default_1], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_67 == nullptr) {
        kernels.triton_tem_fused_addmm_67 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cabwypkngum4onu7d6derkivvu7kechfk77hrqsebhbeqhpwkfvq.cubin", "triton_tem_fused_addmm_67", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_460 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_6.data_ptr());
    CUdeviceptr var_461 = reinterpret_cast<CUdeviceptr>(buf169.data_ptr());
    CUdeviceptr var_462 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_37.data_ptr());
    CUdeviceptr var_463 = reinterpret_cast<CUdeviceptr>(buf170.data_ptr());
    int32_t var_464 = s0;
    void* kernel_args_var_91[] = {&var_460, &var_461, &var_462, &var_463, &var_464};
    Grid triton_tem_fused_addmm_67_grid_91 = Grid(8L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_67_grid_91.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_67, triton_tem_fused_addmm_67_grid_91.grid_x, triton_tem_fused_addmm_67_grid_91.grid_y, triton_tem_fused_addmm_67_grid_91.grid_z, 8, 49152, kernel_args_var_91, stream);
    }
    buf169.reset();
    AtenTensorHandle buf195_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_42, int_array_43, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf195_handle));
    RAIIAtenTensorHandle buf195(buf195_handle);
    // Topologically Sorted Source Nodes: [contiguous_2, layer_norm_37, sigmoid_1, mul_508], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_68 == nullptr) {
        kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_68 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cp6nxti4thk6q24n7hffg54f5tym65j3jlvp4b5emjd5bd7obiv4.cubin", "triton_per_fused_clone_mul_native_layer_norm_sigmoid_68", 8, this->cubin_dir_);
    }
    CUdeviceptr var_465 = reinterpret_cast<CUdeviceptr>(buf170.data_ptr());
    CUdeviceptr var_466 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale.data_ptr());
    CUdeviceptr var_467 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias.data_ptr());
    CUdeviceptr var_468 = reinterpret_cast<CUdeviceptr>(buf195.data_ptr());
    int32_t var_469 = s0;
    int var_470 = 256L;
    void* kernel_args_var_92[] = {&var_465, &var_466, &var_467, &var_468, &var_469, &var_470};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_68_grid_92 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_68_grid_92.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_68, triton_per_fused_clone_mul_native_layer_norm_sigmoid_68_grid_92.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_68_grid_92.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_68_grid_92.grid_z, 2, 8, kernel_args_var_92, stream);
    }
    const int64_t int_array_48[] = {s0, 200L, 64L};
    static constexpr int64_t int_array_49[] = {12800L, 64L, 1L};
    AtenTensorHandle buf202_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_48, int_array_49, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf202_handle));
    RAIIAtenTensorHandle buf202(buf202_handle);
    // Topologically Sorted Source Nodes: [add_779, layer_norm_38], Original ATen: [aten.add, aten.native_layer_norm]
    int64_t triton_per_fused_add_native_layer_norm_69_xnumel = 200L*s0;
    if (kernels.triton_per_fused_add_native_layer_norm_69 == nullptr) {
        kernels.triton_per_fused_add_native_layer_norm_69 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cqegdfvtvqck4v4xzwor4rtpd6eghzm77reagkkpxnblpeu3brm3.cubin", "triton_per_fused_add_native_layer_norm_69", 0, this->cubin_dir_);
    }
    CUdeviceptr var_471 = reinterpret_cast<CUdeviceptr>(arg613_1.data_ptr());
    CUdeviceptr var_472 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb.data_ptr());
    CUdeviceptr var_473 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight.data_ptr());
    CUdeviceptr var_474 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias.data_ptr());
    CUdeviceptr var_475 = reinterpret_cast<CUdeviceptr>(buf202.data_ptr());
    int32_t var_476 = triton_per_fused_add_native_layer_norm_69_xnumel;
    int var_477 = 64L;
    void* kernel_args_var_93[] = {&var_471, &var_472, &var_473, &var_474, &var_475, &var_476, &var_477};
    Grid triton_per_fused_add_native_layer_norm_69_grid_93 = Grid((-1L)*static_cast<int64_t>(std::floor((-25.0/4.0)*s0)), 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_69_grid_93.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_69, triton_per_fused_add_native_layer_norm_69_grid_93.grid_x, triton_per_fused_add_native_layer_norm_69_grid_93.grid_y, triton_per_fused_add_native_layer_norm_69_grid_93.grid_z, 8, 0, kernel_args_var_93, stream);
    }
    arg613_1.reset();
    AtenTensorHandle buf212_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_48, int_array_49, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf212_handle));
    RAIIAtenTensorHandle buf212(buf212_handle);
    // Topologically Sorted Source Nodes: [add_784, layer_norm_39], Original ATen: [aten.add, aten.native_layer_norm]
    triton_per_fused_add_native_layer_norm_69_xnumel = 200L*s0;
    CUdeviceptr var_478 = reinterpret_cast<CUdeviceptr>(arg614_1.data_ptr());
    CUdeviceptr var_479 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb.data_ptr());
    CUdeviceptr var_480 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight.data_ptr());
    CUdeviceptr var_481 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias.data_ptr());
    CUdeviceptr var_482 = reinterpret_cast<CUdeviceptr>(buf212.data_ptr());
    int32_t var_483 = triton_per_fused_add_native_layer_norm_69_xnumel;
    int var_484 = 64L;
    void* kernel_args_var_94[] = {&var_478, &var_479, &var_480, &var_481, &var_482, &var_483, &var_484};
    Grid triton_per_fused_add_native_layer_norm_69_grid_94 = Grid((-1L)*static_cast<int64_t>(std::floor((-25.0/4.0)*s0)), 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_69_grid_94.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_69, triton_per_fused_add_native_layer_norm_69_grid_94.grid_x, triton_per_fused_add_native_layer_norm_69_grid_94.grid_y, triton_per_fused_add_native_layer_norm_69_grid_94.grid_z, 8, 0, kernel_args_var_94, stream);
    }
    arg614_1.reset();
    const int64_t int_array_50[] = {s0, 32L, 64L};
    static constexpr int64_t int_array_51[] = {2048L, 64L, 1L};
    AtenTensorHandle buf200_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_50, int_array_51, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf200_handle));
    RAIIAtenTensorHandle buf200(buf200_handle);
    // Topologically Sorted Source Nodes: [repeat, layer_norm_40], Original ATen: [aten.repeat, aten.native_layer_norm]
    int64_t triton_per_fused_native_layer_norm_repeat_70_xnumel = 32L*s0;
    if (kernels.triton_per_fused_native_layer_norm_repeat_70 == nullptr) {
        kernels.triton_per_fused_native_layer_norm_repeat_70 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cy2q4m6kwg3x5vhozpbikx7cn433zn7hsl256a7uc4dxs4peosxn.cubin", "triton_per_fused_native_layer_norm_repeat_70", 0, this->cubin_dir_);
    }
    CUdeviceptr var_485 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb.data_ptr());
    CUdeviceptr var_486 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight.data_ptr());
    CUdeviceptr var_487 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias.data_ptr());
    CUdeviceptr var_488 = reinterpret_cast<CUdeviceptr>(buf200.data_ptr());
    int32_t var_489 = triton_per_fused_native_layer_norm_repeat_70_xnumel;
    int var_490 = 64L;
    void* kernel_args_var_95[] = {&var_485, &var_486, &var_487, &var_488, &var_489, &var_490};
    Grid triton_per_fused_native_layer_norm_repeat_70_grid_95 = Grid(s0, 1L, 1L);
    if (triton_per_fused_native_layer_norm_repeat_70_grid_95.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_native_layer_norm_repeat_70, triton_per_fused_native_layer_norm_repeat_70_grid_95.grid_x, triton_per_fused_native_layer_norm_repeat_70_grid_95.grid_y, triton_per_fused_native_layer_norm_repeat_70_grid_95.grid_z, 8, 0, kernel_args_var_95, stream);
    }
    AtenTensorHandle buf210_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_50, int_array_51, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf210_handle));
    RAIIAtenTensorHandle buf210(buf210_handle);
    // Topologically Sorted Source Nodes: [repeat_1, layer_norm_41], Original ATen: [aten.repeat, aten.native_layer_norm]
    triton_per_fused_native_layer_norm_repeat_70_xnumel = 32L*s0;
    CUdeviceptr var_491 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb.data_ptr());
    CUdeviceptr var_492 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight.data_ptr());
    CUdeviceptr var_493 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias.data_ptr());
    CUdeviceptr var_494 = reinterpret_cast<CUdeviceptr>(buf210.data_ptr());
    int32_t var_495 = triton_per_fused_native_layer_norm_repeat_70_xnumel;
    int var_496 = 64L;
    void* kernel_args_var_96[] = {&var_491, &var_492, &var_493, &var_494, &var_495, &var_496};
    Grid triton_per_fused_native_layer_norm_repeat_70_grid_96 = Grid(s0, 1L, 1L);
    if (triton_per_fused_native_layer_norm_repeat_70_grid_96.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_native_layer_norm_repeat_70, triton_per_fused_native_layer_norm_repeat_70_grid_96.grid_x, triton_per_fused_native_layer_norm_repeat_70_grid_96.grid_y, triton_per_fused_native_layer_norm_repeat_70_grid_96.grid_z, 8, 0, kernel_args_var_96, stream);
    }
    const int64_t int_array_52[] = {s0, 3026L};
    static constexpr int64_t int_array_53[] = {3026L, 1L};
    AtenTensorHandle buf187_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_52, int_array_53, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf187_handle));
    RAIIAtenTensorHandle buf187(buf187_handle);
    // Topologically Sorted Source Nodes: [linear_default, layer_norm_36, sigmoid, mul_477, linear_42], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71 == nullptr) {
        kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cwzvndgzv5xdquls5bkrpffx3jmtx2e3ljo23r4egero7j2pk3fg.cubin", "triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_497 = reinterpret_cast<CUdeviceptr>(buf186.data_ptr());
    CUdeviceptr var_498 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_40.data_ptr());
    CUdeviceptr var_499 = reinterpret_cast<CUdeviceptr>(buf187.data_ptr());
    int32_t var_500 = s0;
    void* kernel_args_var_97[] = {&var_497, &var_498, &var_499, &var_500};
    Grid triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71_grid_97 = Grid(24L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71_grid_97.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71_grid_97.grid_x, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71_grid_97.grid_y, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_71_grid_97.grid_z, 4, 49152, kernel_args_var_97, stream);
    }
    const int64_t int_array_54[] = {s0, 3282L};
    static constexpr int64_t int_array_55[] = {3282L, 1L};
    AtenTensorHandle buf191_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_54, int_array_55, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf191_handle));
    RAIIAtenTensorHandle buf191(buf191_handle);
    const int64_t int_array_10[] = {s0, 3026L};
    static constexpr int64_t int_array_11[] = {3282L, 1L};
    auto tmp_tensor_handle_51 = reinterpret_tensor_wrapper(buf191, 2, int_array_10, int_array_11, 256L);
    RAIIAtenTensorHandle tmp_tensor_handle_51_raii(tmp_tensor_handle_51);
    decltype(auto) buf188 = std::move(tmp_tensor_handle_51_raii);  // alias
    // Topologically Sorted Source Nodes: [linear_42, sigmoid_2, mul_497], Original ATen: [aten.addmm, aten.sigmoid, aten.mul]
    int64_t triton_poi_fused_addmm_mul_sigmoid_72_xnumel = 3026L*s0;
    if (kernels.triton_poi_fused_addmm_mul_sigmoid_72 == nullptr) {
        kernels.triton_poi_fused_addmm_mul_sigmoid_72 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cxbybojtkoatstxd3dpzym4pgwnneb2f3wxmatkqho5ttv5q4szg.cubin", "triton_poi_fused_addmm_mul_sigmoid_72", 2048, this->cubin_dir_);
    }
    CUdeviceptr var_501 = reinterpret_cast<CUdeviceptr>(arg606_1.data_ptr());
    CUdeviceptr var_502 = reinterpret_cast<CUdeviceptr>(buf187.data_ptr());
    CUdeviceptr var_503 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b.data_ptr());
    CUdeviceptr var_504 = reinterpret_cast<CUdeviceptr>(buf188.data_ptr());
    int32_t var_505 = triton_poi_fused_addmm_mul_sigmoid_72_xnumel;
    void* kernel_args_var_98[] = {&var_501, &var_502, &var_503, &var_504, &var_505};
    Grid triton_poi_fused_addmm_mul_sigmoid_72_grid_98 = Grid((-1L)*static_cast<int64_t>(std::floor((-1513.0/512.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_mul_sigmoid_72_grid_98.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_mul_sigmoid_72, triton_poi_fused_addmm_mul_sigmoid_72_grid_98.grid_x, triton_poi_fused_addmm_mul_sigmoid_72_grid_98.grid_y, triton_poi_fused_addmm_mul_sigmoid_72_grid_98.grid_z, 4, 2048, kernel_args_var_98, stream);
    }
    arg606_1.reset();
    buf187.reset();
    auto buf189 = std::move(buf186);  // reuse
    // Topologically Sorted Source Nodes: [linear_42, sigmoid_2, mul_497, linear_43], Original ATen: [aten.addmm, aten.sigmoid, aten.mul]
    if (kernels.triton_tem_fused_addmm_mul_sigmoid_73 == nullptr) {
        kernels.triton_tem_fused_addmm_mul_sigmoid_73 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/clheevpypyhltzf3y6mdxeh7vumgtmqp53n7qokdrgs4jtjcfqqh.cubin", "triton_tem_fused_addmm_mul_sigmoid_73", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_506 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b.data_ptr());
    CUdeviceptr var_507 = reinterpret_cast<CUdeviceptr>(buf188.data_ptr());
    CUdeviceptr var_508 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_41.data_ptr());
    CUdeviceptr var_509 = reinterpret_cast<CUdeviceptr>(buf189.data_ptr());
    int32_t var_510 = s0;
    void* kernel_args_var_99[] = {&var_506, &var_507, &var_508, &var_509, &var_510};
    Grid triton_tem_fused_addmm_mul_sigmoid_73_grid_99 = Grid(4L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_mul_sigmoid_73_grid_99.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_mul_sigmoid_73, triton_tem_fused_addmm_mul_sigmoid_73_grid_99.grid_x, triton_tem_fused_addmm_mul_sigmoid_73_grid_99.grid_y, triton_tem_fused_addmm_mul_sigmoid_73_grid_99.grid_z, 8, 49152, kernel_args_var_99, stream);
    }
    const int64_t int_array_12[] = {s0, 256L};
    auto tmp_tensor_handle_52 = reinterpret_tensor_wrapper(buf191, 2, int_array_12, int_array_11, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_52_raii(tmp_tensor_handle_52);
    decltype(auto) buf190 = std::move(tmp_tensor_handle_52_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_8], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_74_xnumel = 256L*s0;
    if (kernels.triton_poi_fused_cat_74 == nullptr) {
        kernels.triton_poi_fused_cat_74 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ccmvebmkzqzig5kvrljv5mbxur2bdkyrb6px63xi5bnig2grg5ae.cubin", "triton_poi_fused_cat_74", 2048, this->cubin_dir_);
    }
    CUdeviceptr var_511 = reinterpret_cast<CUdeviceptr>(buf189.data_ptr());
    CUdeviceptr var_512 = reinterpret_cast<CUdeviceptr>(buf190.data_ptr());
    int32_t var_513 = triton_poi_fused_cat_74_xnumel;
    void* kernel_args_var_100[] = {&var_511, &var_512, &var_513};
    Grid triton_poi_fused_cat_74_grid_100 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_74_grid_100.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_74, triton_poi_fused_cat_74_grid_100.grid_x, triton_poi_fused_cat_74_grid_100.grid_y, triton_poi_fused_cat_74_grid_100.grid_z, 4, 2048, kernel_args_var_100, stream);
    }
    buf189.reset();
    AtenTensorHandle buf230_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_54, int_array_55, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf230_handle));
    RAIIAtenTensorHandle buf230(buf230_handle);
    // Topologically Sorted Source Nodes: [layer_norm_42, sigmoid_3, mul_567], Original ATen: [aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_red_fused_mul_native_layer_norm_sigmoid_75 == nullptr) {
        kernels.triton_red_fused_mul_native_layer_norm_sigmoid_75 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c4rijewgvn76ksycrwckke2e7s2hd2pkjk5bdq7zopoao4bbv4jn.cubin", "triton_red_fused_mul_native_layer_norm_sigmoid_75", 192, this->cubin_dir_);
    }
    CUdeviceptr var_514 = reinterpret_cast<CUdeviceptr>(buf191.data_ptr());
    CUdeviceptr var_515 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale.data_ptr());
    CUdeviceptr var_516 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias.data_ptr());
    CUdeviceptr var_517 = reinterpret_cast<CUdeviceptr>(buf230.data_ptr());
    int32_t var_518 = s0;
    int var_519 = 3282L;
    void* kernel_args_var_101[] = {&var_514, &var_515, &var_516, &var_517, &var_518, &var_519};
    Grid triton_red_fused_mul_native_layer_norm_sigmoid_75_grid_101 = Grid(s0, 1L, 1L);
    if (triton_red_fused_mul_native_layer_norm_sigmoid_75_grid_101.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_mul_native_layer_norm_sigmoid_75, triton_red_fused_mul_native_layer_norm_sigmoid_75_grid_101.grid_x, triton_red_fused_mul_native_layer_norm_sigmoid_75_grid_101.grid_y, triton_red_fused_mul_native_layer_norm_sigmoid_75_grid_101.grid_z, 16, 192, kernel_args_var_101, stream);
    }
    buf188.reset();
    buf190.reset();
    buf191.reset();
    const int64_t int_array_56[] = {s0, 1024L};
    static constexpr int64_t int_array_57[] = {1024L, 1L};
    AtenTensorHandle buf196_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_56, int_array_57, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf196_handle));
    RAIIAtenTensorHandle buf196(buf196_handle);
    // Topologically Sorted Source Nodes: [contiguous_2, layer_norm_37, sigmoid_1, mul_508, linear_46], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul, aten.addmm]
    if (kernels.triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76 == nullptr) {
        kernels.triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjkom3f6sc3lw754nu7xqezhsptaezkihynzlvpjc3z3uouadcm6.cubin", "triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_520 = reinterpret_cast<CUdeviceptr>(buf195.data_ptr());
    CUdeviceptr var_521 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_44.data_ptr());
    CUdeviceptr var_522 = reinterpret_cast<CUdeviceptr>(buf196.data_ptr());
    int32_t var_523 = s0;
    void* kernel_args_var_102[] = {&var_520, &var_521, &var_522, &var_523};
    Grid triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76_grid_102 = Grid(16L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76_grid_102.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76, triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76_grid_102.grid_x, triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76_grid_102.grid_y, triton_tem_fused_addmm_clone_mul_native_layer_norm_sigmoid_76_grid_102.grid_z, 8, 49152, kernel_args_var_102, stream);
    }
    auto buf457 = std::move(buf196);  // reuse
    // Topologically Sorted Source Nodes: [linear_46, layer_norm_43, sigmoid_4, mul_570], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77 == nullptr) {
        kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/clbhk4lm4eywnmapoaprrxpotmmy56gbsgqdr5fybxfnuw6qbddn.cubin", "triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77", 32, this->cubin_dir_);
    }
    CUdeviceptr var_524 = reinterpret_cast<CUdeviceptr>(buf457.data_ptr());
    CUdeviceptr var_525 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_526 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale.data_ptr());
    CUdeviceptr var_527 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias.data_ptr());
    int32_t var_528 = s0;
    int var_529 = 1024L;
    void* kernel_args_var_103[] = {&var_524, &var_525, &var_526, &var_527, &var_528, &var_529};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77_grid_103 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77_grid_103.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77_grid_103.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77_grid_103.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_77_grid_103.grid_z, 8, 32, kernel_args_var_103, stream);
    }
    const int64_t int_array_58[] = {32L*s0, 64L};
    static constexpr int64_t int_array_59[] = {64L, 1L};
    AtenTensorHandle buf201_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_58, int_array_59, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf201_handle));
    RAIIAtenTensorHandle buf201(buf201_handle);
    // Topologically Sorted Source Nodes: [linear_47], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_78 == nullptr) {
        kernels.triton_tem_fused_addmm_78 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ct3rs5qe32ephipqcqtki2jbkzhe7atiwrc7k75scghvh4zko7ia.cubin", "triton_tem_fused_addmm_78", 18432, this->cubin_dir_);
    }
    CUdeviceptr var_530 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias.data_ptr());
    CUdeviceptr var_531 = reinterpret_cast<CUdeviceptr>(buf200.data_ptr());
    CUdeviceptr var_532 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_45.data_ptr());
    CUdeviceptr var_533 = reinterpret_cast<CUdeviceptr>(buf201.data_ptr());
    int32_t var_534 = s0;
    void* kernel_args_var_104[] = {&var_530, &var_531, &var_532, &var_533, &var_534};
    Grid triton_tem_fused_addmm_78_grid_104 = Grid(c10::div_floor_integer(static_cast<int64_t>(63L + 32L*s0), static_cast<int64_t>(64L)), 1L, 1L);
    if (triton_tem_fused_addmm_78_grid_104.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_78, triton_tem_fused_addmm_78_grid_104.grid_x, triton_tem_fused_addmm_78_grid_104.grid_y, triton_tem_fused_addmm_78_grid_104.grid_z, 4, 18432, kernel_args_var_104, stream);
    }
    buf200.reset();
    const int64_t int_array_60[] = {200L*s0, 64L};
    AtenTensorHandle buf203_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_60, int_array_59, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf203_handle));
    RAIIAtenTensorHandle buf203(buf203_handle);
    // Topologically Sorted Source Nodes: [linear_44], Original ATen: [aten.mm]
    if (kernels.triton_tem_fused_mm_79 == nullptr) {
        kernels.triton_tem_fused_mm_79 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cy5eniskv2dvo4y647h3pg6zr3uaocmyzpt4yy5akkrpglkidvj4.cubin", "triton_tem_fused_mm_79", 18432, this->cubin_dir_);
    }
    CUdeviceptr var_535 = reinterpret_cast<CUdeviceptr>(buf202.data_ptr());
    CUdeviceptr var_536 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_42.data_ptr());
    CUdeviceptr var_537 = reinterpret_cast<CUdeviceptr>(buf203.data_ptr());
    int32_t var_538 = s0;
    void* kernel_args_var_105[] = {&var_535, &var_536, &var_537, &var_538};
    Grid triton_tem_fused_mm_79_grid_105 = Grid(c10::div_floor_integer(static_cast<int64_t>(63L + 200L*s0), static_cast<int64_t>(64L)), 1L, 1L);
    if (triton_tem_fused_mm_79_grid_105.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_mm_79, triton_tem_fused_mm_79_grid_105.grid_x, triton_tem_fused_mm_79_grid_105.grid_y, triton_tem_fused_mm_79_grid_105.grid_z, 4, 18432, kernel_args_var_105, stream);
    }
    // Topologically Sorted Source Nodes: [scaled_dot_product_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
    const int64_t int_array_13[] = {s0, 1L, 32L, 64L};
    static constexpr int64_t int_array_14[] = {2048L, 64L, 64L, 1L};
    auto tmp_tensor_handle_53 = reinterpret_tensor_wrapper(buf201, 4, int_array_13, int_array_14, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_53_raii(tmp_tensor_handle_53);
    const int64_t int_array_15[] = {s0, 1L, 200L, 64L};
    static constexpr int64_t int_array_16[] = {12800L, 64L, 64L, 1L};
    auto tmp_tensor_handle_54 = reinterpret_tensor_wrapper(buf203, 4, int_array_15, int_array_16, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_54_raii(tmp_tensor_handle_54);
    auto tmp_tensor_handle_55 = reinterpret_tensor_wrapper(buf202, 4, int_array_15, int_array_16, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_55_raii(tmp_tensor_handle_55);
    double var_539 = 0.125;
    AtenTensorHandle buf205_handle;
    AtenTensorHandle buf206_handle;
    int64_t buf204_4 = 32;
    int64_t buf204_5 = 200;
    AtenTensorHandle buf207_handle;
    AtenTensorHandle buf208_handle;
    AtenTensorHandle buf209_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda__scaled_dot_product_flash_attention(tmp_tensor_handle_53_raii, tmp_tensor_handle_54_raii, tmp_tensor_handle_55_raii, 0.0, 0, 0, &var_539, &buf205_handle, &buf206_handle, nullptr, nullptr, &buf204_4, &buf204_5, &buf207_handle, &buf208_handle, &buf209_handle));
    RAIIAtenTensorHandle buf205(buf205_handle);
    RAIIAtenTensorHandle buf206(buf206_handle);
    RAIIAtenTensorHandle buf207(buf207_handle);
    RAIIAtenTensorHandle buf208(buf208_handle);
    RAIIAtenTensorHandle buf209(buf209_handle);
    buf202.reset();

    auto buf211 = std::move(buf201);  // reuse
    // Topologically Sorted Source Nodes: [linear_48], Original ATen: [aten.addmm]
    CUdeviceptr var_540 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias.data_ptr());
    CUdeviceptr var_541 = reinterpret_cast<CUdeviceptr>(buf210.data_ptr());
    CUdeviceptr var_542 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_46.data_ptr());
    CUdeviceptr var_543 = reinterpret_cast<CUdeviceptr>(buf211.data_ptr());
    int32_t var_544 = s0;
    void* kernel_args_var_106[] = {&var_540, &var_541, &var_542, &var_543, &var_544};
    Grid triton_tem_fused_addmm_78_grid_106 = Grid(c10::div_floor_integer(static_cast<int64_t>(63L + 32L*s0), static_cast<int64_t>(64L)), 1L, 1L);
    if (triton_tem_fused_addmm_78_grid_106.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_78, triton_tem_fused_addmm_78_grid_106.grid_x, triton_tem_fused_addmm_78_grid_106.grid_y, triton_tem_fused_addmm_78_grid_106.grid_z, 4, 18432, kernel_args_var_106, stream);
    }
    auto buf213 = std::move(buf203);  // reuse
    // Topologically Sorted Source Nodes: [linear_45], Original ATen: [aten.mm]
    CUdeviceptr var_545 = reinterpret_cast<CUdeviceptr>(buf212.data_ptr());
    CUdeviceptr var_546 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_43.data_ptr());
    CUdeviceptr var_547 = reinterpret_cast<CUdeviceptr>(buf213.data_ptr());
    int32_t var_548 = s0;
    void* kernel_args_var_107[] = {&var_545, &var_546, &var_547, &var_548};
    Grid triton_tem_fused_mm_79_grid_107 = Grid(c10::div_floor_integer(static_cast<int64_t>(63L + 200L*s0), static_cast<int64_t>(64L)), 1L, 1L);
    if (triton_tem_fused_mm_79_grid_107.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_mm_79, triton_tem_fused_mm_79_grid_107.grid_x, triton_tem_fused_mm_79_grid_107.grid_y, triton_tem_fused_mm_79_grid_107.grid_z, 4, 18432, kernel_args_var_107, stream);
    }
    // Topologically Sorted Source Nodes: [scaled_dot_product_attention_1], Original ATen: [aten._scaled_dot_product_flash_attention]
    auto tmp_tensor_handle_56 = reinterpret_tensor_wrapper(buf211, 4, int_array_13, int_array_14, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_56_raii(tmp_tensor_handle_56);
    auto tmp_tensor_handle_57 = reinterpret_tensor_wrapper(buf213, 4, int_array_15, int_array_16, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_57_raii(tmp_tensor_handle_57);
    auto tmp_tensor_handle_58 = reinterpret_tensor_wrapper(buf212, 4, int_array_15, int_array_16, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_58_raii(tmp_tensor_handle_58);
    double var_549 = 0.125;
    AtenTensorHandle buf215_handle;
    AtenTensorHandle buf216_handle;
    int64_t buf214_4 = 32;
    int64_t buf214_5 = 200;
    AtenTensorHandle buf217_handle;
    AtenTensorHandle buf218_handle;
    AtenTensorHandle buf219_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda__scaled_dot_product_flash_attention(tmp_tensor_handle_56_raii, tmp_tensor_handle_57_raii, tmp_tensor_handle_58_raii, 0.0, 0, 0, &var_549, &buf215_handle, &buf216_handle, nullptr, nullptr, &buf214_4, &buf214_5, &buf217_handle, &buf218_handle, &buf219_handle));
    RAIIAtenTensorHandle buf215(buf215_handle);
    RAIIAtenTensorHandle buf216(buf216_handle);
    RAIIAtenTensorHandle buf217(buf217_handle);
    RAIIAtenTensorHandle buf218(buf218_handle);
    RAIIAtenTensorHandle buf219(buf219_handle);
    buf212.reset();
    buf213.reset();

    auto tmp_tensor_handle_168 = reinterpret_tensor_wrapper(buf211, 3, int_array_50, int_array_51, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_168_raii(tmp_tensor_handle_168);
    decltype(auto) buf236 = std::move(tmp_tensor_handle_168_raii); buf211.reset();  // reuse
    // Topologically Sorted Source Nodes: [repeat, add_976, layer_norm_44], Original ATen: [aten.repeat, aten.add, aten.native_layer_norm]
    int64_t triton_per_fused_add_native_layer_norm_repeat_80_xnumel = 32L*s0;
    if (kernels.triton_per_fused_add_native_layer_norm_repeat_80 == nullptr) {
        kernels.triton_per_fused_add_native_layer_norm_repeat_80 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/csknkyo6mluuhb3dc4yzx7hy7bmdpj6nscstquprhebdu63acoqs.cubin", "triton_per_fused_add_native_layer_norm_repeat_80", 0, this->cubin_dir_);
    }
    CUdeviceptr var_550 = reinterpret_cast<CUdeviceptr>(buf205.data_ptr());
    CUdeviceptr var_551 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb.data_ptr());
    CUdeviceptr var_552 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight.data_ptr());
    CUdeviceptr var_553 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias.data_ptr());
    CUdeviceptr var_554 = reinterpret_cast<CUdeviceptr>(buf236.data_ptr());
    int32_t var_555 = triton_per_fused_add_native_layer_norm_repeat_80_xnumel;
    int var_556 = 64L;
    void* kernel_args_var_108[] = {&var_550, &var_551, &var_552, &var_553, &var_554, &var_555, &var_556};
    Grid triton_per_fused_add_native_layer_norm_repeat_80_grid_108 = Grid(s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_repeat_80_grid_108.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_repeat_80, triton_per_fused_add_native_layer_norm_repeat_80_grid_108.grid_x, triton_per_fused_add_native_layer_norm_repeat_80_grid_108.grid_y, triton_per_fused_add_native_layer_norm_repeat_80_grid_108.grid_z, 8, 0, kernel_args_var_108, stream);
    }
    auto buf226 = std::move(buf210);  // reuse
    // Topologically Sorted Source Nodes: [repeat_1, add_985, layer_norm_45], Original ATen: [aten.repeat, aten.add, aten.native_layer_norm]
    triton_per_fused_add_native_layer_norm_repeat_80_xnumel = 32L*s0;
    CUdeviceptr var_557 = reinterpret_cast<CUdeviceptr>(buf215.data_ptr());
    CUdeviceptr var_558 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb.data_ptr());
    CUdeviceptr var_559 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight.data_ptr());
    CUdeviceptr var_560 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias.data_ptr());
    CUdeviceptr var_561 = reinterpret_cast<CUdeviceptr>(buf226.data_ptr());
    int32_t var_562 = triton_per_fused_add_native_layer_norm_repeat_80_xnumel;
    int var_563 = 64L;
    void* kernel_args_var_109[] = {&var_557, &var_558, &var_559, &var_560, &var_561, &var_562, &var_563};
    Grid triton_per_fused_add_native_layer_norm_repeat_80_grid_109 = Grid(s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_repeat_80_grid_109.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_repeat_80, triton_per_fused_add_native_layer_norm_repeat_80_grid_109.grid_x, triton_per_fused_add_native_layer_norm_repeat_80_grid_109.grid_y, triton_per_fused_add_native_layer_norm_repeat_80_grid_109.grid_z, 8, 0, kernel_args_var_109, stream);
    }
    const int64_t int_array_61[] = {32L*s0, 128L};
    static constexpr int64_t int_array_62[] = {128L, 1L};
    AtenTensorHandle buf227_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_61, int_array_62, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf227_handle));
    RAIIAtenTensorHandle buf227(buf227_handle);
    // Topologically Sorted Source Nodes: [linear_56], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_81 == nullptr) {
        kernels.triton_tem_fused_addmm_81 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/camgbe4k6xzhrjh3hyflemhps22jkmmehcw2sgjl3nt6iujvtr4m.cubin", "triton_tem_fused_addmm_81", 34816, this->cubin_dir_);
    }
    CUdeviceptr var_564 = reinterpret_cast<CUdeviceptr>(buf226.data_ptr());
    CUdeviceptr var_565 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_57.data_ptr());
    CUdeviceptr var_566 = reinterpret_cast<CUdeviceptr>(buf227.data_ptr());
    int32_t var_567 = s0;
    void* kernel_args_var_110[] = {&var_564, &var_565, &var_566, &var_567};
    Grid triton_tem_fused_addmm_81_grid_110 = Grid(c10::div_floor_integer(static_cast<int64_t>(127L + 32L*s0), static_cast<int64_t>(128L)), 1L, 1L);
    if (triton_tem_fused_addmm_81_grid_110.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_81, triton_tem_fused_addmm_81_grid_110.grid_x, triton_tem_fused_addmm_81_grid_110.grid_y, triton_tem_fused_addmm_81_grid_110.grid_z, 4, 34816, kernel_args_var_110, stream);
    }
    const int64_t int_array_63[] = {s0, 32L, 128L};
    static constexpr int64_t int_array_64[] = {4096L, 128L, 1L};
    auto tmp_tensor_handle_169 = reinterpret_tensor_wrapper(buf227, 3, int_array_63, int_array_64, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_169_raii(tmp_tensor_handle_169);
    decltype(auto) buf228 = std::move(tmp_tensor_handle_169_raii); buf227.reset();  // reuse
    // Topologically Sorted Source Nodes: [gelu_1], Original ATen: [aten.gelu]
    int64_t triton_poi_fused_gelu_82_xnumel = 4096L*s0;
    if (kernels.triton_poi_fused_gelu_82 == nullptr) {
        kernels.triton_poi_fused_gelu_82 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ce75jzbejgiqtcycnhqbocsaqt4eiakid63oophhzfw24xnf6uct.cubin", "triton_poi_fused_gelu_82", 0, this->cubin_dir_);
    }
    CUdeviceptr var_568 = reinterpret_cast<CUdeviceptr>(buf228.data_ptr());
    CUdeviceptr var_569 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias.data_ptr());
    int32_t var_570 = triton_poi_fused_gelu_82_xnumel;
    void* kernel_args_var_111[] = {&var_568, &var_569, &var_570};
    Grid triton_poi_fused_gelu_82_grid_111 = Grid(4L*s0, 1L, 1L);
    if (triton_poi_fused_gelu_82_grid_111.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_gelu_82, triton_poi_fused_gelu_82_grid_111.grid_x, triton_poi_fused_gelu_82_grid_111.grid_y, triton_poi_fused_gelu_82_grid_111.grid_z, 4, 0, kernel_args_var_111, stream);
    }
    auto tmp_tensor_handle_170 = reinterpret_tensor_wrapper(buf226, 2, int_array_58, int_array_59, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_170_raii(tmp_tensor_handle_170);
    decltype(auto) buf229 = std::move(tmp_tensor_handle_170_raii); buf226.reset();  // reuse
    // Topologically Sorted Source Nodes: [linear_58], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_83 == nullptr) {
        kernels.triton_tem_fused_addmm_83 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/crccppe6k2by4lw2n25o7weu5vjdgihjuqhzi7q2kmvrv6gbd32h.cubin", "triton_tem_fused_addmm_83", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_571 = reinterpret_cast<CUdeviceptr>(buf228.data_ptr());
    CUdeviceptr var_572 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_59.data_ptr());
    CUdeviceptr var_573 = reinterpret_cast<CUdeviceptr>(buf229.data_ptr());
    int32_t var_574 = s0;
    void* kernel_args_var_112[] = {&var_571, &var_572, &var_573, &var_574};
    Grid triton_tem_fused_addmm_83_grid_112 = Grid(c10::div_floor_integer(static_cast<int64_t>(63L + 32L*s0), static_cast<int64_t>(64L)), 1L, 1L);
    if (triton_tem_fused_addmm_83_grid_112.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_83, triton_tem_fused_addmm_83_grid_112.grid_x, triton_tem_fused_addmm_83_grid_112.grid_y, triton_tem_fused_addmm_83_grid_112.grid_z, 4, 49152, kernel_args_var_112, stream);
    }
    const int64_t int_array_65[] = {s0, 3288L};
    static constexpr int64_t int_array_66[] = {3288L, 1L};
    AtenTensorHandle buf231_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_65, int_array_66, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf231_handle));
    RAIIAtenTensorHandle buf231(buf231_handle);
    // Topologically Sorted Source Nodes: [linear_default_2], Original ATen: [aten.addmm]
    int64_t triton_poi_fused_addmm_84_xnumel = 3288L*s0;
    if (kernels.triton_poi_fused_addmm_84 == nullptr) {
        kernels.triton_poi_fused_addmm_84 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c6xu3cpkdp6co6p6mizyh6hom65jn444seqv57g7raglgmmxipwe.cubin", "triton_poi_fused_addmm_84", 0, this->cubin_dir_);
    }
    CUdeviceptr var_575 = reinterpret_cast<CUdeviceptr>(buf230.data_ptr());
    CUdeviceptr var_576 = reinterpret_cast<CUdeviceptr>(buf231.data_ptr());
    int32_t var_577 = triton_poi_fused_addmm_84_xnumel;
    void* kernel_args_var_113[] = {&var_575, &var_576, &var_577};
    Grid triton_poi_fused_addmm_84_grid_113 = Grid((-1L)*static_cast<int64_t>(std::floor((-411.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_84_grid_113.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_84, triton_poi_fused_addmm_84_grid_113.grid_x, triton_poi_fused_addmm_84_grid_113.grid_y, triton_poi_fused_addmm_84_grid_113.grid_z, 8, 0, kernel_args_var_113, stream);
    }
    const int64_t int_array_67[] = {s0, 1152L};
    static constexpr int64_t int_array_68[] = {1152L, 1L};
    AtenTensorHandle buf232_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_67, int_array_68, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf232_handle));
    RAIIAtenTensorHandle buf232(buf232_handle);
    // Topologically Sorted Source Nodes: [linear_default_2], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_85 == nullptr) {
        kernels.triton_tem_fused_addmm_85 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c7yihksgv3khts3k73czbakubpicn5odpnfedfp4oxugkgn2h2mj.cubin", "triton_tem_fused_addmm_85", 98304, this->cubin_dir_);
    }
    CUdeviceptr var_578 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_9.data_ptr());
    CUdeviceptr var_579 = reinterpret_cast<CUdeviceptr>(buf231.data_ptr());
    CUdeviceptr var_580 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_constant_pad_nd_default_21.data_ptr());
    CUdeviceptr var_581 = reinterpret_cast<CUdeviceptr>(buf232.data_ptr());
    int32_t var_582 = s0;
    void* kernel_args_var_114[] = {&var_578, &var_579, &var_580, &var_581, &var_582};
    Grid triton_tem_fused_addmm_85_grid_114 = Grid(9L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_85_grid_114.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_85, triton_tem_fused_addmm_85_grid_114.grid_x, triton_tem_fused_addmm_85_grid_114.grid_y, triton_tem_fused_addmm_85_grid_114.grid_z, 4, 98304, kernel_args_var_114, stream);
    }
    buf231.reset();
    auto buf233 = std::move(buf195);  // reuse
    // Topologically Sorted Source Nodes: [contiguous_3, relu_default, nan_to_num_default], Original ATen: [aten.clone, aten.relu, aten.nan_to_num]
    int64_t triton_poi_fused_clone_nan_to_num_relu_86_xnumel = 256L*s0;
    if (kernels.triton_poi_fused_clone_nan_to_num_relu_86 == nullptr) {
        kernels.triton_poi_fused_clone_nan_to_num_relu_86 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cwcpdneil3f22nrcxogl6mjbywbvzsicgjh4kdgz44aqgdo5keo6.cubin", "triton_poi_fused_clone_nan_to_num_relu_86", 0, this->cubin_dir_);
    }
    CUdeviceptr var_583 = reinterpret_cast<CUdeviceptr>(buf170.data_ptr());
    CUdeviceptr var_584 = reinterpret_cast<CUdeviceptr>(buf233.data_ptr());
    int32_t var_585 = triton_poi_fused_clone_nan_to_num_relu_86_xnumel;
    void* kernel_args_var_115[] = {&var_583, &var_584, &var_585};
    Grid triton_poi_fused_clone_nan_to_num_relu_86_grid_115 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/2.0)*s0)), 1L, 1L);
    if (triton_poi_fused_clone_nan_to_num_relu_86_grid_115.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_clone_nan_to_num_relu_86, triton_poi_fused_clone_nan_to_num_relu_86_grid_115.grid_x, triton_poi_fused_clone_nan_to_num_relu_86_grid_115.grid_y, triton_poi_fused_clone_nan_to_num_relu_86_grid_115.grid_z, 8, 0, kernel_args_var_115, stream);
    }
    const int64_t int_array_69[] = {s0, 960L};
    static constexpr int64_t int_array_70[] = {960L, 1L};
    AtenTensorHandle buf234_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_69, int_array_70, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf234_handle));
    RAIIAtenTensorHandle buf234(buf234_handle);
    // Topologically Sorted Source Nodes: [contiguous_3, relu_default, nan_to_num_default, linear_40], Original ATen: [aten.clone, aten.relu, aten.nan_to_num, aten.addmm]
    if (kernels.triton_tem_fused_addmm_clone_nan_to_num_relu_87 == nullptr) {
        kernels.triton_tem_fused_addmm_clone_nan_to_num_relu_87 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/csrk4zbasehkqmbf5mk4lt23gbchmscoise5a3oo7qrc2bgwqbox.cubin", "triton_tem_fused_addmm_clone_nan_to_num_relu_87", 73728, this->cubin_dir_);
    }
    CUdeviceptr var_586 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b.data_ptr());
    CUdeviceptr var_587 = reinterpret_cast<CUdeviceptr>(buf233.data_ptr());
    CUdeviceptr var_588 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_38.data_ptr());
    CUdeviceptr var_589 = reinterpret_cast<CUdeviceptr>(buf234.data_ptr());
    int32_t var_590 = s0;
    void* kernel_args_var_116[] = {&var_586, &var_587, &var_588, &var_589, &var_590};
    Grid triton_tem_fused_addmm_clone_nan_to_num_relu_87_grid_116 = Grid(8L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_clone_nan_to_num_relu_87_grid_116.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_clone_nan_to_num_relu_87, triton_tem_fused_addmm_clone_nan_to_num_relu_87_grid_116.grid_x, triton_tem_fused_addmm_clone_nan_to_num_relu_87_grid_116.grid_y, triton_tem_fused_addmm_clone_nan_to_num_relu_87_grid_116.grid_z, 4, 73728, kernel_args_var_116, stream);
    }
    buf233.reset();
    const int64_t int_array_71[] = {s0, 1536L};
    static constexpr int64_t int_array_72[] = {1536L, 1L};
    AtenTensorHandle buf235_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_71, int_array_72, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf235_handle));
    RAIIAtenTensorHandle buf235(buf235_handle);
    // Topologically Sorted Source Nodes: [linear_41], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_88 == nullptr) {
        kernels.triton_tem_fused_addmm_88 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/chvrlujqqgn7lmh5azrunzznahtsffv5pgmw5getuczdm3epdrfi.cubin", "triton_tem_fused_addmm_88", 73728, this->cubin_dir_);
    }
    CUdeviceptr var_591 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b.data_ptr());
    CUdeviceptr var_592 = reinterpret_cast<CUdeviceptr>(buf234.data_ptr());
    CUdeviceptr var_593 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_39.data_ptr());
    CUdeviceptr var_594 = reinterpret_cast<CUdeviceptr>(buf235.data_ptr());
    int32_t var_595 = s0;
    void* kernel_args_var_117[] = {&var_591, &var_592, &var_593, &var_594, &var_595};
    Grid triton_tem_fused_addmm_88_grid_117 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_88_grid_117.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_88, triton_tem_fused_addmm_88_grid_117.grid_x, triton_tem_fused_addmm_88_grid_117.grid_y, triton_tem_fused_addmm_88_grid_117.grid_z, 4, 73728, kernel_args_var_117, stream);
    }
    buf234.reset();
    auto tmp_tensor_handle_171 = reinterpret_tensor_wrapper(buf228, 2, int_array_61, int_array_62, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_171_raii(tmp_tensor_handle_171);
    decltype(auto) buf237 = std::move(tmp_tensor_handle_171_raii); buf228.reset();  // reuse
    // Topologically Sorted Source Nodes: [linear_55], Original ATen: [aten.addmm]
    CUdeviceptr var_596 = reinterpret_cast<CUdeviceptr>(buf236.data_ptr());
    CUdeviceptr var_597 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_56.data_ptr());
    CUdeviceptr var_598 = reinterpret_cast<CUdeviceptr>(buf237.data_ptr());
    int32_t var_599 = s0;
    void* kernel_args_var_118[] = {&var_596, &var_597, &var_598, &var_599};
    Grid triton_tem_fused_addmm_81_grid_118 = Grid(c10::div_floor_integer(static_cast<int64_t>(127L + 32L*s0), static_cast<int64_t>(128L)), 1L, 1L);
    if (triton_tem_fused_addmm_81_grid_118.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_81, triton_tem_fused_addmm_81_grid_118.grid_x, triton_tem_fused_addmm_81_grid_118.grid_y, triton_tem_fused_addmm_81_grid_118.grid_z, 4, 34816, kernel_args_var_118, stream);
    }
    auto tmp_tensor_handle_172 = reinterpret_tensor_wrapper(buf237, 3, int_array_63, int_array_64, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_172_raii(tmp_tensor_handle_172);
    decltype(auto) buf238 = std::move(tmp_tensor_handle_172_raii); buf237.reset();  // reuse
    // Topologically Sorted Source Nodes: [gelu], Original ATen: [aten.gelu]
    triton_poi_fused_gelu_82_xnumel = 4096L*s0;
    CUdeviceptr var_600 = reinterpret_cast<CUdeviceptr>(buf238.data_ptr());
    CUdeviceptr var_601 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias.data_ptr());
    int32_t var_602 = triton_poi_fused_gelu_82_xnumel;
    void* kernel_args_var_119[] = {&var_600, &var_601, &var_602};
    Grid triton_poi_fused_gelu_82_grid_119 = Grid(4L*s0, 1L, 1L);
    if (triton_poi_fused_gelu_82_grid_119.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_gelu_82, triton_poi_fused_gelu_82_grid_119.grid_x, triton_poi_fused_gelu_82_grid_119.grid_y, triton_poi_fused_gelu_82_grid_119.grid_z, 4, 0, kernel_args_var_119, stream);
    }
    auto tmp_tensor_handle_173 = reinterpret_tensor_wrapper(buf236, 2, int_array_58, int_array_59, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_173_raii(tmp_tensor_handle_173);
    decltype(auto) buf239 = std::move(tmp_tensor_handle_173_raii); buf236.reset();  // reuse
    // Topologically Sorted Source Nodes: [linear_57], Original ATen: [aten.addmm]
    CUdeviceptr var_603 = reinterpret_cast<CUdeviceptr>(buf238.data_ptr());
    CUdeviceptr var_604 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_58.data_ptr());
    CUdeviceptr var_605 = reinterpret_cast<CUdeviceptr>(buf239.data_ptr());
    int32_t var_606 = s0;
    void* kernel_args_var_120[] = {&var_603, &var_604, &var_605, &var_606};
    Grid triton_tem_fused_addmm_83_grid_120 = Grid(c10::div_floor_integer(static_cast<int64_t>(63L + 32L*s0), static_cast<int64_t>(64L)), 1L, 1L);
    if (triton_tem_fused_addmm_83_grid_120.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_83, triton_tem_fused_addmm_83_grid_120.grid_x, triton_tem_fused_addmm_83_grid_120.grid_y, triton_tem_fused_addmm_83_grid_120.grid_z, 4, 49152, kernel_args_var_120, stream);
    }
    const int64_t int_array_73[] = {64L, s0, 64L};
    const int64_t int_array_74[] = {64L*s0, 64L, 1L};
    auto tmp_tensor_handle_174 = reinterpret_tensor_wrapper(buf238, 3, int_array_73, int_array_74, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_174_raii(tmp_tensor_handle_174);
    decltype(auto) buf273 = std::move(tmp_tensor_handle_174_raii); buf238.reset();  // reuse
    const int64_t int_array_17[] = {1L, s0, 64L};
    const int64_t int_array_18[] = {64L*s0, 64L, 1L};
    auto tmp_tensor_handle_59 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_59_raii(tmp_tensor_handle_59);
    decltype(auto) buf240 = std::move(tmp_tensor_handle_59_raii);  // alias
    auto tmp_tensor_handle_60 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 64L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_60_raii(tmp_tensor_handle_60);
    decltype(auto) buf241 = std::move(tmp_tensor_handle_60_raii);  // alias
    auto tmp_tensor_handle_61 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 128L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_61_raii(tmp_tensor_handle_61);
    decltype(auto) buf242 = std::move(tmp_tensor_handle_61_raii);  // alias
    auto tmp_tensor_handle_62 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 192L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_62_raii(tmp_tensor_handle_62);
    decltype(auto) buf243 = std::move(tmp_tensor_handle_62_raii);  // alias
    auto tmp_tensor_handle_63 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 256L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_63_raii(tmp_tensor_handle_63);
    decltype(auto) buf244 = std::move(tmp_tensor_handle_63_raii);  // alias
    auto tmp_tensor_handle_64 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 320L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_64_raii(tmp_tensor_handle_64);
    decltype(auto) buf245 = std::move(tmp_tensor_handle_64_raii);  // alias
    auto tmp_tensor_handle_65 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 384L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_65_raii(tmp_tensor_handle_65);
    decltype(auto) buf246 = std::move(tmp_tensor_handle_65_raii);  // alias
    auto tmp_tensor_handle_66 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 448L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_66_raii(tmp_tensor_handle_66);
    decltype(auto) buf247 = std::move(tmp_tensor_handle_66_raii);  // alias
    auto tmp_tensor_handle_67 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 512L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_67_raii(tmp_tensor_handle_67);
    decltype(auto) buf248 = std::move(tmp_tensor_handle_67_raii);  // alias
    auto tmp_tensor_handle_68 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 576L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_68_raii(tmp_tensor_handle_68);
    decltype(auto) buf249 = std::move(tmp_tensor_handle_68_raii);  // alias
    auto tmp_tensor_handle_69 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 640L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_69_raii(tmp_tensor_handle_69);
    decltype(auto) buf250 = std::move(tmp_tensor_handle_69_raii);  // alias
    auto tmp_tensor_handle_70 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 704L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_70_raii(tmp_tensor_handle_70);
    decltype(auto) buf251 = std::move(tmp_tensor_handle_70_raii);  // alias
    auto tmp_tensor_handle_71 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 768L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_71_raii(tmp_tensor_handle_71);
    decltype(auto) buf252 = std::move(tmp_tensor_handle_71_raii);  // alias
    auto tmp_tensor_handle_72 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 832L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_72_raii(tmp_tensor_handle_72);
    decltype(auto) buf253 = std::move(tmp_tensor_handle_72_raii);  // alias
    auto tmp_tensor_handle_73 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 896L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_73_raii(tmp_tensor_handle_73);
    decltype(auto) buf254 = std::move(tmp_tensor_handle_73_raii);  // alias
    auto tmp_tensor_handle_74 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 960L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_74_raii(tmp_tensor_handle_74);
    decltype(auto) buf255 = std::move(tmp_tensor_handle_74_raii);  // alias
    auto tmp_tensor_handle_75 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1024L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_75_raii(tmp_tensor_handle_75);
    decltype(auto) buf256 = std::move(tmp_tensor_handle_75_raii);  // alias
    auto tmp_tensor_handle_76 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1088L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_76_raii(tmp_tensor_handle_76);
    decltype(auto) buf257 = std::move(tmp_tensor_handle_76_raii);  // alias
    auto tmp_tensor_handle_77 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1152L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_77_raii(tmp_tensor_handle_77);
    decltype(auto) buf258 = std::move(tmp_tensor_handle_77_raii);  // alias
    auto tmp_tensor_handle_78 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1216L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_78_raii(tmp_tensor_handle_78);
    decltype(auto) buf259 = std::move(tmp_tensor_handle_78_raii);  // alias
    auto tmp_tensor_handle_79 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1280L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_79_raii(tmp_tensor_handle_79);
    decltype(auto) buf260 = std::move(tmp_tensor_handle_79_raii);  // alias
    auto tmp_tensor_handle_80 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1344L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_80_raii(tmp_tensor_handle_80);
    decltype(auto) buf261 = std::move(tmp_tensor_handle_80_raii);  // alias
    auto tmp_tensor_handle_81 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1408L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_81_raii(tmp_tensor_handle_81);
    decltype(auto) buf262 = std::move(tmp_tensor_handle_81_raii);  // alias
    auto tmp_tensor_handle_82 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1472L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_82_raii(tmp_tensor_handle_82);
    decltype(auto) buf263 = std::move(tmp_tensor_handle_82_raii);  // alias
    auto tmp_tensor_handle_83 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1536L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_83_raii(tmp_tensor_handle_83);
    decltype(auto) buf264 = std::move(tmp_tensor_handle_83_raii);  // alias
    auto tmp_tensor_handle_84 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1600L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_84_raii(tmp_tensor_handle_84);
    decltype(auto) buf265 = std::move(tmp_tensor_handle_84_raii);  // alias
    auto tmp_tensor_handle_85 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1664L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_85_raii(tmp_tensor_handle_85);
    decltype(auto) buf266 = std::move(tmp_tensor_handle_85_raii);  // alias
    auto tmp_tensor_handle_86 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1728L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_86_raii(tmp_tensor_handle_86);
    decltype(auto) buf267 = std::move(tmp_tensor_handle_86_raii);  // alias
    auto tmp_tensor_handle_87 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1792L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_87_raii(tmp_tensor_handle_87);
    decltype(auto) buf268 = std::move(tmp_tensor_handle_87_raii);  // alias
    auto tmp_tensor_handle_88 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1856L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_88_raii(tmp_tensor_handle_88);
    decltype(auto) buf269 = std::move(tmp_tensor_handle_88_raii);  // alias
    auto tmp_tensor_handle_89 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1920L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_89_raii(tmp_tensor_handle_89);
    decltype(auto) buf270 = std::move(tmp_tensor_handle_89_raii);  // alias
    auto tmp_tensor_handle_90 = reinterpret_tensor_wrapper(buf273, 3, int_array_17, int_array_18, 1984L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_90_raii(tmp_tensor_handle_90);
    decltype(auto) buf271 = std::move(tmp_tensor_handle_90_raii);  // alias
    // Topologically Sorted Source Nodes: [stack_default], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_89_xnumel = 64L*s0;
    if (kernels.triton_poi_fused_cat_89 == nullptr) {
        kernels.triton_poi_fused_cat_89 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjxfx2el5ywyek45f5cwhoix6erlhjl3rz25zp42n3qikq5vyffa.cubin", "triton_poi_fused_cat_89", 0, this->cubin_dir_);
    }
    CUdeviceptr var_607 = reinterpret_cast<CUdeviceptr>(buf215.data_ptr());
    CUdeviceptr var_608 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb.data_ptr());
    CUdeviceptr var_609 = reinterpret_cast<CUdeviceptr>(buf229.data_ptr());
    CUdeviceptr var_610 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias.data_ptr());
    CUdeviceptr var_611 = reinterpret_cast<CUdeviceptr>(buf240.data_ptr());
    CUdeviceptr var_612 = reinterpret_cast<CUdeviceptr>(buf241.data_ptr());
    CUdeviceptr var_613 = reinterpret_cast<CUdeviceptr>(buf242.data_ptr());
    CUdeviceptr var_614 = reinterpret_cast<CUdeviceptr>(buf243.data_ptr());
    CUdeviceptr var_615 = reinterpret_cast<CUdeviceptr>(buf244.data_ptr());
    CUdeviceptr var_616 = reinterpret_cast<CUdeviceptr>(buf245.data_ptr());
    CUdeviceptr var_617 = reinterpret_cast<CUdeviceptr>(buf246.data_ptr());
    CUdeviceptr var_618 = reinterpret_cast<CUdeviceptr>(buf247.data_ptr());
    CUdeviceptr var_619 = reinterpret_cast<CUdeviceptr>(buf248.data_ptr());
    CUdeviceptr var_620 = reinterpret_cast<CUdeviceptr>(buf249.data_ptr());
    CUdeviceptr var_621 = reinterpret_cast<CUdeviceptr>(buf250.data_ptr());
    CUdeviceptr var_622 = reinterpret_cast<CUdeviceptr>(buf251.data_ptr());
    CUdeviceptr var_623 = reinterpret_cast<CUdeviceptr>(buf252.data_ptr());
    CUdeviceptr var_624 = reinterpret_cast<CUdeviceptr>(buf253.data_ptr());
    CUdeviceptr var_625 = reinterpret_cast<CUdeviceptr>(buf254.data_ptr());
    CUdeviceptr var_626 = reinterpret_cast<CUdeviceptr>(buf255.data_ptr());
    CUdeviceptr var_627 = reinterpret_cast<CUdeviceptr>(buf256.data_ptr());
    CUdeviceptr var_628 = reinterpret_cast<CUdeviceptr>(buf257.data_ptr());
    CUdeviceptr var_629 = reinterpret_cast<CUdeviceptr>(buf258.data_ptr());
    CUdeviceptr var_630 = reinterpret_cast<CUdeviceptr>(buf259.data_ptr());
    CUdeviceptr var_631 = reinterpret_cast<CUdeviceptr>(buf260.data_ptr());
    CUdeviceptr var_632 = reinterpret_cast<CUdeviceptr>(buf261.data_ptr());
    CUdeviceptr var_633 = reinterpret_cast<CUdeviceptr>(buf262.data_ptr());
    CUdeviceptr var_634 = reinterpret_cast<CUdeviceptr>(buf263.data_ptr());
    CUdeviceptr var_635 = reinterpret_cast<CUdeviceptr>(buf264.data_ptr());
    CUdeviceptr var_636 = reinterpret_cast<CUdeviceptr>(buf265.data_ptr());
    CUdeviceptr var_637 = reinterpret_cast<CUdeviceptr>(buf266.data_ptr());
    CUdeviceptr var_638 = reinterpret_cast<CUdeviceptr>(buf267.data_ptr());
    CUdeviceptr var_639 = reinterpret_cast<CUdeviceptr>(buf268.data_ptr());
    CUdeviceptr var_640 = reinterpret_cast<CUdeviceptr>(buf269.data_ptr());
    CUdeviceptr var_641 = reinterpret_cast<CUdeviceptr>(buf270.data_ptr());
    CUdeviceptr var_642 = reinterpret_cast<CUdeviceptr>(buf271.data_ptr());
    int32_t var_643 = triton_poi_fused_cat_89_xnumel;
    void* kernel_args_var_121[] = {&var_607, &var_608, &var_609, &var_610, &var_611, &var_612, &var_613, &var_614, &var_615, &var_616, &var_617, &var_618, &var_619, &var_620, &var_621, &var_622, &var_623, &var_624, &var_625, &var_626, &var_627, &var_628, &var_629, &var_630, &var_631, &var_632, &var_633, &var_634, &var_635, &var_636, &var_637, &var_638, &var_639, &var_640, &var_641, &var_642, &var_643};
    Grid triton_poi_fused_cat_89_grid_121 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_89_grid_121.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_89, triton_poi_fused_cat_89_grid_121.grid_x, triton_poi_fused_cat_89_grid_121.grid_y, triton_poi_fused_cat_89_grid_121.grid_z, 8, 0, kernel_args_var_121, stream);
    }
    buf215.reset();
    buf229.reset();
    const int64_t int_array_19[] = {32L, s0, 64L};
    auto tmp_tensor_handle_91 = reinterpret_tensor_wrapper(buf273, 3, int_array_19, int_array_18, 2048L*s0);
    RAIIAtenTensorHandle tmp_tensor_handle_91_raii(tmp_tensor_handle_91);
    decltype(auto) buf272 = std::move(tmp_tensor_handle_91_raii);  // alias
    // Topologically Sorted Source Nodes: [stack_default], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_90_xnumel = 2048L*s0;
    if (kernels.triton_poi_fused_cat_90 == nullptr) {
        kernels.triton_poi_fused_cat_90 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c2wxm2kqzsff5taqvbz6aoso6sjlewvf3f4dmgwumsgin2mbi2gv.cubin", "triton_poi_fused_cat_90", 0, this->cubin_dir_);
    }
    CUdeviceptr var_644 = reinterpret_cast<CUdeviceptr>(buf205.data_ptr());
    CUdeviceptr var_645 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb.data_ptr());
    CUdeviceptr var_646 = reinterpret_cast<CUdeviceptr>(buf239.data_ptr());
    CUdeviceptr var_647 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias.data_ptr());
    CUdeviceptr var_648 = reinterpret_cast<CUdeviceptr>(buf272.data_ptr());
    int32_t var_649 = s0;
    int32_t var_650 = triton_poi_fused_cat_90_xnumel;
    void* kernel_args_var_122[] = {&var_644, &var_645, &var_646, &var_647, &var_648, &var_649, &var_650};
    Grid triton_poi_fused_cat_90_grid_122 = Grid(2L*s0, 1L, 1L);
    if (triton_poi_fused_cat_90_grid_122.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_90, triton_poi_fused_cat_90_grid_122.grid_x, triton_poi_fused_cat_90_grid_122.grid_y, triton_poi_fused_cat_90_grid_122.grid_z, 4, 0, kernel_args_var_122, stream);
    }
    buf205.reset();
    AtenTensorHandle buf274_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_73, int_array_74, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf274_handle));
    RAIIAtenTensorHandle buf274(buf274_handle);
    // Topologically Sorted Source Nodes: [nan_to_num, clamp], Original ATen: [aten.nan_to_num, aten.clamp]
    int64_t triton_poi_fused_clamp_nan_to_num_91_xnumel = 4096L*s0;
    if (kernels.triton_poi_fused_clamp_nan_to_num_91 == nullptr) {
        kernels.triton_poi_fused_clamp_nan_to_num_91 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c2strx6dbux43bh62zmt4tpmgc25o375iz6gts3ql7m6ivdngico.cubin", "triton_poi_fused_clamp_nan_to_num_91", 0, this->cubin_dir_);
    }
    CUdeviceptr var_651 = reinterpret_cast<CUdeviceptr>(buf273.data_ptr());
    CUdeviceptr var_652 = reinterpret_cast<CUdeviceptr>(buf274.data_ptr());
    int32_t var_653 = triton_poi_fused_clamp_nan_to_num_91_xnumel;
    void* kernel_args_var_123[] = {&var_651, &var_652, &var_653};
    Grid triton_poi_fused_clamp_nan_to_num_91_grid_123 = Grid(4L*s0, 1L, 1L);
    if (triton_poi_fused_clamp_nan_to_num_91_grid_123.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_clamp_nan_to_num_91, triton_poi_fused_clamp_nan_to_num_91_grid_123.grid_x, triton_poi_fused_clamp_nan_to_num_91_grid_123.grid_y, triton_poi_fused_clamp_nan_to_num_91_grid_123.grid_z, 4, 0, kernel_args_var_123, stream);
    }
    buf240.reset();
    buf241.reset();
    buf242.reset();
    buf243.reset();
    buf244.reset();
    buf245.reset();
    buf246.reset();
    buf247.reset();
    buf248.reset();
    buf249.reset();
    buf250.reset();
    buf251.reset();
    buf252.reset();
    buf253.reset();
    buf254.reset();
    buf255.reset();
    buf256.reset();
    buf257.reset();
    buf258.reset();
    buf259.reset();
    buf260.reset();
    buf261.reset();
    buf262.reset();
    buf263.reset();
    buf264.reset();
    buf265.reset();
    buf266.reset();
    buf267.reset();
    buf268.reset();
    buf269.reset();
    buf270.reset();
    buf271.reset();
    buf272.reset();
    buf273.reset();
    const int64_t int_array_75[] = {64L, s0, 192L};
    const int64_t int_array_76[] = {192L*s0, 192L, 1L};
    AtenTensorHandle buf275_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_75, int_array_76, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf275_handle));
    RAIIAtenTensorHandle buf275(buf275_handle);
    // Topologically Sorted Source Nodes: [nan_to_num, clamp, baddbmm], Original ATen: [aten.nan_to_num, aten.clamp, aten.baddbmm]
    if (kernels.triton_tem_fused_baddbmm_clamp_nan_to_num_92 == nullptr) {
        kernels.triton_tem_fused_baddbmm_clamp_nan_to_num_92 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/chryw3pfnmd7xb6db3kf43echxjmfazaqwauqubtmf2t6omzysjo.cubin", "triton_tem_fused_baddbmm_clamp_nan_to_num_92", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_654 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_655 = reinterpret_cast<CUdeviceptr>(buf274.data_ptr());
    CUdeviceptr var_656 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight.data_ptr());
    CUdeviceptr var_657 = reinterpret_cast<CUdeviceptr>(buf275.data_ptr());
    int32_t var_658 = s0;
    void* kernel_args_var_124[] = {&var_654, &var_655, &var_656, &var_657, &var_658};
    Grid triton_tem_fused_baddbmm_clamp_nan_to_num_92_grid_124 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 64L, 1L);
    if (triton_tem_fused_baddbmm_clamp_nan_to_num_92_grid_124.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_baddbmm_clamp_nan_to_num_92, triton_tem_fused_baddbmm_clamp_nan_to_num_92_grid_124.grid_x, triton_tem_fused_baddbmm_clamp_nan_to_num_92_grid_124.grid_y, triton_tem_fused_baddbmm_clamp_nan_to_num_92_grid_124.grid_z, 8, 49152, kernel_args_var_124, stream);
    }
    buf274.reset();
    const int64_t int_array_20[] = {s0, 2880L};
    auto tmp_tensor_handle_92 = reinterpret_tensor_wrapper(buf388, 2, int_array_20, int_array_1, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_92_raii(tmp_tensor_handle_92);
    decltype(auto) buf276 = std::move(tmp_tensor_handle_92_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_93_xnumel = 2880L*s0;
    if (kernels.triton_poi_fused_cat_93 == nullptr) {
        kernels.triton_poi_fused_cat_93 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/co6qtv4bijwg5toqlujalfx4kyww2hlswa235crflnm2qr4l7tqm.cubin", "triton_poi_fused_cat_93", 0, this->cubin_dir_);
    }
    CUdeviceptr var_659 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_660 = reinterpret_cast<CUdeviceptr>(buf276.data_ptr());
    int32_t var_661 = triton_poi_fused_cat_93_xnumel;
    void* kernel_args_var_125[] = {&var_659, &var_660, &var_661};
    Grid triton_poi_fused_cat_93_grid_125 = Grid((-1L)*static_cast<int64_t>(std::floor((-45.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_93_grid_125.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_93, triton_poi_fused_cat_93_grid_125.grid_x, triton_poi_fused_cat_93_grid_125.grid_y, triton_poi_fused_cat_93_grid_125.grid_z, 4, 0, kernel_args_var_125, stream);
    }
    auto tmp_tensor_handle_93 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 2880L);
    RAIIAtenTensorHandle tmp_tensor_handle_93_raii(tmp_tensor_handle_93);
    decltype(auto) buf277 = std::move(tmp_tensor_handle_93_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_94_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_94 == nullptr) {
        kernels.triton_poi_fused_cat_94 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckrnslm25edhrm5g6nvlvl6x5e44uss6sla3t6zm47zo2oc34icu.cubin", "triton_poi_fused_cat_94", 0, this->cubin_dir_);
    }
    CUdeviceptr var_662 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_663 = reinterpret_cast<CUdeviceptr>(buf277.data_ptr());
    int32_t var_664 = triton_poi_fused_cat_94_xnumel;
    void* kernel_args_var_126[] = {&var_662, &var_663, &var_664};
    Grid triton_poi_fused_cat_94_grid_126 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_94_grid_126.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_94, triton_poi_fused_cat_94_grid_126.grid_x, triton_poi_fused_cat_94_grid_126.grid_y, triton_poi_fused_cat_94_grid_126.grid_z, 4, 0, kernel_args_var_126, stream);
    }
    const int64_t int_array_21[] = {s0, 3648L};
    auto tmp_tensor_handle_94 = reinterpret_tensor_wrapper(buf388, 2, int_array_21, int_array_1, 3072L);
    RAIIAtenTensorHandle tmp_tensor_handle_94_raii(tmp_tensor_handle_94);
    decltype(auto) buf278 = std::move(tmp_tensor_handle_94_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_95_xnumel = 3648L*s0;
    if (kernels.triton_poi_fused_cat_95 == nullptr) {
        kernels.triton_poi_fused_cat_95 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cbmzbrflfgss4fn2w3qmjhfgqv7ea3ele4q4mlkio7sgsptom3pr.cubin", "triton_poi_fused_cat_95", 0, this->cubin_dir_);
    }
    CUdeviceptr var_665 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_666 = reinterpret_cast<CUdeviceptr>(buf278.data_ptr());
    int32_t var_667 = triton_poi_fused_cat_95_xnumel;
    void* kernel_args_var_127[] = {&var_665, &var_666, &var_667};
    Grid triton_poi_fused_cat_95_grid_127 = Grid((-1L)*static_cast<int64_t>(std::floor((-57.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_95_grid_127.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_95, triton_poi_fused_cat_95_grid_127.grid_x, triton_poi_fused_cat_95_grid_127.grid_y, triton_poi_fused_cat_95_grid_127.grid_z, 4, 0, kernel_args_var_127, stream);
    }
    auto tmp_tensor_handle_95 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 6720L);
    RAIIAtenTensorHandle tmp_tensor_handle_95_raii(tmp_tensor_handle_95);
    decltype(auto) buf279 = std::move(tmp_tensor_handle_95_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_96_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_96 == nullptr) {
        kernels.triton_poi_fused_cat_96 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cenmuw7pdq5wtl64lbae73erjtpwl3emy5uduyrk4oo5ntvlpved.cubin", "triton_poi_fused_cat_96", 0, this->cubin_dir_);
    }
    CUdeviceptr var_668 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_669 = reinterpret_cast<CUdeviceptr>(buf279.data_ptr());
    int32_t var_670 = triton_poi_fused_cat_96_xnumel;
    void* kernel_args_var_128[] = {&var_668, &var_669, &var_670};
    Grid triton_poi_fused_cat_96_grid_128 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_96_grid_128.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_96, triton_poi_fused_cat_96_grid_128.grid_x, triton_poi_fused_cat_96_grid_128.grid_y, triton_poi_fused_cat_96_grid_128.grid_z, 8, 0, kernel_args_var_128, stream);
    }
    const int64_t int_array_22[] = {s0, 768L};
    auto tmp_tensor_handle_96 = reinterpret_tensor_wrapper(buf388, 2, int_array_22, int_array_1, 6912L);
    RAIIAtenTensorHandle tmp_tensor_handle_96_raii(tmp_tensor_handle_96);
    decltype(auto) buf280 = std::move(tmp_tensor_handle_96_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_97_xnumel = 768L*s0;
    if (kernels.triton_poi_fused_cat_97 == nullptr) {
        kernels.triton_poi_fused_cat_97 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/clmk5phzc7kabbbh2nrarw3ox632ysykuxbro4t2rqhbncownv33.cubin", "triton_poi_fused_cat_97", 0, this->cubin_dir_);
    }
    CUdeviceptr var_671 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_672 = reinterpret_cast<CUdeviceptr>(buf280.data_ptr());
    int32_t var_673 = triton_poi_fused_cat_97_xnumel;
    void* kernel_args_var_129[] = {&var_671, &var_672, &var_673};
    Grid triton_poi_fused_cat_97_grid_129 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_97_grid_129.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_97, triton_poi_fused_cat_97_grid_129.grid_x, triton_poi_fused_cat_97_grid_129.grid_y, triton_poi_fused_cat_97_grid_129.grid_z, 4, 0, kernel_args_var_129, stream);
    }
    auto tmp_tensor_handle_97 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 7680L);
    RAIIAtenTensorHandle tmp_tensor_handle_97_raii(tmp_tensor_handle_97);
    decltype(auto) buf281 = std::move(tmp_tensor_handle_97_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_98_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_98 == nullptr) {
        kernels.triton_poi_fused_cat_98 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cw5zpxycqoahbafcmkffxxyuxdclhprh5hiogdrkkl5cnnnfcfmg.cubin", "triton_poi_fused_cat_98", 0, this->cubin_dir_);
    }
    CUdeviceptr var_674 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_675 = reinterpret_cast<CUdeviceptr>(buf281.data_ptr());
    int32_t var_676 = triton_poi_fused_cat_98_xnumel;
    void* kernel_args_var_130[] = {&var_674, &var_675, &var_676};
    Grid triton_poi_fused_cat_98_grid_130 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_98_grid_130.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_98, triton_poi_fused_cat_98_grid_130.grid_x, triton_poi_fused_cat_98_grid_130.grid_y, triton_poi_fused_cat_98_grid_130.grid_z, 4, 0, kernel_args_var_130, stream);
    }
    auto tmp_tensor_handle_98 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 7872L);
    RAIIAtenTensorHandle tmp_tensor_handle_98_raii(tmp_tensor_handle_98);
    decltype(auto) buf282 = std::move(tmp_tensor_handle_98_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_99_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_99 == nullptr) {
        kernels.triton_poi_fused_cat_99 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/czfqkbbkxdzgflj5mhtu5azapemxqaddubftmwzuvllbgn6r5pg3.cubin", "triton_poi_fused_cat_99", 0, this->cubin_dir_);
    }
    CUdeviceptr var_677 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_678 = reinterpret_cast<CUdeviceptr>(buf282.data_ptr());
    int32_t var_679 = triton_poi_fused_cat_99_xnumel;
    void* kernel_args_var_131[] = {&var_677, &var_678, &var_679};
    Grid triton_poi_fused_cat_99_grid_131 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_99_grid_131.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_99, triton_poi_fused_cat_99_grid_131.grid_x, triton_poi_fused_cat_99_grid_131.grid_y, triton_poi_fused_cat_99_grid_131.grid_z, 4, 0, kernel_args_var_131, stream);
    }
    const int64_t int_array_23[] = {s0, 384L};
    auto tmp_tensor_handle_99 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 8064L);
    RAIIAtenTensorHandle tmp_tensor_handle_99_raii(tmp_tensor_handle_99);
    decltype(auto) buf283 = std::move(tmp_tensor_handle_99_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_100_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_100 == nullptr) {
        kernels.triton_poi_fused_cat_100 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ciuisug73t53naffh5tn6szzbahvawmhs7pq5kzxettvkyhplpdb.cubin", "triton_poi_fused_cat_100", 0, this->cubin_dir_);
    }
    CUdeviceptr var_680 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_681 = reinterpret_cast<CUdeviceptr>(buf283.data_ptr());
    int32_t var_682 = triton_poi_fused_cat_100_xnumel;
    void* kernel_args_var_132[] = {&var_680, &var_681, &var_682};
    Grid triton_poi_fused_cat_100_grid_132 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_100_grid_132.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_100, triton_poi_fused_cat_100_grid_132.grid_x, triton_poi_fused_cat_100_grid_132.grid_y, triton_poi_fused_cat_100_grid_132.grid_z, 4, 0, kernel_args_var_132, stream);
    }
    const int64_t int_array_24[] = {s0, 1152L};
    auto tmp_tensor_handle_100 = reinterpret_tensor_wrapper(buf388, 2, int_array_24, int_array_1, 8448L);
    RAIIAtenTensorHandle tmp_tensor_handle_100_raii(tmp_tensor_handle_100);
    decltype(auto) buf284 = std::move(tmp_tensor_handle_100_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_101_xnumel = 1152L*s0;
    if (kernels.triton_poi_fused_cat_101 == nullptr) {
        kernels.triton_poi_fused_cat_101 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cpgnbumkb56nkgszx65sfd234tldmncplajxakowonchmo7qfc2e.cubin", "triton_poi_fused_cat_101", 0, this->cubin_dir_);
    }
    CUdeviceptr var_683 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_684 = reinterpret_cast<CUdeviceptr>(buf284.data_ptr());
    int32_t var_685 = triton_poi_fused_cat_101_xnumel;
    void* kernel_args_var_133[] = {&var_683, &var_684, &var_685};
    Grid triton_poi_fused_cat_101_grid_133 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_101_grid_133.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_101, triton_poi_fused_cat_101_grid_133.grid_x, triton_poi_fused_cat_101_grid_133.grid_y, triton_poi_fused_cat_101_grid_133.grid_z, 4, 0, kernel_args_var_133, stream);
    }
    auto tmp_tensor_handle_101 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 9600L);
    RAIIAtenTensorHandle tmp_tensor_handle_101_raii(tmp_tensor_handle_101);
    decltype(auto) buf285 = std::move(tmp_tensor_handle_101_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_102_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_102 == nullptr) {
        kernels.triton_poi_fused_cat_102 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cgmnkk43inc7ntg3jf4sztxtjige7u6l5qp5jqu5u3ner5gdds63.cubin", "triton_poi_fused_cat_102", 0, this->cubin_dir_);
    }
    CUdeviceptr var_686 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_687 = reinterpret_cast<CUdeviceptr>(buf285.data_ptr());
    int32_t var_688 = triton_poi_fused_cat_102_xnumel;
    void* kernel_args_var_134[] = {&var_686, &var_687, &var_688};
    Grid triton_poi_fused_cat_102_grid_134 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_102_grid_134.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_102, triton_poi_fused_cat_102_grid_134.grid_x, triton_poi_fused_cat_102_grid_134.grid_y, triton_poi_fused_cat_102_grid_134.grid_z, 8, 0, kernel_args_var_134, stream);
    }
    const int64_t int_array_25[] = {s0, 960L};
    auto tmp_tensor_handle_102 = reinterpret_tensor_wrapper(buf388, 2, int_array_25, int_array_1, 9792L);
    RAIIAtenTensorHandle tmp_tensor_handle_102_raii(tmp_tensor_handle_102);
    decltype(auto) buf286 = std::move(tmp_tensor_handle_102_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_103_xnumel = 960L*s0;
    if (kernels.triton_poi_fused_cat_103 == nullptr) {
        kernels.triton_poi_fused_cat_103 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cfynedhpxxmfiwv4tbadm4gpxqhxibl2dazwx3vamtutsjobh55z.cubin", "triton_poi_fused_cat_103", 0, this->cubin_dir_);
    }
    CUdeviceptr var_689 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_690 = reinterpret_cast<CUdeviceptr>(buf286.data_ptr());
    int32_t var_691 = triton_poi_fused_cat_103_xnumel;
    void* kernel_args_var_135[] = {&var_689, &var_690, &var_691};
    Grid triton_poi_fused_cat_103_grid_135 = Grid((-1L)*static_cast<int64_t>(std::floor((-15.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_103_grid_135.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_103, triton_poi_fused_cat_103_grid_135.grid_x, triton_poi_fused_cat_103_grid_135.grid_y, triton_poi_fused_cat_103_grid_135.grid_z, 4, 0, kernel_args_var_135, stream);
    }
    auto tmp_tensor_handle_103 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 10752L);
    RAIIAtenTensorHandle tmp_tensor_handle_103_raii(tmp_tensor_handle_103);
    decltype(auto) buf287 = std::move(tmp_tensor_handle_103_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_104_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_104 == nullptr) {
        kernels.triton_poi_fused_cat_104 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cmgtjddlvh633fkjbd6e5fwev2bsz2qthtgonmsvbq6umkrjbyfj.cubin", "triton_poi_fused_cat_104", 0, this->cubin_dir_);
    }
    CUdeviceptr var_692 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_693 = reinterpret_cast<CUdeviceptr>(buf287.data_ptr());
    int32_t var_694 = triton_poi_fused_cat_104_xnumel;
    void* kernel_args_var_136[] = {&var_692, &var_693, &var_694};
    Grid triton_poi_fused_cat_104_grid_136 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_104_grid_136.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_104, triton_poi_fused_cat_104_grid_136.grid_x, triton_poi_fused_cat_104_grid_136.grid_y, triton_poi_fused_cat_104_grid_136.grid_z, 4, 0, kernel_args_var_136, stream);
    }
    const int64_t int_array_26[] = {s0, 576L};
    auto tmp_tensor_handle_104 = reinterpret_tensor_wrapper(buf388, 2, int_array_26, int_array_1, 10944L);
    RAIIAtenTensorHandle tmp_tensor_handle_104_raii(tmp_tensor_handle_104);
    decltype(auto) buf288 = std::move(tmp_tensor_handle_104_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_105_xnumel = 576L*s0;
    if (kernels.triton_poi_fused_cat_105 == nullptr) {
        kernels.triton_poi_fused_cat_105 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/calc3sc6e7zghv7jr25x4tkel7e2ohoknyfnkf3yvb2jx7nlmjci.cubin", "triton_poi_fused_cat_105", 0, this->cubin_dir_);
    }
    CUdeviceptr var_695 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_696 = reinterpret_cast<CUdeviceptr>(buf288.data_ptr());
    int32_t var_697 = triton_poi_fused_cat_105_xnumel;
    void* kernel_args_var_137[] = {&var_695, &var_696, &var_697};
    Grid triton_poi_fused_cat_105_grid_137 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_105_grid_137.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_105, triton_poi_fused_cat_105_grid_137.grid_x, triton_poi_fused_cat_105_grid_137.grid_y, triton_poi_fused_cat_105_grid_137.grid_z, 4, 0, kernel_args_var_137, stream);
    }
    auto tmp_tensor_handle_105 = reinterpret_tensor_wrapper(buf388, 2, int_array_22, int_array_1, 11520L);
    RAIIAtenTensorHandle tmp_tensor_handle_105_raii(tmp_tensor_handle_105);
    decltype(auto) buf289 = std::move(tmp_tensor_handle_105_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_106_xnumel = 768L*s0;
    if (kernels.triton_poi_fused_cat_106 == nullptr) {
        kernels.triton_poi_fused_cat_106 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c2rm3ss7nkl47yc4ien2cwgl7te6ua3wu7djvaayofc5r2w464uk.cubin", "triton_poi_fused_cat_106", 0, this->cubin_dir_);
    }
    CUdeviceptr var_698 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_699 = reinterpret_cast<CUdeviceptr>(buf289.data_ptr());
    int32_t var_700 = triton_poi_fused_cat_106_xnumel;
    void* kernel_args_var_138[] = {&var_698, &var_699, &var_700};
    Grid triton_poi_fused_cat_106_grid_138 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_106_grid_138.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_106, triton_poi_fused_cat_106_grid_138.grid_x, triton_poi_fused_cat_106_grid_138.grid_y, triton_poi_fused_cat_106_grid_138.grid_z, 4, 0, kernel_args_var_138, stream);
    }
    auto tmp_tensor_handle_106 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 12288L);
    RAIIAtenTensorHandle tmp_tensor_handle_106_raii(tmp_tensor_handle_106);
    decltype(auto) buf290 = std::move(tmp_tensor_handle_106_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_107_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_107 == nullptr) {
        kernels.triton_poi_fused_cat_107 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c3fi2fqicz7uvv3ml4n6pex3qkzutw3eofq4lmickazwe7ppkmwy.cubin", "triton_poi_fused_cat_107", 0, this->cubin_dir_);
    }
    CUdeviceptr var_701 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_702 = reinterpret_cast<CUdeviceptr>(buf290.data_ptr());
    int32_t var_703 = triton_poi_fused_cat_107_xnumel;
    void* kernel_args_var_139[] = {&var_701, &var_702, &var_703};
    Grid triton_poi_fused_cat_107_grid_139 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_107_grid_139.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_107, triton_poi_fused_cat_107_grid_139.grid_x, triton_poi_fused_cat_107_grid_139.grid_y, triton_poi_fused_cat_107_grid_139.grid_z, 4, 0, kernel_args_var_139, stream);
    }
    auto tmp_tensor_handle_107 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 12480L);
    RAIIAtenTensorHandle tmp_tensor_handle_107_raii(tmp_tensor_handle_107);
    decltype(auto) buf291 = std::move(tmp_tensor_handle_107_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_108_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_108 == nullptr) {
        kernels.triton_poi_fused_cat_108 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/clpmcct63abu4y4jpf7swtymktshus2z6ql4yrnvhomc3qh5n3nj.cubin", "triton_poi_fused_cat_108", 0, this->cubin_dir_);
    }
    CUdeviceptr var_704 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_705 = reinterpret_cast<CUdeviceptr>(buf291.data_ptr());
    int32_t var_706 = triton_poi_fused_cat_108_xnumel;
    void* kernel_args_var_140[] = {&var_704, &var_705, &var_706};
    Grid triton_poi_fused_cat_108_grid_140 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_108_grid_140.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_108, triton_poi_fused_cat_108_grid_140.grid_x, triton_poi_fused_cat_108_grid_140.grid_y, triton_poi_fused_cat_108_grid_140.grid_z, 8, 0, kernel_args_var_140, stream);
    }
    auto tmp_tensor_handle_108 = reinterpret_tensor_wrapper(buf388, 2, int_array_22, int_array_1, 12672L);
    RAIIAtenTensorHandle tmp_tensor_handle_108_raii(tmp_tensor_handle_108);
    decltype(auto) buf292 = std::move(tmp_tensor_handle_108_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_109_xnumel = 768L*s0;
    if (kernels.triton_poi_fused_cat_109 == nullptr) {
        kernels.triton_poi_fused_cat_109 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cj6gitw6gmpylcuozxq3ad7spcpoynbp4c3kpayes5kprydp2mx2.cubin", "triton_poi_fused_cat_109", 0, this->cubin_dir_);
    }
    CUdeviceptr var_707 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_708 = reinterpret_cast<CUdeviceptr>(buf292.data_ptr());
    int32_t var_709 = triton_poi_fused_cat_109_xnumel;
    void* kernel_args_var_141[] = {&var_707, &var_708, &var_709};
    Grid triton_poi_fused_cat_109_grid_141 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_109_grid_141.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_109, triton_poi_fused_cat_109_grid_141.grid_x, triton_poi_fused_cat_109_grid_141.grid_y, triton_poi_fused_cat_109_grid_141.grid_z, 4, 0, kernel_args_var_141, stream);
    }
    auto tmp_tensor_handle_109 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 13440L);
    RAIIAtenTensorHandle tmp_tensor_handle_109_raii(tmp_tensor_handle_109);
    decltype(auto) buf293 = std::move(tmp_tensor_handle_109_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_110_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_110 == nullptr) {
        kernels.triton_poi_fused_cat_110 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cizgnqxnnze45rcsysjbofu3kncvlnqzukpgapinfvk4kgm2kkxa.cubin", "triton_poi_fused_cat_110", 0, this->cubin_dir_);
    }
    CUdeviceptr var_710 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_711 = reinterpret_cast<CUdeviceptr>(buf293.data_ptr());
    int32_t var_712 = triton_poi_fused_cat_110_xnumel;
    void* kernel_args_var_142[] = {&var_710, &var_711, &var_712};
    Grid triton_poi_fused_cat_110_grid_142 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_110_grid_142.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_110, triton_poi_fused_cat_110_grid_142.grid_x, triton_poi_fused_cat_110_grid_142.grid_y, triton_poi_fused_cat_110_grid_142.grid_z, 4, 0, kernel_args_var_142, stream);
    }
    auto tmp_tensor_handle_110 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 13824L);
    RAIIAtenTensorHandle tmp_tensor_handle_110_raii(tmp_tensor_handle_110);
    decltype(auto) buf294 = std::move(tmp_tensor_handle_110_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_111_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_111 == nullptr) {
        kernels.triton_poi_fused_cat_111 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/carpetipsnebsiqptdsvxi4bsfp2hu6crspuvxjg3hec2d3etpp6.cubin", "triton_poi_fused_cat_111", 0, this->cubin_dir_);
    }
    CUdeviceptr var_713 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_714 = reinterpret_cast<CUdeviceptr>(buf294.data_ptr());
    int32_t var_715 = triton_poi_fused_cat_111_xnumel;
    void* kernel_args_var_143[] = {&var_713, &var_714, &var_715};
    Grid triton_poi_fused_cat_111_grid_143 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_111_grid_143.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_111, triton_poi_fused_cat_111_grid_143.grid_x, triton_poi_fused_cat_111_grid_143.grid_y, triton_poi_fused_cat_111_grid_143.grid_z, 4, 0, kernel_args_var_143, stream);
    }
    auto tmp_tensor_handle_111 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 14208L);
    RAIIAtenTensorHandle tmp_tensor_handle_111_raii(tmp_tensor_handle_111);
    decltype(auto) buf295 = std::move(tmp_tensor_handle_111_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_112_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_112 == nullptr) {
        kernels.triton_poi_fused_cat_112 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ca362al7w37sdryr7364d6l5ubqxmwqcxg6wquokjc2fii4jhdof.cubin", "triton_poi_fused_cat_112", 0, this->cubin_dir_);
    }
    CUdeviceptr var_716 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_717 = reinterpret_cast<CUdeviceptr>(buf295.data_ptr());
    int32_t var_718 = triton_poi_fused_cat_112_xnumel;
    void* kernel_args_var_144[] = {&var_716, &var_717, &var_718};
    Grid triton_poi_fused_cat_112_grid_144 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_112_grid_144.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_112, triton_poi_fused_cat_112_grid_144.grid_x, triton_poi_fused_cat_112_grid_144.grid_y, triton_poi_fused_cat_112_grid_144.grid_z, 4, 0, kernel_args_var_144, stream);
    }
    auto tmp_tensor_handle_112 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 14400L);
    RAIIAtenTensorHandle tmp_tensor_handle_112_raii(tmp_tensor_handle_112);
    decltype(auto) buf296 = std::move(tmp_tensor_handle_112_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_113_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_113 == nullptr) {
        kernels.triton_poi_fused_cat_113 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c43id3eoz3ixv7afdu7vjsggqkk67ok7yw44xniyyvqosxyguyx2.cubin", "triton_poi_fused_cat_113", 0, this->cubin_dir_);
    }
    CUdeviceptr var_719 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_720 = reinterpret_cast<CUdeviceptr>(buf296.data_ptr());
    int32_t var_721 = triton_poi_fused_cat_113_xnumel;
    void* kernel_args_var_145[] = {&var_719, &var_720, &var_721};
    Grid triton_poi_fused_cat_113_grid_145 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_113_grid_145.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_113, triton_poi_fused_cat_113_grid_145.grid_x, triton_poi_fused_cat_113_grid_145.grid_y, triton_poi_fused_cat_113_grid_145.grid_z, 4, 0, kernel_args_var_145, stream);
    }
    auto tmp_tensor_handle_113 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 14784L);
    RAIIAtenTensorHandle tmp_tensor_handle_113_raii(tmp_tensor_handle_113);
    decltype(auto) buf297 = std::move(tmp_tensor_handle_113_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_114_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_114 == nullptr) {
        kernels.triton_poi_fused_cat_114 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cintmwiibvx65fji6amaa26gniz6inl2qqvd2ocxuwciadpzsavp.cubin", "triton_poi_fused_cat_114", 0, this->cubin_dir_);
    }
    CUdeviceptr var_722 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_723 = reinterpret_cast<CUdeviceptr>(buf297.data_ptr());
    int32_t var_724 = triton_poi_fused_cat_114_xnumel;
    void* kernel_args_var_146[] = {&var_722, &var_723, &var_724};
    Grid triton_poi_fused_cat_114_grid_146 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_114_grid_146.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_114, triton_poi_fused_cat_114_grid_146.grid_x, triton_poi_fused_cat_114_grid_146.grid_y, triton_poi_fused_cat_114_grid_146.grid_z, 4, 0, kernel_args_var_146, stream);
    }
    auto tmp_tensor_handle_114 = reinterpret_tensor_wrapper(buf388, 2, int_array_24, int_array_1, 14976L);
    RAIIAtenTensorHandle tmp_tensor_handle_114_raii(tmp_tensor_handle_114);
    decltype(auto) buf298 = std::move(tmp_tensor_handle_114_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_115_xnumel = 1152L*s0;
    if (kernels.triton_poi_fused_cat_115 == nullptr) {
        kernels.triton_poi_fused_cat_115 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cfnmtewgvxpjruqyvljwwxmcwcnj2dkrlm5yqntpdmn6deulzfry.cubin", "triton_poi_fused_cat_115", 0, this->cubin_dir_);
    }
    CUdeviceptr var_725 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_726 = reinterpret_cast<CUdeviceptr>(buf298.data_ptr());
    int32_t var_727 = triton_poi_fused_cat_115_xnumel;
    void* kernel_args_var_147[] = {&var_725, &var_726, &var_727};
    Grid triton_poi_fused_cat_115_grid_147 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_115_grid_147.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_115, triton_poi_fused_cat_115_grid_147.grid_x, triton_poi_fused_cat_115_grid_147.grid_y, triton_poi_fused_cat_115_grid_147.grid_z, 4, 0, kernel_args_var_147, stream);
    }
    auto tmp_tensor_handle_115 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 16128L);
    RAIIAtenTensorHandle tmp_tensor_handle_115_raii(tmp_tensor_handle_115);
    decltype(auto) buf299 = std::move(tmp_tensor_handle_115_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_116_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_116 == nullptr) {
        kernels.triton_poi_fused_cat_116 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/crtrk2a6cpq4pr6snngeezuydzwvka6um35cadplla2y5oup6zi7.cubin", "triton_poi_fused_cat_116", 0, this->cubin_dir_);
    }
    CUdeviceptr var_728 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_729 = reinterpret_cast<CUdeviceptr>(buf299.data_ptr());
    int32_t var_730 = triton_poi_fused_cat_116_xnumel;
    void* kernel_args_var_148[] = {&var_728, &var_729, &var_730};
    Grid triton_poi_fused_cat_116_grid_148 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_116_grid_148.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_116, triton_poi_fused_cat_116_grid_148.grid_x, triton_poi_fused_cat_116_grid_148.grid_y, triton_poi_fused_cat_116_grid_148.grid_z, 4, 0, kernel_args_var_148, stream);
    }
    auto tmp_tensor_handle_116 = reinterpret_tensor_wrapper(buf388, 2, int_array_22, int_array_1, 16320L);
    RAIIAtenTensorHandle tmp_tensor_handle_116_raii(tmp_tensor_handle_116);
    decltype(auto) buf300 = std::move(tmp_tensor_handle_116_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_117_xnumel = 768L*s0;
    if (kernels.triton_poi_fused_cat_117 == nullptr) {
        kernels.triton_poi_fused_cat_117 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cbv3mgnpd6hwiadtydg35qiuhne6dev3bi7om5rvevrfy5rz7q4e.cubin", "triton_poi_fused_cat_117", 0, this->cubin_dir_);
    }
    CUdeviceptr var_731 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_732 = reinterpret_cast<CUdeviceptr>(buf300.data_ptr());
    int32_t var_733 = triton_poi_fused_cat_117_xnumel;
    void* kernel_args_var_149[] = {&var_731, &var_732, &var_733};
    Grid triton_poi_fused_cat_117_grid_149 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_117_grid_149.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_117, triton_poi_fused_cat_117_grid_149.grid_x, triton_poi_fused_cat_117_grid_149.grid_y, triton_poi_fused_cat_117_grid_149.grid_z, 4, 0, kernel_args_var_149, stream);
    }
    auto tmp_tensor_handle_117 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 17088L);
    RAIIAtenTensorHandle tmp_tensor_handle_117_raii(tmp_tensor_handle_117);
    decltype(auto) buf301 = std::move(tmp_tensor_handle_117_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_118_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_118 == nullptr) {
        kernels.triton_poi_fused_cat_118 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ceot6kfgasvf6k45jroxd55bi7f5qmh7jvdilzvtj33gcnsvixop.cubin", "triton_poi_fused_cat_118", 0, this->cubin_dir_);
    }
    CUdeviceptr var_734 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_735 = reinterpret_cast<CUdeviceptr>(buf301.data_ptr());
    int32_t var_736 = triton_poi_fused_cat_118_xnumel;
    void* kernel_args_var_150[] = {&var_734, &var_735, &var_736};
    Grid triton_poi_fused_cat_118_grid_150 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_118_grid_150.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_118, triton_poi_fused_cat_118_grid_150.grid_x, triton_poi_fused_cat_118_grid_150.grid_y, triton_poi_fused_cat_118_grid_150.grid_z, 8, 0, kernel_args_var_150, stream);
    }
    auto tmp_tensor_handle_118 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 17280L);
    RAIIAtenTensorHandle tmp_tensor_handle_118_raii(tmp_tensor_handle_118);
    decltype(auto) buf302 = std::move(tmp_tensor_handle_118_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_119_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_119 == nullptr) {
        kernels.triton_poi_fused_cat_119 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c5mauafvp3yualiim26q34vc5e2kz6ufax5xd2noy64v3thctuqm.cubin", "triton_poi_fused_cat_119", 0, this->cubin_dir_);
    }
    CUdeviceptr var_737 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_738 = reinterpret_cast<CUdeviceptr>(buf302.data_ptr());
    int32_t var_739 = triton_poi_fused_cat_119_xnumel;
    void* kernel_args_var_151[] = {&var_737, &var_738, &var_739};
    Grid triton_poi_fused_cat_119_grid_151 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_119_grid_151.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_119, triton_poi_fused_cat_119_grid_151.grid_x, triton_poi_fused_cat_119_grid_151.grid_y, triton_poi_fused_cat_119_grid_151.grid_z, 4, 0, kernel_args_var_151, stream);
    }
    auto tmp_tensor_handle_119 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 17664L);
    RAIIAtenTensorHandle tmp_tensor_handle_119_raii(tmp_tensor_handle_119);
    decltype(auto) buf303 = std::move(tmp_tensor_handle_119_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_120_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_120 == nullptr) {
        kernels.triton_poi_fused_cat_120 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cvjfflkscug7pdc2urvbw4trh3cbgqyaqyxfk5hubpv7kvdzd6jh.cubin", "triton_poi_fused_cat_120", 0, this->cubin_dir_);
    }
    CUdeviceptr var_740 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_741 = reinterpret_cast<CUdeviceptr>(buf303.data_ptr());
    int32_t var_742 = triton_poi_fused_cat_120_xnumel;
    void* kernel_args_var_152[] = {&var_740, &var_741, &var_742};
    Grid triton_poi_fused_cat_120_grid_152 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_120_grid_152.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_120, triton_poi_fused_cat_120_grid_152.grid_x, triton_poi_fused_cat_120_grid_152.grid_y, triton_poi_fused_cat_120_grid_152.grid_z, 8, 0, kernel_args_var_152, stream);
    }
    auto tmp_tensor_handle_120 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 17856L);
    RAIIAtenTensorHandle tmp_tensor_handle_120_raii(tmp_tensor_handle_120);
    decltype(auto) buf304 = std::move(tmp_tensor_handle_120_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_121_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_121 == nullptr) {
        kernels.triton_poi_fused_cat_121 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cu4vzdlzb5oh4s2xjdoxjts6nmus5omkcnrx42lc5zs2vriq7qoj.cubin", "triton_poi_fused_cat_121", 0, this->cubin_dir_);
    }
    CUdeviceptr var_743 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_744 = reinterpret_cast<CUdeviceptr>(buf304.data_ptr());
    int32_t var_745 = triton_poi_fused_cat_121_xnumel;
    void* kernel_args_var_153[] = {&var_743, &var_744, &var_745};
    Grid triton_poi_fused_cat_121_grid_153 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_121_grid_153.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_121, triton_poi_fused_cat_121_grid_153.grid_x, triton_poi_fused_cat_121_grid_153.grid_y, triton_poi_fused_cat_121_grid_153.grid_z, 8, 0, kernel_args_var_153, stream);
    }
    auto tmp_tensor_handle_121 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 18048L);
    RAIIAtenTensorHandle tmp_tensor_handle_121_raii(tmp_tensor_handle_121);
    decltype(auto) buf305 = std::move(tmp_tensor_handle_121_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_122_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_122 == nullptr) {
        kernels.triton_poi_fused_cat_122 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c4lbwyoqnc7hf2jtsxlximgyt6b4kde2t5y4dtkoaancmcxjlyyh.cubin", "triton_poi_fused_cat_122", 0, this->cubin_dir_);
    }
    CUdeviceptr var_746 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_747 = reinterpret_cast<CUdeviceptr>(buf305.data_ptr());
    int32_t var_748 = triton_poi_fused_cat_122_xnumel;
    void* kernel_args_var_154[] = {&var_746, &var_747, &var_748};
    Grid triton_poi_fused_cat_122_grid_154 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_122_grid_154.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_122, triton_poi_fused_cat_122_grid_154.grid_x, triton_poi_fused_cat_122_grid_154.grid_y, triton_poi_fused_cat_122_grid_154.grid_z, 4, 0, kernel_args_var_154, stream);
    }
    auto tmp_tensor_handle_122 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 18432L);
    RAIIAtenTensorHandle tmp_tensor_handle_122_raii(tmp_tensor_handle_122);
    decltype(auto) buf306 = std::move(tmp_tensor_handle_122_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_123_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_123 == nullptr) {
        kernels.triton_poi_fused_cat_123 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cszraa3blvob6tuavoq62l2lh26334dtpmmvwf44jxosvsx3uw72.cubin", "triton_poi_fused_cat_123", 0, this->cubin_dir_);
    }
    CUdeviceptr var_749 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_750 = reinterpret_cast<CUdeviceptr>(buf306.data_ptr());
    int32_t var_751 = triton_poi_fused_cat_123_xnumel;
    void* kernel_args_var_155[] = {&var_749, &var_750, &var_751};
    Grid triton_poi_fused_cat_123_grid_155 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_123_grid_155.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_123, triton_poi_fused_cat_123_grid_155.grid_x, triton_poi_fused_cat_123_grid_155.grid_y, triton_poi_fused_cat_123_grid_155.grid_z, 4, 0, kernel_args_var_155, stream);
    }
    auto tmp_tensor_handle_123 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 18816L);
    RAIIAtenTensorHandle tmp_tensor_handle_123_raii(tmp_tensor_handle_123);
    decltype(auto) buf307 = std::move(tmp_tensor_handle_123_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_124_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_124 == nullptr) {
        kernels.triton_poi_fused_cat_124 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cp5leascyaljhlgzku3wexuoxlo3szkyksrhxgokthebah53j55f.cubin", "triton_poi_fused_cat_124", 0, this->cubin_dir_);
    }
    CUdeviceptr var_752 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_753 = reinterpret_cast<CUdeviceptr>(buf307.data_ptr());
    int32_t var_754 = triton_poi_fused_cat_124_xnumel;
    void* kernel_args_var_156[] = {&var_752, &var_753, &var_754};
    Grid triton_poi_fused_cat_124_grid_156 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_124_grid_156.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_124, triton_poi_fused_cat_124_grid_156.grid_x, triton_poi_fused_cat_124_grid_156.grid_y, triton_poi_fused_cat_124_grid_156.grid_z, 8, 0, kernel_args_var_156, stream);
    }
    auto tmp_tensor_handle_124 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 19008L);
    RAIIAtenTensorHandle tmp_tensor_handle_124_raii(tmp_tensor_handle_124);
    decltype(auto) buf308 = std::move(tmp_tensor_handle_124_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_125_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_125 == nullptr) {
        kernels.triton_poi_fused_cat_125 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckypwzdhjblnxb5v6p7fxq27ouzrtgpevikzxnxxe662jgpelrr2.cubin", "triton_poi_fused_cat_125", 0, this->cubin_dir_);
    }
    CUdeviceptr var_755 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_756 = reinterpret_cast<CUdeviceptr>(buf308.data_ptr());
    int32_t var_757 = triton_poi_fused_cat_125_xnumel;
    void* kernel_args_var_157[] = {&var_755, &var_756, &var_757};
    Grid triton_poi_fused_cat_125_grid_157 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_125_grid_157.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_125, triton_poi_fused_cat_125_grid_157.grid_x, triton_poi_fused_cat_125_grid_157.grid_y, triton_poi_fused_cat_125_grid_157.grid_z, 4, 0, kernel_args_var_157, stream);
    }
    auto tmp_tensor_handle_125 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 19200L);
    RAIIAtenTensorHandle tmp_tensor_handle_125_raii(tmp_tensor_handle_125);
    decltype(auto) buf309 = std::move(tmp_tensor_handle_125_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_126_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_126 == nullptr) {
        kernels.triton_poi_fused_cat_126 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cvylv2rlwgjz4e5czsmot66yplketqxryelhjhpprbkf2ut2rqv6.cubin", "triton_poi_fused_cat_126", 0, this->cubin_dir_);
    }
    CUdeviceptr var_758 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_759 = reinterpret_cast<CUdeviceptr>(buf309.data_ptr());
    int32_t var_760 = triton_poi_fused_cat_126_xnumel;
    void* kernel_args_var_158[] = {&var_758, &var_759, &var_760};
    Grid triton_poi_fused_cat_126_grid_158 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_126_grid_158.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_126, triton_poi_fused_cat_126_grid_158.grid_x, triton_poi_fused_cat_126_grid_158.grid_y, triton_poi_fused_cat_126_grid_158.grid_z, 4, 0, kernel_args_var_158, stream);
    }
    auto tmp_tensor_handle_126 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 19392L);
    RAIIAtenTensorHandle tmp_tensor_handle_126_raii(tmp_tensor_handle_126);
    decltype(auto) buf310 = std::move(tmp_tensor_handle_126_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_127_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_127 == nullptr) {
        kernels.triton_poi_fused_cat_127 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cqfce72s7azkwmh5tdhcrv73m37s7frzlawqvr2pzea2ff7jdrgj.cubin", "triton_poi_fused_cat_127", 0, this->cubin_dir_);
    }
    CUdeviceptr var_761 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_762 = reinterpret_cast<CUdeviceptr>(buf310.data_ptr());
    int32_t var_763 = triton_poi_fused_cat_127_xnumel;
    void* kernel_args_var_159[] = {&var_761, &var_762, &var_763};
    Grid triton_poi_fused_cat_127_grid_159 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_127_grid_159.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_127, triton_poi_fused_cat_127_grid_159.grid_x, triton_poi_fused_cat_127_grid_159.grid_y, triton_poi_fused_cat_127_grid_159.grid_z, 4, 0, kernel_args_var_159, stream);
    }
    auto tmp_tensor_handle_127 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 19776L);
    RAIIAtenTensorHandle tmp_tensor_handle_127_raii(tmp_tensor_handle_127);
    decltype(auto) buf311 = std::move(tmp_tensor_handle_127_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_128_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_128 == nullptr) {
        kernels.triton_poi_fused_cat_128 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/clqyo6lxbu247xgekhfampxtwc63tlc5eevww6fms5a4h2gn74qi.cubin", "triton_poi_fused_cat_128", 0, this->cubin_dir_);
    }
    CUdeviceptr var_764 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_765 = reinterpret_cast<CUdeviceptr>(buf311.data_ptr());
    int32_t var_766 = triton_poi_fused_cat_128_xnumel;
    void* kernel_args_var_160[] = {&var_764, &var_765, &var_766};
    Grid triton_poi_fused_cat_128_grid_160 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_128_grid_160.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_128, triton_poi_fused_cat_128_grid_160.grid_x, triton_poi_fused_cat_128_grid_160.grid_y, triton_poi_fused_cat_128_grid_160.grid_z, 4, 0, kernel_args_var_160, stream);
    }
    auto tmp_tensor_handle_128 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 20160L);
    RAIIAtenTensorHandle tmp_tensor_handle_128_raii(tmp_tensor_handle_128);
    decltype(auto) buf312 = std::move(tmp_tensor_handle_128_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_129_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_129 == nullptr) {
        kernels.triton_poi_fused_cat_129 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cv5am6qseyum4r2l6ht2collsnkb4q3kjxjyqmysrk3ckn34ccuw.cubin", "triton_poi_fused_cat_129", 0, this->cubin_dir_);
    }
    CUdeviceptr var_767 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_768 = reinterpret_cast<CUdeviceptr>(buf312.data_ptr());
    int32_t var_769 = triton_poi_fused_cat_129_xnumel;
    void* kernel_args_var_161[] = {&var_767, &var_768, &var_769};
    Grid triton_poi_fused_cat_129_grid_161 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_129_grid_161.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_129, triton_poi_fused_cat_129_grid_161.grid_x, triton_poi_fused_cat_129_grid_161.grid_y, triton_poi_fused_cat_129_grid_161.grid_z, 4, 0, kernel_args_var_161, stream);
    }
    const int64_t int_array_27[] = {s0, 13056L};
    auto tmp_tensor_handle_129 = reinterpret_tensor_wrapper(buf388, 2, int_array_27, int_array_1, 20544L);
    RAIIAtenTensorHandle tmp_tensor_handle_129_raii(tmp_tensor_handle_129);
    decltype(auto) buf313 = std::move(tmp_tensor_handle_129_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_130_xnumel = 13056L*s0;
    if (kernels.triton_poi_fused_cat_130 == nullptr) {
        kernels.triton_poi_fused_cat_130 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cyfhvydnrqz24jt7zupyf5sgqehi3v2tp6ng2ip2msbvd7fdwhbp.cubin", "triton_poi_fused_cat_130", 0, this->cubin_dir_);
    }
    CUdeviceptr var_770 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_771 = reinterpret_cast<CUdeviceptr>(buf313.data_ptr());
    int32_t var_772 = triton_poi_fused_cat_130_xnumel;
    void* kernel_args_var_162[] = {&var_770, &var_771, &var_772};
    Grid triton_poi_fused_cat_130_grid_162 = Grid((-1L)*static_cast<int64_t>(std::floor((-51.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_130_grid_162.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_130, triton_poi_fused_cat_130_grid_162.grid_x, triton_poi_fused_cat_130_grid_162.grid_y, triton_poi_fused_cat_130_grid_162.grid_z, 4, 0, kernel_args_var_162, stream);
    }
    auto tmp_tensor_handle_130 = reinterpret_tensor_wrapper(buf388, 2, int_array_22, int_array_1, 33600L);
    RAIIAtenTensorHandle tmp_tensor_handle_130_raii(tmp_tensor_handle_130);
    decltype(auto) buf314 = std::move(tmp_tensor_handle_130_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_131_xnumel = 768L*s0;
    if (kernels.triton_poi_fused_cat_131 == nullptr) {
        kernels.triton_poi_fused_cat_131 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckb25iybwqdp256fx2gbelqi422ghsuspenc2nqnsvyxr4ukemlb.cubin", "triton_poi_fused_cat_131", 0, this->cubin_dir_);
    }
    CUdeviceptr var_773 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_774 = reinterpret_cast<CUdeviceptr>(buf314.data_ptr());
    int32_t var_775 = triton_poi_fused_cat_131_xnumel;
    void* kernel_args_var_163[] = {&var_773, &var_774, &var_775};
    Grid triton_poi_fused_cat_131_grid_163 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_131_grid_163.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_131, triton_poi_fused_cat_131_grid_163.grid_x, triton_poi_fused_cat_131_grid_163.grid_y, triton_poi_fused_cat_131_grid_163.grid_z, 4, 0, kernel_args_var_163, stream);
    }
    auto tmp_tensor_handle_131 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 34368L);
    RAIIAtenTensorHandle tmp_tensor_handle_131_raii(tmp_tensor_handle_131);
    decltype(auto) buf315 = std::move(tmp_tensor_handle_131_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_132_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_132 == nullptr) {
        kernels.triton_poi_fused_cat_132 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cttim37xralbljh23bir7kxv3jvjttt7oheu3b2k62hqw2pa6ha5.cubin", "triton_poi_fused_cat_132", 0, this->cubin_dir_);
    }
    CUdeviceptr var_776 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_777 = reinterpret_cast<CUdeviceptr>(buf315.data_ptr());
    int32_t var_778 = triton_poi_fused_cat_132_xnumel;
    void* kernel_args_var_164[] = {&var_776, &var_777, &var_778};
    Grid triton_poi_fused_cat_132_grid_164 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_132_grid_164.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_132, triton_poi_fused_cat_132_grid_164.grid_x, triton_poi_fused_cat_132_grid_164.grid_y, triton_poi_fused_cat_132_grid_164.grid_z, 4, 0, kernel_args_var_164, stream);
    }
    auto tmp_tensor_handle_132 = reinterpret_tensor_wrapper(buf388, 2, int_array_24, int_array_1, 34560L);
    RAIIAtenTensorHandle tmp_tensor_handle_132_raii(tmp_tensor_handle_132);
    decltype(auto) buf316 = std::move(tmp_tensor_handle_132_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_133_xnumel = 1152L*s0;
    if (kernels.triton_poi_fused_cat_133 == nullptr) {
        kernels.triton_poi_fused_cat_133 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/crmrwknc47uesabumx2jtn2kiuilpq35cdq3bg6wvoklxxqddbaw.cubin", "triton_poi_fused_cat_133", 0, this->cubin_dir_);
    }
    CUdeviceptr var_779 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_780 = reinterpret_cast<CUdeviceptr>(buf316.data_ptr());
    int32_t var_781 = triton_poi_fused_cat_133_xnumel;
    void* kernel_args_var_165[] = {&var_779, &var_780, &var_781};
    Grid triton_poi_fused_cat_133_grid_165 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_133_grid_165.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_133, triton_poi_fused_cat_133_grid_165.grid_x, triton_poi_fused_cat_133_grid_165.grid_y, triton_poi_fused_cat_133_grid_165.grid_z, 4, 0, kernel_args_var_165, stream);
    }
    auto tmp_tensor_handle_133 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 35712L);
    RAIIAtenTensorHandle tmp_tensor_handle_133_raii(tmp_tensor_handle_133);
    decltype(auto) buf317 = std::move(tmp_tensor_handle_133_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_134_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_134 == nullptr) {
        kernels.triton_poi_fused_cat_134 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cgh24qud5wsl5y2j5gyptstvi5whjfpml6dlrfrtwpnveuuoiet5.cubin", "triton_poi_fused_cat_134", 0, this->cubin_dir_);
    }
    CUdeviceptr var_782 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_783 = reinterpret_cast<CUdeviceptr>(buf317.data_ptr());
    int32_t var_784 = triton_poi_fused_cat_134_xnumel;
    void* kernel_args_var_166[] = {&var_782, &var_783, &var_784};
    Grid triton_poi_fused_cat_134_grid_166 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_134_grid_166.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_134, triton_poi_fused_cat_134_grid_166.grid_x, triton_poi_fused_cat_134_grid_166.grid_y, triton_poi_fused_cat_134_grid_166.grid_z, 4, 0, kernel_args_var_166, stream);
    }
    auto tmp_tensor_handle_134 = reinterpret_tensor_wrapper(buf388, 2, int_array_26, int_array_1, 35904L);
    RAIIAtenTensorHandle tmp_tensor_handle_134_raii(tmp_tensor_handle_134);
    decltype(auto) buf318 = std::move(tmp_tensor_handle_134_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_135_xnumel = 576L*s0;
    if (kernels.triton_poi_fused_cat_135 == nullptr) {
        kernels.triton_poi_fused_cat_135 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ctkr3amw4i2nqadujy64sthpxzrlxjde7iduj75ubsvlun4rufj3.cubin", "triton_poi_fused_cat_135", 0, this->cubin_dir_);
    }
    CUdeviceptr var_785 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_786 = reinterpret_cast<CUdeviceptr>(buf318.data_ptr());
    int32_t var_787 = triton_poi_fused_cat_135_xnumel;
    void* kernel_args_var_167[] = {&var_785, &var_786, &var_787};
    Grid triton_poi_fused_cat_135_grid_167 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_135_grid_167.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_135, triton_poi_fused_cat_135_grid_167.grid_x, triton_poi_fused_cat_135_grid_167.grid_y, triton_poi_fused_cat_135_grid_167.grid_z, 4, 0, kernel_args_var_167, stream);
    }
    auto tmp_tensor_handle_135 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 36480L);
    RAIIAtenTensorHandle tmp_tensor_handle_135_raii(tmp_tensor_handle_135);
    decltype(auto) buf319 = std::move(tmp_tensor_handle_135_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_136_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_136 == nullptr) {
        kernels.triton_poi_fused_cat_136 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c3faal3epberhkwt4zdzzbfdj4irvj7ney5w2cd2o6627mvbjtmr.cubin", "triton_poi_fused_cat_136", 0, this->cubin_dir_);
    }
    CUdeviceptr var_788 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_789 = reinterpret_cast<CUdeviceptr>(buf319.data_ptr());
    int32_t var_790 = triton_poi_fused_cat_136_xnumel;
    void* kernel_args_var_168[] = {&var_788, &var_789, &var_790};
    Grid triton_poi_fused_cat_136_grid_168 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_136_grid_168.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_136, triton_poi_fused_cat_136_grid_168.grid_x, triton_poi_fused_cat_136_grid_168.grid_y, triton_poi_fused_cat_136_grid_168.grid_z, 4, 0, kernel_args_var_168, stream);
    }
    auto tmp_tensor_handle_136 = reinterpret_tensor_wrapper(buf388, 2, int_array_20, int_array_1, 36672L);
    RAIIAtenTensorHandle tmp_tensor_handle_136_raii(tmp_tensor_handle_136);
    decltype(auto) buf320 = std::move(tmp_tensor_handle_136_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_137_xnumel = 2880L*s0;
    if (kernels.triton_poi_fused_cat_137 == nullptr) {
        kernels.triton_poi_fused_cat_137 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cnth3zvfax7kjbu2isgztj6b3ouscdass6pa4bi7pyb2yclwmxr6.cubin", "triton_poi_fused_cat_137", 0, this->cubin_dir_);
    }
    CUdeviceptr var_791 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_792 = reinterpret_cast<CUdeviceptr>(buf320.data_ptr());
    int32_t var_793 = triton_poi_fused_cat_137_xnumel;
    void* kernel_args_var_169[] = {&var_791, &var_792, &var_793};
    Grid triton_poi_fused_cat_137_grid_169 = Grid((-1L)*static_cast<int64_t>(std::floor((-45.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_137_grid_169.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_137, triton_poi_fused_cat_137_grid_169.grid_x, triton_poi_fused_cat_137_grid_169.grid_y, triton_poi_fused_cat_137_grid_169.grid_z, 4, 0, kernel_args_var_169, stream);
    }
    auto tmp_tensor_handle_137 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 39552L);
    RAIIAtenTensorHandle tmp_tensor_handle_137_raii(tmp_tensor_handle_137);
    decltype(auto) buf321 = std::move(tmp_tensor_handle_137_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_138_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_138 == nullptr) {
        kernels.triton_poi_fused_cat_138 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c3bjlb274dysuric6f5daq5rpkdlxliu3576asmdovzuszu475ik.cubin", "triton_poi_fused_cat_138", 0, this->cubin_dir_);
    }
    CUdeviceptr var_794 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_795 = reinterpret_cast<CUdeviceptr>(buf321.data_ptr());
    int32_t var_796 = triton_poi_fused_cat_138_xnumel;
    void* kernel_args_var_170[] = {&var_794, &var_795, &var_796};
    Grid triton_poi_fused_cat_138_grid_170 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_138_grid_170.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_138, triton_poi_fused_cat_138_grid_170.grid_x, triton_poi_fused_cat_138_grid_170.grid_y, triton_poi_fused_cat_138_grid_170.grid_z, 4, 0, kernel_args_var_170, stream);
    }
    auto tmp_tensor_handle_138 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 39936L);
    RAIIAtenTensorHandle tmp_tensor_handle_138_raii(tmp_tensor_handle_138);
    decltype(auto) buf322 = std::move(tmp_tensor_handle_138_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_139_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_139 == nullptr) {
        kernels.triton_poi_fused_cat_139 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/co4pvjilwm6g7lcqi7yqnjfxcnz3vwd27g55r3imm5pfcfqvlaso.cubin", "triton_poi_fused_cat_139", 0, this->cubin_dir_);
    }
    CUdeviceptr var_797 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_798 = reinterpret_cast<CUdeviceptr>(buf322.data_ptr());
    int32_t var_799 = triton_poi_fused_cat_139_xnumel;
    void* kernel_args_var_171[] = {&var_797, &var_798, &var_799};
    Grid triton_poi_fused_cat_139_grid_171 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_139_grid_171.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_139, triton_poi_fused_cat_139_grid_171.grid_x, triton_poi_fused_cat_139_grid_171.grid_y, triton_poi_fused_cat_139_grid_171.grid_z, 8, 0, kernel_args_var_171, stream);
    }
    auto tmp_tensor_handle_139 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 40320L);
    RAIIAtenTensorHandle tmp_tensor_handle_139_raii(tmp_tensor_handle_139);
    decltype(auto) buf323 = std::move(tmp_tensor_handle_139_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_140_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_140 == nullptr) {
        kernels.triton_poi_fused_cat_140 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjmueokxn6ftmiuk2mearslta3fp7dwpq3jr5i5egjjdy6qc7uvr.cubin", "triton_poi_fused_cat_140", 0, this->cubin_dir_);
    }
    CUdeviceptr var_800 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_801 = reinterpret_cast<CUdeviceptr>(buf323.data_ptr());
    int32_t var_802 = triton_poi_fused_cat_140_xnumel;
    void* kernel_args_var_172[] = {&var_800, &var_801, &var_802};
    Grid triton_poi_fused_cat_140_grid_172 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_140_grid_172.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_140, triton_poi_fused_cat_140_grid_172.grid_x, triton_poi_fused_cat_140_grid_172.grid_y, triton_poi_fused_cat_140_grid_172.grid_z, 4, 0, kernel_args_var_172, stream);
    }
    auto tmp_tensor_handle_140 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 40512L);
    RAIIAtenTensorHandle tmp_tensor_handle_140_raii(tmp_tensor_handle_140);
    decltype(auto) buf324 = std::move(tmp_tensor_handle_140_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_141_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_141 == nullptr) {
        kernels.triton_poi_fused_cat_141 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjuyaeo33ngufoxy3canwuksniuhkf6p5dfu5f5g5cogwjedkjjh.cubin", "triton_poi_fused_cat_141", 0, this->cubin_dir_);
    }
    CUdeviceptr var_803 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_804 = reinterpret_cast<CUdeviceptr>(buf324.data_ptr());
    int32_t var_805 = triton_poi_fused_cat_141_xnumel;
    void* kernel_args_var_173[] = {&var_803, &var_804, &var_805};
    Grid triton_poi_fused_cat_141_grid_173 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_141_grid_173.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_141, triton_poi_fused_cat_141_grid_173.grid_x, triton_poi_fused_cat_141_grid_173.grid_y, triton_poi_fused_cat_141_grid_173.grid_z, 4, 0, kernel_args_var_173, stream);
    }
    auto tmp_tensor_handle_141 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 40704L);
    RAIIAtenTensorHandle tmp_tensor_handle_141_raii(tmp_tensor_handle_141);
    decltype(auto) buf325 = std::move(tmp_tensor_handle_141_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_142_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_142 == nullptr) {
        kernels.triton_poi_fused_cat_142 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckngzmuz2utqphva5u66wombcttc5a26pqoatpflww2et43fogp7.cubin", "triton_poi_fused_cat_142", 0, this->cubin_dir_);
    }
    CUdeviceptr var_806 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_807 = reinterpret_cast<CUdeviceptr>(buf325.data_ptr());
    int32_t var_808 = triton_poi_fused_cat_142_xnumel;
    void* kernel_args_var_174[] = {&var_806, &var_807, &var_808};
    Grid triton_poi_fused_cat_142_grid_174 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_142_grid_174.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_142, triton_poi_fused_cat_142_grid_174.grid_x, triton_poi_fused_cat_142_grid_174.grid_y, triton_poi_fused_cat_142_grid_174.grid_z, 8, 0, kernel_args_var_174, stream);
    }
    const int64_t int_array_28[] = {s0, 1920L};
    auto tmp_tensor_handle_142 = reinterpret_tensor_wrapper(buf388, 2, int_array_28, int_array_1, 40896L);
    RAIIAtenTensorHandle tmp_tensor_handle_142_raii(tmp_tensor_handle_142);
    decltype(auto) buf326 = std::move(tmp_tensor_handle_142_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_143_xnumel = 1920L*s0;
    if (kernels.triton_poi_fused_cat_143 == nullptr) {
        kernels.triton_poi_fused_cat_143 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/chnggnwtr3pqlikdsfly2bn3so7m6mxbi5s27dwmyrsisl3fbs5c.cubin", "triton_poi_fused_cat_143", 0, this->cubin_dir_);
    }
    CUdeviceptr var_809 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_810 = reinterpret_cast<CUdeviceptr>(buf326.data_ptr());
    int32_t var_811 = triton_poi_fused_cat_143_xnumel;
    void* kernel_args_var_175[] = {&var_809, &var_810, &var_811};
    Grid triton_poi_fused_cat_143_grid_175 = Grid((-1L)*static_cast<int64_t>(std::floor((-15.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_143_grid_175.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_143, triton_poi_fused_cat_143_grid_175.grid_x, triton_poi_fused_cat_143_grid_175.grid_y, triton_poi_fused_cat_143_grid_175.grid_z, 4, 0, kernel_args_var_175, stream);
    }
    auto tmp_tensor_handle_143 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 42816L);
    RAIIAtenTensorHandle tmp_tensor_handle_143_raii(tmp_tensor_handle_143);
    decltype(auto) buf327 = std::move(tmp_tensor_handle_143_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_144_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_144 == nullptr) {
        kernels.triton_poi_fused_cat_144 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cok2wpkims5x3oznaq4ybik3ozouj55vefejjnuy76c7u6aht7d4.cubin", "triton_poi_fused_cat_144", 0, this->cubin_dir_);
    }
    CUdeviceptr var_812 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_813 = reinterpret_cast<CUdeviceptr>(buf327.data_ptr());
    int32_t var_814 = triton_poi_fused_cat_144_xnumel;
    void* kernel_args_var_176[] = {&var_812, &var_813, &var_814};
    Grid triton_poi_fused_cat_144_grid_176 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_144_grid_176.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_144, triton_poi_fused_cat_144_grid_176.grid_x, triton_poi_fused_cat_144_grid_176.grid_y, triton_poi_fused_cat_144_grid_176.grid_z, 4, 0, kernel_args_var_176, stream);
    }
    const int64_t int_array_29[] = {s0, 9792L};
    auto tmp_tensor_handle_144 = reinterpret_tensor_wrapper(buf388, 2, int_array_29, int_array_1, 43200L);
    RAIIAtenTensorHandle tmp_tensor_handle_144_raii(tmp_tensor_handle_144);
    decltype(auto) buf328 = std::move(tmp_tensor_handle_144_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_145_xnumel = 9792L*s0;
    if (kernels.triton_poi_fused_cat_145 == nullptr) {
        kernels.triton_poi_fused_cat_145 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c3uureiw43e6dp7s2vjzhpd3mbruz3kmrbcmlhiixchxobnaezyc.cubin", "triton_poi_fused_cat_145", 0, this->cubin_dir_);
    }
    CUdeviceptr var_815 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_816 = reinterpret_cast<CUdeviceptr>(buf328.data_ptr());
    int32_t var_817 = triton_poi_fused_cat_145_xnumel;
    void* kernel_args_var_177[] = {&var_815, &var_816, &var_817};
    Grid triton_poi_fused_cat_145_grid_177 = Grid((-1L)*static_cast<int64_t>(std::floor((-153.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_145_grid_177.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_145, triton_poi_fused_cat_145_grid_177.grid_x, triton_poi_fused_cat_145_grid_177.grid_y, triton_poi_fused_cat_145_grid_177.grid_z, 4, 0, kernel_args_var_177, stream);
    }
    auto tmp_tensor_handle_145 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 52992L);
    RAIIAtenTensorHandle tmp_tensor_handle_145_raii(tmp_tensor_handle_145);
    decltype(auto) buf329 = std::move(tmp_tensor_handle_145_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_146_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_146 == nullptr) {
        kernels.triton_poi_fused_cat_146 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cge7ro5glfjrd4lsvpl2inqzmk5m6hpgkekg5r26ctadn7qf7qr6.cubin", "triton_poi_fused_cat_146", 0, this->cubin_dir_);
    }
    CUdeviceptr var_818 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_819 = reinterpret_cast<CUdeviceptr>(buf329.data_ptr());
    int32_t var_820 = triton_poi_fused_cat_146_xnumel;
    void* kernel_args_var_178[] = {&var_818, &var_819, &var_820};
    Grid triton_poi_fused_cat_146_grid_178 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_146_grid_178.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_146, triton_poi_fused_cat_146_grid_178.grid_x, triton_poi_fused_cat_146_grid_178.grid_y, triton_poi_fused_cat_146_grid_178.grid_z, 4, 0, kernel_args_var_178, stream);
    }
    auto tmp_tensor_handle_146 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 53184L);
    RAIIAtenTensorHandle tmp_tensor_handle_146_raii(tmp_tensor_handle_146);
    decltype(auto) buf330 = std::move(tmp_tensor_handle_146_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_147_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_147 == nullptr) {
        kernels.triton_poi_fused_cat_147 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c4urc5aod5cuz2hlmn3srxamsbyez7qci33fhg22jwxpevxc6uph.cubin", "triton_poi_fused_cat_147", 0, this->cubin_dir_);
    }
    CUdeviceptr var_821 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_822 = reinterpret_cast<CUdeviceptr>(buf330.data_ptr());
    int32_t var_823 = triton_poi_fused_cat_147_xnumel;
    void* kernel_args_var_179[] = {&var_821, &var_822, &var_823};
    Grid triton_poi_fused_cat_147_grid_179 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_147_grid_179.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_147, triton_poi_fused_cat_147_grid_179.grid_x, triton_poi_fused_cat_147_grid_179.grid_y, triton_poi_fused_cat_147_grid_179.grid_z, 8, 0, kernel_args_var_179, stream);
    }
    auto tmp_tensor_handle_147 = reinterpret_tensor_wrapper(buf388, 2, int_array_22, int_array_1, 53376L);
    RAIIAtenTensorHandle tmp_tensor_handle_147_raii(tmp_tensor_handle_147);
    decltype(auto) buf331 = std::move(tmp_tensor_handle_147_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_148_xnumel = 768L*s0;
    if (kernels.triton_poi_fused_cat_148 == nullptr) {
        kernels.triton_poi_fused_cat_148 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cgkypovv5tplcu3igngydv5cslgw4tingj4m76znsehjhdki55vj.cubin", "triton_poi_fused_cat_148", 0, this->cubin_dir_);
    }
    CUdeviceptr var_824 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_825 = reinterpret_cast<CUdeviceptr>(buf331.data_ptr());
    int32_t var_826 = triton_poi_fused_cat_148_xnumel;
    void* kernel_args_var_180[] = {&var_824, &var_825, &var_826};
    Grid triton_poi_fused_cat_148_grid_180 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_148_grid_180.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_148, triton_poi_fused_cat_148_grid_180.grid_x, triton_poi_fused_cat_148_grid_180.grid_y, triton_poi_fused_cat_148_grid_180.grid_z, 4, 0, kernel_args_var_180, stream);
    }
    auto tmp_tensor_handle_148 = reinterpret_tensor_wrapper(buf388, 2, int_array_26, int_array_1, 54144L);
    RAIIAtenTensorHandle tmp_tensor_handle_148_raii(tmp_tensor_handle_148);
    decltype(auto) buf332 = std::move(tmp_tensor_handle_148_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_149_xnumel = 576L*s0;
    if (kernels.triton_poi_fused_cat_149 == nullptr) {
        kernels.triton_poi_fused_cat_149 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cbmnnd3m6fkk3kxh3wxrv6c74al3kolkzvw6wmx46sb3s3zuskgp.cubin", "triton_poi_fused_cat_149", 0, this->cubin_dir_);
    }
    CUdeviceptr var_827 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_828 = reinterpret_cast<CUdeviceptr>(buf332.data_ptr());
    int32_t var_829 = triton_poi_fused_cat_149_xnumel;
    void* kernel_args_var_181[] = {&var_827, &var_828, &var_829};
    Grid triton_poi_fused_cat_149_grid_181 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_149_grid_181.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_149, triton_poi_fused_cat_149_grid_181.grid_x, triton_poi_fused_cat_149_grid_181.grid_y, triton_poi_fused_cat_149_grid_181.grid_z, 4, 0, kernel_args_var_181, stream);
    }
    auto tmp_tensor_handle_149 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 54720L);
    RAIIAtenTensorHandle tmp_tensor_handle_149_raii(tmp_tensor_handle_149);
    decltype(auto) buf333 = std::move(tmp_tensor_handle_149_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_150_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_150 == nullptr) {
        kernels.triton_poi_fused_cat_150 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cs3ewdaehmqwuh6oos4gwst6jsgzpbjujlzceaeblqj2tkibwl5z.cubin", "triton_poi_fused_cat_150", 0, this->cubin_dir_);
    }
    CUdeviceptr var_830 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_831 = reinterpret_cast<CUdeviceptr>(buf333.data_ptr());
    int32_t var_832 = triton_poi_fused_cat_150_xnumel;
    void* kernel_args_var_182[] = {&var_830, &var_831, &var_832};
    Grid triton_poi_fused_cat_150_grid_182 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_150_grid_182.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_150, triton_poi_fused_cat_150_grid_182.grid_x, triton_poi_fused_cat_150_grid_182.grid_y, triton_poi_fused_cat_150_grid_182.grid_z, 4, 0, kernel_args_var_182, stream);
    }
    auto tmp_tensor_handle_150 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 54912L);
    RAIIAtenTensorHandle tmp_tensor_handle_150_raii(tmp_tensor_handle_150);
    decltype(auto) buf334 = std::move(tmp_tensor_handle_150_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_151_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_151 == nullptr) {
        kernels.triton_poi_fused_cat_151 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckc4dl3gvaedpj6ukqb5pbnoyixup7uoimcbwltuy5lln3aslzj6.cubin", "triton_poi_fused_cat_151", 0, this->cubin_dir_);
    }
    CUdeviceptr var_833 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_834 = reinterpret_cast<CUdeviceptr>(buf334.data_ptr());
    int32_t var_835 = triton_poi_fused_cat_151_xnumel;
    void* kernel_args_var_183[] = {&var_833, &var_834, &var_835};
    Grid triton_poi_fused_cat_151_grid_183 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_151_grid_183.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_151, triton_poi_fused_cat_151_grid_183.grid_x, triton_poi_fused_cat_151_grid_183.grid_y, triton_poi_fused_cat_151_grid_183.grid_z, 4, 0, kernel_args_var_183, stream);
    }
    auto tmp_tensor_handle_151 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 55104L);
    RAIIAtenTensorHandle tmp_tensor_handle_151_raii(tmp_tensor_handle_151);
    decltype(auto) buf335 = std::move(tmp_tensor_handle_151_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_152_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_152 == nullptr) {
        kernels.triton_poi_fused_cat_152 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ctblj7az7swmwips5hhsty7xtt5doosk66ti64vac5b26dr7txkm.cubin", "triton_poi_fused_cat_152", 0, this->cubin_dir_);
    }
    CUdeviceptr var_836 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_837 = reinterpret_cast<CUdeviceptr>(buf335.data_ptr());
    int32_t var_838 = triton_poi_fused_cat_152_xnumel;
    void* kernel_args_var_184[] = {&var_836, &var_837, &var_838};
    Grid triton_poi_fused_cat_152_grid_184 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_152_grid_184.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_152, triton_poi_fused_cat_152_grid_184.grid_x, triton_poi_fused_cat_152_grid_184.grid_y, triton_poi_fused_cat_152_grid_184.grid_z, 4, 0, kernel_args_var_184, stream);
    }
    auto tmp_tensor_handle_152 = reinterpret_tensor_wrapper(buf388, 2, int_array_23, int_array_1, 55488L);
    RAIIAtenTensorHandle tmp_tensor_handle_152_raii(tmp_tensor_handle_152);
    decltype(auto) buf336 = std::move(tmp_tensor_handle_152_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_153_xnumel = 384L*s0;
    if (kernels.triton_poi_fused_cat_153 == nullptr) {
        kernels.triton_poi_fused_cat_153 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ceth6ruqj5qujws2fsr2bkpsqltabdwrevfyfkqvzfkyhnhzv4nf.cubin", "triton_poi_fused_cat_153", 0, this->cubin_dir_);
    }
    CUdeviceptr var_839 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_840 = reinterpret_cast<CUdeviceptr>(buf336.data_ptr());
    int32_t var_841 = triton_poi_fused_cat_153_xnumel;
    void* kernel_args_var_185[] = {&var_839, &var_840, &var_841};
    Grid triton_poi_fused_cat_153_grid_185 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_153_grid_185.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_153, triton_poi_fused_cat_153_grid_185.grid_x, triton_poi_fused_cat_153_grid_185.grid_y, triton_poi_fused_cat_153_grid_185.grid_z, 4, 0, kernel_args_var_185, stream);
    }
    const int64_t int_array_30[] = {s0, 2496L};
    auto tmp_tensor_handle_153 = reinterpret_tensor_wrapper(buf388, 2, int_array_30, int_array_1, 55872L);
    RAIIAtenTensorHandle tmp_tensor_handle_153_raii(tmp_tensor_handle_153);
    decltype(auto) buf337 = std::move(tmp_tensor_handle_153_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_154_xnumel = 2496L*s0;
    if (kernels.triton_poi_fused_cat_154 == nullptr) {
        kernels.triton_poi_fused_cat_154 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjjbc35ds5lyhor3skhnhhzlctq6xykykanmbvfc5vzfrwrp6prf.cubin", "triton_poi_fused_cat_154", 0, this->cubin_dir_);
    }
    CUdeviceptr var_842 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_843 = reinterpret_cast<CUdeviceptr>(buf337.data_ptr());
    int32_t var_844 = triton_poi_fused_cat_154_xnumel;
    void* kernel_args_var_186[] = {&var_842, &var_843, &var_844};
    Grid triton_poi_fused_cat_154_grid_186 = Grid((-1L)*static_cast<int64_t>(std::floor((-39.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_154_grid_186.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_154, triton_poi_fused_cat_154_grid_186.grid_x, triton_poi_fused_cat_154_grid_186.grid_y, triton_poi_fused_cat_154_grid_186.grid_z, 4, 0, kernel_args_var_186, stream);
    }
    auto tmp_tensor_handle_154 = reinterpret_tensor_wrapper(buf388, 2, int_array_26, int_array_1, 58368L);
    RAIIAtenTensorHandle tmp_tensor_handle_154_raii(tmp_tensor_handle_154);
    decltype(auto) buf338 = std::move(tmp_tensor_handle_154_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_155_xnumel = 576L*s0;
    if (kernels.triton_poi_fused_cat_155 == nullptr) {
        kernels.triton_poi_fused_cat_155 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cria5r7menszxmb376p2kxnxsar3lhqek5fgjfvaa5xsyuxiwaqm.cubin", "triton_poi_fused_cat_155", 0, this->cubin_dir_);
    }
    CUdeviceptr var_845 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_846 = reinterpret_cast<CUdeviceptr>(buf338.data_ptr());
    int32_t var_847 = triton_poi_fused_cat_155_xnumel;
    void* kernel_args_var_187[] = {&var_845, &var_846, &var_847};
    Grid triton_poi_fused_cat_155_grid_187 = Grid((-1L)*static_cast<int64_t>(std::floor((-9.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_155_grid_187.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_155, triton_poi_fused_cat_155_grid_187.grid_x, triton_poi_fused_cat_155_grid_187.grid_y, triton_poi_fused_cat_155_grid_187.grid_z, 8, 0, kernel_args_var_187, stream);
    }
    auto tmp_tensor_handle_155 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 58944L);
    RAIIAtenTensorHandle tmp_tensor_handle_155_raii(tmp_tensor_handle_155);
    decltype(auto) buf339 = std::move(tmp_tensor_handle_155_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_156_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_156 == nullptr) {
        kernels.triton_poi_fused_cat_156 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cwfazqryxrncvz5rmkoaznt6okw3ehxdpzqnouufdnjfvegwlawh.cubin", "triton_poi_fused_cat_156", 0, this->cubin_dir_);
    }
    CUdeviceptr var_848 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_849 = reinterpret_cast<CUdeviceptr>(buf339.data_ptr());
    int32_t var_850 = triton_poi_fused_cat_156_xnumel;
    void* kernel_args_var_188[] = {&var_848, &var_849, &var_850};
    Grid triton_poi_fused_cat_156_grid_188 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_156_grid_188.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_156, triton_poi_fused_cat_156_grid_188.grid_x, triton_poi_fused_cat_156_grid_188.grid_y, triton_poi_fused_cat_156_grid_188.grid_z, 4, 0, kernel_args_var_188, stream);
    }
    auto tmp_tensor_handle_156 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 59136L);
    RAIIAtenTensorHandle tmp_tensor_handle_156_raii(tmp_tensor_handle_156);
    decltype(auto) buf340 = std::move(tmp_tensor_handle_156_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_157_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_157 == nullptr) {
        kernels.triton_poi_fused_cat_157 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cbqph4dsjgkwrb72ld4lfdfyxtfs5evelqpo5c745zauuy6wz2wk.cubin", "triton_poi_fused_cat_157", 0, this->cubin_dir_);
    }
    CUdeviceptr var_851 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_852 = reinterpret_cast<CUdeviceptr>(buf340.data_ptr());
    int32_t var_853 = triton_poi_fused_cat_157_xnumel;
    void* kernel_args_var_189[] = {&var_851, &var_852, &var_853};
    Grid triton_poi_fused_cat_157_grid_189 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_157_grid_189.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_157, triton_poi_fused_cat_157_grid_189.grid_x, triton_poi_fused_cat_157_grid_189.grid_y, triton_poi_fused_cat_157_grid_189.grid_z, 4, 0, kernel_args_var_189, stream);
    }
    auto tmp_tensor_handle_157 = reinterpret_tensor_wrapper(buf388, 2, int_array_22, int_array_1, 59328L);
    RAIIAtenTensorHandle tmp_tensor_handle_157_raii(tmp_tensor_handle_157);
    decltype(auto) buf341 = std::move(tmp_tensor_handle_157_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_158_xnumel = 768L*s0;
    if (kernels.triton_poi_fused_cat_158 == nullptr) {
        kernels.triton_poi_fused_cat_158 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cskncap44fvbbxd6thi6xau7w4asr4sjcxjcalakrpgcjnnsbkt4.cubin", "triton_poi_fused_cat_158", 0, this->cubin_dir_);
    }
    CUdeviceptr var_854 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_855 = reinterpret_cast<CUdeviceptr>(buf341.data_ptr());
    int32_t var_856 = triton_poi_fused_cat_158_xnumel;
    void* kernel_args_var_190[] = {&var_854, &var_855, &var_856};
    Grid triton_poi_fused_cat_158_grid_190 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/4.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_158_grid_190.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_158, triton_poi_fused_cat_158_grid_190.grid_x, triton_poi_fused_cat_158_grid_190.grid_y, triton_poi_fused_cat_158_grid_190.grid_z, 4, 0, kernel_args_var_190, stream);
    }
    auto tmp_tensor_handle_158 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 60096L);
    RAIIAtenTensorHandle tmp_tensor_handle_158_raii(tmp_tensor_handle_158);
    decltype(auto) buf342 = std::move(tmp_tensor_handle_158_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_159_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_cat_159 == nullptr) {
        kernels.triton_poi_fused_cat_159 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckizp2c2pxx2ccn3tzhy5r3wryquzuqntaehtrrbbnyaodaqwyit.cubin", "triton_poi_fused_cat_159", 0, this->cubin_dir_);
    }
    CUdeviceptr var_857 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_858 = reinterpret_cast<CUdeviceptr>(buf342.data_ptr());
    int32_t var_859 = triton_poi_fused_cat_159_xnumel;
    void* kernel_args_var_191[] = {&var_857, &var_858, &var_859};
    Grid triton_poi_fused_cat_159_grid_191 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_159_grid_191.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_159, triton_poi_fused_cat_159_grid_191.grid_x, triton_poi_fused_cat_159_grid_191.grid_y, triton_poi_fused_cat_159_grid_191.grid_z, 4, 0, kernel_args_var_191, stream);
    }
    const int64_t int_array_31[] = {s0, 5760L};
    auto tmp_tensor_handle_159 = reinterpret_tensor_wrapper(buf388, 2, int_array_31, int_array_1, 60288L);
    RAIIAtenTensorHandle tmp_tensor_handle_159_raii(tmp_tensor_handle_159);
    decltype(auto) buf343 = std::move(tmp_tensor_handle_159_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_160_xnumel = 5760L*s0;
    if (kernels.triton_poi_fused_cat_160 == nullptr) {
        kernels.triton_poi_fused_cat_160 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ccdekgjm5vbageici3m24cg5nxhlcowkvkhcsm73b5grj5unbpml.cubin", "triton_poi_fused_cat_160", 0, this->cubin_dir_);
    }
    CUdeviceptr var_860 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_861 = reinterpret_cast<CUdeviceptr>(buf343.data_ptr());
    int32_t var_862 = triton_poi_fused_cat_160_xnumel;
    void* kernel_args_var_192[] = {&var_860, &var_861, &var_862};
    Grid triton_poi_fused_cat_160_grid_192 = Grid((-1L)*static_cast<int64_t>(std::floor((-45.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_160_grid_192.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_160, triton_poi_fused_cat_160_grid_192.grid_x, triton_poi_fused_cat_160_grid_192.grid_y, triton_poi_fused_cat_160_grid_192.grid_z, 4, 0, kernel_args_var_192, stream);
    }
    auto tmp_tensor_handle_160 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 66048L);
    RAIIAtenTensorHandle tmp_tensor_handle_160_raii(tmp_tensor_handle_160);
    decltype(auto) buf344 = std::move(tmp_tensor_handle_160_raii);  // alias
    // Topologically Sorted Source Nodes: [contiguous_4], Original ATen: [aten.clone]
    int64_t triton_poi_fused_clone_161_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_clone_161 == nullptr) {
        kernels.triton_poi_fused_clone_161 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c62yp42yi3ufdlkeil2tubjjqeuex4wk46ksxqssatm4wbr5m2tt.cubin", "triton_poi_fused_clone_161", 0, this->cubin_dir_);
    }
    CUdeviceptr var_863 = reinterpret_cast<CUdeviceptr>(buf232.data_ptr());
    CUdeviceptr var_864 = reinterpret_cast<CUdeviceptr>(buf344.data_ptr());
    int32_t var_865 = triton_poi_fused_clone_161_xnumel;
    void* kernel_args_var_193[] = {&var_863, &var_864, &var_865};
    Grid triton_poi_fused_clone_161_grid_193 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_clone_161_grid_193.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_clone_161, triton_poi_fused_clone_161_grid_193.grid_x, triton_poi_fused_clone_161_grid_193.grid_y, triton_poi_fused_clone_161_grid_193.grid_z, 8, 0, kernel_args_var_193, stream);
    }
    auto tmp_tensor_handle_161 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 66240L);
    RAIIAtenTensorHandle tmp_tensor_handle_161_raii(tmp_tensor_handle_161);
    decltype(auto) buf345 = std::move(tmp_tensor_handle_161_raii);  // alias
    // Topologically Sorted Source Nodes: [contiguous_5], Original ATen: [aten.clone]
    int64_t triton_poi_fused_clone_162_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_clone_162 == nullptr) {
        kernels.triton_poi_fused_clone_162 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cnlvhri2ez54zpnqrpzmpgzqxxalxbteso7sfksxd5hxff5laryt.cubin", "triton_poi_fused_clone_162", 0, this->cubin_dir_);
    }
    CUdeviceptr var_866 = reinterpret_cast<CUdeviceptr>(buf232.data_ptr());
    CUdeviceptr var_867 = reinterpret_cast<CUdeviceptr>(buf345.data_ptr());
    int32_t var_868 = triton_poi_fused_clone_162_xnumel;
    void* kernel_args_var_194[] = {&var_866, &var_867, &var_868};
    Grid triton_poi_fused_clone_162_grid_194 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_clone_162_grid_194.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_clone_162, triton_poi_fused_clone_162_grid_194.grid_x, triton_poi_fused_clone_162_grid_194.grid_y, triton_poi_fused_clone_162_grid_194.grid_z, 4, 0, kernel_args_var_194, stream);
    }
    auto tmp_tensor_handle_162 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 66432L);
    RAIIAtenTensorHandle tmp_tensor_handle_162_raii(tmp_tensor_handle_162);
    decltype(auto) buf346 = std::move(tmp_tensor_handle_162_raii);  // alias
    // Topologically Sorted Source Nodes: [contiguous_6], Original ATen: [aten.clone]
    int64_t triton_poi_fused_clone_163_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_clone_163 == nullptr) {
        kernels.triton_poi_fused_clone_163 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cj7vncwt2gu4mvws6osvopuyvcqd7lrqm7rf6o72hkwi2shlwn2m.cubin", "triton_poi_fused_clone_163", 0, this->cubin_dir_);
    }
    CUdeviceptr var_869 = reinterpret_cast<CUdeviceptr>(buf232.data_ptr());
    CUdeviceptr var_870 = reinterpret_cast<CUdeviceptr>(buf346.data_ptr());
    int32_t var_871 = triton_poi_fused_clone_163_xnumel;
    void* kernel_args_var_195[] = {&var_869, &var_870, &var_871};
    Grid triton_poi_fused_clone_163_grid_195 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_clone_163_grid_195.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_clone_163, triton_poi_fused_clone_163_grid_195.grid_x, triton_poi_fused_clone_163_grid_195.grid_y, triton_poi_fused_clone_163_grid_195.grid_z, 4, 0, kernel_args_var_195, stream);
    }
    auto tmp_tensor_handle_163 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 66624L);
    RAIIAtenTensorHandle tmp_tensor_handle_163_raii(tmp_tensor_handle_163);
    decltype(auto) buf347 = std::move(tmp_tensor_handle_163_raii);  // alias
    // Topologically Sorted Source Nodes: [contiguous_7], Original ATen: [aten.clone]
    int64_t triton_poi_fused_clone_164_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_clone_164 == nullptr) {
        kernels.triton_poi_fused_clone_164 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cdqpg7yxtmp4bxp4mgqnzte4ruerjar23zpihldas5wclgtbbt2f.cubin", "triton_poi_fused_clone_164", 0, this->cubin_dir_);
    }
    CUdeviceptr var_872 = reinterpret_cast<CUdeviceptr>(buf232.data_ptr());
    CUdeviceptr var_873 = reinterpret_cast<CUdeviceptr>(buf347.data_ptr());
    int32_t var_874 = triton_poi_fused_clone_164_xnumel;
    void* kernel_args_var_196[] = {&var_872, &var_873, &var_874};
    Grid triton_poi_fused_clone_164_grid_196 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/8.0)*s0)), 1L, 1L);
    if (triton_poi_fused_clone_164_grid_196.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_clone_164, triton_poi_fused_clone_164_grid_196.grid_x, triton_poi_fused_clone_164_grid_196.grid_y, triton_poi_fused_clone_164_grid_196.grid_z, 8, 0, kernel_args_var_196, stream);
    }
    auto tmp_tensor_handle_164 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 66816L);
    RAIIAtenTensorHandle tmp_tensor_handle_164_raii(tmp_tensor_handle_164);
    decltype(auto) buf348 = std::move(tmp_tensor_handle_164_raii);  // alias
    // Topologically Sorted Source Nodes: [contiguous_8], Original ATen: [aten.clone]
    int64_t triton_poi_fused_clone_165_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_clone_165 == nullptr) {
        kernels.triton_poi_fused_clone_165 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cgrxuhoc4uqlpzcoagip4iggbrugqebok5wwaluywr7sf3ebkifa.cubin", "triton_poi_fused_clone_165", 0, this->cubin_dir_);
    }
    CUdeviceptr var_875 = reinterpret_cast<CUdeviceptr>(buf232.data_ptr());
    CUdeviceptr var_876 = reinterpret_cast<CUdeviceptr>(buf348.data_ptr());
    int32_t var_877 = triton_poi_fused_clone_165_xnumel;
    void* kernel_args_var_197[] = {&var_875, &var_876, &var_877};
    Grid triton_poi_fused_clone_165_grid_197 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_clone_165_grid_197.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_clone_165, triton_poi_fused_clone_165_grid_197.grid_x, triton_poi_fused_clone_165_grid_197.grid_y, triton_poi_fused_clone_165_grid_197.grid_z, 4, 0, kernel_args_var_197, stream);
    }
    auto tmp_tensor_handle_165 = reinterpret_tensor_wrapper(buf388, 2, int_array_0, int_array_1, 67008L);
    RAIIAtenTensorHandle tmp_tensor_handle_165_raii(tmp_tensor_handle_165);
    decltype(auto) buf349 = std::move(tmp_tensor_handle_165_raii);  // alias
    // Topologically Sorted Source Nodes: [contiguous_9], Original ATen: [aten.clone]
    int64_t triton_poi_fused_clone_166_xnumel = 192L*s0;
    if (kernels.triton_poi_fused_clone_166 == nullptr) {
        kernels.triton_poi_fused_clone_166 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cdywnek5vstv4cav5wdpr3mbhda2ukofmoheauyjmqufxbmavjci.cubin", "triton_poi_fused_clone_166", 0, this->cubin_dir_);
    }
    CUdeviceptr var_878 = reinterpret_cast<CUdeviceptr>(buf232.data_ptr());
    CUdeviceptr var_879 = reinterpret_cast<CUdeviceptr>(buf349.data_ptr());
    int32_t var_880 = triton_poi_fused_clone_166_xnumel;
    void* kernel_args_var_198[] = {&var_878, &var_879, &var_880};
    Grid triton_poi_fused_clone_166_grid_198 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_clone_166_grid_198.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_clone_166, triton_poi_fused_clone_166_grid_198.grid_x, triton_poi_fused_clone_166_grid_198.grid_y, triton_poi_fused_clone_166_grid_198.grid_z, 4, 0, kernel_args_var_198, stream);
    }
    buf232.reset();
    const int64_t int_array_32[] = {s0, 1536L};
    auto tmp_tensor_handle_166 = reinterpret_tensor_wrapper(buf388, 2, int_array_32, int_array_1, 67200L);
    RAIIAtenTensorHandle tmp_tensor_handle_166_raii(tmp_tensor_handle_166);
    decltype(auto) buf350 = std::move(tmp_tensor_handle_166_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_167_xnumel = 1536L*s0;
    if (kernels.triton_poi_fused_cat_167 == nullptr) {
        kernels.triton_poi_fused_cat_167 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cbmnzsr4acamrmqfb5rpqpfameg4apcvkupe56oz5cpfg5yc4e4c.cubin", "triton_poi_fused_cat_167", 0, this->cubin_dir_);
    }
    CUdeviceptr var_881 = reinterpret_cast<CUdeviceptr>(buf235.data_ptr());
    CUdeviceptr var_882 = reinterpret_cast<CUdeviceptr>(buf350.data_ptr());
    int32_t var_883 = triton_poi_fused_cat_167_xnumel;
    void* kernel_args_var_199[] = {&var_881, &var_882, &var_883};
    Grid triton_poi_fused_cat_167_grid_199 = Grid((-1L)*static_cast<int64_t>(std::floor((-3.0/2.0)*s0)), 1L, 1L);
    if (triton_poi_fused_cat_167_grid_199.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_167, triton_poi_fused_cat_167_grid_199.grid_x, triton_poi_fused_cat_167_grid_199.grid_y, triton_poi_fused_cat_167_grid_199.grid_z, 4, 0, kernel_args_var_199, stream);
    }
    const int64_t int_array_33[] = {s0, 12288L};
    auto tmp_tensor_handle_167 = reinterpret_tensor_wrapper(buf388, 2, int_array_33, int_array_1, 75648L);
    RAIIAtenTensorHandle tmp_tensor_handle_167_raii(tmp_tensor_handle_167);
    decltype(auto) buf387 = std::move(tmp_tensor_handle_167_raii);  // alias
    // Topologically Sorted Source Nodes: [cat_default_7], Original ATen: [aten.cat]
    int64_t triton_poi_fused_cat_168_xnumel = 12288L*s0;
    if (kernels.triton_poi_fused_cat_168 == nullptr) {
        kernels.triton_poi_fused_cat_168 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cxmncyezaopnqnnhzopebxznxntyajafwqvndn5rlt22embwgvrp.cubin", "triton_poi_fused_cat_168", 0, this->cubin_dir_);
    }
    CUdeviceptr var_884 = reinterpret_cast<CUdeviceptr>(buf275.data_ptr());
    CUdeviceptr var_885 = reinterpret_cast<CUdeviceptr>(buf387.data_ptr());
    int32_t var_886 = s0;
    int32_t var_887 = triton_poi_fused_cat_168_xnumel;
    void* kernel_args_var_200[] = {&var_884, &var_885, &var_886, &var_887};
    Grid triton_poi_fused_cat_168_grid_200 = Grid(12L*s0, 1L, 1L);
    if (triton_poi_fused_cat_168_grid_200.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_cat_168, triton_poi_fused_cat_168_grid_200.grid_x, triton_poi_fused_cat_168_grid_200.grid_y, triton_poi_fused_cat_168_grid_200.grid_z, 4, 0, kernel_args_var_200, stream);
    }
    buf275.reset();
    buf276.reset();
    buf277.reset();
    buf278.reset();
    buf279.reset();
    buf280.reset();
    buf281.reset();
    buf282.reset();
    buf283.reset();
    buf284.reset();
    buf285.reset();
    buf286.reset();
    buf287.reset();
    buf288.reset();
    buf289.reset();
    buf290.reset();
    buf291.reset();
    buf292.reset();
    buf293.reset();
    buf294.reset();
    buf295.reset();
    buf296.reset();
    buf297.reset();
    buf298.reset();
    buf299.reset();
    buf300.reset();
    buf301.reset();
    buf302.reset();
    buf303.reset();
    buf304.reset();
    buf305.reset();
    buf306.reset();
    buf307.reset();
    buf308.reset();
    buf309.reset();
    buf310.reset();
    buf311.reset();
    buf312.reset();
    buf313.reset();
    buf314.reset();
    buf315.reset();
    buf316.reset();
    buf317.reset();
    buf318.reset();
    buf319.reset();
    buf320.reset();
    buf321.reset();
    buf322.reset();
    buf323.reset();
    buf324.reset();
    buf325.reset();
    buf326.reset();
    buf327.reset();
    buf328.reset();
    buf329.reset();
    buf330.reset();
    buf331.reset();
    buf332.reset();
    buf333.reset();
    buf334.reset();
    buf335.reset();
    buf336.reset();
    buf337.reset();
    buf338.reset();
    buf339.reset();
    buf340.reset();
    buf341.reset();
    buf342.reset();
    buf343.reset();
    buf350.reset();
    buf351.reset();
    buf352.reset();
    buf353.reset();
    buf354.reset();
    buf355.reset();
    buf356.reset();
    buf357.reset();
    buf358.reset();
    buf359.reset();
    buf360.reset();
    buf361.reset();
    buf362.reset();
    buf363.reset();
    buf364.reset();
    buf365.reset();
    buf366.reset();
    buf367.reset();
    buf368.reset();
    buf369.reset();
    buf370.reset();
    buf371.reset();
    buf372.reset();
    buf373.reset();
    buf374.reset();
    buf375.reset();
    buf376.reset();
    buf377.reset();
    buf378.reset();
    buf379.reset();
    buf380.reset();
    buf381.reset();
    buf382.reset();
    buf383.reset();
    buf384.reset();
    buf385.reset();
    buf386.reset();
    buf387.reset();
    const int64_t int_array_77[] = {s0, 174L, 192L};
    static constexpr int64_t int_array_78[] = {33408L, 192L, 1L};
    AtenTensorHandle buf389_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_77, int_array_78, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf389_handle));
    RAIIAtenTensorHandle buf389(buf389_handle);
    // Topologically Sorted Source Nodes: [matmul], Original ATen: [aten.bmm]
    if (kernels.triton_tem_fused_bmm_169 == nullptr) {
        kernels.triton_tem_fused_bmm_169 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c2n5j2i2gsq5lp6i4ea46eysh3k2bykkee7nh3mwmtyngutxncd2.cubin", "triton_tem_fused_bmm_169", 36864, this->cubin_dir_);
    }
    CUdeviceptr var_888 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w.data_ptr());
    CUdeviceptr var_889 = reinterpret_cast<CUdeviceptr>(buf388.data_ptr());
    CUdeviceptr var_890 = reinterpret_cast<CUdeviceptr>(buf389.data_ptr());
    void* kernel_args_var_201[] = {&var_888, &var_889, &var_890};
    Grid triton_tem_fused_bmm_169_grid_201 = Grid(6L, s0, 1L);
    if (triton_tem_fused_bmm_169_grid_201.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_169, triton_tem_fused_bmm_169_grid_201.grid_x, triton_tem_fused_bmm_169_grid_201.grid_y, triton_tem_fused_bmm_169_grid_201.grid_z, 4, 36864, kernel_args_var_201, stream);
    }
    auto buf393 = std::move(buf389);  // reuse
    // Topologically Sorted Source Nodes: [add_1891, layer_norm_46], Original ATen: [aten.add, aten.native_layer_norm]
    int64_t triton_per_fused_add_native_layer_norm_170_xnumel = 174L*s0;
    if (kernels.triton_per_fused_add_native_layer_norm_170 == nullptr) {
        kernels.triton_per_fused_add_native_layer_norm_170 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c4l7fasoiybnkbp73apbrwn2mnttf2qmoxh6yoxp2xlhl3icwy2g.cubin", "triton_per_fused_add_native_layer_norm_170", 8, this->cubin_dir_);
    }
    CUdeviceptr var_891 = reinterpret_cast<CUdeviceptr>(buf393.data_ptr());
    CUdeviceptr var_892 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b.data_ptr());
    CUdeviceptr var_893 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w.data_ptr());
    CUdeviceptr var_894 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b.data_ptr());
    int32_t var_895 = triton_per_fused_add_native_layer_norm_170_xnumel;
    int var_896 = 192L;
    void* kernel_args_var_202[] = {&var_891, &var_892, &var_893, &var_894, &var_895, &var_896};
    Grid triton_per_fused_add_native_layer_norm_170_grid_202 = Grid(174L*s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_170_grid_202.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_170, triton_per_fused_add_native_layer_norm_170_grid_202.grid_x, triton_per_fused_add_native_layer_norm_170_grid_202.grid_y, triton_per_fused_add_native_layer_norm_170_grid_202.grid_z, 2, 8, kernel_args_var_202, stream);
    }
    auto buf394 = std::move(buf235);  // reuse
    // Topologically Sorted Source Nodes: [linear_default_3], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_171 == nullptr) {
        kernels.triton_tem_fused_addmm_171 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cm5w6bxxw56h6ukw6pcygipuwx6a7jy4ke22322q2axo45tkr7av.cubin", "triton_tem_fused_addmm_171", 73728, this->cubin_dir_);
    }
    CUdeviceptr var_897 = reinterpret_cast<CUdeviceptr>(buf393.data_ptr());
    CUdeviceptr var_898 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_63.data_ptr());
    CUdeviceptr var_899 = reinterpret_cast<CUdeviceptr>(buf394.data_ptr());
    int32_t var_900 = s0;
    void* kernel_args_var_203[] = {&var_897, &var_898, &var_899, &var_900};
    Grid triton_tem_fused_addmm_171_grid_203 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_171_grid_203.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_171, triton_tem_fused_addmm_171_grid_203.grid_x, triton_tem_fused_addmm_171_grid_203.grid_y, triton_tem_fused_addmm_171_grid_203.grid_z, 4, 73728, kernel_args_var_203, stream);
    }
    const int64_t int_array_79[] = {s0, 768L};
    static constexpr int64_t int_array_80[] = {768L, 1L};
    AtenTensorHandle buf409_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_79, int_array_80, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf409_handle));
    RAIIAtenTensorHandle buf409(buf409_handle);
    // Topologically Sorted Source Nodes: [contiguous_10, layer_norm_47, sigmoid_5, mul_1509, layer_norm_49], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_172 == nullptr) {
        kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_172 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cfjbfyx5ay44rqf2jgiivopyeqcstivx6mm3cvyk3jenhnsnvj3r.cubin", "triton_per_fused_clone_mul_native_layer_norm_sigmoid_172", 32, this->cubin_dir_);
    }
    CUdeviceptr var_901 = reinterpret_cast<CUdeviceptr>(buf394.data_ptr());
    CUdeviceptr var_902 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_13.data_ptr());
    CUdeviceptr var_903 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_904 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_905 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_906 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_907 = reinterpret_cast<CUdeviceptr>(buf409.data_ptr());
    int32_t var_908 = s0;
    int var_909 = 768L;
    void* kernel_args_var_204[] = {&var_901, &var_902, &var_903, &var_904, &var_905, &var_906, &var_907, &var_908, &var_909};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_204 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_204.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_172, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_204.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_204.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_204.grid_z, 8, 32, kernel_args_var_204, stream);
    }
    AtenTensorHandle buf414_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_79, int_array_80, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf414_handle));
    RAIIAtenTensorHandle buf414(buf414_handle);
    // Topologically Sorted Source Nodes: [contiguous_11, layer_norm_48, sigmoid_6, mul_1514, layer_norm_50], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_173 == nullptr) {
        kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_173 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ctffxiilqy4varonzq3aaniksxyumrhkiwsxbomqlvxpqaewgegh.cubin", "triton_per_fused_clone_mul_native_layer_norm_sigmoid_173", 32, this->cubin_dir_);
    }
    CUdeviceptr var_910 = reinterpret_cast<CUdeviceptr>(buf394.data_ptr());
    CUdeviceptr var_911 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_13.data_ptr());
    CUdeviceptr var_912 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_913 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_914 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_915 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_916 = reinterpret_cast<CUdeviceptr>(buf414.data_ptr());
    int32_t var_917 = s0;
    int var_918 = 768L;
    void* kernel_args_var_205[] = {&var_910, &var_911, &var_912, &var_913, &var_914, &var_915, &var_916, &var_917, &var_918};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_205 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_205.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_173, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_205.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_205.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_205.grid_z, 8, 32, kernel_args_var_205, stream);
    }
    AtenTensorHandle buf410_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_79, int_array_80, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf410_handle));
    RAIIAtenTensorHandle buf410(buf410_handle);
    // Topologically Sorted Source Nodes: [layer_norm_49, linear_61], Original ATen: [aten.native_layer_norm, aten.addmm]
    if (kernels.triton_tem_fused_addmm_native_layer_norm_174 == nullptr) {
        kernels.triton_tem_fused_addmm_native_layer_norm_174 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cirnjur7uzopavye4plx7tgf5s5yztos2kwf45tojrl3ct4rkm63.cubin", "triton_tem_fused_addmm_native_layer_norm_174", 163840, this->cubin_dir_);
    }
    CUdeviceptr var_919 = reinterpret_cast<CUdeviceptr>(buf409.data_ptr());
    CUdeviceptr var_920 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_64.data_ptr());
    CUdeviceptr var_921 = reinterpret_cast<CUdeviceptr>(buf410.data_ptr());
    int32_t var_922 = s0;
    void* kernel_args_var_206[] = {&var_919, &var_920, &var_921, &var_922};
    Grid triton_tem_fused_addmm_native_layer_norm_174_grid_206 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_174_grid_206.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_174, triton_tem_fused_addmm_native_layer_norm_174_grid_206.grid_x, triton_tem_fused_addmm_native_layer_norm_174_grid_206.grid_y, triton_tem_fused_addmm_native_layer_norm_174_grid_206.grid_z, 8, 163840, kernel_args_var_206, stream);
    }
    auto buf427 = std::move(buf409);  // reuse
    // Topologically Sorted Source Nodes: [linear_61, layer_norm_51, sigmoid_7, mul_1531, layer_norm_53], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175 == nullptr) {
        kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cbkv5uxgcqbjahawp342luea3vxel7bbhe2ywvgga6636ewvwxrr.cubin", "triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175", 32, this->cubin_dir_);
    }
    CUdeviceptr var_923 = reinterpret_cast<CUdeviceptr>(buf410.data_ptr());
    CUdeviceptr var_924 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias.data_ptr());
    CUdeviceptr var_925 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight.data_ptr());
    CUdeviceptr var_926 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias.data_ptr());
    CUdeviceptr var_927 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w.data_ptr());
    CUdeviceptr var_928 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b.data_ptr());
    CUdeviceptr var_929 = reinterpret_cast<CUdeviceptr>(buf427.data_ptr());
    int32_t var_930 = s0;
    int var_931 = 768L;
    void* kernel_args_var_207[] = {&var_923, &var_924, &var_925, &var_926, &var_927, &var_928, &var_929, &var_930, &var_931};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_207 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_207.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_207.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_207.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_207.grid_z, 8, 32, kernel_args_var_207, stream);
    }
    auto buf415 = std::move(buf410);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_50, linear_62], Original ATen: [aten.native_layer_norm, aten.addmm]
    CUdeviceptr var_932 = reinterpret_cast<CUdeviceptr>(buf414.data_ptr());
    CUdeviceptr var_933 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_65.data_ptr());
    CUdeviceptr var_934 = reinterpret_cast<CUdeviceptr>(buf415.data_ptr());
    int32_t var_935 = s0;
    void* kernel_args_var_208[] = {&var_932, &var_933, &var_934, &var_935};
    Grid triton_tem_fused_addmm_native_layer_norm_174_grid_208 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_174_grid_208.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_174, triton_tem_fused_addmm_native_layer_norm_174_grid_208.grid_x, triton_tem_fused_addmm_native_layer_norm_174_grid_208.grid_y, triton_tem_fused_addmm_native_layer_norm_174_grid_208.grid_z, 8, 163840, kernel_args_var_208, stream);
    }
    auto buf432 = std::move(buf414);  // reuse
    // Topologically Sorted Source Nodes: [linear_62, layer_norm_52, sigmoid_8, mul_1536, layer_norm_54], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_936 = reinterpret_cast<CUdeviceptr>(buf415.data_ptr());
    CUdeviceptr var_937 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias.data_ptr());
    CUdeviceptr var_938 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight.data_ptr());
    CUdeviceptr var_939 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias.data_ptr());
    CUdeviceptr var_940 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w.data_ptr());
    CUdeviceptr var_941 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b.data_ptr());
    CUdeviceptr var_942 = reinterpret_cast<CUdeviceptr>(buf432.data_ptr());
    int32_t var_943 = s0;
    int var_944 = 768L;
    void* kernel_args_var_209[] = {&var_936, &var_937, &var_938, &var_939, &var_940, &var_941, &var_942, &var_943, &var_944};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_209 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_209.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_209.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_209.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_209.grid_z, 8, 32, kernel_args_var_209, stream);
    }
    const int64_t int_array_81[] = {s0, 21984L};
    static constexpr int64_t int_array_82[] = {21984L, 1L};
    AtenTensorHandle buf428_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_81, int_array_82, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf428_handle));
    RAIIAtenTensorHandle buf428(buf428_handle);
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf428, buf427, _FOLDED_CONST_permute_66));
    auto buf437 = std::move(buf428);  // reuse
    // Topologically Sorted Source Nodes: [linear_63, layer_norm_55], Original ATen: [aten.addmm, aten.native_layer_norm]
    if (kernels.triton_red_fused_addmm_native_layer_norm_176 == nullptr) {
        kernels.triton_red_fused_addmm_native_layer_norm_176 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ch7tpme7meeu2unctpi52lbtglobdgceqq6fc4ncowvo3bcg6lli.cubin", "triton_red_fused_addmm_native_layer_norm_176", 192, this->cubin_dir_);
    }
    CUdeviceptr var_945 = reinterpret_cast<CUdeviceptr>(buf437.data_ptr());
    CUdeviceptr var_946 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_947 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_948 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b.data_ptr());
    int32_t var_949 = s0;
    int var_950 = 21984L;
    void* kernel_args_var_210[] = {&var_945, &var_946, &var_947, &var_948, &var_949, &var_950};
    Grid triton_red_fused_addmm_native_layer_norm_176_grid_210 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addmm_native_layer_norm_176_grid_210.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_native_layer_norm_176, triton_red_fused_addmm_native_layer_norm_176_grid_210.grid_x, triton_red_fused_addmm_native_layer_norm_176_grid_210.grid_y, triton_red_fused_addmm_native_layer_norm_176_grid_210.grid_z, 16, 192, kernel_args_var_210, stream);
    }
    const int64_t int_array_83[] = {s0, 9216L};
    static constexpr int64_t int_array_84[] = {9216L, 1L};
    AtenTensorHandle buf433_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_83, int_array_84, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf433_handle));
    RAIIAtenTensorHandle buf433(buf433_handle);
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf433, buf432, _FOLDED_CONST_permute_67));
    const int64_t int_array_85[] = {s0, 1L};
    const int64_t int_array_86[] = {1L, s0};
    AtenTensorHandle buf434_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_85, int_array_86, cached_torch_dtype_float32, cached_torch_device_type_cuda, this->device_idx_, &buf434_handle));
    RAIIAtenTensorHandle buf434(buf434_handle);
    AtenTensorHandle buf435_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_85, int_array_86, cached_torch_dtype_float32, cached_torch_device_type_cuda, this->device_idx_, &buf435_handle));
    RAIIAtenTensorHandle buf435(buf435_handle);
    // Topologically Sorted Source Nodes: [linear_64, layer_norm_56], Original ATen: [aten.addmm, aten.native_layer_norm]
    if (kernels.triton_red_fused_addmm_native_layer_norm_177 == nullptr) {
        kernels.triton_red_fused_addmm_native_layer_norm_177 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/clmgw5yxw4yvnmgyuhknnz6pgmarlzmsf545am5cviqc76ig2op7.cubin", "triton_red_fused_addmm_native_layer_norm_177", 192, this->cubin_dir_);
    }
    CUdeviceptr var_951 = reinterpret_cast<CUdeviceptr>(buf433.data_ptr());
    CUdeviceptr var_952 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_953 = reinterpret_cast<CUdeviceptr>(buf434.data_ptr());
    CUdeviceptr var_954 = reinterpret_cast<CUdeviceptr>(buf435.data_ptr());
    int32_t var_955 = s0;
    int var_956 = 9216L;
    void* kernel_args_var_211[] = {&var_951, &var_952, &var_953, &var_954, &var_955, &var_956};
    Grid triton_red_fused_addmm_native_layer_norm_177_grid_211 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_native_layer_norm_177_grid_211.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_native_layer_norm_177, triton_red_fused_addmm_native_layer_norm_177_grid_211.grid_x, triton_red_fused_addmm_native_layer_norm_177_grid_211.grid_y, triton_red_fused_addmm_native_layer_norm_177_grid_211.grid_z, 16, 192, kernel_args_var_211, stream);
    }
    const int64_t int_array_87[] = {s0, 192L, 48L};
    static constexpr int64_t int_array_88[] = {9216L, 48L, 1L};
    AtenTensorHandle buf438_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_87, int_array_88, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf438_handle));
    RAIIAtenTensorHandle buf438(buf438_handle);
    // Topologically Sorted Source Nodes: [bmm], Original ATen: [aten.bmm]
    if (kernels.triton_tem_fused_bmm_178 == nullptr) {
        kernels.triton_tem_fused_bmm_178 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/citymitoyaiqwmdeinwy7v63veqy64zhfp6djulvx5kwoo6lcw6o.cubin", "triton_tem_fused_bmm_178", 24576, this->cubin_dir_);
    }
    CUdeviceptr var_957 = reinterpret_cast<CUdeviceptr>(buf388.data_ptr());
    CUdeviceptr var_958 = reinterpret_cast<CUdeviceptr>(buf437.data_ptr());
    CUdeviceptr var_959 = reinterpret_cast<CUdeviceptr>(buf438.data_ptr());
    void* kernel_args_var_212[] = {&var_957, &var_958, &var_959};
    Grid triton_tem_fused_bmm_178_grid_212 = Grid(3L, s0, 1L);
    if (triton_tem_fused_bmm_178_grid_212.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_178, triton_tem_fused_bmm_178_grid_212.grid_x, triton_tem_fused_bmm_178_grid_212.grid_y, triton_tem_fused_bmm_178_grid_212.grid_z, 4, 24576, kernel_args_var_212, stream);
    }
    AtenTensorHandle buf443_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_87, int_array_88, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf443_handle));
    RAIIAtenTensorHandle buf443(buf443_handle);
    // Topologically Sorted Source Nodes: [add_2006, layer_norm_57], Original ATen: [aten.add, aten.native_layer_norm]
    int64_t triton_per_fused_add_native_layer_norm_179_xnumel = 192L*s0;
    if (kernels.triton_per_fused_add_native_layer_norm_179 == nullptr) {
        kernels.triton_per_fused_add_native_layer_norm_179 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c67msojag4jjua6x2jxx4nne4e3bcyorpqc2hmobcmbhmfrfi2lm.cubin", "triton_per_fused_add_native_layer_norm_179", 0, this->cubin_dir_);
    }
    CUdeviceptr var_960 = reinterpret_cast<CUdeviceptr>(buf433.data_ptr());
    CUdeviceptr var_961 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_962 = reinterpret_cast<CUdeviceptr>(buf434.data_ptr());
    CUdeviceptr var_963 = reinterpret_cast<CUdeviceptr>(buf435.data_ptr());
    CUdeviceptr var_964 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_965 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_966 = reinterpret_cast<CUdeviceptr>(buf438.data_ptr());
    CUdeviceptr var_967 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w.data_ptr());
    CUdeviceptr var_968 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b.data_ptr());
    CUdeviceptr var_969 = reinterpret_cast<CUdeviceptr>(buf443.data_ptr());
    int32_t var_970 = triton_per_fused_add_native_layer_norm_179_xnumel;
    int var_971 = 48L;
    void* kernel_args_var_213[] = {&var_960, &var_961, &var_962, &var_963, &var_964, &var_965, &var_966, &var_967, &var_968, &var_969, &var_970, &var_971};
    Grid triton_per_fused_add_native_layer_norm_179_grid_213 = Grid(6L*s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_179_grid_213.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_179, triton_per_fused_add_native_layer_norm_179_grid_213.grid_x, triton_per_fused_add_native_layer_norm_179_grid_213.grid_y, triton_per_fused_add_native_layer_norm_179_grid_213.grid_z, 8, 0, kernel_args_var_213, stream);
    }
    const int64_t int_array_89[] = {s0, 458L, 48L};
    static constexpr int64_t int_array_90[] = {21984L, 48L, 1L};
    auto tmp_tensor_handle_175 = reinterpret_tensor_wrapper(buf437, 3, int_array_89, int_array_90, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_175_raii(tmp_tensor_handle_175);
    decltype(auto) buf444 = std::move(tmp_tensor_handle_175_raii); buf437.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_57, bmm_1], Original ATen: [aten.native_layer_norm, aten.bmm]
    if (kernels.triton_tem_fused_bmm_native_layer_norm_180 == nullptr) {
        kernels.triton_tem_fused_bmm_native_layer_norm_180 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cpxxfce7fed5e5hzfhlnhwzghrk3ighrbjxzvog2oqgtsqcfckn5.cubin", "triton_tem_fused_bmm_native_layer_norm_180", 36864, this->cubin_dir_);
    }
    CUdeviceptr var_972 = reinterpret_cast<CUdeviceptr>(buf388.data_ptr());
    CUdeviceptr var_973 = reinterpret_cast<CUdeviceptr>(buf443.data_ptr());
    CUdeviceptr var_974 = reinterpret_cast<CUdeviceptr>(buf444.data_ptr());
    void* kernel_args_var_214[] = {&var_972, &var_973, &var_974};
    Grid triton_tem_fused_bmm_native_layer_norm_180_grid_214 = Grid(4L, s0, 1L);
    if (triton_tem_fused_bmm_native_layer_norm_180_grid_214.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_native_layer_norm_180, triton_tem_fused_bmm_native_layer_norm_180_grid_214.grid_x, triton_tem_fused_bmm_native_layer_norm_180_grid_214.grid_y, triton_tem_fused_bmm_native_layer_norm_180_grid_214.grid_z, 4, 36864, kernel_args_var_214, stream);
    }
    auto tmp_tensor_handle_176 = reinterpret_tensor_wrapper(buf444, 2, int_array_81, int_array_82, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_176_raii(tmp_tensor_handle_176);
    decltype(auto) buf448 = std::move(tmp_tensor_handle_176_raii); buf444.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_58], Original ATen: [aten.native_layer_norm]
    if (kernels.triton_red_fused_native_layer_norm_181 == nullptr) {
        kernels.triton_red_fused_native_layer_norm_181 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cbt3a3wgzxkosxieryphr64lvjxrbijhpp5so3ananydx7re4qmf.cubin", "triton_red_fused_native_layer_norm_181", 192, this->cubin_dir_);
    }
    CUdeviceptr var_975 = reinterpret_cast<CUdeviceptr>(buf448.data_ptr());
    CUdeviceptr var_976 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w.data_ptr());
    CUdeviceptr var_977 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b.data_ptr());
    int32_t var_978 = s0;
    int var_979 = 21984L;
    void* kernel_args_var_215[] = {&var_975, &var_976, &var_977, &var_978, &var_979};
    Grid triton_red_fused_native_layer_norm_181_grid_215 = Grid(s0, 1L, 1L);
    if (triton_red_fused_native_layer_norm_181_grid_215.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_native_layer_norm_181, triton_red_fused_native_layer_norm_181_grid_215.grid_x, triton_red_fused_native_layer_norm_181_grid_215.grid_y, triton_red_fused_native_layer_norm_181_grid_215.grid_z, 16, 192, kernel_args_var_215, stream);
    }
    const int64_t int_array_91[] = {s0, 2048L};
    static constexpr int64_t int_array_92[] = {2048L, 1L};
    auto tmp_tensor_handle_177 = reinterpret_tensor_wrapper(buf239, 2, int_array_91, int_array_92, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_177_raii(tmp_tensor_handle_177);
    decltype(auto) buf449 = std::move(tmp_tensor_handle_177_raii); buf239.reset();  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf449, buf448, _FOLDED_CONST_permute_68));
    buf448.reset();
    AtenTensorHandle buf453_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_91, int_array_92, cached_torch_dtype_float32, cached_torch_device_type_cuda, this->device_idx_, &buf453_handle));
    RAIIAtenTensorHandle buf453(buf453_handle);
    auto buf454 = std::move(buf435);  // reuse
    auto buf455 = std::move(buf434);  // reuse
    // Topologically Sorted Source Nodes: [linear_65, layer_norm_59, sigmoid_9, mul_1580, layer_norm_60], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182 == nullptr) {
        kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ca3elvxerhpbfamlbjuzgtzrphffjjud5p4yhz5btil5bjd4ql4x.cubin", "triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182", 192, this->cubin_dir_);
    }
    CUdeviceptr var_980 = reinterpret_cast<CUdeviceptr>(buf449.data_ptr());
    CUdeviceptr var_981 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_982 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_983 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_984 = reinterpret_cast<CUdeviceptr>(buf453.data_ptr());
    CUdeviceptr var_985 = reinterpret_cast<CUdeviceptr>(buf454.data_ptr());
    CUdeviceptr var_986 = reinterpret_cast<CUdeviceptr>(buf455.data_ptr());
    int32_t var_987 = s0;
    int var_988 = 2048L;
    void* kernel_args_var_216[] = {&var_980, &var_981, &var_982, &var_983, &var_984, &var_985, &var_986, &var_987, &var_988};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_216 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_216.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_216.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_216.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_216.grid_z, 16, 192, kernel_args_var_216, stream);
    }
    const int64_t int_array_93[] = {s0, 6354L};
    static constexpr int64_t int_array_94[] = {6354L, 1L};
    AtenTensorHandle buf458_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_93, int_array_94, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf458_handle));
    RAIIAtenTensorHandle buf458(buf458_handle);
    auto buf462 = std::move(buf458);  // reuse
    // Topologically Sorted Source Nodes: [cat_default_6, layer_norm_61], Original ATen: [aten.cat, aten.native_layer_norm]
    if (kernels.triton_red_fused_cat_native_layer_norm_183 == nullptr) {
        kernels.triton_red_fused_cat_native_layer_norm_183 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c2gcvih5rg6b4mhpgmubvcwfkrr625okwxkhya4ckytt56viyfxu.cubin", "triton_red_fused_cat_native_layer_norm_183", 4096, this->cubin_dir_);
    }
    CUdeviceptr var_989 = reinterpret_cast<CUdeviceptr>(buf462.data_ptr());
    CUdeviceptr var_990 = reinterpret_cast<CUdeviceptr>(buf457.data_ptr());
    CUdeviceptr var_991 = reinterpret_cast<CUdeviceptr>(buf230.data_ptr());
    CUdeviceptr var_992 = reinterpret_cast<CUdeviceptr>(buf453.data_ptr());
    CUdeviceptr var_993 = reinterpret_cast<CUdeviceptr>(buf454.data_ptr());
    CUdeviceptr var_994 = reinterpret_cast<CUdeviceptr>(buf455.data_ptr());
    CUdeviceptr var_995 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_996 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_997 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w.data_ptr());
    CUdeviceptr var_998 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b.data_ptr());
    int32_t var_999 = s0;
    int var_1000 = 6354L;
    void* kernel_args_var_217[] = {&var_989, &var_990, &var_991, &var_992, &var_993, &var_994, &var_995, &var_996, &var_997, &var_998, &var_999, &var_1000};
    Grid triton_red_fused_cat_native_layer_norm_183_grid_217 = Grid(s0, 1L, 1L);
    if (triton_red_fused_cat_native_layer_norm_183_grid_217.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_cat_native_layer_norm_183, triton_red_fused_cat_native_layer_norm_183_grid_217.grid_x, triton_red_fused_cat_native_layer_norm_183_grid_217.grid_y, triton_red_fused_cat_native_layer_norm_183_grid_217.grid_z, 8, 4096, kernel_args_var_217, stream);
    }
    const int64_t int_array_95[] = {s0, 6360L};
    static constexpr int64_t int_array_96[] = {6360L, 1L};
    AtenTensorHandle buf463_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_95, int_array_96, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf463_handle));
    RAIIAtenTensorHandle buf463(buf463_handle);
    // Topologically Sorted Source Nodes: [linear_66], Original ATen: [aten.addmm]
    int64_t triton_poi_fused_addmm_184_xnumel = 6360L*s0;
    if (kernels.triton_poi_fused_addmm_184 == nullptr) {
        kernels.triton_poi_fused_addmm_184 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjlck3c5lkso6kfrkpnvzgiqmsymoggiu6knpr4x6anc4c7qjck6.cubin", "triton_poi_fused_addmm_184", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1001 = reinterpret_cast<CUdeviceptr>(buf462.data_ptr());
    CUdeviceptr var_1002 = reinterpret_cast<CUdeviceptr>(buf463.data_ptr());
    int32_t var_1003 = triton_poi_fused_addmm_184_xnumel;
    void* kernel_args_var_218[] = {&var_1001, &var_1002, &var_1003};
    Grid triton_poi_fused_addmm_184_grid_218 = Grid((-1L)*static_cast<int64_t>(std::floor((-795.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_184_grid_218.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_184, triton_poi_fused_addmm_184_grid_218.grid_x, triton_poi_fused_addmm_184_grid_218.grid_y, triton_poi_fused_addmm_184_grid_218.grid_z, 8, 0, kernel_args_var_218, stream);
    }
    const int64_t int_array_97[] = {s0, 384L};
    static constexpr int64_t int_array_98[] = {384L, 1L};
    AtenTensorHandle buf464_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_97, int_array_98, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf464_handle));
    RAIIAtenTensorHandle buf464(buf464_handle);
    // Topologically Sorted Source Nodes: [linear_66], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_185 == nullptr) {
        kernels.triton_tem_fused_addmm_185 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cfvuczujqk5hj4wtb6zlzxb4orullgkcr5ariqqmrs4a4yacotvv.cubin", "triton_tem_fused_addmm_185", 196608, this->cubin_dir_);
    }
    CUdeviceptr var_1004 = reinterpret_cast<CUdeviceptr>(buf463.data_ptr());
    CUdeviceptr var_1005 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_constant_pad_nd_default_19.data_ptr());
    CUdeviceptr var_1006 = reinterpret_cast<CUdeviceptr>(buf464.data_ptr());
    int32_t var_1007 = s0;
    void* kernel_args_var_219[] = {&var_1004, &var_1005, &var_1006, &var_1007};
    Grid triton_tem_fused_addmm_185_grid_219 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_185_grid_219.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_185, triton_tem_fused_addmm_185_grid_219.grid_x, triton_tem_fused_addmm_185_grid_219.grid_y, triton_tem_fused_addmm_185_grid_219.grid_z, 4, 196608, kernel_args_var_219, stream);
    }
    auto buf468 = std::move(buf464);  // reuse
    // Topologically Sorted Source Nodes: [linear_66, layer_norm_62], Original ATen: [aten.addmm, aten.native_layer_norm]
    if (kernels.triton_per_fused_addmm_native_layer_norm_186 == nullptr) {
        kernels.triton_per_fused_addmm_native_layer_norm_186 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cedrnstsvbasuygvdgajssgvouapexkdgdm732eozkfaxlcjo2k2.cubin", "triton_per_fused_addmm_native_layer_norm_186", 16, this->cubin_dir_);
    }
    CUdeviceptr var_1008 = reinterpret_cast<CUdeviceptr>(buf468.data_ptr());
    CUdeviceptr var_1009 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1010 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1011 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b.data_ptr());
    int32_t var_1012 = s0;
    int var_1013 = 384L;
    void* kernel_args_var_220[] = {&var_1008, &var_1009, &var_1010, &var_1011, &var_1012, &var_1013};
    Grid triton_per_fused_addmm_native_layer_norm_186_grid_220 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_186_grid_220.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_186, triton_per_fused_addmm_native_layer_norm_186_grid_220.grid_x, triton_per_fused_addmm_native_layer_norm_186_grid_220.grid_y, triton_per_fused_addmm_native_layer_norm_186_grid_220.grid_z, 4, 16, kernel_args_var_220, stream);
    }
    AtenTensorHandle buf469_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_93, int_array_94, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf469_handle));
    RAIIAtenTensorHandle buf469(buf469_handle);
    // Topologically Sorted Source Nodes: [linear_66, layer_norm_62, linear_67], Original ATen: [aten.addmm, aten.native_layer_norm]
    if (kernels.triton_tem_fused_addmm_native_layer_norm_187 == nullptr) {
        kernels.triton_tem_fused_addmm_native_layer_norm_187 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/caq6xpiy57ctzxqywtqexh5v7kccceodcuwj2wxdaoroi5o4db7p.cubin", "triton_tem_fused_addmm_native_layer_norm_187", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_1014 = reinterpret_cast<CUdeviceptr>(buf468.data_ptr());
    CUdeviceptr var_1015 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_70.data_ptr());
    CUdeviceptr var_1016 = reinterpret_cast<CUdeviceptr>(buf469.data_ptr());
    int32_t var_1017 = s0;
    void* kernel_args_var_221[] = {&var_1014, &var_1015, &var_1016, &var_1017};
    Grid triton_tem_fused_addmm_native_layer_norm_187_grid_221 = Grid(50L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_187_grid_221.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_187, triton_tem_fused_addmm_native_layer_norm_187_grid_221.grid_x, triton_tem_fused_addmm_native_layer_norm_187_grid_221.grid_y, triton_tem_fused_addmm_native_layer_norm_187_grid_221.grid_z, 4, 49152, kernel_args_var_221, stream);
    }
    AtenTensorHandle buf473_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_93, int_array_94, cached_torch_dtype_float32, cached_torch_device_type_cuda, this->device_idx_, &buf473_handle));
    RAIIAtenTensorHandle buf473(buf473_handle);
    auto buf474 = std::move(buf455);  // reuse
    auto buf475 = std::move(buf454);  // reuse
    // Topologically Sorted Source Nodes: [linear_67, layer_norm_63, addcmul, layer_norm_64], Original ATen: [aten.addmm, aten.native_layer_norm, aten.addcmul]
    if (kernels.triton_red_fused_addcmul_addmm_native_layer_norm_188 == nullptr) {
        kernels.triton_red_fused_addcmul_addmm_native_layer_norm_188 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cdiambkvgfx3o65pj75ywyvxabmjewe6n64efucms5efqwsol4ld.cubin", "triton_red_fused_addcmul_addmm_native_layer_norm_188", 96, this->cubin_dir_);
    }
    CUdeviceptr var_1018 = reinterpret_cast<CUdeviceptr>(buf469.data_ptr());
    CUdeviceptr var_1019 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1020 = reinterpret_cast<CUdeviceptr>(buf462.data_ptr());
    CUdeviceptr var_1021 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1022 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1023 = reinterpret_cast<CUdeviceptr>(buf473.data_ptr());
    CUdeviceptr var_1024 = reinterpret_cast<CUdeviceptr>(buf474.data_ptr());
    CUdeviceptr var_1025 = reinterpret_cast<CUdeviceptr>(buf475.data_ptr());
    int32_t var_1026 = s0;
    int var_1027 = 6354L;
    void* kernel_args_var_222[] = {&var_1018, &var_1019, &var_1020, &var_1021, &var_1022, &var_1023, &var_1024, &var_1025, &var_1026, &var_1027};
    Grid triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_222 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_222.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addcmul_addmm_native_layer_norm_188, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_222.grid_x, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_222.grid_y, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_222.grid_z, 8, 96, kernel_args_var_222, stream);
    }
    auto buf477 = std::move(buf463);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_64, linear_68], Original ATen: [aten.native_layer_norm, aten.addmm]
    int64_t triton_poi_fused_addmm_native_layer_norm_189_xnumel = 6360L*s0;
    if (kernels.triton_poi_fused_addmm_native_layer_norm_189 == nullptr) {
        kernels.triton_poi_fused_addmm_native_layer_norm_189 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cioqvnkzekx3bhukkmqnojfy2spnkix4hi5hmpqy2kqylhz3hhmw.cubin", "triton_poi_fused_addmm_native_layer_norm_189", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1028 = reinterpret_cast<CUdeviceptr>(buf473.data_ptr());
    CUdeviceptr var_1029 = reinterpret_cast<CUdeviceptr>(buf474.data_ptr());
    CUdeviceptr var_1030 = reinterpret_cast<CUdeviceptr>(buf475.data_ptr());
    CUdeviceptr var_1031 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w.data_ptr());
    CUdeviceptr var_1032 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b.data_ptr());
    CUdeviceptr var_1033 = reinterpret_cast<CUdeviceptr>(buf477.data_ptr());
    int32_t var_1034 = triton_poi_fused_addmm_native_layer_norm_189_xnumel;
    void* kernel_args_var_223[] = {&var_1028, &var_1029, &var_1030, &var_1031, &var_1032, &var_1033, &var_1034};
    Grid triton_poi_fused_addmm_native_layer_norm_189_grid_223 = Grid((-1L)*static_cast<int64_t>(std::floor((-795.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_native_layer_norm_189_grid_223.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_native_layer_norm_189, triton_poi_fused_addmm_native_layer_norm_189_grid_223.grid_x, triton_poi_fused_addmm_native_layer_norm_189_grid_223.grid_y, triton_poi_fused_addmm_native_layer_norm_189_grid_223.grid_z, 8, 0, kernel_args_var_223, stream);
    }
    const int64_t int_array_99[] = {s0, 3072L};
    static constexpr int64_t int_array_100[] = {3072L, 1L};
    AtenTensorHandle buf478_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_99, int_array_100, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf478_handle));
    RAIIAtenTensorHandle buf478(buf478_handle);
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf478, buf477, _FOLDED_CONST_constant_pad_nd_default_17));
    AtenTensorHandle buf482_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_99, int_array_100, cached_torch_dtype_float32, cached_torch_device_type_cuda, this->device_idx_, &buf482_handle));
    RAIIAtenTensorHandle buf482(buf482_handle);
    AtenTensorHandle buf486_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_99, int_array_100, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf486_handle));
    RAIIAtenTensorHandle buf486(buf486_handle);
    // Topologically Sorted Source Nodes: [linear_68, layer_norm_65, sigmoid_10, mul_1607, layer_norm_66], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190 == nullptr) {
        kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjrf2wsdw5s2mkxuljogdebocxyglpjsvz4biqt57kejo22w5zt7.cubin", "triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190", 96, this->cubin_dir_);
    }
    CUdeviceptr var_1035 = reinterpret_cast<CUdeviceptr>(buf478.data_ptr());
    CUdeviceptr var_1036 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1037 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1038 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1039 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1040 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1041 = reinterpret_cast<CUdeviceptr>(buf482.data_ptr());
    CUdeviceptr var_1042 = reinterpret_cast<CUdeviceptr>(buf486.data_ptr());
    int32_t var_1043 = s0;
    int var_1044 = 3072L;
    void* kernel_args_var_224[] = {&var_1035, &var_1036, &var_1037, &var_1038, &var_1039, &var_1040, &var_1041, &var_1042, &var_1043, &var_1044};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_224 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_224.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_224.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_224.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_224.grid_z, 8, 96, kernel_args_var_224, stream);
    }
    auto buf487 = std::move(buf394);  // reuse
    // Topologically Sorted Source Nodes: [linear_69], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_191 == nullptr) {
        kernels.triton_tem_fused_addmm_191 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cpsdcjt3f6ezhe3xpc3h36yaosgyvc42zmq5sjxun5hore4bcryl.cubin", "triton_tem_fused_addmm_191", 73728, this->cubin_dir_);
    }
    CUdeviceptr var_1045 = reinterpret_cast<CUdeviceptr>(buf486.data_ptr());
    CUdeviceptr var_1046 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_72.data_ptr());
    CUdeviceptr var_1047 = reinterpret_cast<CUdeviceptr>(buf487.data_ptr());
    int32_t var_1048 = s0;
    void* kernel_args_var_225[] = {&var_1045, &var_1046, &var_1047, &var_1048};
    Grid triton_tem_fused_addmm_191_grid_225 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_191_grid_225.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_191, triton_tem_fused_addmm_191_grid_225.grid_x, triton_tem_fused_addmm_191_grid_225.grid_y, triton_tem_fused_addmm_191_grid_225.grid_z, 4, 73728, kernel_args_var_225, stream);
    }
    AtenTensorHandle buf491_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_71, int_array_72, cached_torch_dtype_float32, cached_torch_device_type_cuda, this->device_idx_, &buf491_handle));
    RAIIAtenTensorHandle buf491(buf491_handle);
    AtenTensorHandle buf495_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_71, int_array_72, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf495_handle));
    RAIIAtenTensorHandle buf495(buf495_handle);
    // Topologically Sorted Source Nodes: [linear_69, layer_norm_67, sigmoid_11, mul_1618, layer_norm_68], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192 == nullptr) {
        kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cgcstc2ign46j2lysuys5bjuceevuspj4thnmml4zht7z4msjt56.cubin", "triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192", 192, this->cubin_dir_);
    }
    CUdeviceptr var_1049 = reinterpret_cast<CUdeviceptr>(buf487.data_ptr());
    CUdeviceptr var_1050 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1051 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1052 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1053 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1054 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1055 = reinterpret_cast<CUdeviceptr>(buf491.data_ptr());
    CUdeviceptr var_1056 = reinterpret_cast<CUdeviceptr>(buf495.data_ptr());
    int32_t var_1057 = s0;
    int var_1058 = 1536L;
    void* kernel_args_var_226[] = {&var_1049, &var_1050, &var_1051, &var_1052, &var_1053, &var_1054, &var_1055, &var_1056, &var_1057, &var_1058};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_226 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_226.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_226.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_226.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_226.grid_z, 16, 192, kernel_args_var_226, stream);
    }
    auto buf496 = std::move(buf478);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf496, buf495, _FOLDED_CONST_permute_73));
    auto buf500 = std::move(buf496);  // reuse
    auto buf504 = std::move(buf500);  // reuse
    // Topologically Sorted Source Nodes: [linear_70, layer_norm_69, add_2100, layer_norm_70, sigmoid_12, mul_1633], Original ATen: [aten.addmm, aten.native_layer_norm, aten.add, aten.sigmoid, aten.mul]
    if (kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193 == nullptr) {
        kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckkcsf2lf7r3uaxsznvqm5263g4oehbkjqsfgtr4o6eoits3ggaf.cubin", "triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193", 96, this->cubin_dir_);
    }
    CUdeviceptr var_1059 = reinterpret_cast<CUdeviceptr>(buf504.data_ptr());
    CUdeviceptr var_1060 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1061 = reinterpret_cast<CUdeviceptr>(buf486.data_ptr());
    CUdeviceptr var_1062 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1063 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1064 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight.data_ptr());
    CUdeviceptr var_1065 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias.data_ptr());
    int32_t var_1066 = s0;
    int var_1067 = 3072L;
    void* kernel_args_var_227[] = {&var_1059, &var_1060, &var_1061, &var_1062, &var_1063, &var_1064, &var_1065, &var_1066, &var_1067};
    Grid triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_227 = Grid(s0, 1L, 1L);
    if (triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_227.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_227.grid_x, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_227.grid_y, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_227.grid_z, 8, 96, kernel_args_var_227, stream);
    }
    auto buf505 = std::move(buf495);  // reuse
    // Topologically Sorted Source Nodes: [linear_71], Original ATen: [aten.addmm]
    CUdeviceptr var_1068 = reinterpret_cast<CUdeviceptr>(buf504.data_ptr());
    CUdeviceptr var_1069 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_74.data_ptr());
    CUdeviceptr var_1070 = reinterpret_cast<CUdeviceptr>(buf505.data_ptr());
    int32_t var_1071 = s0;
    void* kernel_args_var_228[] = {&var_1068, &var_1069, &var_1070, &var_1071};
    Grid triton_tem_fused_addmm_191_grid_228 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_191_grid_228.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_191, triton_tem_fused_addmm_191_grid_228.grid_x, triton_tem_fused_addmm_191_grid_228.grid_y, triton_tem_fused_addmm_191_grid_228.grid_z, 4, 73728, kernel_args_var_228, stream);
    }
    auto buf509 = std::move(buf491);  // reuse
    auto buf513 = std::move(buf487);  // reuse
    // Topologically Sorted Source Nodes: [linear_71, layer_norm_71, sigmoid_13, mul_1644, layer_norm_72], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1072 = reinterpret_cast<CUdeviceptr>(buf505.data_ptr());
    CUdeviceptr var_1073 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1074 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1075 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1076 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1077 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1078 = reinterpret_cast<CUdeviceptr>(buf509.data_ptr());
    CUdeviceptr var_1079 = reinterpret_cast<CUdeviceptr>(buf513.data_ptr());
    int32_t var_1080 = s0;
    int var_1081 = 1536L;
    void* kernel_args_var_229[] = {&var_1072, &var_1073, &var_1074, &var_1075, &var_1076, &var_1077, &var_1078, &var_1079, &var_1080, &var_1081};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_229 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_229.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_229.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_229.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_229.grid_z, 16, 192, kernel_args_var_229, stream);
    }
    AtenTensorHandle buf514_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_99, int_array_100, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf514_handle));
    RAIIAtenTensorHandle buf514(buf514_handle);
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf514, buf513, _FOLDED_CONST_permute_75));
    auto buf518 = std::move(buf486);  // reuse
    auto buf522 = std::move(buf518);  // reuse
    // Topologically Sorted Source Nodes: [linear_72, layer_norm_73, add_2113, add_2138, layer_norm_74, sigmoid_14, mul_1659], Original ATen: [aten.addmm, aten.native_layer_norm, aten.add, aten.sigmoid, aten.mul]
    if (kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194 == nullptr) {
        kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cogo3czag5sj56wvrnvf4pzbcnwqv7apri6o3bt3qi7tycoy34mo.cubin", "triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194", 96, this->cubin_dir_);
    }
    CUdeviceptr var_1082 = reinterpret_cast<CUdeviceptr>(buf522.data_ptr());
    CUdeviceptr var_1083 = reinterpret_cast<CUdeviceptr>(buf514.data_ptr());
    CUdeviceptr var_1084 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1085 = reinterpret_cast<CUdeviceptr>(buf504.data_ptr());
    CUdeviceptr var_1086 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1087 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1088 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1089 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias.data_ptr());
    int32_t var_1090 = s0;
    int var_1091 = 3072L;
    void* kernel_args_var_230[] = {&var_1082, &var_1083, &var_1084, &var_1085, &var_1086, &var_1087, &var_1088, &var_1089, &var_1090, &var_1091};
    Grid triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_230 = Grid(s0, 1L, 1L);
    if (triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_230.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_230.grid_x, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_230.grid_y, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_230.grid_z, 8, 96, kernel_args_var_230, stream);
    }
    auto tmp_tensor_handle_178 = reinterpret_tensor_wrapper(buf443, 2, int_array_83, int_array_84, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_178_raii(tmp_tensor_handle_178);
    decltype(auto) buf523 = std::move(tmp_tensor_handle_178_raii); buf443.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_74, sigmoid_14, mul_1659, linear_73], Original ATen: [aten.native_layer_norm, aten.sigmoid, aten.mul, aten.addmm]
    if (kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195 == nullptr) {
        kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cvkurplrtzcgf6k7kqvt3xstvmdlximlcbmo37udoaa6fozwa5g6.cubin", "triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195", 98304, this->cubin_dir_);
    }
    CUdeviceptr var_1092 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1093 = reinterpret_cast<CUdeviceptr>(buf522.data_ptr());
    CUdeviceptr var_1094 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_76.data_ptr());
    CUdeviceptr var_1095 = reinterpret_cast<CUdeviceptr>(buf523.data_ptr());
    int32_t var_1096 = s0;
    void* kernel_args_var_231[] = {&var_1092, &var_1093, &var_1094, &var_1095, &var_1096};
    Grid triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_231 = Grid(72L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_231.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_231.grid_x, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_231.grid_y, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_231.grid_z, 4, 98304, kernel_args_var_231, stream);
    }
    const int64_t int_array_101[] = {s0, 19584L};
    static constexpr int64_t int_array_102[] = {19584L, 1L};
    AtenTensorHandle buf524_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_101, int_array_102, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf524_handle));
    RAIIAtenTensorHandle buf524(buf524_handle);
    const int64_t int_array_103[] = {s0, 102L, 192L};
    static constexpr int64_t int_array_104[] = {19584L, 192L, 1L};
    auto tmp_tensor_handle_179 = reinterpret_tensor_wrapper(buf524, 3, int_array_103, int_array_104, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_179_raii(tmp_tensor_handle_179);
    decltype(auto) buf528 = std::move(tmp_tensor_handle_179_raii); buf524.reset();  // reuse
    // Topologically Sorted Source Nodes: [cat_default_5, add_2161, layer_norm_75], Original ATen: [aten.cat, aten.add, aten.native_layer_norm]
    int64_t triton_red_fused_add_cat_native_layer_norm_196_xnumel = 102L*s0;
    if (kernels.triton_red_fused_add_cat_native_layer_norm_196 == nullptr) {
        kernels.triton_red_fused_add_cat_native_layer_norm_196 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ca6qfzbyrzsdvog4yl2wqykgksr663j2zsnfmyix7ax2rlspxseh.cubin", "triton_red_fused_add_cat_native_layer_norm_196", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1097 = reinterpret_cast<CUdeviceptr>(buf528.data_ptr());
    CUdeviceptr var_1098 = reinterpret_cast<CUdeviceptr>(buf344.data_ptr());
    CUdeviceptr var_1099 = reinterpret_cast<CUdeviceptr>(buf345.data_ptr());
    CUdeviceptr var_1100 = reinterpret_cast<CUdeviceptr>(buf346.data_ptr());
    CUdeviceptr var_1101 = reinterpret_cast<CUdeviceptr>(buf347.data_ptr());
    CUdeviceptr var_1102 = reinterpret_cast<CUdeviceptr>(buf348.data_ptr());
    CUdeviceptr var_1103 = reinterpret_cast<CUdeviceptr>(buf349.data_ptr());
    CUdeviceptr var_1104 = reinterpret_cast<CUdeviceptr>(buf393.data_ptr());
    CUdeviceptr var_1105 = reinterpret_cast<CUdeviceptr>(buf523.data_ptr());
    CUdeviceptr var_1106 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w.data_ptr());
    CUdeviceptr var_1107 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b.data_ptr());
    int32_t var_1108 = triton_red_fused_add_cat_native_layer_norm_196_xnumel;
    int var_1109 = 192L;
    void* kernel_args_var_232[] = {&var_1097, &var_1098, &var_1099, &var_1100, &var_1101, &var_1102, &var_1103, &var_1104, &var_1105, &var_1106, &var_1107, &var_1108, &var_1109};
    Grid triton_red_fused_add_cat_native_layer_norm_196_grid_232 = Grid((-1L)*static_cast<int64_t>(std::floor((-51.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_add_cat_native_layer_norm_196_grid_232.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_cat_native_layer_norm_196, triton_red_fused_add_cat_native_layer_norm_196_grid_232.grid_x, triton_red_fused_add_cat_native_layer_norm_196_grid_232.grid_y, triton_red_fused_add_cat_native_layer_norm_196_grid_232.grid_z, 16, 0, kernel_args_var_232, stream);
    }
    buf393.reset();
    const int64_t int_array_105[] = {s0, 72L, 104L};
    static constexpr int64_t int_array_106[] = {7488L, 104L, 1L};
    AtenTensorHandle buf529_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_105, int_array_106, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf529_handle));
    RAIIAtenTensorHandle buf529(buf529_handle);
    // Topologically Sorted Source Nodes: [matmul_1], Original ATen: [aten.bmm]
    int64_t triton_poi_fused_bmm_197_xnumel = 7488L*s0;
    if (kernels.triton_poi_fused_bmm_197 == nullptr) {
        kernels.triton_poi_fused_bmm_197 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c7dvlptwqfiamubizxfy7qrocx44apeya2j3m6nwxrl7srmkk2jb.cubin", "triton_poi_fused_bmm_197", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1110 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w.data_ptr());
    CUdeviceptr var_1111 = reinterpret_cast<CUdeviceptr>(buf529.data_ptr());
    int32_t var_1112 = triton_poi_fused_bmm_197_xnumel;
    void* kernel_args_var_233[] = {&var_1110, &var_1111, &var_1112};
    Grid triton_poi_fused_bmm_197_grid_233 = Grid((-1L)*static_cast<int64_t>(std::floor((-117.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_bmm_197_grid_233.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_bmm_197, triton_poi_fused_bmm_197_grid_233.grid_x, triton_poi_fused_bmm_197_grid_233.grid_y, triton_poi_fused_bmm_197_grid_233.grid_z, 4, 0, kernel_args_var_233, stream);
    }
    const int64_t int_array_107[] = {s0, 104L, 192L};
    static constexpr int64_t int_array_108[] = {19968L, 192L, 1L};
    AtenTensorHandle buf530_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_107, int_array_108, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf530_handle));
    RAIIAtenTensorHandle buf530(buf530_handle);
    // Topologically Sorted Source Nodes: [matmul_1], Original ATen: [aten.bmm]
    int64_t triton_poi_fused_bmm_198_xnumel = 19968L*s0;
    if (kernels.triton_poi_fused_bmm_198 == nullptr) {
        kernels.triton_poi_fused_bmm_198 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cvc7itqlja3lsepb5fr7izxvoqxgze3xkgeawhdxhpnzrlmosai2.cubin", "triton_poi_fused_bmm_198", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1113 = reinterpret_cast<CUdeviceptr>(buf528.data_ptr());
    CUdeviceptr var_1114 = reinterpret_cast<CUdeviceptr>(buf530.data_ptr());
    int32_t var_1115 = triton_poi_fused_bmm_198_xnumel;
    void* kernel_args_var_234[] = {&var_1113, &var_1114, &var_1115};
    Grid triton_poi_fused_bmm_198_grid_234 = Grid((-1L)*static_cast<int64_t>(std::floor((-39.0/2.0)*s0)), 1L, 1L);
    if (triton_poi_fused_bmm_198_grid_234.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_bmm_198, triton_poi_fused_bmm_198_grid_234.grid_x, triton_poi_fused_bmm_198_grid_234.grid_y, triton_poi_fused_bmm_198_grid_234.grid_z, 4, 0, kernel_args_var_234, stream);
    }
    const int64_t int_array_109[] = {s0, 72L, 192L};
    static constexpr int64_t int_array_110[] = {13824L, 192L, 1L};
    AtenTensorHandle buf531_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_109, int_array_110, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf531_handle));
    RAIIAtenTensorHandle buf531(buf531_handle);
    // Topologically Sorted Source Nodes: [matmul_1], Original ATen: [aten.bmm]
    if (kernels.triton_tem_fused_bmm_199 == nullptr) {
        kernels.triton_tem_fused_bmm_199 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cvzjomoums3p4crgobub5kro23wq7ag7onbb55peszsmqdfgtocn.cubin", "triton_tem_fused_bmm_199", 98304, this->cubin_dir_);
    }
    CUdeviceptr var_1116 = reinterpret_cast<CUdeviceptr>(buf529.data_ptr());
    CUdeviceptr var_1117 = reinterpret_cast<CUdeviceptr>(buf530.data_ptr());
    CUdeviceptr var_1118 = reinterpret_cast<CUdeviceptr>(buf531.data_ptr());
    void* kernel_args_var_235[] = {&var_1116, &var_1117, &var_1118};
    Grid triton_tem_fused_bmm_199_grid_235 = Grid(2L, s0, 1L);
    if (triton_tem_fused_bmm_199_grid_235.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_199, triton_tem_fused_bmm_199_grid_235.grid_x, triton_tem_fused_bmm_199_grid_235.grid_y, triton_tem_fused_bmm_199_grid_235.grid_z, 4, 98304, kernel_args_var_235, stream);
    }
    auto buf535 = std::move(buf531);  // reuse
    // Topologically Sorted Source Nodes: [add_2174, layer_norm_76], Original ATen: [aten.add, aten.native_layer_norm]
    int64_t triton_per_fused_add_native_layer_norm_200_xnumel = 72L*s0;
    if (kernels.triton_per_fused_add_native_layer_norm_200 == nullptr) {
        kernels.triton_per_fused_add_native_layer_norm_200 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cmqycbvlwbx54d3ascq3nypf7ucfnuq7gcwj764ggoaf6mncvlc2.cubin", "triton_per_fused_add_native_layer_norm_200", 8, this->cubin_dir_);
    }
    CUdeviceptr var_1119 = reinterpret_cast<CUdeviceptr>(buf535.data_ptr());
    CUdeviceptr var_1120 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b.data_ptr());
    CUdeviceptr var_1121 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w.data_ptr());
    CUdeviceptr var_1122 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b.data_ptr());
    int32_t var_1123 = triton_per_fused_add_native_layer_norm_200_xnumel;
    int var_1124 = 192L;
    void* kernel_args_var_236[] = {&var_1119, &var_1120, &var_1121, &var_1122, &var_1123, &var_1124};
    Grid triton_per_fused_add_native_layer_norm_200_grid_236 = Grid(72L*s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_200_grid_236.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_200, triton_per_fused_add_native_layer_norm_200_grid_236.grid_x, triton_per_fused_add_native_layer_norm_200_grid_236.grid_y, triton_per_fused_add_native_layer_norm_200_grid_236.grid_z, 2, 8, kernel_args_var_236, stream);
    }
    auto buf536 = std::move(buf513);  // reuse
    // Topologically Sorted Source Nodes: [linear_default_4], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_201 == nullptr) {
        kernels.triton_tem_fused_addmm_201 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/crqtscfjqplxcqindftsg3dyvvgfva2wkdtmvndvudixf5aszfrg.cubin", "triton_tem_fused_addmm_201", 73728, this->cubin_dir_);
    }
    CUdeviceptr var_1125 = reinterpret_cast<CUdeviceptr>(buf535.data_ptr());
    CUdeviceptr var_1126 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_78.data_ptr());
    CUdeviceptr var_1127 = reinterpret_cast<CUdeviceptr>(buf536.data_ptr());
    int32_t var_1128 = s0;
    void* kernel_args_var_237[] = {&var_1125, &var_1126, &var_1127, &var_1128};
    Grid triton_tem_fused_addmm_201_grid_237 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_201_grid_237.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_201, triton_tem_fused_addmm_201_grid_237.grid_x, triton_tem_fused_addmm_201_grid_237.grid_y, triton_tem_fused_addmm_201_grid_237.grid_z, 4, 73728, kernel_args_var_237, stream);
    }
    auto buf551 = std::move(buf432);  // reuse
    // Topologically Sorted Source Nodes: [contiguous_12, layer_norm_77, sigmoid_15, mul_1708, layer_norm_79], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1129 = reinterpret_cast<CUdeviceptr>(buf536.data_ptr());
    CUdeviceptr var_1130 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_17.data_ptr());
    CUdeviceptr var_1131 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1132 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1133 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1134 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1135 = reinterpret_cast<CUdeviceptr>(buf551.data_ptr());
    int32_t var_1136 = s0;
    int var_1137 = 768L;
    void* kernel_args_var_238[] = {&var_1129, &var_1130, &var_1131, &var_1132, &var_1133, &var_1134, &var_1135, &var_1136, &var_1137};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_238 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_238.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_172, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_238.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_238.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_238.grid_z, 8, 32, kernel_args_var_238, stream);
    }
    auto buf556 = std::move(buf427);  // reuse
    // Topologically Sorted Source Nodes: [contiguous_13, layer_norm_78, sigmoid_16, mul_1713, layer_norm_80], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1138 = reinterpret_cast<CUdeviceptr>(buf536.data_ptr());
    CUdeviceptr var_1139 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_17.data_ptr());
    CUdeviceptr var_1140 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1141 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1142 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1143 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1144 = reinterpret_cast<CUdeviceptr>(buf556.data_ptr());
    int32_t var_1145 = s0;
    int var_1146 = 768L;
    void* kernel_args_var_239[] = {&var_1138, &var_1139, &var_1140, &var_1141, &var_1142, &var_1143, &var_1144, &var_1145, &var_1146};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_239 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_239.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_173, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_239.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_239.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_239.grid_z, 8, 32, kernel_args_var_239, stream);
    }
    auto buf552 = std::move(buf415);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_79, linear_76], Original ATen: [aten.native_layer_norm, aten.addmm]
    CUdeviceptr var_1147 = reinterpret_cast<CUdeviceptr>(buf551.data_ptr());
    CUdeviceptr var_1148 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_79.data_ptr());
    CUdeviceptr var_1149 = reinterpret_cast<CUdeviceptr>(buf552.data_ptr());
    int32_t var_1150 = s0;
    void* kernel_args_var_240[] = {&var_1147, &var_1148, &var_1149, &var_1150};
    Grid triton_tem_fused_addmm_native_layer_norm_174_grid_240 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_174_grid_240.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_174, triton_tem_fused_addmm_native_layer_norm_174_grid_240.grid_x, triton_tem_fused_addmm_native_layer_norm_174_grid_240.grid_y, triton_tem_fused_addmm_native_layer_norm_174_grid_240.grid_z, 8, 163840, kernel_args_var_240, stream);
    }
    auto buf569 = std::move(buf551);  // reuse
    // Topologically Sorted Source Nodes: [linear_76, layer_norm_81, sigmoid_17, mul_1730, layer_norm_83], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1151 = reinterpret_cast<CUdeviceptr>(buf552.data_ptr());
    CUdeviceptr var_1152 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias.data_ptr());
    CUdeviceptr var_1153 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1154 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias.data_ptr());
    CUdeviceptr var_1155 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w.data_ptr());
    CUdeviceptr var_1156 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b.data_ptr());
    CUdeviceptr var_1157 = reinterpret_cast<CUdeviceptr>(buf569.data_ptr());
    int32_t var_1158 = s0;
    int var_1159 = 768L;
    void* kernel_args_var_241[] = {&var_1151, &var_1152, &var_1153, &var_1154, &var_1155, &var_1156, &var_1157, &var_1158, &var_1159};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_241 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_241.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_241.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_241.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_241.grid_z, 8, 32, kernel_args_var_241, stream);
    }
    auto buf557 = std::move(buf552);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_80, linear_77], Original ATen: [aten.native_layer_norm, aten.addmm]
    CUdeviceptr var_1160 = reinterpret_cast<CUdeviceptr>(buf556.data_ptr());
    CUdeviceptr var_1161 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_80.data_ptr());
    CUdeviceptr var_1162 = reinterpret_cast<CUdeviceptr>(buf557.data_ptr());
    int32_t var_1163 = s0;
    void* kernel_args_var_242[] = {&var_1160, &var_1161, &var_1162, &var_1163};
    Grid triton_tem_fused_addmm_native_layer_norm_174_grid_242 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_174_grid_242.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_174, triton_tem_fused_addmm_native_layer_norm_174_grid_242.grid_x, triton_tem_fused_addmm_native_layer_norm_174_grid_242.grid_y, triton_tem_fused_addmm_native_layer_norm_174_grid_242.grid_z, 8, 163840, kernel_args_var_242, stream);
    }
    auto buf574 = std::move(buf556);  // reuse
    // Topologically Sorted Source Nodes: [linear_77, layer_norm_82, sigmoid_18, mul_1735, layer_norm_84], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1164 = reinterpret_cast<CUdeviceptr>(buf557.data_ptr());
    CUdeviceptr var_1165 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias.data_ptr());
    CUdeviceptr var_1166 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1167 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias.data_ptr());
    CUdeviceptr var_1168 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w.data_ptr());
    CUdeviceptr var_1169 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b.data_ptr());
    CUdeviceptr var_1170 = reinterpret_cast<CUdeviceptr>(buf574.data_ptr());
    int32_t var_1171 = s0;
    int var_1172 = 768L;
    void* kernel_args_var_243[] = {&var_1164, &var_1165, &var_1166, &var_1167, &var_1168, &var_1169, &var_1170, &var_1171, &var_1172};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_243 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_243.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_243.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_243.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_243.grid_z, 8, 32, kernel_args_var_243, stream);
    }
    const int64_t int_array_111[] = {s0, 4896L};
    static constexpr int64_t int_array_112[] = {4896L, 1L};
    AtenTensorHandle buf570_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_111, int_array_112, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf570_handle));
    RAIIAtenTensorHandle buf570(buf570_handle);
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf570, buf569, _FOLDED_CONST_permute_81));
    auto buf579 = std::move(buf570);  // reuse
    // Topologically Sorted Source Nodes: [linear_78, layer_norm_85], Original ATen: [aten.addmm, aten.native_layer_norm]
    if (kernels.triton_red_fused_addmm_native_layer_norm_202 == nullptr) {
        kernels.triton_red_fused_addmm_native_layer_norm_202 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/czu5doiwaalqrbbu6qzyyetom2xknkpuhzvadkonsjm7fprmx7bq.cubin", "triton_red_fused_addmm_native_layer_norm_202", 192, this->cubin_dir_);
    }
    CUdeviceptr var_1173 = reinterpret_cast<CUdeviceptr>(buf579.data_ptr());
    CUdeviceptr var_1174 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1175 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1176 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b.data_ptr());
    int32_t var_1177 = s0;
    int var_1178 = 4896L;
    void* kernel_args_var_244[] = {&var_1173, &var_1174, &var_1175, &var_1176, &var_1177, &var_1178};
    Grid triton_red_fused_addmm_native_layer_norm_202_grid_244 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addmm_native_layer_norm_202_grid_244.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_native_layer_norm_202, triton_red_fused_addmm_native_layer_norm_202_grid_244.grid_x, triton_red_fused_addmm_native_layer_norm_202_grid_244.grid_y, triton_red_fused_addmm_native_layer_norm_202_grid_244.grid_z, 16, 192, kernel_args_var_244, stream);
    }
    auto buf575 = std::move(buf523);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf575, buf574, _FOLDED_CONST_permute_82));
    auto buf576 = std::move(buf475);  // reuse
    auto buf577 = std::move(buf474);  // reuse
    // Topologically Sorted Source Nodes: [linear_79, layer_norm_86], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1179 = reinterpret_cast<CUdeviceptr>(buf575.data_ptr());
    CUdeviceptr var_1180 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1181 = reinterpret_cast<CUdeviceptr>(buf576.data_ptr());
    CUdeviceptr var_1182 = reinterpret_cast<CUdeviceptr>(buf577.data_ptr());
    int32_t var_1183 = s0;
    int var_1184 = 9216L;
    void* kernel_args_var_245[] = {&var_1179, &var_1180, &var_1181, &var_1182, &var_1183, &var_1184};
    Grid triton_red_fused_addmm_native_layer_norm_177_grid_245 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_native_layer_norm_177_grid_245.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_native_layer_norm_177, triton_red_fused_addmm_native_layer_norm_177_grid_245.grid_x, triton_red_fused_addmm_native_layer_norm_177_grid_245.grid_y, triton_red_fused_addmm_native_layer_norm_177_grid_245.grid_z, 16, 192, kernel_args_var_245, stream);
    }
    auto buf580 = std::move(buf438);  // reuse
    // Topologically Sorted Source Nodes: [bmm_2], Original ATen: [aten.bmm]
    if (kernels.triton_tem_fused_bmm_203 == nullptr) {
        kernels.triton_tem_fused_bmm_203 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cmrruaw3hv4jn2hdlxrcccayzgxog2jqusz5mcdn5x3rsluzjfz5.cubin", "triton_tem_fused_bmm_203", 24576, this->cubin_dir_);
    }
    CUdeviceptr var_1185 = reinterpret_cast<CUdeviceptr>(buf528.data_ptr());
    CUdeviceptr var_1186 = reinterpret_cast<CUdeviceptr>(buf579.data_ptr());
    CUdeviceptr var_1187 = reinterpret_cast<CUdeviceptr>(buf580.data_ptr());
    void* kernel_args_var_246[] = {&var_1185, &var_1186, &var_1187};
    Grid triton_tem_fused_bmm_203_grid_246 = Grid(3L, s0, 1L);
    if (triton_tem_fused_bmm_203_grid_246.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_203, triton_tem_fused_bmm_203_grid_246.grid_x, triton_tem_fused_bmm_203_grid_246.grid_y, triton_tem_fused_bmm_203_grid_246.grid_z, 4, 24576, kernel_args_var_246, stream);
    }
    auto tmp_tensor_handle_180 = reinterpret_tensor_wrapper(buf433, 3, int_array_87, int_array_88, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_180_raii(tmp_tensor_handle_180);
    decltype(auto) buf585 = std::move(tmp_tensor_handle_180_raii); buf433.reset();  // reuse
    // Topologically Sorted Source Nodes: [add_2285, layer_norm_87], Original ATen: [aten.add, aten.native_layer_norm]
    triton_per_fused_add_native_layer_norm_179_xnumel = 192L*s0;
    CUdeviceptr var_1188 = reinterpret_cast<CUdeviceptr>(buf575.data_ptr());
    CUdeviceptr var_1189 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1190 = reinterpret_cast<CUdeviceptr>(buf576.data_ptr());
    CUdeviceptr var_1191 = reinterpret_cast<CUdeviceptr>(buf577.data_ptr());
    CUdeviceptr var_1192 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1193 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1194 = reinterpret_cast<CUdeviceptr>(buf580.data_ptr());
    CUdeviceptr var_1195 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w.data_ptr());
    CUdeviceptr var_1196 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b.data_ptr());
    CUdeviceptr var_1197 = reinterpret_cast<CUdeviceptr>(buf585.data_ptr());
    int32_t var_1198 = triton_per_fused_add_native_layer_norm_179_xnumel;
    int var_1199 = 48L;
    void* kernel_args_var_247[] = {&var_1188, &var_1189, &var_1190, &var_1191, &var_1192, &var_1193, &var_1194, &var_1195, &var_1196, &var_1197, &var_1198, &var_1199};
    Grid triton_per_fused_add_native_layer_norm_179_grid_247 = Grid(6L*s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_179_grid_247.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_179, triton_per_fused_add_native_layer_norm_179_grid_247.grid_x, triton_per_fused_add_native_layer_norm_179_grid_247.grid_y, triton_per_fused_add_native_layer_norm_179_grid_247.grid_z, 8, 0, kernel_args_var_247, stream);
    }
    const int64_t int_array_113[] = {s0, 102L, 48L};
    static constexpr int64_t int_array_114[] = {4896L, 48L, 1L};
    auto tmp_tensor_handle_181 = reinterpret_tensor_wrapper(buf579, 3, int_array_113, int_array_114, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_181_raii(tmp_tensor_handle_181);
    decltype(auto) buf586 = std::move(tmp_tensor_handle_181_raii); buf579.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_87, bmm_3], Original ATen: [aten.native_layer_norm, aten.bmm]
    if (kernels.triton_tem_fused_bmm_native_layer_norm_204 == nullptr) {
        kernels.triton_tem_fused_bmm_native_layer_norm_204 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cm6la74levdrejrxxhwv6ctffqvmvtvz7ioc2m4bvk4x443uqo5s.cubin", "triton_tem_fused_bmm_native_layer_norm_204", 73728, this->cubin_dir_);
    }
    CUdeviceptr var_1200 = reinterpret_cast<CUdeviceptr>(buf528.data_ptr());
    CUdeviceptr var_1201 = reinterpret_cast<CUdeviceptr>(buf585.data_ptr());
    CUdeviceptr var_1202 = reinterpret_cast<CUdeviceptr>(buf586.data_ptr());
    void* kernel_args_var_248[] = {&var_1200, &var_1201, &var_1202};
    Grid triton_tem_fused_bmm_native_layer_norm_204_grid_248 = Grid(1L, s0, 1L);
    if (triton_tem_fused_bmm_native_layer_norm_204_grid_248.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_native_layer_norm_204, triton_tem_fused_bmm_native_layer_norm_204_grid_248.grid_x, triton_tem_fused_bmm_native_layer_norm_204_grid_248.grid_y, triton_tem_fused_bmm_native_layer_norm_204_grid_248.grid_z, 4, 73728, kernel_args_var_248, stream);
    }
    auto tmp_tensor_handle_182 = reinterpret_tensor_wrapper(buf586, 2, int_array_111, int_array_112, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_182_raii(tmp_tensor_handle_182);
    decltype(auto) buf590 = std::move(tmp_tensor_handle_182_raii); buf586.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_88], Original ATen: [aten.native_layer_norm]
    if (kernels.triton_red_fused_native_layer_norm_205 == nullptr) {
        kernels.triton_red_fused_native_layer_norm_205 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cqlljc6vcb2ersmlpxcyxdz2foif62yyuhxwsdsdnfujyti4idjc.cubin", "triton_red_fused_native_layer_norm_205", 16640, this->cubin_dir_);
    }
    CUdeviceptr var_1203 = reinterpret_cast<CUdeviceptr>(buf590.data_ptr());
    CUdeviceptr var_1204 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w.data_ptr());
    CUdeviceptr var_1205 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b.data_ptr());
    int32_t var_1206 = s0;
    int var_1207 = 4896L;
    void* kernel_args_var_249[] = {&var_1203, &var_1204, &var_1205, &var_1206, &var_1207};
    Grid triton_red_fused_native_layer_norm_205_grid_249 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_native_layer_norm_205_grid_249.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_native_layer_norm_205, triton_red_fused_native_layer_norm_205_grid_249.grid_x, triton_red_fused_native_layer_norm_205_grid_249.grid_y, triton_red_fused_native_layer_norm_205_grid_249.grid_z, 16, 16640, kernel_args_var_249, stream);
    }
    auto buf591 = std::move(buf449);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf591, buf590, _FOLDED_CONST_permute_83));
    auto buf595 = std::move(buf453);  // reuse
    auto buf596 = std::move(buf577);  // reuse
    auto buf597 = std::move(buf576);  // reuse
    // Topologically Sorted Source Nodes: [linear_80, layer_norm_89, sigmoid_19, mul_1779, layer_norm_90], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1208 = reinterpret_cast<CUdeviceptr>(buf591.data_ptr());
    CUdeviceptr var_1209 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1210 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1211 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1212 = reinterpret_cast<CUdeviceptr>(buf595.data_ptr());
    CUdeviceptr var_1213 = reinterpret_cast<CUdeviceptr>(buf596.data_ptr());
    CUdeviceptr var_1214 = reinterpret_cast<CUdeviceptr>(buf597.data_ptr());
    int32_t var_1215 = s0;
    int var_1216 = 2048L;
    void* kernel_args_var_250[] = {&var_1208, &var_1209, &var_1210, &var_1211, &var_1212, &var_1213, &var_1214, &var_1215, &var_1216};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_250 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_250.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_250.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_250.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_250.grid_z, 16, 192, kernel_args_var_250, stream);
    }
    auto buf599 = std::move(buf469);  // reuse
    auto buf603 = std::move(buf599);  // reuse
    // Topologically Sorted Source Nodes: [cat_default_4, layer_norm_91], Original ATen: [aten.cat, aten.native_layer_norm]
    CUdeviceptr var_1217 = reinterpret_cast<CUdeviceptr>(buf603.data_ptr());
    CUdeviceptr var_1218 = reinterpret_cast<CUdeviceptr>(buf457.data_ptr());
    CUdeviceptr var_1219 = reinterpret_cast<CUdeviceptr>(buf230.data_ptr());
    CUdeviceptr var_1220 = reinterpret_cast<CUdeviceptr>(buf595.data_ptr());
    CUdeviceptr var_1221 = reinterpret_cast<CUdeviceptr>(buf596.data_ptr());
    CUdeviceptr var_1222 = reinterpret_cast<CUdeviceptr>(buf597.data_ptr());
    CUdeviceptr var_1223 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1224 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1225 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w.data_ptr());
    CUdeviceptr var_1226 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b.data_ptr());
    int32_t var_1227 = s0;
    int var_1228 = 6354L;
    void* kernel_args_var_251[] = {&var_1217, &var_1218, &var_1219, &var_1220, &var_1221, &var_1222, &var_1223, &var_1224, &var_1225, &var_1226, &var_1227, &var_1228};
    Grid triton_red_fused_cat_native_layer_norm_183_grid_251 = Grid(s0, 1L, 1L);
    if (triton_red_fused_cat_native_layer_norm_183_grid_251.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_cat_native_layer_norm_183, triton_red_fused_cat_native_layer_norm_183_grid_251.grid_x, triton_red_fused_cat_native_layer_norm_183_grid_251.grid_y, triton_red_fused_cat_native_layer_norm_183_grid_251.grid_z, 8, 4096, kernel_args_var_251, stream);
    }
    auto buf604 = std::move(buf477);  // reuse
    // Topologically Sorted Source Nodes: [linear_81], Original ATen: [aten.addmm]
    triton_poi_fused_addmm_184_xnumel = 6360L*s0;
    CUdeviceptr var_1229 = reinterpret_cast<CUdeviceptr>(buf603.data_ptr());
    CUdeviceptr var_1230 = reinterpret_cast<CUdeviceptr>(buf604.data_ptr());
    int32_t var_1231 = triton_poi_fused_addmm_184_xnumel;
    void* kernel_args_var_252[] = {&var_1229, &var_1230, &var_1231};
    Grid triton_poi_fused_addmm_184_grid_252 = Grid((-1L)*static_cast<int64_t>(std::floor((-795.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_184_grid_252.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_184, triton_poi_fused_addmm_184_grid_252.grid_x, triton_poi_fused_addmm_184_grid_252.grid_y, triton_poi_fused_addmm_184_grid_252.grid_z, 8, 0, kernel_args_var_252, stream);
    }
    auto buf605 = std::move(buf468);  // reuse
    // Topologically Sorted Source Nodes: [linear_81], Original ATen: [aten.addmm]
    CUdeviceptr var_1232 = reinterpret_cast<CUdeviceptr>(buf604.data_ptr());
    CUdeviceptr var_1233 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_constant_pad_nd_default_13.data_ptr());
    CUdeviceptr var_1234 = reinterpret_cast<CUdeviceptr>(buf605.data_ptr());
    int32_t var_1235 = s0;
    void* kernel_args_var_253[] = {&var_1232, &var_1233, &var_1234, &var_1235};
    Grid triton_tem_fused_addmm_185_grid_253 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_185_grid_253.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_185, triton_tem_fused_addmm_185_grid_253.grid_x, triton_tem_fused_addmm_185_grid_253.grid_y, triton_tem_fused_addmm_185_grid_253.grid_z, 4, 196608, kernel_args_var_253, stream);
    }
    auto buf609 = std::move(buf605);  // reuse
    // Topologically Sorted Source Nodes: [linear_81, layer_norm_92], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1236 = reinterpret_cast<CUdeviceptr>(buf609.data_ptr());
    CUdeviceptr var_1237 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1238 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1239 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b.data_ptr());
    int32_t var_1240 = s0;
    int var_1241 = 384L;
    void* kernel_args_var_254[] = {&var_1236, &var_1237, &var_1238, &var_1239, &var_1240, &var_1241};
    Grid triton_per_fused_addmm_native_layer_norm_186_grid_254 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_186_grid_254.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_186, triton_per_fused_addmm_native_layer_norm_186_grid_254.grid_x, triton_per_fused_addmm_native_layer_norm_186_grid_254.grid_y, triton_per_fused_addmm_native_layer_norm_186_grid_254.grid_z, 4, 16, kernel_args_var_254, stream);
    }
    auto buf610 = std::move(buf462);  // reuse
    // Topologically Sorted Source Nodes: [linear_81, layer_norm_92, linear_82], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1242 = reinterpret_cast<CUdeviceptr>(buf609.data_ptr());
    CUdeviceptr var_1243 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_85.data_ptr());
    CUdeviceptr var_1244 = reinterpret_cast<CUdeviceptr>(buf610.data_ptr());
    int32_t var_1245 = s0;
    void* kernel_args_var_255[] = {&var_1242, &var_1243, &var_1244, &var_1245};
    Grid triton_tem_fused_addmm_native_layer_norm_187_grid_255 = Grid(50L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_187_grid_255.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_187, triton_tem_fused_addmm_native_layer_norm_187_grid_255.grid_x, triton_tem_fused_addmm_native_layer_norm_187_grid_255.grid_y, triton_tem_fused_addmm_native_layer_norm_187_grid_255.grid_z, 4, 49152, kernel_args_var_255, stream);
    }
    auto buf614 = std::move(buf473);  // reuse
    auto buf615 = std::move(buf597);  // reuse
    auto buf616 = std::move(buf596);  // reuse
    // Topologically Sorted Source Nodes: [linear_82, layer_norm_93, addcmul_1, layer_norm_94], Original ATen: [aten.addmm, aten.native_layer_norm, aten.addcmul]
    CUdeviceptr var_1246 = reinterpret_cast<CUdeviceptr>(buf610.data_ptr());
    CUdeviceptr var_1247 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1248 = reinterpret_cast<CUdeviceptr>(buf603.data_ptr());
    CUdeviceptr var_1249 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1250 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1251 = reinterpret_cast<CUdeviceptr>(buf614.data_ptr());
    CUdeviceptr var_1252 = reinterpret_cast<CUdeviceptr>(buf615.data_ptr());
    CUdeviceptr var_1253 = reinterpret_cast<CUdeviceptr>(buf616.data_ptr());
    int32_t var_1254 = s0;
    int var_1255 = 6354L;
    void* kernel_args_var_256[] = {&var_1246, &var_1247, &var_1248, &var_1249, &var_1250, &var_1251, &var_1252, &var_1253, &var_1254, &var_1255};
    Grid triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_256 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_256.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addcmul_addmm_native_layer_norm_188, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_256.grid_x, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_256.grid_y, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_256.grid_z, 8, 96, kernel_args_var_256, stream);
    }
    auto buf618 = std::move(buf604);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_94, linear_83], Original ATen: [aten.native_layer_norm, aten.addmm]
    triton_poi_fused_addmm_native_layer_norm_189_xnumel = 6360L*s0;
    CUdeviceptr var_1256 = reinterpret_cast<CUdeviceptr>(buf614.data_ptr());
    CUdeviceptr var_1257 = reinterpret_cast<CUdeviceptr>(buf615.data_ptr());
    CUdeviceptr var_1258 = reinterpret_cast<CUdeviceptr>(buf616.data_ptr());
    CUdeviceptr var_1259 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w.data_ptr());
    CUdeviceptr var_1260 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b.data_ptr());
    CUdeviceptr var_1261 = reinterpret_cast<CUdeviceptr>(buf618.data_ptr());
    int32_t var_1262 = triton_poi_fused_addmm_native_layer_norm_189_xnumel;
    void* kernel_args_var_257[] = {&var_1256, &var_1257, &var_1258, &var_1259, &var_1260, &var_1261, &var_1262};
    Grid triton_poi_fused_addmm_native_layer_norm_189_grid_257 = Grid((-1L)*static_cast<int64_t>(std::floor((-795.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_native_layer_norm_189_grid_257.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_native_layer_norm_189, triton_poi_fused_addmm_native_layer_norm_189_grid_257.grid_x, triton_poi_fused_addmm_native_layer_norm_189_grid_257.grid_y, triton_poi_fused_addmm_native_layer_norm_189_grid_257.grid_z, 8, 0, kernel_args_var_257, stream);
    }
    auto buf619 = std::move(buf522);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf619, buf618, _FOLDED_CONST_constant_pad_nd_default_11));
    auto buf623 = std::move(buf482);  // reuse
    auto buf627 = std::move(buf514);  // reuse
    // Topologically Sorted Source Nodes: [linear_83, layer_norm_95, sigmoid_20, mul_1806, layer_norm_96], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1263 = reinterpret_cast<CUdeviceptr>(buf619.data_ptr());
    CUdeviceptr var_1264 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1265 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1266 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1267 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1268 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1269 = reinterpret_cast<CUdeviceptr>(buf623.data_ptr());
    CUdeviceptr var_1270 = reinterpret_cast<CUdeviceptr>(buf627.data_ptr());
    int32_t var_1271 = s0;
    int var_1272 = 3072L;
    void* kernel_args_var_258[] = {&var_1263, &var_1264, &var_1265, &var_1266, &var_1267, &var_1268, &var_1269, &var_1270, &var_1271, &var_1272};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_258 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_258.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_258.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_258.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_258.grid_z, 8, 96, kernel_args_var_258, stream);
    }
    auto buf628 = std::move(buf536);  // reuse
    // Topologically Sorted Source Nodes: [linear_84], Original ATen: [aten.addmm]
    CUdeviceptr var_1273 = reinterpret_cast<CUdeviceptr>(buf627.data_ptr());
    CUdeviceptr var_1274 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_87.data_ptr());
    CUdeviceptr var_1275 = reinterpret_cast<CUdeviceptr>(buf628.data_ptr());
    int32_t var_1276 = s0;
    void* kernel_args_var_259[] = {&var_1273, &var_1274, &var_1275, &var_1276};
    Grid triton_tem_fused_addmm_191_grid_259 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_191_grid_259.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_191, triton_tem_fused_addmm_191_grid_259.grid_x, triton_tem_fused_addmm_191_grid_259.grid_y, triton_tem_fused_addmm_191_grid_259.grid_z, 4, 73728, kernel_args_var_259, stream);
    }
    auto buf632 = std::move(buf509);  // reuse
    auto buf636 = std::move(buf505);  // reuse
    // Topologically Sorted Source Nodes: [linear_84, layer_norm_97, sigmoid_21, mul_1817, layer_norm_98], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1277 = reinterpret_cast<CUdeviceptr>(buf628.data_ptr());
    CUdeviceptr var_1278 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1279 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1280 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1281 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1282 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1283 = reinterpret_cast<CUdeviceptr>(buf632.data_ptr());
    CUdeviceptr var_1284 = reinterpret_cast<CUdeviceptr>(buf636.data_ptr());
    int32_t var_1285 = s0;
    int var_1286 = 1536L;
    void* kernel_args_var_260[] = {&var_1277, &var_1278, &var_1279, &var_1280, &var_1281, &var_1282, &var_1283, &var_1284, &var_1285, &var_1286};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_260 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_260.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_260.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_260.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_260.grid_z, 16, 192, kernel_args_var_260, stream);
    }
    auto buf637 = std::move(buf619);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf637, buf636, _FOLDED_CONST_permute_88));
    auto buf641 = std::move(buf637);  // reuse
    auto buf645 = std::move(buf641);  // reuse
    // Topologically Sorted Source Nodes: [linear_85, layer_norm_99, add_2379, layer_norm_100, sigmoid_22, mul_1832], Original ATen: [aten.addmm, aten.native_layer_norm, aten.add, aten.sigmoid, aten.mul]
    CUdeviceptr var_1287 = reinterpret_cast<CUdeviceptr>(buf645.data_ptr());
    CUdeviceptr var_1288 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1289 = reinterpret_cast<CUdeviceptr>(buf627.data_ptr());
    CUdeviceptr var_1290 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1291 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1292 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight.data_ptr());
    CUdeviceptr var_1293 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias.data_ptr());
    int32_t var_1294 = s0;
    int var_1295 = 3072L;
    void* kernel_args_var_261[] = {&var_1287, &var_1288, &var_1289, &var_1290, &var_1291, &var_1292, &var_1293, &var_1294, &var_1295};
    Grid triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_261 = Grid(s0, 1L, 1L);
    if (triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_261.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_261.grid_x, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_261.grid_y, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_261.grid_z, 8, 96, kernel_args_var_261, stream);
    }
    auto buf646 = std::move(buf636);  // reuse
    // Topologically Sorted Source Nodes: [linear_86], Original ATen: [aten.addmm]
    CUdeviceptr var_1296 = reinterpret_cast<CUdeviceptr>(buf645.data_ptr());
    CUdeviceptr var_1297 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_89.data_ptr());
    CUdeviceptr var_1298 = reinterpret_cast<CUdeviceptr>(buf646.data_ptr());
    int32_t var_1299 = s0;
    void* kernel_args_var_262[] = {&var_1296, &var_1297, &var_1298, &var_1299};
    Grid triton_tem_fused_addmm_191_grid_262 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_191_grid_262.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_191, triton_tem_fused_addmm_191_grid_262.grid_x, triton_tem_fused_addmm_191_grid_262.grid_y, triton_tem_fused_addmm_191_grid_262.grid_z, 4, 73728, kernel_args_var_262, stream);
    }
    auto buf650 = std::move(buf632);  // reuse
    auto buf654 = std::move(buf628);  // reuse
    // Topologically Sorted Source Nodes: [linear_86, layer_norm_101, sigmoid_23, mul_1843, layer_norm_102], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1300 = reinterpret_cast<CUdeviceptr>(buf646.data_ptr());
    CUdeviceptr var_1301 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1302 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1303 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1304 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1305 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1306 = reinterpret_cast<CUdeviceptr>(buf650.data_ptr());
    CUdeviceptr var_1307 = reinterpret_cast<CUdeviceptr>(buf654.data_ptr());
    int32_t var_1308 = s0;
    int var_1309 = 1536L;
    void* kernel_args_var_263[] = {&var_1300, &var_1301, &var_1302, &var_1303, &var_1304, &var_1305, &var_1306, &var_1307, &var_1308, &var_1309};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_263 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_263.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_263.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_263.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_263.grid_z, 16, 192, kernel_args_var_263, stream);
    }
    auto buf655 = std::move(buf504);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf655, buf654, _FOLDED_CONST_permute_90));
    auto buf659 = std::move(buf627);  // reuse
    auto buf663 = std::move(buf659);  // reuse
    // Topologically Sorted Source Nodes: [linear_87, layer_norm_103, add_2392, add_2417, layer_norm_104, sigmoid_24, mul_1858], Original ATen: [aten.addmm, aten.native_layer_norm, aten.add, aten.sigmoid, aten.mul]
    CUdeviceptr var_1310 = reinterpret_cast<CUdeviceptr>(buf663.data_ptr());
    CUdeviceptr var_1311 = reinterpret_cast<CUdeviceptr>(buf655.data_ptr());
    CUdeviceptr var_1312 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1313 = reinterpret_cast<CUdeviceptr>(buf645.data_ptr());
    CUdeviceptr var_1314 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1315 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1316 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1317 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias.data_ptr());
    int32_t var_1318 = s0;
    int var_1319 = 3072L;
    void* kernel_args_var_264[] = {&var_1310, &var_1311, &var_1312, &var_1313, &var_1314, &var_1315, &var_1316, &var_1317, &var_1318, &var_1319};
    Grid triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_264 = Grid(s0, 1L, 1L);
    if (triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_264.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_264.grid_x, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_264.grid_y, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_264.grid_z, 8, 96, kernel_args_var_264, stream);
    }
    auto tmp_tensor_handle_183 = reinterpret_tensor_wrapper(buf585, 2, int_array_83, int_array_84, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_183_raii(tmp_tensor_handle_183);
    decltype(auto) buf664 = std::move(tmp_tensor_handle_183_raii); buf585.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_104, sigmoid_24, mul_1858, linear_88], Original ATen: [aten.native_layer_norm, aten.sigmoid, aten.mul, aten.addmm]
    CUdeviceptr var_1320 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1321 = reinterpret_cast<CUdeviceptr>(buf663.data_ptr());
    CUdeviceptr var_1322 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_91.data_ptr());
    CUdeviceptr var_1323 = reinterpret_cast<CUdeviceptr>(buf664.data_ptr());
    int32_t var_1324 = s0;
    void* kernel_args_var_265[] = {&var_1320, &var_1321, &var_1322, &var_1323, &var_1324};
    Grid triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_265 = Grid(72L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_265.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_265.grid_x, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_265.grid_y, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_265.grid_z, 4, 98304, kernel_args_var_265, stream);
    }
    AtenTensorHandle buf665_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_101, int_array_102, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf665_handle));
    RAIIAtenTensorHandle buf665(buf665_handle);
    auto tmp_tensor_handle_184 = reinterpret_tensor_wrapper(buf665, 3, int_array_103, int_array_104, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_184_raii(tmp_tensor_handle_184);
    decltype(auto) buf669 = std::move(tmp_tensor_handle_184_raii); buf665.reset();  // reuse
    // Topologically Sorted Source Nodes: [cat_default_3, add_2440, layer_norm_105], Original ATen: [aten.cat, aten.add, aten.native_layer_norm]
    int64_t triton_per_fused_add_cat_native_layer_norm_206_xnumel = 102L*s0;
    if (kernels.triton_per_fused_add_cat_native_layer_norm_206 == nullptr) {
        kernels.triton_per_fused_add_cat_native_layer_norm_206 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/clhougdlo7nvlfhu6fn54argrkft6h6gjuibccs7tytsgxgeo566.cubin", "triton_per_fused_add_cat_native_layer_norm_206", 8, this->cubin_dir_);
    }
    CUdeviceptr var_1325 = reinterpret_cast<CUdeviceptr>(buf669.data_ptr());
    CUdeviceptr var_1326 = reinterpret_cast<CUdeviceptr>(buf344.data_ptr());
    CUdeviceptr var_1327 = reinterpret_cast<CUdeviceptr>(buf345.data_ptr());
    CUdeviceptr var_1328 = reinterpret_cast<CUdeviceptr>(buf346.data_ptr());
    CUdeviceptr var_1329 = reinterpret_cast<CUdeviceptr>(buf347.data_ptr());
    CUdeviceptr var_1330 = reinterpret_cast<CUdeviceptr>(buf348.data_ptr());
    CUdeviceptr var_1331 = reinterpret_cast<CUdeviceptr>(buf349.data_ptr());
    CUdeviceptr var_1332 = reinterpret_cast<CUdeviceptr>(buf535.data_ptr());
    CUdeviceptr var_1333 = reinterpret_cast<CUdeviceptr>(buf664.data_ptr());
    CUdeviceptr var_1334 = reinterpret_cast<CUdeviceptr>(buf528.data_ptr());
    CUdeviceptr var_1335 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w.data_ptr());
    CUdeviceptr var_1336 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b.data_ptr());
    int32_t var_1337 = triton_per_fused_add_cat_native_layer_norm_206_xnumel;
    int var_1338 = 192L;
    void* kernel_args_var_266[] = {&var_1325, &var_1326, &var_1327, &var_1328, &var_1329, &var_1330, &var_1331, &var_1332, &var_1333, &var_1334, &var_1335, &var_1336, &var_1337, &var_1338};
    Grid triton_per_fused_add_cat_native_layer_norm_206_grid_266 = Grid(102L*s0, 1L, 1L);
    if (triton_per_fused_add_cat_native_layer_norm_206_grid_266.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_cat_native_layer_norm_206, triton_per_fused_add_cat_native_layer_norm_206_grid_266.grid_x, triton_per_fused_add_cat_native_layer_norm_206_grid_266.grid_y, triton_per_fused_add_cat_native_layer_norm_206_grid_266.grid_z, 2, 8, kernel_args_var_266, stream);
    }
    auto buf670 = std::move(buf529);  // reuse
    // Topologically Sorted Source Nodes: [matmul_2], Original ATen: [aten.bmm]
    triton_poi_fused_bmm_197_xnumel = 7488L*s0;
    CUdeviceptr var_1339 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w.data_ptr());
    CUdeviceptr var_1340 = reinterpret_cast<CUdeviceptr>(buf670.data_ptr());
    int32_t var_1341 = triton_poi_fused_bmm_197_xnumel;
    void* kernel_args_var_267[] = {&var_1339, &var_1340, &var_1341};
    Grid triton_poi_fused_bmm_197_grid_267 = Grid((-1L)*static_cast<int64_t>(std::floor((-117.0/16.0)*s0)), 1L, 1L);
    if (triton_poi_fused_bmm_197_grid_267.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_bmm_197, triton_poi_fused_bmm_197_grid_267.grid_x, triton_poi_fused_bmm_197_grid_267.grid_y, triton_poi_fused_bmm_197_grid_267.grid_z, 4, 0, kernel_args_var_267, stream);
    }
    auto buf671 = std::move(buf530);  // reuse
    // Topologically Sorted Source Nodes: [matmul_2], Original ATen: [aten.bmm]
    triton_poi_fused_bmm_198_xnumel = 19968L*s0;
    CUdeviceptr var_1342 = reinterpret_cast<CUdeviceptr>(buf669.data_ptr());
    CUdeviceptr var_1343 = reinterpret_cast<CUdeviceptr>(buf671.data_ptr());
    int32_t var_1344 = triton_poi_fused_bmm_198_xnumel;
    void* kernel_args_var_268[] = {&var_1342, &var_1343, &var_1344};
    Grid triton_poi_fused_bmm_198_grid_268 = Grid((-1L)*static_cast<int64_t>(std::floor((-39.0/2.0)*s0)), 1L, 1L);
    if (triton_poi_fused_bmm_198_grid_268.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_bmm_198, triton_poi_fused_bmm_198_grid_268.grid_x, triton_poi_fused_bmm_198_grid_268.grid_y, triton_poi_fused_bmm_198_grid_268.grid_z, 4, 0, kernel_args_var_268, stream);
    }
    auto buf672 = std::move(buf535);  // reuse
    // Topologically Sorted Source Nodes: [matmul_2], Original ATen: [aten.bmm]
    CUdeviceptr var_1345 = reinterpret_cast<CUdeviceptr>(buf670.data_ptr());
    CUdeviceptr var_1346 = reinterpret_cast<CUdeviceptr>(buf671.data_ptr());
    CUdeviceptr var_1347 = reinterpret_cast<CUdeviceptr>(buf672.data_ptr());
    void* kernel_args_var_269[] = {&var_1345, &var_1346, &var_1347};
    Grid triton_tem_fused_bmm_199_grid_269 = Grid(2L, s0, 1L);
    if (triton_tem_fused_bmm_199_grid_269.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_199, triton_tem_fused_bmm_199_grid_269.grid_x, triton_tem_fused_bmm_199_grid_269.grid_y, triton_tem_fused_bmm_199_grid_269.grid_z, 4, 98304, kernel_args_var_269, stream);
    }
    buf670.reset();
    buf671.reset();
    auto buf676 = std::move(buf672);  // reuse
    // Topologically Sorted Source Nodes: [add_2453, layer_norm_106], Original ATen: [aten.add, aten.native_layer_norm]
    triton_per_fused_add_native_layer_norm_200_xnumel = 72L*s0;
    CUdeviceptr var_1348 = reinterpret_cast<CUdeviceptr>(buf676.data_ptr());
    CUdeviceptr var_1349 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b.data_ptr());
    CUdeviceptr var_1350 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w.data_ptr());
    CUdeviceptr var_1351 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b.data_ptr());
    int32_t var_1352 = triton_per_fused_add_native_layer_norm_200_xnumel;
    int var_1353 = 192L;
    void* kernel_args_var_270[] = {&var_1348, &var_1349, &var_1350, &var_1351, &var_1352, &var_1353};
    Grid triton_per_fused_add_native_layer_norm_200_grid_270 = Grid(72L*s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_200_grid_270.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_200, triton_per_fused_add_native_layer_norm_200_grid_270.grid_x, triton_per_fused_add_native_layer_norm_200_grid_270.grid_y, triton_per_fused_add_native_layer_norm_200_grid_270.grid_z, 2, 8, kernel_args_var_270, stream);
    }
    auto buf677 = std::move(buf654);  // reuse
    // Topologically Sorted Source Nodes: [linear_default_5], Original ATen: [aten.addmm]
    CUdeviceptr var_1354 = reinterpret_cast<CUdeviceptr>(buf676.data_ptr());
    CUdeviceptr var_1355 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_93.data_ptr());
    CUdeviceptr var_1356 = reinterpret_cast<CUdeviceptr>(buf677.data_ptr());
    int32_t var_1357 = s0;
    void* kernel_args_var_271[] = {&var_1354, &var_1355, &var_1356, &var_1357};
    Grid triton_tem_fused_addmm_201_grid_271 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_201_grid_271.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_201, triton_tem_fused_addmm_201_grid_271.grid_x, triton_tem_fused_addmm_201_grid_271.grid_y, triton_tem_fused_addmm_201_grid_271.grid_z, 4, 73728, kernel_args_var_271, stream);
    }
    auto buf692 = std::move(buf574);  // reuse
    // Topologically Sorted Source Nodes: [contiguous_14, layer_norm_107, sigmoid_25, mul_1907, layer_norm_109], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1358 = reinterpret_cast<CUdeviceptr>(buf677.data_ptr());
    CUdeviceptr var_1359 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_21.data_ptr());
    CUdeviceptr var_1360 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1361 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1362 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1363 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1364 = reinterpret_cast<CUdeviceptr>(buf692.data_ptr());
    int32_t var_1365 = s0;
    int var_1366 = 768L;
    void* kernel_args_var_272[] = {&var_1358, &var_1359, &var_1360, &var_1361, &var_1362, &var_1363, &var_1364, &var_1365, &var_1366};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_272 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_272.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_172, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_272.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_272.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_272.grid_z, 8, 32, kernel_args_var_272, stream);
    }
    auto buf697 = std::move(buf569);  // reuse
    // Topologically Sorted Source Nodes: [contiguous_15, layer_norm_108, sigmoid_26, mul_1912, layer_norm_110], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1367 = reinterpret_cast<CUdeviceptr>(buf677.data_ptr());
    CUdeviceptr var_1368 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_21.data_ptr());
    CUdeviceptr var_1369 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1370 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1371 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1372 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1373 = reinterpret_cast<CUdeviceptr>(buf697.data_ptr());
    int32_t var_1374 = s0;
    int var_1375 = 768L;
    void* kernel_args_var_273[] = {&var_1367, &var_1368, &var_1369, &var_1370, &var_1371, &var_1372, &var_1373, &var_1374, &var_1375};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_273 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_273.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_173, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_273.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_273.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_273.grid_z, 8, 32, kernel_args_var_273, stream);
    }
    auto buf693 = std::move(buf557);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_109, linear_91], Original ATen: [aten.native_layer_norm, aten.addmm]
    CUdeviceptr var_1376 = reinterpret_cast<CUdeviceptr>(buf692.data_ptr());
    CUdeviceptr var_1377 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_94.data_ptr());
    CUdeviceptr var_1378 = reinterpret_cast<CUdeviceptr>(buf693.data_ptr());
    int32_t var_1379 = s0;
    void* kernel_args_var_274[] = {&var_1376, &var_1377, &var_1378, &var_1379};
    Grid triton_tem_fused_addmm_native_layer_norm_174_grid_274 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_174_grid_274.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_174, triton_tem_fused_addmm_native_layer_norm_174_grid_274.grid_x, triton_tem_fused_addmm_native_layer_norm_174_grid_274.grid_y, triton_tem_fused_addmm_native_layer_norm_174_grid_274.grid_z, 8, 163840, kernel_args_var_274, stream);
    }
    auto buf710 = std::move(buf692);  // reuse
    // Topologically Sorted Source Nodes: [linear_91, layer_norm_111, sigmoid_27, mul_1929, layer_norm_113], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1380 = reinterpret_cast<CUdeviceptr>(buf693.data_ptr());
    CUdeviceptr var_1381 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias.data_ptr());
    CUdeviceptr var_1382 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1383 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias.data_ptr());
    CUdeviceptr var_1384 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w.data_ptr());
    CUdeviceptr var_1385 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b.data_ptr());
    CUdeviceptr var_1386 = reinterpret_cast<CUdeviceptr>(buf710.data_ptr());
    int32_t var_1387 = s0;
    int var_1388 = 768L;
    void* kernel_args_var_275[] = {&var_1380, &var_1381, &var_1382, &var_1383, &var_1384, &var_1385, &var_1386, &var_1387, &var_1388};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_275 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_275.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_275.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_275.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_275.grid_z, 8, 32, kernel_args_var_275, stream);
    }
    auto buf698 = std::move(buf693);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_110, linear_92], Original ATen: [aten.native_layer_norm, aten.addmm]
    CUdeviceptr var_1389 = reinterpret_cast<CUdeviceptr>(buf697.data_ptr());
    CUdeviceptr var_1390 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_95.data_ptr());
    CUdeviceptr var_1391 = reinterpret_cast<CUdeviceptr>(buf698.data_ptr());
    int32_t var_1392 = s0;
    void* kernel_args_var_276[] = {&var_1389, &var_1390, &var_1391, &var_1392};
    Grid triton_tem_fused_addmm_native_layer_norm_174_grid_276 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_174_grid_276.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_174, triton_tem_fused_addmm_native_layer_norm_174_grid_276.grid_x, triton_tem_fused_addmm_native_layer_norm_174_grid_276.grid_y, triton_tem_fused_addmm_native_layer_norm_174_grid_276.grid_z, 8, 163840, kernel_args_var_276, stream);
    }
    auto buf715 = std::move(buf697);  // reuse
    // Topologically Sorted Source Nodes: [linear_92, layer_norm_112, sigmoid_28, mul_1934, layer_norm_114], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1393 = reinterpret_cast<CUdeviceptr>(buf698.data_ptr());
    CUdeviceptr var_1394 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias.data_ptr());
    CUdeviceptr var_1395 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1396 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias.data_ptr());
    CUdeviceptr var_1397 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w.data_ptr());
    CUdeviceptr var_1398 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b.data_ptr());
    CUdeviceptr var_1399 = reinterpret_cast<CUdeviceptr>(buf715.data_ptr());
    int32_t var_1400 = s0;
    int var_1401 = 768L;
    void* kernel_args_var_277[] = {&var_1393, &var_1394, &var_1395, &var_1396, &var_1397, &var_1398, &var_1399, &var_1400, &var_1401};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_277 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_277.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_277.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_277.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_277.grid_z, 8, 32, kernel_args_var_277, stream);
    }
    auto buf711 = std::move(buf590);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf711, buf710, _FOLDED_CONST_permute_96));
    auto buf720 = std::move(buf711);  // reuse
    // Topologically Sorted Source Nodes: [linear_93, layer_norm_115], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1402 = reinterpret_cast<CUdeviceptr>(buf720.data_ptr());
    CUdeviceptr var_1403 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1404 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1405 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b.data_ptr());
    int32_t var_1406 = s0;
    int var_1407 = 4896L;
    void* kernel_args_var_278[] = {&var_1402, &var_1403, &var_1404, &var_1405, &var_1406, &var_1407};
    Grid triton_red_fused_addmm_native_layer_norm_202_grid_278 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addmm_native_layer_norm_202_grid_278.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_native_layer_norm_202, triton_red_fused_addmm_native_layer_norm_202_grid_278.grid_x, triton_red_fused_addmm_native_layer_norm_202_grid_278.grid_y, triton_red_fused_addmm_native_layer_norm_202_grid_278.grid_z, 16, 192, kernel_args_var_278, stream);
    }
    auto buf716 = std::move(buf664);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf716, buf715, _FOLDED_CONST_permute_97));
    auto buf717 = std::move(buf616);  // reuse
    auto buf718 = std::move(buf615);  // reuse
    // Topologically Sorted Source Nodes: [linear_94, layer_norm_116], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1408 = reinterpret_cast<CUdeviceptr>(buf716.data_ptr());
    CUdeviceptr var_1409 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1410 = reinterpret_cast<CUdeviceptr>(buf717.data_ptr());
    CUdeviceptr var_1411 = reinterpret_cast<CUdeviceptr>(buf718.data_ptr());
    int32_t var_1412 = s0;
    int var_1413 = 9216L;
    void* kernel_args_var_279[] = {&var_1408, &var_1409, &var_1410, &var_1411, &var_1412, &var_1413};
    Grid triton_red_fused_addmm_native_layer_norm_177_grid_279 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_native_layer_norm_177_grid_279.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_native_layer_norm_177, triton_red_fused_addmm_native_layer_norm_177_grid_279.grid_x, triton_red_fused_addmm_native_layer_norm_177_grid_279.grid_y, triton_red_fused_addmm_native_layer_norm_177_grid_279.grid_z, 16, 192, kernel_args_var_279, stream);
    }
    auto buf721 = std::move(buf580);  // reuse
    // Topologically Sorted Source Nodes: [bmm_4], Original ATen: [aten.bmm]
    CUdeviceptr var_1414 = reinterpret_cast<CUdeviceptr>(buf669.data_ptr());
    CUdeviceptr var_1415 = reinterpret_cast<CUdeviceptr>(buf720.data_ptr());
    CUdeviceptr var_1416 = reinterpret_cast<CUdeviceptr>(buf721.data_ptr());
    void* kernel_args_var_280[] = {&var_1414, &var_1415, &var_1416};
    Grid triton_tem_fused_bmm_203_grid_280 = Grid(3L, s0, 1L);
    if (triton_tem_fused_bmm_203_grid_280.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_203, triton_tem_fused_bmm_203_grid_280.grid_x, triton_tem_fused_bmm_203_grid_280.grid_y, triton_tem_fused_bmm_203_grid_280.grid_z, 4, 24576, kernel_args_var_280, stream);
    }
    auto tmp_tensor_handle_185 = reinterpret_tensor_wrapper(buf575, 3, int_array_87, int_array_88, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_185_raii(tmp_tensor_handle_185);
    decltype(auto) buf726 = std::move(tmp_tensor_handle_185_raii); buf575.reset();  // reuse
    // Topologically Sorted Source Nodes: [add_2564, layer_norm_117], Original ATen: [aten.add, aten.native_layer_norm]
    triton_per_fused_add_native_layer_norm_179_xnumel = 192L*s0;
    CUdeviceptr var_1417 = reinterpret_cast<CUdeviceptr>(buf716.data_ptr());
    CUdeviceptr var_1418 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1419 = reinterpret_cast<CUdeviceptr>(buf717.data_ptr());
    CUdeviceptr var_1420 = reinterpret_cast<CUdeviceptr>(buf718.data_ptr());
    CUdeviceptr var_1421 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1422 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1423 = reinterpret_cast<CUdeviceptr>(buf721.data_ptr());
    CUdeviceptr var_1424 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w.data_ptr());
    CUdeviceptr var_1425 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b.data_ptr());
    CUdeviceptr var_1426 = reinterpret_cast<CUdeviceptr>(buf726.data_ptr());
    int32_t var_1427 = triton_per_fused_add_native_layer_norm_179_xnumel;
    int var_1428 = 48L;
    void* kernel_args_var_281[] = {&var_1417, &var_1418, &var_1419, &var_1420, &var_1421, &var_1422, &var_1423, &var_1424, &var_1425, &var_1426, &var_1427, &var_1428};
    Grid triton_per_fused_add_native_layer_norm_179_grid_281 = Grid(6L*s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_179_grid_281.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_179, triton_per_fused_add_native_layer_norm_179_grid_281.grid_x, triton_per_fused_add_native_layer_norm_179_grid_281.grid_y, triton_per_fused_add_native_layer_norm_179_grid_281.grid_z, 8, 0, kernel_args_var_281, stream);
    }
    auto tmp_tensor_handle_186 = reinterpret_tensor_wrapper(buf720, 3, int_array_113, int_array_114, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_186_raii(tmp_tensor_handle_186);
    decltype(auto) buf727 = std::move(tmp_tensor_handle_186_raii); buf720.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_117, bmm_5], Original ATen: [aten.native_layer_norm, aten.bmm]
    CUdeviceptr var_1429 = reinterpret_cast<CUdeviceptr>(buf669.data_ptr());
    CUdeviceptr var_1430 = reinterpret_cast<CUdeviceptr>(buf726.data_ptr());
    CUdeviceptr var_1431 = reinterpret_cast<CUdeviceptr>(buf727.data_ptr());
    void* kernel_args_var_282[] = {&var_1429, &var_1430, &var_1431};
    Grid triton_tem_fused_bmm_native_layer_norm_204_grid_282 = Grid(1L, s0, 1L);
    if (triton_tem_fused_bmm_native_layer_norm_204_grid_282.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_native_layer_norm_204, triton_tem_fused_bmm_native_layer_norm_204_grid_282.grid_x, triton_tem_fused_bmm_native_layer_norm_204_grid_282.grid_y, triton_tem_fused_bmm_native_layer_norm_204_grid_282.grid_z, 4, 73728, kernel_args_var_282, stream);
    }
    auto tmp_tensor_handle_187 = reinterpret_tensor_wrapper(buf727, 2, int_array_111, int_array_112, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_187_raii(tmp_tensor_handle_187);
    decltype(auto) buf731 = std::move(tmp_tensor_handle_187_raii); buf727.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_118], Original ATen: [aten.native_layer_norm]
    CUdeviceptr var_1432 = reinterpret_cast<CUdeviceptr>(buf731.data_ptr());
    CUdeviceptr var_1433 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w.data_ptr());
    CUdeviceptr var_1434 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b.data_ptr());
    int32_t var_1435 = s0;
    int var_1436 = 4896L;
    void* kernel_args_var_283[] = {&var_1432, &var_1433, &var_1434, &var_1435, &var_1436};
    Grid triton_red_fused_native_layer_norm_205_grid_283 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_native_layer_norm_205_grid_283.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_native_layer_norm_205, triton_red_fused_native_layer_norm_205_grid_283.grid_x, triton_red_fused_native_layer_norm_205_grid_283.grid_y, triton_red_fused_native_layer_norm_205_grid_283.grid_z, 16, 16640, kernel_args_var_283, stream);
    }
    auto buf732 = std::move(buf591);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf732, buf731, _FOLDED_CONST_permute_98));
    auto buf736 = std::move(buf595);  // reuse
    auto buf737 = std::move(buf718);  // reuse
    auto buf738 = std::move(buf717);  // reuse
    // Topologically Sorted Source Nodes: [linear_95, layer_norm_119, sigmoid_29, mul_1978, layer_norm_120], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1437 = reinterpret_cast<CUdeviceptr>(buf732.data_ptr());
    CUdeviceptr var_1438 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1439 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1440 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1441 = reinterpret_cast<CUdeviceptr>(buf736.data_ptr());
    CUdeviceptr var_1442 = reinterpret_cast<CUdeviceptr>(buf737.data_ptr());
    CUdeviceptr var_1443 = reinterpret_cast<CUdeviceptr>(buf738.data_ptr());
    int32_t var_1444 = s0;
    int var_1445 = 2048L;
    void* kernel_args_var_284[] = {&var_1437, &var_1438, &var_1439, &var_1440, &var_1441, &var_1442, &var_1443, &var_1444, &var_1445};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_284 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_284.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_284.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_284.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_284.grid_z, 16, 192, kernel_args_var_284, stream);
    }
    auto buf740 = std::move(buf610);  // reuse
    auto buf744 = std::move(buf740);  // reuse
    // Topologically Sorted Source Nodes: [cat_default_2, layer_norm_121], Original ATen: [aten.cat, aten.native_layer_norm]
    CUdeviceptr var_1446 = reinterpret_cast<CUdeviceptr>(buf744.data_ptr());
    CUdeviceptr var_1447 = reinterpret_cast<CUdeviceptr>(buf457.data_ptr());
    CUdeviceptr var_1448 = reinterpret_cast<CUdeviceptr>(buf230.data_ptr());
    CUdeviceptr var_1449 = reinterpret_cast<CUdeviceptr>(buf736.data_ptr());
    CUdeviceptr var_1450 = reinterpret_cast<CUdeviceptr>(buf737.data_ptr());
    CUdeviceptr var_1451 = reinterpret_cast<CUdeviceptr>(buf738.data_ptr());
    CUdeviceptr var_1452 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1453 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1454 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w.data_ptr());
    CUdeviceptr var_1455 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b.data_ptr());
    int32_t var_1456 = s0;
    int var_1457 = 6354L;
    void* kernel_args_var_285[] = {&var_1446, &var_1447, &var_1448, &var_1449, &var_1450, &var_1451, &var_1452, &var_1453, &var_1454, &var_1455, &var_1456, &var_1457};
    Grid triton_red_fused_cat_native_layer_norm_183_grid_285 = Grid(s0, 1L, 1L);
    if (triton_red_fused_cat_native_layer_norm_183_grid_285.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_cat_native_layer_norm_183, triton_red_fused_cat_native_layer_norm_183_grid_285.grid_x, triton_red_fused_cat_native_layer_norm_183_grid_285.grid_y, triton_red_fused_cat_native_layer_norm_183_grid_285.grid_z, 8, 4096, kernel_args_var_285, stream);
    }
    auto buf745 = std::move(buf618);  // reuse
    // Topologically Sorted Source Nodes: [linear_96], Original ATen: [aten.addmm]
    triton_poi_fused_addmm_184_xnumel = 6360L*s0;
    CUdeviceptr var_1458 = reinterpret_cast<CUdeviceptr>(buf744.data_ptr());
    CUdeviceptr var_1459 = reinterpret_cast<CUdeviceptr>(buf745.data_ptr());
    int32_t var_1460 = triton_poi_fused_addmm_184_xnumel;
    void* kernel_args_var_286[] = {&var_1458, &var_1459, &var_1460};
    Grid triton_poi_fused_addmm_184_grid_286 = Grid((-1L)*static_cast<int64_t>(std::floor((-795.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_184_grid_286.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_184, triton_poi_fused_addmm_184_grid_286.grid_x, triton_poi_fused_addmm_184_grid_286.grid_y, triton_poi_fused_addmm_184_grid_286.grid_z, 8, 0, kernel_args_var_286, stream);
    }
    auto buf746 = std::move(buf609);  // reuse
    // Topologically Sorted Source Nodes: [linear_96], Original ATen: [aten.addmm]
    CUdeviceptr var_1461 = reinterpret_cast<CUdeviceptr>(buf745.data_ptr());
    CUdeviceptr var_1462 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_constant_pad_nd_default_7.data_ptr());
    CUdeviceptr var_1463 = reinterpret_cast<CUdeviceptr>(buf746.data_ptr());
    int32_t var_1464 = s0;
    void* kernel_args_var_287[] = {&var_1461, &var_1462, &var_1463, &var_1464};
    Grid triton_tem_fused_addmm_185_grid_287 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_185_grid_287.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_185, triton_tem_fused_addmm_185_grid_287.grid_x, triton_tem_fused_addmm_185_grid_287.grid_y, triton_tem_fused_addmm_185_grid_287.grid_z, 4, 196608, kernel_args_var_287, stream);
    }
    auto buf750 = std::move(buf746);  // reuse
    // Topologically Sorted Source Nodes: [linear_96, layer_norm_122], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1465 = reinterpret_cast<CUdeviceptr>(buf750.data_ptr());
    CUdeviceptr var_1466 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1467 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1468 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b.data_ptr());
    int32_t var_1469 = s0;
    int var_1470 = 384L;
    void* kernel_args_var_288[] = {&var_1465, &var_1466, &var_1467, &var_1468, &var_1469, &var_1470};
    Grid triton_per_fused_addmm_native_layer_norm_186_grid_288 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_186_grid_288.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_186, triton_per_fused_addmm_native_layer_norm_186_grid_288.grid_x, triton_per_fused_addmm_native_layer_norm_186_grid_288.grid_y, triton_per_fused_addmm_native_layer_norm_186_grid_288.grid_z, 4, 16, kernel_args_var_288, stream);
    }
    auto buf751 = std::move(buf603);  // reuse
    // Topologically Sorted Source Nodes: [linear_96, layer_norm_122, linear_97], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1471 = reinterpret_cast<CUdeviceptr>(buf750.data_ptr());
    CUdeviceptr var_1472 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_100.data_ptr());
    CUdeviceptr var_1473 = reinterpret_cast<CUdeviceptr>(buf751.data_ptr());
    int32_t var_1474 = s0;
    void* kernel_args_var_289[] = {&var_1471, &var_1472, &var_1473, &var_1474};
    Grid triton_tem_fused_addmm_native_layer_norm_187_grid_289 = Grid(50L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_187_grid_289.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_187, triton_tem_fused_addmm_native_layer_norm_187_grid_289.grid_x, triton_tem_fused_addmm_native_layer_norm_187_grid_289.grid_y, triton_tem_fused_addmm_native_layer_norm_187_grid_289.grid_z, 4, 49152, kernel_args_var_289, stream);
    }
    auto buf755 = std::move(buf614);  // reuse
    auto buf756 = std::move(buf738);  // reuse
    auto buf757 = std::move(buf737);  // reuse
    // Topologically Sorted Source Nodes: [linear_97, layer_norm_123, addcmul_2, layer_norm_124], Original ATen: [aten.addmm, aten.native_layer_norm, aten.addcmul]
    CUdeviceptr var_1475 = reinterpret_cast<CUdeviceptr>(buf751.data_ptr());
    CUdeviceptr var_1476 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1477 = reinterpret_cast<CUdeviceptr>(buf744.data_ptr());
    CUdeviceptr var_1478 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1479 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1480 = reinterpret_cast<CUdeviceptr>(buf755.data_ptr());
    CUdeviceptr var_1481 = reinterpret_cast<CUdeviceptr>(buf756.data_ptr());
    CUdeviceptr var_1482 = reinterpret_cast<CUdeviceptr>(buf757.data_ptr());
    int32_t var_1483 = s0;
    int var_1484 = 6354L;
    void* kernel_args_var_290[] = {&var_1475, &var_1476, &var_1477, &var_1478, &var_1479, &var_1480, &var_1481, &var_1482, &var_1483, &var_1484};
    Grid triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_290 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_290.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addcmul_addmm_native_layer_norm_188, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_290.grid_x, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_290.grid_y, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_290.grid_z, 8, 96, kernel_args_var_290, stream);
    }
    auto buf759 = std::move(buf745);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_124, linear_98], Original ATen: [aten.native_layer_norm, aten.addmm]
    triton_poi_fused_addmm_native_layer_norm_189_xnumel = 6360L*s0;
    CUdeviceptr var_1485 = reinterpret_cast<CUdeviceptr>(buf755.data_ptr());
    CUdeviceptr var_1486 = reinterpret_cast<CUdeviceptr>(buf756.data_ptr());
    CUdeviceptr var_1487 = reinterpret_cast<CUdeviceptr>(buf757.data_ptr());
    CUdeviceptr var_1488 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w.data_ptr());
    CUdeviceptr var_1489 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b.data_ptr());
    CUdeviceptr var_1490 = reinterpret_cast<CUdeviceptr>(buf759.data_ptr());
    int32_t var_1491 = triton_poi_fused_addmm_native_layer_norm_189_xnumel;
    void* kernel_args_var_291[] = {&var_1485, &var_1486, &var_1487, &var_1488, &var_1489, &var_1490, &var_1491};
    Grid triton_poi_fused_addmm_native_layer_norm_189_grid_291 = Grid((-1L)*static_cast<int64_t>(std::floor((-795.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_native_layer_norm_189_grid_291.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_native_layer_norm_189, triton_poi_fused_addmm_native_layer_norm_189_grid_291.grid_x, triton_poi_fused_addmm_native_layer_norm_189_grid_291.grid_y, triton_poi_fused_addmm_native_layer_norm_189_grid_291.grid_z, 8, 0, kernel_args_var_291, stream);
    }
    auto buf760 = std::move(buf663);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf760, buf759, _FOLDED_CONST_constant_pad_nd_default_5));
    auto buf764 = std::move(buf623);  // reuse
    auto buf768 = std::move(buf655);  // reuse
    // Topologically Sorted Source Nodes: [linear_98, layer_norm_125, sigmoid_30, mul_2005, layer_norm_126], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1492 = reinterpret_cast<CUdeviceptr>(buf760.data_ptr());
    CUdeviceptr var_1493 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1494 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1495 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1496 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1497 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1498 = reinterpret_cast<CUdeviceptr>(buf764.data_ptr());
    CUdeviceptr var_1499 = reinterpret_cast<CUdeviceptr>(buf768.data_ptr());
    int32_t var_1500 = s0;
    int var_1501 = 3072L;
    void* kernel_args_var_292[] = {&var_1492, &var_1493, &var_1494, &var_1495, &var_1496, &var_1497, &var_1498, &var_1499, &var_1500, &var_1501};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_292 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_292.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_292.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_292.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_292.grid_z, 8, 96, kernel_args_var_292, stream);
    }
    auto buf769 = std::move(buf677);  // reuse
    // Topologically Sorted Source Nodes: [linear_99], Original ATen: [aten.addmm]
    CUdeviceptr var_1502 = reinterpret_cast<CUdeviceptr>(buf768.data_ptr());
    CUdeviceptr var_1503 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_102.data_ptr());
    CUdeviceptr var_1504 = reinterpret_cast<CUdeviceptr>(buf769.data_ptr());
    int32_t var_1505 = s0;
    void* kernel_args_var_293[] = {&var_1502, &var_1503, &var_1504, &var_1505};
    Grid triton_tem_fused_addmm_191_grid_293 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_191_grid_293.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_191, triton_tem_fused_addmm_191_grid_293.grid_x, triton_tem_fused_addmm_191_grid_293.grid_y, triton_tem_fused_addmm_191_grid_293.grid_z, 4, 73728, kernel_args_var_293, stream);
    }
    auto buf773 = std::move(buf650);  // reuse
    auto buf777 = std::move(buf646);  // reuse
    // Topologically Sorted Source Nodes: [linear_99, layer_norm_127, sigmoid_31, mul_2016, layer_norm_128], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1506 = reinterpret_cast<CUdeviceptr>(buf769.data_ptr());
    CUdeviceptr var_1507 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1508 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1509 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1510 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1511 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1512 = reinterpret_cast<CUdeviceptr>(buf773.data_ptr());
    CUdeviceptr var_1513 = reinterpret_cast<CUdeviceptr>(buf777.data_ptr());
    int32_t var_1514 = s0;
    int var_1515 = 1536L;
    void* kernel_args_var_294[] = {&var_1506, &var_1507, &var_1508, &var_1509, &var_1510, &var_1511, &var_1512, &var_1513, &var_1514, &var_1515};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_294 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_294.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_294.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_294.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_294.grid_z, 16, 192, kernel_args_var_294, stream);
    }
    auto buf778 = std::move(buf760);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf778, buf777, _FOLDED_CONST_permute_103));
    auto buf782 = std::move(buf778);  // reuse
    auto buf786 = std::move(buf782);  // reuse
    // Topologically Sorted Source Nodes: [linear_100, layer_norm_129, add_2658, layer_norm_130, sigmoid_32, mul_2031], Original ATen: [aten.addmm, aten.native_layer_norm, aten.add, aten.sigmoid, aten.mul]
    CUdeviceptr var_1516 = reinterpret_cast<CUdeviceptr>(buf786.data_ptr());
    CUdeviceptr var_1517 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1518 = reinterpret_cast<CUdeviceptr>(buf768.data_ptr());
    CUdeviceptr var_1519 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1520 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1521 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight.data_ptr());
    CUdeviceptr var_1522 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias.data_ptr());
    int32_t var_1523 = s0;
    int var_1524 = 3072L;
    void* kernel_args_var_295[] = {&var_1516, &var_1517, &var_1518, &var_1519, &var_1520, &var_1521, &var_1522, &var_1523, &var_1524};
    Grid triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_295 = Grid(s0, 1L, 1L);
    if (triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_295.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_295.grid_x, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_295.grid_y, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_295.grid_z, 8, 96, kernel_args_var_295, stream);
    }
    auto buf787 = std::move(buf777);  // reuse
    // Topologically Sorted Source Nodes: [linear_101], Original ATen: [aten.addmm]
    CUdeviceptr var_1525 = reinterpret_cast<CUdeviceptr>(buf786.data_ptr());
    CUdeviceptr var_1526 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_104.data_ptr());
    CUdeviceptr var_1527 = reinterpret_cast<CUdeviceptr>(buf787.data_ptr());
    int32_t var_1528 = s0;
    void* kernel_args_var_296[] = {&var_1525, &var_1526, &var_1527, &var_1528};
    Grid triton_tem_fused_addmm_191_grid_296 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_191_grid_296.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_191, triton_tem_fused_addmm_191_grid_296.grid_x, triton_tem_fused_addmm_191_grid_296.grid_y, triton_tem_fused_addmm_191_grid_296.grid_z, 4, 73728, kernel_args_var_296, stream);
    }
    auto buf791 = std::move(buf773);  // reuse
    auto buf795 = std::move(buf769);  // reuse
    // Topologically Sorted Source Nodes: [linear_101, layer_norm_131, sigmoid_33, mul_2042, layer_norm_132], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1529 = reinterpret_cast<CUdeviceptr>(buf787.data_ptr());
    CUdeviceptr var_1530 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1531 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1532 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1533 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1534 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1535 = reinterpret_cast<CUdeviceptr>(buf791.data_ptr());
    CUdeviceptr var_1536 = reinterpret_cast<CUdeviceptr>(buf795.data_ptr());
    int32_t var_1537 = s0;
    int var_1538 = 1536L;
    void* kernel_args_var_297[] = {&var_1529, &var_1530, &var_1531, &var_1532, &var_1533, &var_1534, &var_1535, &var_1536, &var_1537, &var_1538};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_297 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_297.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_297.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_297.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_297.grid_z, 16, 192, kernel_args_var_297, stream);
    }
    auto buf796 = std::move(buf645);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf796, buf795, _FOLDED_CONST_permute_105));
    auto buf800 = std::move(buf768);  // reuse
    auto buf804 = std::move(buf800);  // reuse
    // Topologically Sorted Source Nodes: [linear_102, layer_norm_133, add_2671, add_2696, layer_norm_134, sigmoid_34, mul_2057], Original ATen: [aten.addmm, aten.native_layer_norm, aten.add, aten.sigmoid, aten.mul]
    CUdeviceptr var_1539 = reinterpret_cast<CUdeviceptr>(buf804.data_ptr());
    CUdeviceptr var_1540 = reinterpret_cast<CUdeviceptr>(buf796.data_ptr());
    CUdeviceptr var_1541 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1542 = reinterpret_cast<CUdeviceptr>(buf786.data_ptr());
    CUdeviceptr var_1543 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1544 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1545 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1546 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias.data_ptr());
    int32_t var_1547 = s0;
    int var_1548 = 3072L;
    void* kernel_args_var_298[] = {&var_1539, &var_1540, &var_1541, &var_1542, &var_1543, &var_1544, &var_1545, &var_1546, &var_1547, &var_1548};
    Grid triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_298 = Grid(s0, 1L, 1L);
    if (triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_298.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_298.grid_x, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_298.grid_y, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_298.grid_z, 8, 96, kernel_args_var_298, stream);
    }
    auto tmp_tensor_handle_188 = reinterpret_tensor_wrapper(buf726, 2, int_array_83, int_array_84, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_188_raii(tmp_tensor_handle_188);
    decltype(auto) buf805 = std::move(tmp_tensor_handle_188_raii); buf726.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_134, sigmoid_34, mul_2057, linear_103], Original ATen: [aten.native_layer_norm, aten.sigmoid, aten.mul, aten.addmm]
    CUdeviceptr var_1549 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1550 = reinterpret_cast<CUdeviceptr>(buf804.data_ptr());
    CUdeviceptr var_1551 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_106.data_ptr());
    CUdeviceptr var_1552 = reinterpret_cast<CUdeviceptr>(buf805.data_ptr());
    int32_t var_1553 = s0;
    void* kernel_args_var_299[] = {&var_1549, &var_1550, &var_1551, &var_1552, &var_1553};
    Grid triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_299 = Grid(72L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_299.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_299.grid_x, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_299.grid_y, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_195_grid_299.grid_z, 4, 98304, kernel_args_var_299, stream);
    }
    auto tmp_tensor_handle_189 = reinterpret_tensor_wrapper(buf528, 2, int_array_101, int_array_102, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_189_raii(tmp_tensor_handle_189);
    decltype(auto) buf806 = std::move(tmp_tensor_handle_189_raii); buf528.reset();  // reuse
    auto tmp_tensor_handle_190 = reinterpret_tensor_wrapper(buf806, 3, int_array_103, int_array_104, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_190_raii(tmp_tensor_handle_190);
    decltype(auto) buf810 = std::move(tmp_tensor_handle_190_raii); buf806.reset();  // reuse
    // Topologically Sorted Source Nodes: [cat_default_1, add_2719, layer_norm_135], Original ATen: [aten.cat, aten.add, aten.native_layer_norm]
    triton_per_fused_add_cat_native_layer_norm_206_xnumel = 102L*s0;
    CUdeviceptr var_1554 = reinterpret_cast<CUdeviceptr>(buf810.data_ptr());
    CUdeviceptr var_1555 = reinterpret_cast<CUdeviceptr>(buf344.data_ptr());
    CUdeviceptr var_1556 = reinterpret_cast<CUdeviceptr>(buf345.data_ptr());
    CUdeviceptr var_1557 = reinterpret_cast<CUdeviceptr>(buf346.data_ptr());
    CUdeviceptr var_1558 = reinterpret_cast<CUdeviceptr>(buf347.data_ptr());
    CUdeviceptr var_1559 = reinterpret_cast<CUdeviceptr>(buf348.data_ptr());
    CUdeviceptr var_1560 = reinterpret_cast<CUdeviceptr>(buf349.data_ptr());
    CUdeviceptr var_1561 = reinterpret_cast<CUdeviceptr>(buf676.data_ptr());
    CUdeviceptr var_1562 = reinterpret_cast<CUdeviceptr>(buf805.data_ptr());
    CUdeviceptr var_1563 = reinterpret_cast<CUdeviceptr>(buf669.data_ptr());
    CUdeviceptr var_1564 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w.data_ptr());
    CUdeviceptr var_1565 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b.data_ptr());
    int32_t var_1566 = triton_per_fused_add_cat_native_layer_norm_206_xnumel;
    int var_1567 = 192L;
    void* kernel_args_var_300[] = {&var_1554, &var_1555, &var_1556, &var_1557, &var_1558, &var_1559, &var_1560, &var_1561, &var_1562, &var_1563, &var_1564, &var_1565, &var_1566, &var_1567};
    Grid triton_per_fused_add_cat_native_layer_norm_206_grid_300 = Grid(102L*s0, 1L, 1L);
    if (triton_per_fused_add_cat_native_layer_norm_206_grid_300.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_cat_native_layer_norm_206, triton_per_fused_add_cat_native_layer_norm_206_grid_300.grid_x, triton_per_fused_add_cat_native_layer_norm_206_grid_300.grid_y, triton_per_fused_add_cat_native_layer_norm_206_grid_300.grid_z, 2, 8, kernel_args_var_300, stream);
    }
    buf344.reset();
    buf345.reset();
    buf346.reset();
    buf347.reset();
    buf348.reset();
    buf349.reset();
    buf388.reset();
    buf669.reset();
    buf676.reset();
    const int64_t int_array_115[] = {s0, 24L, 192L};
    static constexpr int64_t int_array_116[] = {4608L, 192L, 1L};
    AtenTensorHandle buf811_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(3, int_array_115, int_array_116, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf811_handle));
    RAIIAtenTensorHandle buf811(buf811_handle);
    // Topologically Sorted Source Nodes: [matmul_3], Original ATen: [aten.bmm]
    if (kernels.triton_tem_fused_bmm_207 == nullptr) {
        kernels.triton_tem_fused_bmm_207 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c25t6nwj7zionfnytb62bcg7vnluj3b3gdaut4ta2uif4abbzpry.cubin", "triton_tem_fused_bmm_207", 40960, this->cubin_dir_);
    }
    CUdeviceptr var_1568 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w.data_ptr());
    CUdeviceptr var_1569 = reinterpret_cast<CUdeviceptr>(buf810.data_ptr());
    CUdeviceptr var_1570 = reinterpret_cast<CUdeviceptr>(buf811.data_ptr());
    void* kernel_args_var_301[] = {&var_1568, &var_1569, &var_1570};
    Grid triton_tem_fused_bmm_207_grid_301 = Grid(2L, s0, 1L);
    if (triton_tem_fused_bmm_207_grid_301.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_207, triton_tem_fused_bmm_207_grid_301.grid_x, triton_tem_fused_bmm_207_grid_301.grid_y, triton_tem_fused_bmm_207_grid_301.grid_z, 4, 40960, kernel_args_var_301, stream);
    }
    auto buf815 = std::move(buf811);  // reuse
    // Topologically Sorted Source Nodes: [add_2732, layer_norm_136], Original ATen: [aten.add, aten.native_layer_norm]
    int64_t triton_per_fused_add_native_layer_norm_208_xnumel = 24L*s0;
    if (kernels.triton_per_fused_add_native_layer_norm_208 == nullptr) {
        kernels.triton_per_fused_add_native_layer_norm_208 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cdasd2jteawvnsl4mhpskztehnvljysbz2l3k6chfww6kz5jeyee.cubin", "triton_per_fused_add_native_layer_norm_208", 8, this->cubin_dir_);
    }
    CUdeviceptr var_1571 = reinterpret_cast<CUdeviceptr>(buf815.data_ptr());
    CUdeviceptr var_1572 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b.data_ptr());
    CUdeviceptr var_1573 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w.data_ptr());
    CUdeviceptr var_1574 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b.data_ptr());
    int32_t var_1575 = triton_per_fused_add_native_layer_norm_208_xnumel;
    int var_1576 = 192L;
    void* kernel_args_var_302[] = {&var_1571, &var_1572, &var_1573, &var_1574, &var_1575, &var_1576};
    Grid triton_per_fused_add_native_layer_norm_208_grid_302 = Grid(24L*s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_208_grid_302.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_208, triton_per_fused_add_native_layer_norm_208_grid_302.grid_x, triton_per_fused_add_native_layer_norm_208_grid_302.grid_y, triton_per_fused_add_native_layer_norm_208_grid_302.grid_z, 2, 8, kernel_args_var_302, stream);
    }
    auto buf816 = std::move(buf795);  // reuse
    // Topologically Sorted Source Nodes: [linear_default_6], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_209 == nullptr) {
        kernels.triton_tem_fused_addmm_209 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ckvd5ibwpq5l3nxm734scfi43v5tsah2uuctz7dbopo4lfec5zgk.cubin", "triton_tem_fused_addmm_209", 73728, this->cubin_dir_);
    }
    CUdeviceptr var_1577 = reinterpret_cast<CUdeviceptr>(buf815.data_ptr());
    CUdeviceptr var_1578 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_108.data_ptr());
    CUdeviceptr var_1579 = reinterpret_cast<CUdeviceptr>(buf816.data_ptr());
    int32_t var_1580 = s0;
    void* kernel_args_var_303[] = {&var_1577, &var_1578, &var_1579, &var_1580};
    Grid triton_tem_fused_addmm_209_grid_303 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_209_grid_303.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_209, triton_tem_fused_addmm_209_grid_303.grid_x, triton_tem_fused_addmm_209_grid_303.grid_y, triton_tem_fused_addmm_209_grid_303.grid_z, 4, 73728, kernel_args_var_303, stream);
    }
    buf815.reset();
    auto buf831 = std::move(buf715);  // reuse
    // Topologically Sorted Source Nodes: [contiguous_16, layer_norm_137, sigmoid_35, mul_2095, layer_norm_139], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1581 = reinterpret_cast<CUdeviceptr>(buf816.data_ptr());
    CUdeviceptr var_1582 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_25.data_ptr());
    CUdeviceptr var_1583 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1584 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1585 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1586 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1587 = reinterpret_cast<CUdeviceptr>(buf831.data_ptr());
    int32_t var_1588 = s0;
    int var_1589 = 768L;
    void* kernel_args_var_304[] = {&var_1581, &var_1582, &var_1583, &var_1584, &var_1585, &var_1586, &var_1587, &var_1588, &var_1589};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_304 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_304.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_172, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_304.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_304.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_172_grid_304.grid_z, 8, 32, kernel_args_var_304, stream);
    }
    auto buf836 = std::move(buf710);  // reuse
    // Topologically Sorted Source Nodes: [contiguous_17, layer_norm_138, sigmoid_36, mul_2100, layer_norm_140], Original ATen: [aten.clone, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1590 = reinterpret_cast<CUdeviceptr>(buf816.data_ptr());
    CUdeviceptr var_1591 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_cat_25.data_ptr());
    CUdeviceptr var_1592 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1593 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1594 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1595 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1596 = reinterpret_cast<CUdeviceptr>(buf836.data_ptr());
    int32_t var_1597 = s0;
    int var_1598 = 768L;
    void* kernel_args_var_305[] = {&var_1590, &var_1591, &var_1592, &var_1593, &var_1594, &var_1595, &var_1596, &var_1597, &var_1598};
    Grid triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_305 = Grid(s0, 1L, 1L);
    if (triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_305.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_clone_mul_native_layer_norm_sigmoid_173, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_305.grid_x, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_305.grid_y, triton_per_fused_clone_mul_native_layer_norm_sigmoid_173_grid_305.grid_z, 8, 32, kernel_args_var_305, stream);
    }
    auto buf832 = std::move(buf698);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_139, linear_106], Original ATen: [aten.native_layer_norm, aten.addmm]
    CUdeviceptr var_1599 = reinterpret_cast<CUdeviceptr>(buf831.data_ptr());
    CUdeviceptr var_1600 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_109.data_ptr());
    CUdeviceptr var_1601 = reinterpret_cast<CUdeviceptr>(buf832.data_ptr());
    int32_t var_1602 = s0;
    void* kernel_args_var_306[] = {&var_1599, &var_1600, &var_1601, &var_1602};
    Grid triton_tem_fused_addmm_native_layer_norm_174_grid_306 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_174_grid_306.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_174, triton_tem_fused_addmm_native_layer_norm_174_grid_306.grid_x, triton_tem_fused_addmm_native_layer_norm_174_grid_306.grid_y, triton_tem_fused_addmm_native_layer_norm_174_grid_306.grid_z, 8, 163840, kernel_args_var_306, stream);
    }
    auto buf849 = std::move(buf831);  // reuse
    // Topologically Sorted Source Nodes: [linear_106, layer_norm_141, sigmoid_37, mul_2117, layer_norm_143], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1603 = reinterpret_cast<CUdeviceptr>(buf832.data_ptr());
    CUdeviceptr var_1604 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias.data_ptr());
    CUdeviceptr var_1605 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1606 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias.data_ptr());
    CUdeviceptr var_1607 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w.data_ptr());
    CUdeviceptr var_1608 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b.data_ptr());
    CUdeviceptr var_1609 = reinterpret_cast<CUdeviceptr>(buf849.data_ptr());
    int32_t var_1610 = s0;
    int var_1611 = 768L;
    void* kernel_args_var_307[] = {&var_1603, &var_1604, &var_1605, &var_1606, &var_1607, &var_1608, &var_1609, &var_1610, &var_1611};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_307 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_307.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_307.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_307.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_307.grid_z, 8, 32, kernel_args_var_307, stream);
    }
    auto buf837 = std::move(buf832);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_140, linear_107], Original ATen: [aten.native_layer_norm, aten.addmm]
    CUdeviceptr var_1612 = reinterpret_cast<CUdeviceptr>(buf836.data_ptr());
    CUdeviceptr var_1613 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_110.data_ptr());
    CUdeviceptr var_1614 = reinterpret_cast<CUdeviceptr>(buf837.data_ptr());
    int32_t var_1615 = s0;
    void* kernel_args_var_308[] = {&var_1612, &var_1613, &var_1614, &var_1615};
    Grid triton_tem_fused_addmm_native_layer_norm_174_grid_308 = Grid(6L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_174_grid_308.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_174, triton_tem_fused_addmm_native_layer_norm_174_grid_308.grid_x, triton_tem_fused_addmm_native_layer_norm_174_grid_308.grid_y, triton_tem_fused_addmm_native_layer_norm_174_grid_308.grid_z, 8, 163840, kernel_args_var_308, stream);
    }
    auto buf854 = std::move(buf836);  // reuse
    // Topologically Sorted Source Nodes: [linear_107, layer_norm_142, sigmoid_38, mul_2122, layer_norm_144], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1616 = reinterpret_cast<CUdeviceptr>(buf837.data_ptr());
    CUdeviceptr var_1617 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias.data_ptr());
    CUdeviceptr var_1618 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1619 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias.data_ptr());
    CUdeviceptr var_1620 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w.data_ptr());
    CUdeviceptr var_1621 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b.data_ptr());
    CUdeviceptr var_1622 = reinterpret_cast<CUdeviceptr>(buf854.data_ptr());
    int32_t var_1623 = s0;
    int var_1624 = 768L;
    void* kernel_args_var_309[] = {&var_1616, &var_1617, &var_1618, &var_1619, &var_1620, &var_1621, &var_1622, &var_1623, &var_1624};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_309 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_309.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_309.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_309.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_175_grid_309.grid_z, 8, 32, kernel_args_var_309, stream);
    }
    buf837.reset();
    auto buf850 = std::move(buf731);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf850, buf849, _FOLDED_CONST_permute_111));
    buf849.reset();
    auto buf859 = std::move(buf850);  // reuse
    // Topologically Sorted Source Nodes: [linear_108, layer_norm_145], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1625 = reinterpret_cast<CUdeviceptr>(buf859.data_ptr());
    CUdeviceptr var_1626 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1627 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1628 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b.data_ptr());
    int32_t var_1629 = s0;
    int var_1630 = 4896L;
    void* kernel_args_var_310[] = {&var_1625, &var_1626, &var_1627, &var_1628, &var_1629, &var_1630};
    Grid triton_red_fused_addmm_native_layer_norm_202_grid_310 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addmm_native_layer_norm_202_grid_310.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_native_layer_norm_202, triton_red_fused_addmm_native_layer_norm_202_grid_310.grid_x, triton_red_fused_addmm_native_layer_norm_202_grid_310.grid_y, triton_red_fused_addmm_native_layer_norm_202_grid_310.grid_z, 16, 192, kernel_args_var_310, stream);
    }
    auto buf855 = std::move(buf805);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf855, buf854, _FOLDED_CONST_permute_112));
    buf854.reset();
    auto buf856 = std::move(buf757);  // reuse
    auto buf857 = std::move(buf756);  // reuse
    // Topologically Sorted Source Nodes: [linear_109, layer_norm_146], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1631 = reinterpret_cast<CUdeviceptr>(buf855.data_ptr());
    CUdeviceptr var_1632 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1633 = reinterpret_cast<CUdeviceptr>(buf856.data_ptr());
    CUdeviceptr var_1634 = reinterpret_cast<CUdeviceptr>(buf857.data_ptr());
    int32_t var_1635 = s0;
    int var_1636 = 9216L;
    void* kernel_args_var_311[] = {&var_1631, &var_1632, &var_1633, &var_1634, &var_1635, &var_1636};
    Grid triton_red_fused_addmm_native_layer_norm_177_grid_311 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_native_layer_norm_177_grid_311.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_native_layer_norm_177, triton_red_fused_addmm_native_layer_norm_177_grid_311.grid_x, triton_red_fused_addmm_native_layer_norm_177_grid_311.grid_y, triton_red_fused_addmm_native_layer_norm_177_grid_311.grid_z, 16, 192, kernel_args_var_311, stream);
    }
    auto buf860 = std::move(buf721);  // reuse
    // Topologically Sorted Source Nodes: [bmm_6], Original ATen: [aten.bmm]
    CUdeviceptr var_1637 = reinterpret_cast<CUdeviceptr>(buf810.data_ptr());
    CUdeviceptr var_1638 = reinterpret_cast<CUdeviceptr>(buf859.data_ptr());
    CUdeviceptr var_1639 = reinterpret_cast<CUdeviceptr>(buf860.data_ptr());
    void* kernel_args_var_312[] = {&var_1637, &var_1638, &var_1639};
    Grid triton_tem_fused_bmm_203_grid_312 = Grid(3L, s0, 1L);
    if (triton_tem_fused_bmm_203_grid_312.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_203, triton_tem_fused_bmm_203_grid_312.grid_x, triton_tem_fused_bmm_203_grid_312.grid_y, triton_tem_fused_bmm_203_grid_312.grid_z, 4, 24576, kernel_args_var_312, stream);
    }
    auto tmp_tensor_handle_191 = reinterpret_tensor_wrapper(buf716, 3, int_array_87, int_array_88, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_191_raii(tmp_tensor_handle_191);
    decltype(auto) buf865 = std::move(tmp_tensor_handle_191_raii); buf716.reset();  // reuse
    // Topologically Sorted Source Nodes: [add_2832, layer_norm_147], Original ATen: [aten.add, aten.native_layer_norm]
    triton_per_fused_add_native_layer_norm_179_xnumel = 192L*s0;
    CUdeviceptr var_1640 = reinterpret_cast<CUdeviceptr>(buf855.data_ptr());
    CUdeviceptr var_1641 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1642 = reinterpret_cast<CUdeviceptr>(buf856.data_ptr());
    CUdeviceptr var_1643 = reinterpret_cast<CUdeviceptr>(buf857.data_ptr());
    CUdeviceptr var_1644 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1645 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1646 = reinterpret_cast<CUdeviceptr>(buf860.data_ptr());
    CUdeviceptr var_1647 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w.data_ptr());
    CUdeviceptr var_1648 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b.data_ptr());
    CUdeviceptr var_1649 = reinterpret_cast<CUdeviceptr>(buf865.data_ptr());
    int32_t var_1650 = triton_per_fused_add_native_layer_norm_179_xnumel;
    int var_1651 = 48L;
    void* kernel_args_var_313[] = {&var_1640, &var_1641, &var_1642, &var_1643, &var_1644, &var_1645, &var_1646, &var_1647, &var_1648, &var_1649, &var_1650, &var_1651};
    Grid triton_per_fused_add_native_layer_norm_179_grid_313 = Grid(6L*s0, 1L, 1L);
    if (triton_per_fused_add_native_layer_norm_179_grid_313.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_add_native_layer_norm_179, triton_per_fused_add_native_layer_norm_179_grid_313.grid_x, triton_per_fused_add_native_layer_norm_179_grid_313.grid_y, triton_per_fused_add_native_layer_norm_179_grid_313.grid_z, 8, 0, kernel_args_var_313, stream);
    }
    buf855.reset();
    buf860.reset();
    auto tmp_tensor_handle_192 = reinterpret_tensor_wrapper(buf859, 3, int_array_113, int_array_114, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_192_raii(tmp_tensor_handle_192);
    decltype(auto) buf866 = std::move(tmp_tensor_handle_192_raii); buf859.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_147, bmm_7], Original ATen: [aten.native_layer_norm, aten.bmm]
    CUdeviceptr var_1652 = reinterpret_cast<CUdeviceptr>(buf810.data_ptr());
    CUdeviceptr var_1653 = reinterpret_cast<CUdeviceptr>(buf865.data_ptr());
    CUdeviceptr var_1654 = reinterpret_cast<CUdeviceptr>(buf866.data_ptr());
    void* kernel_args_var_314[] = {&var_1652, &var_1653, &var_1654};
    Grid triton_tem_fused_bmm_native_layer_norm_204_grid_314 = Grid(1L, s0, 1L);
    if (triton_tem_fused_bmm_native_layer_norm_204_grid_314.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_bmm_native_layer_norm_204, triton_tem_fused_bmm_native_layer_norm_204_grid_314.grid_x, triton_tem_fused_bmm_native_layer_norm_204_grid_314.grid_y, triton_tem_fused_bmm_native_layer_norm_204_grid_314.grid_z, 4, 73728, kernel_args_var_314, stream);
    }
    buf810.reset();
    buf865.reset();
    auto tmp_tensor_handle_193 = reinterpret_tensor_wrapper(buf866, 2, int_array_111, int_array_112, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_193_raii(tmp_tensor_handle_193);
    decltype(auto) buf870 = std::move(tmp_tensor_handle_193_raii); buf866.reset();  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_148], Original ATen: [aten.native_layer_norm]
    CUdeviceptr var_1655 = reinterpret_cast<CUdeviceptr>(buf870.data_ptr());
    CUdeviceptr var_1656 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w.data_ptr());
    CUdeviceptr var_1657 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b.data_ptr());
    int32_t var_1658 = s0;
    int var_1659 = 4896L;
    void* kernel_args_var_315[] = {&var_1655, &var_1656, &var_1657, &var_1658, &var_1659};
    Grid triton_red_fused_native_layer_norm_205_grid_315 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_native_layer_norm_205_grid_315.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_native_layer_norm_205, triton_red_fused_native_layer_norm_205_grid_315.grid_x, triton_red_fused_native_layer_norm_205_grid_315.grid_y, triton_red_fused_native_layer_norm_205_grid_315.grid_z, 16, 16640, kernel_args_var_315, stream);
    }
    auto buf871 = std::move(buf732);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf871, buf870, _FOLDED_CONST_permute_113));
    buf870.reset();
    auto buf875 = std::move(buf736);  // reuse
    auto buf876 = std::move(buf857);  // reuse
    auto buf877 = std::move(buf856);  // reuse
    // Topologically Sorted Source Nodes: [linear_110, layer_norm_149, sigmoid_39, mul_2166, layer_norm_150], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1660 = reinterpret_cast<CUdeviceptr>(buf871.data_ptr());
    CUdeviceptr var_1661 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1662 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1663 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1664 = reinterpret_cast<CUdeviceptr>(buf875.data_ptr());
    CUdeviceptr var_1665 = reinterpret_cast<CUdeviceptr>(buf876.data_ptr());
    CUdeviceptr var_1666 = reinterpret_cast<CUdeviceptr>(buf877.data_ptr());
    int32_t var_1667 = s0;
    int var_1668 = 2048L;
    void* kernel_args_var_316[] = {&var_1660, &var_1661, &var_1662, &var_1663, &var_1664, &var_1665, &var_1666, &var_1667, &var_1668};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_316 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_316.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_316.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_316.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_182_grid_316.grid_z, 16, 192, kernel_args_var_316, stream);
    }
    buf871.reset();
    auto buf879 = std::move(buf751);  // reuse
    auto buf883 = std::move(buf879);  // reuse
    // Topologically Sorted Source Nodes: [cat_default, layer_norm_151], Original ATen: [aten.cat, aten.native_layer_norm]
    CUdeviceptr var_1669 = reinterpret_cast<CUdeviceptr>(buf883.data_ptr());
    CUdeviceptr var_1670 = reinterpret_cast<CUdeviceptr>(buf457.data_ptr());
    CUdeviceptr var_1671 = reinterpret_cast<CUdeviceptr>(buf230.data_ptr());
    CUdeviceptr var_1672 = reinterpret_cast<CUdeviceptr>(buf875.data_ptr());
    CUdeviceptr var_1673 = reinterpret_cast<CUdeviceptr>(buf876.data_ptr());
    CUdeviceptr var_1674 = reinterpret_cast<CUdeviceptr>(buf877.data_ptr());
    CUdeviceptr var_1675 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1676 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1677 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w.data_ptr());
    CUdeviceptr var_1678 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b.data_ptr());
    int32_t var_1679 = s0;
    int var_1680 = 6354L;
    void* kernel_args_var_317[] = {&var_1669, &var_1670, &var_1671, &var_1672, &var_1673, &var_1674, &var_1675, &var_1676, &var_1677, &var_1678, &var_1679, &var_1680};
    Grid triton_red_fused_cat_native_layer_norm_183_grid_317 = Grid(s0, 1L, 1L);
    if (triton_red_fused_cat_native_layer_norm_183_grid_317.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_cat_native_layer_norm_183, triton_red_fused_cat_native_layer_norm_183_grid_317.grid_x, triton_red_fused_cat_native_layer_norm_183_grid_317.grid_y, triton_red_fused_cat_native_layer_norm_183_grid_317.grid_z, 8, 4096, kernel_args_var_317, stream);
    }
    buf230.reset();
    buf457.reset();
    buf875.reset();
    auto buf884 = std::move(buf759);  // reuse
    // Topologically Sorted Source Nodes: [linear_111], Original ATen: [aten.addmm]
    triton_poi_fused_addmm_184_xnumel = 6360L*s0;
    CUdeviceptr var_1681 = reinterpret_cast<CUdeviceptr>(buf883.data_ptr());
    CUdeviceptr var_1682 = reinterpret_cast<CUdeviceptr>(buf884.data_ptr());
    int32_t var_1683 = triton_poi_fused_addmm_184_xnumel;
    void* kernel_args_var_318[] = {&var_1681, &var_1682, &var_1683};
    Grid triton_poi_fused_addmm_184_grid_318 = Grid((-1L)*static_cast<int64_t>(std::floor((-795.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_184_grid_318.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_184, triton_poi_fused_addmm_184_grid_318.grid_x, triton_poi_fused_addmm_184_grid_318.grid_y, triton_poi_fused_addmm_184_grid_318.grid_z, 8, 0, kernel_args_var_318, stream);
    }
    auto buf885 = std::move(buf750);  // reuse
    // Topologically Sorted Source Nodes: [linear_111], Original ATen: [aten.addmm]
    CUdeviceptr var_1684 = reinterpret_cast<CUdeviceptr>(buf884.data_ptr());
    CUdeviceptr var_1685 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_constant_pad_nd_default_3.data_ptr());
    CUdeviceptr var_1686 = reinterpret_cast<CUdeviceptr>(buf885.data_ptr());
    int32_t var_1687 = s0;
    void* kernel_args_var_319[] = {&var_1684, &var_1685, &var_1686, &var_1687};
    Grid triton_tem_fused_addmm_185_grid_319 = Grid(3L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_185_grid_319.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_185, triton_tem_fused_addmm_185_grid_319.grid_x, triton_tem_fused_addmm_185_grid_319.grid_y, triton_tem_fused_addmm_185_grid_319.grid_z, 4, 196608, kernel_args_var_319, stream);
    }
    auto buf889 = std::move(buf885);  // reuse
    // Topologically Sorted Source Nodes: [linear_111, layer_norm_152], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1688 = reinterpret_cast<CUdeviceptr>(buf889.data_ptr());
    CUdeviceptr var_1689 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1690 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1691 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b.data_ptr());
    int32_t var_1692 = s0;
    int var_1693 = 384L;
    void* kernel_args_var_320[] = {&var_1688, &var_1689, &var_1690, &var_1691, &var_1692, &var_1693};
    Grid triton_per_fused_addmm_native_layer_norm_186_grid_320 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_native_layer_norm_186_grid_320.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_native_layer_norm_186, triton_per_fused_addmm_native_layer_norm_186_grid_320.grid_x, triton_per_fused_addmm_native_layer_norm_186_grid_320.grid_y, triton_per_fused_addmm_native_layer_norm_186_grid_320.grid_z, 4, 16, kernel_args_var_320, stream);
    }
    auto buf890 = std::move(buf744);  // reuse
    // Topologically Sorted Source Nodes: [linear_111, layer_norm_152, linear_112], Original ATen: [aten.addmm, aten.native_layer_norm]
    CUdeviceptr var_1694 = reinterpret_cast<CUdeviceptr>(buf889.data_ptr());
    CUdeviceptr var_1695 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_115.data_ptr());
    CUdeviceptr var_1696 = reinterpret_cast<CUdeviceptr>(buf890.data_ptr());
    int32_t var_1697 = s0;
    void* kernel_args_var_321[] = {&var_1694, &var_1695, &var_1696, &var_1697};
    Grid triton_tem_fused_addmm_native_layer_norm_187_grid_321 = Grid(50L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_native_layer_norm_187_grid_321.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_native_layer_norm_187, triton_tem_fused_addmm_native_layer_norm_187_grid_321.grid_x, triton_tem_fused_addmm_native_layer_norm_187_grid_321.grid_y, triton_tem_fused_addmm_native_layer_norm_187_grid_321.grid_z, 4, 49152, kernel_args_var_321, stream);
    }
    buf889.reset();
    auto buf894 = std::move(buf755);  // reuse
    auto buf895 = std::move(buf877);  // reuse
    auto buf896 = std::move(buf876);  // reuse
    // Topologically Sorted Source Nodes: [linear_112, layer_norm_153, addcmul_3, layer_norm_154], Original ATen: [aten.addmm, aten.native_layer_norm, aten.addcmul]
    CUdeviceptr var_1698 = reinterpret_cast<CUdeviceptr>(buf890.data_ptr());
    CUdeviceptr var_1699 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1700 = reinterpret_cast<CUdeviceptr>(buf883.data_ptr());
    CUdeviceptr var_1701 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1702 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1703 = reinterpret_cast<CUdeviceptr>(buf894.data_ptr());
    CUdeviceptr var_1704 = reinterpret_cast<CUdeviceptr>(buf895.data_ptr());
    CUdeviceptr var_1705 = reinterpret_cast<CUdeviceptr>(buf896.data_ptr());
    int32_t var_1706 = s0;
    int var_1707 = 6354L;
    void* kernel_args_var_322[] = {&var_1698, &var_1699, &var_1700, &var_1701, &var_1702, &var_1703, &var_1704, &var_1705, &var_1706, &var_1707};
    Grid triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_322 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_322.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addcmul_addmm_native_layer_norm_188, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_322.grid_x, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_322.grid_y, triton_red_fused_addcmul_addmm_native_layer_norm_188_grid_322.grid_z, 8, 96, kernel_args_var_322, stream);
    }
    buf883.reset();
    buf890.reset();
    auto buf898 = std::move(buf884);  // reuse
    // Topologically Sorted Source Nodes: [layer_norm_154, linear_113], Original ATen: [aten.native_layer_norm, aten.addmm]
    triton_poi_fused_addmm_native_layer_norm_189_xnumel = 6360L*s0;
    CUdeviceptr var_1708 = reinterpret_cast<CUdeviceptr>(buf894.data_ptr());
    CUdeviceptr var_1709 = reinterpret_cast<CUdeviceptr>(buf895.data_ptr());
    CUdeviceptr var_1710 = reinterpret_cast<CUdeviceptr>(buf896.data_ptr());
    CUdeviceptr var_1711 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w.data_ptr());
    CUdeviceptr var_1712 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b.data_ptr());
    CUdeviceptr var_1713 = reinterpret_cast<CUdeviceptr>(buf898.data_ptr());
    int32_t var_1714 = triton_poi_fused_addmm_native_layer_norm_189_xnumel;
    void* kernel_args_var_323[] = {&var_1708, &var_1709, &var_1710, &var_1711, &var_1712, &var_1713, &var_1714};
    Grid triton_poi_fused_addmm_native_layer_norm_189_grid_323 = Grid((-1L)*static_cast<int64_t>(std::floor((-795.0/64.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_native_layer_norm_189_grid_323.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_native_layer_norm_189, triton_poi_fused_addmm_native_layer_norm_189_grid_323.grid_x, triton_poi_fused_addmm_native_layer_norm_189_grid_323.grid_y, triton_poi_fused_addmm_native_layer_norm_189_grid_323.grid_z, 8, 0, kernel_args_var_323, stream);
    }
    buf894.reset();
    buf895.reset();
    auto buf899 = std::move(buf804);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf899, buf898, _FOLDED_CONST_constant_pad_nd_default_1));
    buf898.reset();
    auto buf903 = std::move(buf764);  // reuse
    auto buf907 = std::move(buf796);  // reuse
    // Topologically Sorted Source Nodes: [linear_113, layer_norm_155, sigmoid_40, mul_2193, layer_norm_156], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1715 = reinterpret_cast<CUdeviceptr>(buf899.data_ptr());
    CUdeviceptr var_1716 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1717 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1718 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1719 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1720 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1721 = reinterpret_cast<CUdeviceptr>(buf903.data_ptr());
    CUdeviceptr var_1722 = reinterpret_cast<CUdeviceptr>(buf907.data_ptr());
    int32_t var_1723 = s0;
    int var_1724 = 3072L;
    void* kernel_args_var_324[] = {&var_1715, &var_1716, &var_1717, &var_1718, &var_1719, &var_1720, &var_1721, &var_1722, &var_1723, &var_1724};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_324 = Grid(s0, 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_324.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_324.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_324.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_190_grid_324.grid_z, 8, 96, kernel_args_var_324, stream);
    }
    buf903.reset();
    auto buf908 = std::move(buf816);  // reuse
    // Topologically Sorted Source Nodes: [linear_114], Original ATen: [aten.addmm]
    CUdeviceptr var_1725 = reinterpret_cast<CUdeviceptr>(buf907.data_ptr());
    CUdeviceptr var_1726 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_117.data_ptr());
    CUdeviceptr var_1727 = reinterpret_cast<CUdeviceptr>(buf908.data_ptr());
    int32_t var_1728 = s0;
    void* kernel_args_var_325[] = {&var_1725, &var_1726, &var_1727, &var_1728};
    Grid triton_tem_fused_addmm_191_grid_325 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_191_grid_325.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_191, triton_tem_fused_addmm_191_grid_325.grid_x, triton_tem_fused_addmm_191_grid_325.grid_y, triton_tem_fused_addmm_191_grid_325.grid_z, 4, 73728, kernel_args_var_325, stream);
    }
    auto buf912 = std::move(buf791);  // reuse
    auto buf916 = std::move(buf787);  // reuse
    // Topologically Sorted Source Nodes: [linear_114, layer_norm_157, sigmoid_41, mul_2204, layer_norm_158], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1729 = reinterpret_cast<CUdeviceptr>(buf908.data_ptr());
    CUdeviceptr var_1730 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1731 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1732 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1733 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1734 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1735 = reinterpret_cast<CUdeviceptr>(buf912.data_ptr());
    CUdeviceptr var_1736 = reinterpret_cast<CUdeviceptr>(buf916.data_ptr());
    int32_t var_1737 = s0;
    int var_1738 = 1536L;
    void* kernel_args_var_326[] = {&var_1729, &var_1730, &var_1731, &var_1732, &var_1733, &var_1734, &var_1735, &var_1736, &var_1737, &var_1738};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_326 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_326.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_326.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_326.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_326.grid_z, 16, 192, kernel_args_var_326, stream);
    }
    auto buf917 = std::move(buf899);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf917, buf916, _FOLDED_CONST_permute_118));
    auto buf921 = std::move(buf917);  // reuse
    auto buf925 = std::move(buf921);  // reuse
    // Topologically Sorted Source Nodes: [linear_115, layer_norm_159, add_2926, layer_norm_160, sigmoid_42, mul_2219], Original ATen: [aten.addmm, aten.native_layer_norm, aten.add, aten.sigmoid, aten.mul]
    CUdeviceptr var_1739 = reinterpret_cast<CUdeviceptr>(buf925.data_ptr());
    CUdeviceptr var_1740 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1741 = reinterpret_cast<CUdeviceptr>(buf907.data_ptr());
    CUdeviceptr var_1742 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1743 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1744 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight.data_ptr());
    CUdeviceptr var_1745 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias.data_ptr());
    int32_t var_1746 = s0;
    int var_1747 = 3072L;
    void* kernel_args_var_327[] = {&var_1739, &var_1740, &var_1741, &var_1742, &var_1743, &var_1744, &var_1745, &var_1746, &var_1747};
    Grid triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_327 = Grid(s0, 1L, 1L);
    if (triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_327.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_327.grid_x, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_327.grid_y, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_193_grid_327.grid_z, 8, 96, kernel_args_var_327, stream);
    }
    auto buf926 = std::move(buf916);  // reuse
    // Topologically Sorted Source Nodes: [linear_116], Original ATen: [aten.addmm]
    CUdeviceptr var_1748 = reinterpret_cast<CUdeviceptr>(buf925.data_ptr());
    CUdeviceptr var_1749 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_119.data_ptr());
    CUdeviceptr var_1750 = reinterpret_cast<CUdeviceptr>(buf926.data_ptr());
    int32_t var_1751 = s0;
    void* kernel_args_var_328[] = {&var_1748, &var_1749, &var_1750, &var_1751};
    Grid triton_tem_fused_addmm_191_grid_328 = Grid(12L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_191_grid_328.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_191, triton_tem_fused_addmm_191_grid_328.grid_x, triton_tem_fused_addmm_191_grid_328.grid_y, triton_tem_fused_addmm_191_grid_328.grid_z, 4, 73728, kernel_args_var_328, stream);
    }
    auto buf930 = std::move(buf912);  // reuse
    auto buf934 = std::move(buf908);  // reuse
    // Topologically Sorted Source Nodes: [linear_116, layer_norm_161, sigmoid_43, mul_2230, layer_norm_162], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1752 = reinterpret_cast<CUdeviceptr>(buf926.data_ptr());
    CUdeviceptr var_1753 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1754 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight.data_ptr());
    CUdeviceptr var_1755 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias.data_ptr());
    CUdeviceptr var_1756 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w.data_ptr());
    CUdeviceptr var_1757 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b.data_ptr());
    CUdeviceptr var_1758 = reinterpret_cast<CUdeviceptr>(buf930.data_ptr());
    CUdeviceptr var_1759 = reinterpret_cast<CUdeviceptr>(buf934.data_ptr());
    int32_t var_1760 = s0;
    int var_1761 = 1536L;
    void* kernel_args_var_329[] = {&var_1752, &var_1753, &var_1754, &var_1755, &var_1756, &var_1757, &var_1758, &var_1759, &var_1760, &var_1761};
    Grid triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_329 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/8.0)*s0)), 1L, 1L);
    if (triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_329.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_329.grid_x, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_329.grid_y, triton_red_fused_addmm_mul_native_layer_norm_sigmoid_192_grid_329.grid_z, 16, 192, kernel_args_var_329, stream);
    }
    buf926.reset();
    buf930.reset();
    auto buf935 = std::move(buf786);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf935, buf934, _FOLDED_CONST_permute_120));
    buf934.reset();
    auto buf939 = std::move(buf907);  // reuse
    auto buf943 = std::move(buf939);  // reuse
    // Topologically Sorted Source Nodes: [linear_117, layer_norm_163, add_2939, add_2964, layer_norm_164, sigmoid_44, mul_2245], Original ATen: [aten.addmm, aten.native_layer_norm, aten.add, aten.sigmoid, aten.mul]
    CUdeviceptr var_1762 = reinterpret_cast<CUdeviceptr>(buf943.data_ptr());
    CUdeviceptr var_1763 = reinterpret_cast<CUdeviceptr>(buf935.data_ptr());
    CUdeviceptr var_1764 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias.data_ptr());
    CUdeviceptr var_1765 = reinterpret_cast<CUdeviceptr>(buf925.data_ptr());
    CUdeviceptr var_1766 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w.data_ptr());
    CUdeviceptr var_1767 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b.data_ptr());
    CUdeviceptr var_1768 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight.data_ptr());
    CUdeviceptr var_1769 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias.data_ptr());
    int32_t var_1770 = s0;
    int var_1771 = 3072L;
    void* kernel_args_var_330[] = {&var_1762, &var_1763, &var_1764, &var_1765, &var_1766, &var_1767, &var_1768, &var_1769, &var_1770, &var_1771};
    Grid triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_330 = Grid(s0, 1L, 1L);
    if (triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_330.is_non_zero()) {
        launchKernel(kernels.triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_330.grid_x, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_330.grid_y, triton_red_fused_add_addmm_mul_native_layer_norm_sigmoid_194_grid_330.grid_z, 8, 96, kernel_args_var_330, stream);
    }
    auto buf944 = std::move(buf170);  // reuse
    // Topologically Sorted Source Nodes: [linear_118], Original ATen: [aten.addmm]
    if (kernels.triton_tem_fused_addmm_210 == nullptr) {
        kernels.triton_tem_fused_addmm_210 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cijgd7hdji2szpyun2veuofx3dh6qbuwe7txdfpbt5wr4o75gtk4.cubin", "triton_tem_fused_addmm_210", 196608, this->cubin_dir_);
    }
    CUdeviceptr var_1772 = reinterpret_cast<CUdeviceptr>(buf943.data_ptr());
    CUdeviceptr var_1773 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_121.data_ptr());
    CUdeviceptr var_1774 = reinterpret_cast<CUdeviceptr>(buf944.data_ptr());
    int32_t var_1775 = s0;
    void* kernel_args_var_331[] = {&var_1772, &var_1773, &var_1774, &var_1775};
    Grid triton_tem_fused_addmm_210_grid_331 = Grid(4L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_210_grid_331.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_210, triton_tem_fused_addmm_210_grid_331.grid_x, triton_tem_fused_addmm_210_grid_331.grid_y, triton_tem_fused_addmm_210_grid_331.grid_z, 4, 196608, kernel_args_var_331, stream);
    }
    auto buf945 = std::move(buf944);  // reuse
    // Topologically Sorted Source Nodes: [linear_118, relu_default_1, nan_to_num_default_1], Original ATen: [aten.addmm, aten.relu, aten.nan_to_num]
    int64_t triton_poi_fused_addmm_nan_to_num_relu_211_xnumel = 512L*s0;
    if (kernels.triton_poi_fused_addmm_nan_to_num_relu_211 == nullptr) {
        kernels.triton_poi_fused_addmm_nan_to_num_relu_211 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/ci2oywjycxc2xb4vpuzpfnjk2sdq63lo2a5dcnbmfegcxzns65jz.cubin", "triton_poi_fused_addmm_nan_to_num_relu_211", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1776 = reinterpret_cast<CUdeviceptr>(buf945.data_ptr());
    CUdeviceptr var_1777 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b.data_ptr());
    int32_t var_1778 = triton_poi_fused_addmm_nan_to_num_relu_211_xnumel;
    void* kernel_args_var_332[] = {&var_1776, &var_1777, &var_1778};
    Grid triton_poi_fused_addmm_nan_to_num_relu_211_grid_332 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/2.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_nan_to_num_relu_211_grid_332.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_nan_to_num_relu_211, triton_poi_fused_addmm_nan_to_num_relu_211_grid_332.grid_x, triton_poi_fused_addmm_nan_to_num_relu_211_grid_332.grid_y, triton_poi_fused_addmm_nan_to_num_relu_211_grid_332.grid_z, 4, 0, kernel_args_var_332, stream);
    }
    auto buf946 = std::move(buf935);  // reuse
    // Topologically Sorted Source Nodes: [linear_118, relu_default_1, nan_to_num_default_1, linear_119], Original ATen: [aten.addmm, aten.relu, aten.nan_to_num]
    if (kernels.triton_tem_fused_addmm_nan_to_num_relu_212 == nullptr) {
        kernels.triton_tem_fused_addmm_nan_to_num_relu_212 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cy3nhvsjgrsmsthox5t3fsaepl7bjmgagag3jx5slyiymso5rdkx.cubin", "triton_tem_fused_addmm_nan_to_num_relu_212", 49152, this->cubin_dir_);
    }
    CUdeviceptr var_1779 = reinterpret_cast<CUdeviceptr>(buf945.data_ptr());
    CUdeviceptr var_1780 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_122.data_ptr());
    CUdeviceptr var_1781 = reinterpret_cast<CUdeviceptr>(buf946.data_ptr());
    int32_t var_1782 = s0;
    void* kernel_args_var_333[] = {&var_1779, &var_1780, &var_1781, &var_1782};
    Grid triton_tem_fused_addmm_nan_to_num_relu_212_grid_333 = Grid(24L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_nan_to_num_relu_212_grid_333.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_nan_to_num_relu_212, triton_tem_fused_addmm_nan_to_num_relu_212_grid_333.grid_x, triton_tem_fused_addmm_nan_to_num_relu_212_grid_333.grid_y, triton_tem_fused_addmm_nan_to_num_relu_212_grid_333.grid_z, 4, 49152, kernel_args_var_333, stream);
    }
    auto buf947 = std::move(buf946);  // reuse
    // Topologically Sorted Source Nodes: [linear_119, relu_default_2, nan_to_num_default_2, add_2989], Original ATen: [aten.addmm, aten.relu, aten.nan_to_num, aten.add]
    int64_t triton_poi_fused_add_addmm_nan_to_num_relu_213_xnumel = 3072L*s0;
    if (kernels.triton_poi_fused_add_addmm_nan_to_num_relu_213 == nullptr) {
        kernels.triton_poi_fused_add_addmm_nan_to_num_relu_213 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cpxhtidpih2jhduhzul3lg433kh4xhhii35qr75lwkoytt24tymb.cubin", "triton_poi_fused_add_addmm_nan_to_num_relu_213", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1783 = reinterpret_cast<CUdeviceptr>(buf947.data_ptr());
    CUdeviceptr var_1784 = reinterpret_cast<CUdeviceptr>(buf943.data_ptr());
    CUdeviceptr var_1785 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b.data_ptr());
    int32_t var_1786 = triton_poi_fused_add_addmm_nan_to_num_relu_213_xnumel;
    void* kernel_args_var_334[] = {&var_1783, &var_1784, &var_1785, &var_1786};
    Grid triton_poi_fused_add_addmm_nan_to_num_relu_213_grid_334 = Grid(3L*s0, 1L, 1L);
    if (triton_poi_fused_add_addmm_nan_to_num_relu_213_grid_334.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_add_addmm_nan_to_num_relu_213, triton_poi_fused_add_addmm_nan_to_num_relu_213_grid_334.grid_x, triton_poi_fused_add_addmm_nan_to_num_relu_213_grid_334.grid_y, triton_poi_fused_add_addmm_nan_to_num_relu_213_grid_334.grid_z, 4, 0, kernel_args_var_334, stream);
    }
    auto buf948 = std::move(buf945);  // reuse
    // Topologically Sorted Source Nodes: [linear_120], Original ATen: [aten.addmm]
    CUdeviceptr var_1787 = reinterpret_cast<CUdeviceptr>(buf947.data_ptr());
    CUdeviceptr var_1788 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_123.data_ptr());
    CUdeviceptr var_1789 = reinterpret_cast<CUdeviceptr>(buf948.data_ptr());
    int32_t var_1790 = s0;
    void* kernel_args_var_335[] = {&var_1787, &var_1788, &var_1789, &var_1790};
    Grid triton_tem_fused_addmm_210_grid_335 = Grid(4L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_210_grid_335.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_210, triton_tem_fused_addmm_210_grid_335.grid_x, triton_tem_fused_addmm_210_grid_335.grid_y, triton_tem_fused_addmm_210_grid_335.grid_z, 4, 196608, kernel_args_var_335, stream);
    }
    auto buf949 = std::move(buf948);  // reuse
    // Topologically Sorted Source Nodes: [linear_120, relu_default_3, nan_to_num_default_3], Original ATen: [aten.addmm, aten.relu, aten.nan_to_num]
    triton_poi_fused_addmm_nan_to_num_relu_211_xnumel = 512L*s0;
    CUdeviceptr var_1791 = reinterpret_cast<CUdeviceptr>(buf949.data_ptr());
    CUdeviceptr var_1792 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b.data_ptr());
    int32_t var_1793 = triton_poi_fused_addmm_nan_to_num_relu_211_xnumel;
    void* kernel_args_var_336[] = {&var_1791, &var_1792, &var_1793};
    Grid triton_poi_fused_addmm_nan_to_num_relu_211_grid_336 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/2.0)*s0)), 1L, 1L);
    if (triton_poi_fused_addmm_nan_to_num_relu_211_grid_336.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_nan_to_num_relu_211, triton_poi_fused_addmm_nan_to_num_relu_211_grid_336.grid_x, triton_poi_fused_addmm_nan_to_num_relu_211_grid_336.grid_y, triton_poi_fused_addmm_nan_to_num_relu_211_grid_336.grid_z, 4, 0, kernel_args_var_336, stream);
    }
    auto buf950 = std::move(buf925);  // reuse
    // Topologically Sorted Source Nodes: [linear_120, relu_default_3, nan_to_num_default_3, linear_121], Original ATen: [aten.addmm, aten.relu, aten.nan_to_num]
    CUdeviceptr var_1794 = reinterpret_cast<CUdeviceptr>(buf949.data_ptr());
    CUdeviceptr var_1795 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_124.data_ptr());
    CUdeviceptr var_1796 = reinterpret_cast<CUdeviceptr>(buf950.data_ptr());
    int32_t var_1797 = s0;
    void* kernel_args_var_337[] = {&var_1794, &var_1795, &var_1796, &var_1797};
    Grid triton_tem_fused_addmm_nan_to_num_relu_212_grid_337 = Grid(24L*(c10::div_floor_integer(static_cast<int64_t>(127L + s0), static_cast<int64_t>(128L))), 1L, 1L);
    if (triton_tem_fused_addmm_nan_to_num_relu_212_grid_337.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_nan_to_num_relu_212, triton_tem_fused_addmm_nan_to_num_relu_212_grid_337.grid_x, triton_tem_fused_addmm_nan_to_num_relu_212_grid_337.grid_y, triton_tem_fused_addmm_nan_to_num_relu_212_grid_337.grid_z, 4, 49152, kernel_args_var_337, stream);
    }
    auto buf951 = std::move(buf943);  // reuse
    // Topologically Sorted Source Nodes: [full_like, mul_2264, add_3008, linear_121, relu_default_4, nan_to_num_default_4, mul_2273, add_3018], Original ATen: [aten.full_like, aten.mul, aten.add, aten.addmm, aten.relu, aten.nan_to_num]
    int64_t triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214_xnumel = 3072L*s0;
    if (kernels.triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214 == nullptr) {
        kernels.triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cxqx5phigajsml6t2arc3nlvkb6iyawekhhpydeisw7axoh25izp.cubin", "triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1798 = reinterpret_cast<CUdeviceptr>(buf951.data_ptr());
    CUdeviceptr var_1799 = reinterpret_cast<CUdeviceptr>(buf947.data_ptr());
    CUdeviceptr var_1800 = reinterpret_cast<CUdeviceptr>(buf950.data_ptr());
    CUdeviceptr var_1801 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b.data_ptr());
    int32_t var_1802 = triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214_xnumel;
    void* kernel_args_var_338[] = {&var_1798, &var_1799, &var_1800, &var_1801, &var_1802};
    Grid triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214_grid_338 = Grid(3L*s0, 1L, 1L);
    if (triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214_grid_338.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214, triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214_grid_338.grid_x, triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214_grid_338.grid_y, triton_poi_fused_add_addmm_full_like_mul_nan_to_num_relu_214_grid_338.grid_z, 4, 0, kernel_args_var_338, stream);
    }
    buf947.reset();
    auto buf952 = std::move(buf950);  // reuse
    // Unsorted Source Nodes: [], Original ATen: []
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_cuda_mm_out(buf952, buf951, _FOLDED_CONST_permute_125));
    auto buf953 = std::move(buf951);  // reuse
    // Topologically Sorted Source Nodes: [linear_122, sigmoid_45, mul_2282], Original ATen: [aten.addmm, aten.sigmoid, aten.mul]
    int64_t triton_poi_fused_addmm_mul_sigmoid_215_xnumel = 3072L*s0;
    if (kernels.triton_poi_fused_addmm_mul_sigmoid_215 == nullptr) {
        kernels.triton_poi_fused_addmm_mul_sigmoid_215 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/c6l3sk3sxs56eqsbbvxbsddo523t53st5432r4xlqeeb7m6zmops.cubin", "triton_poi_fused_addmm_mul_sigmoid_215", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1803 = reinterpret_cast<CUdeviceptr>(buf953.data_ptr());
    CUdeviceptr var_1804 = reinterpret_cast<CUdeviceptr>(buf952.data_ptr());
    CUdeviceptr var_1805 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b.data_ptr());
    int32_t var_1806 = triton_poi_fused_addmm_mul_sigmoid_215_xnumel;
    void* kernel_args_var_339[] = {&var_1803, &var_1804, &var_1805, &var_1806};
    Grid triton_poi_fused_addmm_mul_sigmoid_215_grid_339 = Grid(3L*s0, 1L, 1L);
    if (triton_poi_fused_addmm_mul_sigmoid_215_grid_339.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused_addmm_mul_sigmoid_215, triton_poi_fused_addmm_mul_sigmoid_215_grid_339.grid_x, triton_poi_fused_addmm_mul_sigmoid_215_grid_339.grid_y, triton_poi_fused_addmm_mul_sigmoid_215_grid_339.grid_z, 4, 0, kernel_args_var_339, stream);
    }
    buf952.reset();
    auto buf954 = std::move(buf949);  // reuse
    // Topologically Sorted Source Nodes: [linear_122, sigmoid_45, mul_2282, linear_123], Original ATen: [aten.addmm, aten.sigmoid, aten.mul]
    CUdeviceptr var_1807 = reinterpret_cast<CUdeviceptr>(buf953.data_ptr());
    CUdeviceptr var_1808 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_126.data_ptr());
    CUdeviceptr var_1809 = reinterpret_cast<CUdeviceptr>(buf954.data_ptr());
    int32_t var_1810 = s0;
    void* kernel_args_var_340[] = {&var_1807, &var_1808, &var_1809, &var_1810};
    Grid triton_tem_fused_addmm_210_grid_340 = Grid(4L*(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L))), 1L, 1L);
    if (triton_tem_fused_addmm_210_grid_340.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_210, triton_tem_fused_addmm_210_grid_340.grid_x, triton_tem_fused_addmm_210_grid_340.grid_y, triton_tem_fused_addmm_210_grid_340.grid_z, 4, 196608, kernel_args_var_340, stream);
    }
    buf953.reset();
    auto buf958 = std::move(buf954);  // reuse
    // Topologically Sorted Source Nodes: [linear_123, layer_norm_165, sigmoid_46, mul_2291], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216 == nullptr) {
        kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cjsnraymh5ifhed4omgshjt4ju2gvvd2nwya3xekbt4gfo7jh2vy.cubin", "triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216", 16, this->cubin_dir_);
    }
    CUdeviceptr var_1811 = reinterpret_cast<CUdeviceptr>(buf958.data_ptr());
    CUdeviceptr var_1812 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b.data_ptr());
    CUdeviceptr var_1813 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale.data_ptr());
    CUdeviceptr var_1814 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias.data_ptr());
    int32_t var_1815 = s0;
    int var_1816 = 512L;
    void* kernel_args_var_341[] = {&var_1811, &var_1812, &var_1813, &var_1814, &var_1815, &var_1816};
    Grid triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216_grid_341 = Grid(s0, 1L, 1L);
    if (triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216_grid_341.is_non_zero()) {
        launchKernel(kernels.triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216_grid_341.grid_x, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216_grid_341.grid_y, triton_per_fused_addmm_mul_native_layer_norm_sigmoid_216_grid_341.grid_z, 4, 16, kernel_args_var_341, stream);
    }
    static constexpr int64_t int_array_117[] = {1L, 1L};
    AtenTensorHandle buf959_handle;
    AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_empty_strided(2, int_array_85, int_array_117, cached_torch_dtype_float16, cached_torch_device_type_cuda, this->device_idx_, &buf959_handle));
    RAIIAtenTensorHandle buf959(buf959_handle);
    // Topologically Sorted Source Nodes: [linear_123, layer_norm_165, sigmoid_46, mul_2291, linear_124], Original ATen: [aten.addmm, aten.native_layer_norm, aten.sigmoid, aten.mul]
    if (kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217 == nullptr) {
        kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cj5ewosrbkpitvdzidxgz5hni3xogbv2zg7czux6ztb34eonfknz.cubin", "triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217", 81920, this->cubin_dir_);
    }
    CUdeviceptr var_1817 = reinterpret_cast<CUdeviceptr>(buf958.data_ptr());
    CUdeviceptr var_1818 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_permute_127.data_ptr());
    CUdeviceptr var_1819 = reinterpret_cast<CUdeviceptr>(buf959.data_ptr());
    int32_t var_1820 = s0;
    void* kernel_args_var_342[] = {&var_1817, &var_1818, &var_1819, &var_1820};
    Grid triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217_grid_342 = Grid(c10::div_floor_integer(static_cast<int64_t>(63L + s0), static_cast<int64_t>(64L)), 1L, 1L);
    if (triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217_grid_342.is_non_zero()) {
        launchKernel(kernels.triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217_grid_342.grid_x, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217_grid_342.grid_y, triton_tem_fused_addmm_mul_native_layer_norm_sigmoid_217_grid_342.grid_z, 4, 81920, kernel_args_var_342, stream);
    }
    buf958.reset();
    auto tmp_tensor_handle_194 = reinterpret_tensor_wrapper(buf896, 2, int_array_85, int_array_117, 0L);
    RAIIAtenTensorHandle tmp_tensor_handle_194_raii(tmp_tensor_handle_194);
    decltype(auto) buf966 = std::move(tmp_tensor_handle_194_raii); buf896.reset();  // reuse
    // Topologically Sorted Source Nodes: [submod_1, linear_124, sum_3, sum_5, add_605, sum_10, add_708, sum_11, add_712, sum_9, add_722, sum_7, add_735, sum_6, add_742, sum_4, add_749, sum_8, add_762, sum_12, add_772, sum_2, add_789, sum_1, add_804, add_808], Original ATen: [aten.full_like, aten.addmm, aten.add, aten.sigmoid, aten.gt, aten._to_copy, aten.mul, aten.sub, aten.logit, aten.sum]
    if (kernels.triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218 == nullptr) {
        kernels.triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218 = loadKernel("/tmp/torchinductor_guorachel/tmpyhywxbq9/0x8078f826789e2ae6/cqt2dtfgzpxgjlq4affxecruc2kq5tgpc2wd5budvnz5jc5krh3n.cubin", "triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218", 0, this->cubin_dir_);
    }
    CUdeviceptr var_1821 = reinterpret_cast<CUdeviceptr>(buf2.data_ptr());
    CUdeviceptr var_1822 = reinterpret_cast<CUdeviceptr>(buf4.data_ptr());
    CUdeviceptr var_1823 = reinterpret_cast<CUdeviceptr>(buf959.data_ptr());
    CUdeviceptr var_1824 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b.data_ptr());
    CUdeviceptr var_1825 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_1_main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_positive_weight_calibration_bias.data_ptr());
    CUdeviceptr var_1826 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_0_main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias.data_ptr());
    CUdeviceptr var_1827 = reinterpret_cast<CUdeviceptr>(_FOLDED_CONST_submod_1__tensor_constant1.data_ptr());
    CUdeviceptr var_1828 = reinterpret_cast<CUdeviceptr>(buf966.data_ptr());
    int32_t var_1829 = s0;
    void* kernel_args_var_343[] = {&var_1821, &var_1822, &var_1823, &var_1824, &var_1825, &var_1826, &var_1827, &var_1828, &var_1829};
    Grid triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218_grid_343 = Grid((-1L)*static_cast<int64_t>(std::floor((-1.0/128.0)*s0)), 1L, 1L);
    if (triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218_grid_343.is_non_zero()) {
        launchKernel(kernels.triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218, triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218_grid_343.grid_x, triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218_grid_343.grid_y, triton_poi_fused__to_copy_add_addmm_full_like_gt_logit_mul_sigmoid_sub_sum_218_grid_343.grid_z, 4, 0, kernel_args_var_343, stream);
    }
    buf2.reset();
    buf4.reset();
    buf959.reset();
    output_handles[0] = buf966.release();
    aoti_torch_clone(_FOLDED_CONST__tensor_constant2, &output_handles[1]);
} // AOTInductorModel::run_impl
} // namespace torch::aot_inductor
