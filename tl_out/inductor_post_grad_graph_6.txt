class <lambda>(torch.nn.Module):
    def forward(self):
        arg606_1: "f16[s0, 3890][3890, 1]cuda:0"; arg607_1: "f16[s0, 2688][2688, 1]cuda:0"; arg608_1: "f16[s0, 384][384, 1]cuda:0"; arg609_1: "f16[s0, 384][384, 1]cuda:0"; arg610_1: "f16[s0, 17932][17932, 1]cuda:0"; arg611_1: "f16[s0, 17584][17584, 1]cuda:0"; arg612_1: "f16[s0, 30516][30516, 1]cuda:0"; arg613_1: "f16[s0, 200, 64][12800, 64, 1]cuda:0"; arg614_1: "f16[s0, 200, 64][12800, 64, 1]cuda:0"; 
    
        arg606_1, arg607_1, arg608_1, arg609_1, arg610_1, arg611_1, arg612_1, arg613_1, arg614_1, = fx_pytree.tree_flatten_spec([], self._in_spec)
        # No stacktrace found for following nodes
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 240][240, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 240][240, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_2.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 192][192, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_1.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 192][192, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADPUBLISHER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_AD_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_ENTITY_EQUIVALENCE_KEY_0.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 72][72, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_291594492_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_421801413_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_2_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_323876380_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 72][72, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_368273801_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_3_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 72][72, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246015958_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_487599076_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_246272433_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 72][72, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 72][72, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_EARLY_STAGE_FEATURES_EARLY_STAGE_SCALING_USER_MODEL_367428337_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_UDS_UHM_ONSITE_CONVERSION_UHM_ONSITE_CONVERSION_SINGLE_CHANNEL_CTR.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 72][72, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_343512182_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 72][72, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_F3_BULK_EVAL_DAILY_USER_SIDE_EMBEDDING_FEATURE_GRAPH_LEARNING_EMBEDDING_FEATURE_USER_GRAPH_F3_DAILY_BULK_EVAL_2023_H1_2.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 72][72, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_309862198_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_360324426_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 144][144, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_0.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 144][144, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_GRAPH_LEARNING_FLEXIBLE_BATCH_GRAPH_LEARNING_USER_SIDE_EMBEDDING_FEATURE_F3_GRAPH_LEARNING_EMBEDDING_FEATURE_SEPARABLE_ID_1.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_PROD_FEATURES_SCALING_USER_MODEL_346472987_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 64][64, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_POST_MODEL_EVAL_ADS_SCALING_USER_MODEL_REALTIME_CVR_V0_SCALING_USER_MODEL_510272006_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_0_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[192, 96][96, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3.submodules, "1").scale
        submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_feature_arch.embedding_projection_arch.F3_ADFINDER_USER_ADS_SCALING_USER_MODEL_SG_SCALE_V0_EARLY_STAGE_SCALING_USER_MODEL_530332232_EMBEDDING_1_AVG_3.submodules, "1").bias
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[214, 6052][6052, 1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[214][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_w: "f16[42, 6052][6052, 1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "0").arch.submodules, "0").submodules, "0").shards, "1").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_b: "f16[42][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "0").arch.submodules, "0").submodules, "0").shards, "1").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale: "f16[256][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "0").arch.submodules, "0").submodules, "1").norm.submodules, "0").scale
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias: "f16[256][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "0").arch.submodules, "0").submodules, "1").norm.submodules, "0").bias
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w: "f16[3026, 256][256, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "1").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b: "f16[3026][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "1").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w: "f16[256, 3026][3026, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.linear_archs, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b: "f16[256][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.linear_archs, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale: "f16[3282][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.activations, "0").norm.submodules, "0").scale
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias: "f16[3282][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_projection_arch.activations, "0").norm.submodules, "0").bias
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_w: "f16[192, 3282][3282, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_0.submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_0.submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_w: "f16[192, 3282][3282, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_1.submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_1.submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_w: "f16[192, 3282][3282, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_2.submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_2.submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_w: "f16[192, 3282][3282, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_3.submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_3.submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_w: "f16[192, 3282][3282, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_4.submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_4.submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_w: "f16[192, 3282][3282, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_5.submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_b: "f16[192][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.dense_arch.dense_embedding_archs, "0").submodules.dense_embedding_5.submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[256, 700][700, 1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[256][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale: "f16[256][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch.submodules, "0").arch.submodules, "0").submodules, "1").norm.submodules, "0").scale
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias: "f16[256][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch.submodules, "0").arch.submodules, "0").submodules, "1").norm.submodules, "0").bias
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w: "f16[1024, 256][256, 1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch.submodules, "0").arch.submodules, "1").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b: "f16[1024][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch.submodules, "0").arch.submodules, "1").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale: "f16[1024][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch.submodules, "0").arch.submodules, "1").submodules, "1").norm.submodules, "0").scale
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias: "f16[1024][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch.submodules, "0").arch.submodules, "1").submodules, "1").norm.submodules, "0").bias
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_w: "f16[256, 700][700, 1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch_to_dot.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_b: "f16[256][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch_to_dot.submodules, "0").arch.submodules, "0").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w: "f16[960, 256][256, 1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch_to_dot.submodules, "0").arch.submodules, "1").submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b: "f16[960][1]cuda:0" = getattr(getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch_to_dot.submodules, "0").arch.submodules, "1").submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w: "f16[1536, 960][960, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch_to_dot.submodules, "1").linear_arch.shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.specialized_arch.specialized_module_list, "0").specialized_arch_to_dot.submodules, "1").linear_arch.shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb: "f16[1, 200, 64][12800, 64, 1]cuda:0" = self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.pos_emb
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb: "f16[1, 32, 64][2048, 64, 1]cuda:0" = self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.seed_emb
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_y, "0").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_y, "0").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight: "f16[64, 64][64, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.attns, "0").k_proj.weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight: "f16[64, 64][64, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.attns, "0").q_proj.weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.attns, "0").q_proj.bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_x, "0").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_x, "0").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_ffn, "0").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.ln_ffn, "0").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_weight: "f16[128, 64][64, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.mlps, "0"), "0").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias: "f16[128][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.mlps, "0"), "0").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_weight: "f16[64, 128][128, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.mlps, "0"), "2").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias: "f16[64][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.iaw.relevance_model.pre_norm_pma.mab.mlps, "0"), "2").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb: "f16[1, 200, 64][12800, 64, 1]cuda:0" = self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.pos_emb
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb: "f16[1, 32, 64][2048, 64, 1]cuda:0" = self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.seed_emb
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_y, "0").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_y, "0").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight: "f16[64, 64][64, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.attns, "0").k_proj.weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight: "f16[64, 64][64, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.attns, "0").q_proj.weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.attns, "0").q_proj.bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_x, "0").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_x, "0").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_ffn, "0").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias: "f16[64][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.ln_ffn, "0").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_weight: "f16[128, 64][64, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.mlps, "0"), "0").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias: "f16[128][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.mlps, "0"), "0").bias
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_weight: "f16[64, 128][128, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.mlps, "0"), "2").weight
        submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias: "f16[64][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.event_submodels_dict.user_conv_ads_event.relevance_model.pre_norm_pma.mab.mlps, "0"), "2").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias: "f16[64, 1, 192][192, 192, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_projection_arch.first_fused_mlp, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight: "f16[64, 64, 192][12288, 192, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.embedding_projection_arch.first_fused_mlp, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w: "f16[174, 458][458, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._fused_lce_module._compression_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b: "f16[174, 1][1, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._fused_lce_module._compression_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._fused_lce_module._ln_lce._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._fused_lce_module._ln_lce._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_weight: "f16[768, 4608][4608, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_weight: "f16[768, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "3").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "3").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "5")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_mlp.mlp_net, "5")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_weight: "f16[768, 4608][4608, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_weight: "f16[768, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "3").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "3").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "5")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_mlp.mlp_net, "5")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight: "f16[21984, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_post_match_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias: "f16[21984][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_post_match_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w: "f16[21984][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_post_match_mlp.mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b: "f16[21984][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._weight_arch_post_match_mlp.mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight: "f16[9216, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_post_match_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_post_match_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_post_match_mlp.mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp._resnet_arch_post_match_mlp.mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w: "f16[48][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp.compressed_tensor_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b: "f16[48][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcpp.compressed_tensor_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w: "f16[21984][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcpp_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b: "f16[21984][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcpp_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_weight: "f16[2048, 21984][21984, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcpp_fc._mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcpp_fc._mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight: "f16[2048][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcpp_fc._mlps, "0").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias: "f16[2048][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcpp_fc._mlps, "0").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcpp_fc._mlps, "0").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcpp_fc._mlps, "0").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._ln_on_dsi._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._ln_on_dsi._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight: "f16[384, 6354][6354, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcn._dcn_low_rank_mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcn._dcn_low_rank_mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcn._dcn_low_rank_mlps, "0").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcn._dcn_low_rank_mlps, "0").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_weight: "f16[6354, 384][384, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcn._dcn_match_mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcn._dcn_match_mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcn._dcn_match_mlps, "0").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._dcn._dcn_match_mlps, "0").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcn_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._post_dcn_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_weight: "f16[3072, 6354][6354, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "0").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "0").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "0").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "0").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_weight: "f16[1536, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "1").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "1").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "1").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "1").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "1").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "1").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_weight: "f16[3072, 1536][1536, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "2").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "2").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "2").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "2").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_weight: "f16[1536, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "3").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "3").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "3").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "3").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "3").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "3").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_weight: "f16[3072, 1536][1536, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "4").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "4").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "4").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._mlps, "4").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._residual_activation, "2").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._residual_activation, "2").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._residual_activation, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._residual_mlp._residual_activation, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_weight: "f16[9216, 3072][3072, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._snn_projection.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._snn_projection.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._ln_on_dhen_layer._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "0")._ln_on_dhen_layer._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w: "f16[72, 102][102, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._fused_lce_module._compression_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b: "f16[72, 1][1, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._fused_lce_module._compression_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._fused_lce_module._ln_lce._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._fused_lce_module._ln_lce._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_weight: "f16[768, 4608][4608, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_weight: "f16[768, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "3").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "3").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "5")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_mlp.mlp_net, "5")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_weight: "f16[768, 4608][4608, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_weight: "f16[768, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "3").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "3").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "5")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_mlp.mlp_net, "5")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight: "f16[4896, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_post_match_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_post_match_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_post_match_mlp.mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._weight_arch_post_match_mlp.mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight: "f16[9216, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_post_match_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_post_match_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_post_match_mlp.mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp._resnet_arch_post_match_mlp.mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w: "f16[48][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp.compressed_tensor_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b: "f16[48][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcpp.compressed_tensor_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w: "f16[4896][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcpp_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b: "f16[4896][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcpp_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_weight: "f16[2048, 4896][4896, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcpp_fc._mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcpp_fc._mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight: "f16[2048][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcpp_fc._mlps, "0").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias: "f16[2048][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcpp_fc._mlps, "0").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcpp_fc._mlps, "0").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcpp_fc._mlps, "0").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._ln_on_dsi._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._ln_on_dsi._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight: "f16[384, 6354][6354, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcn._dcn_low_rank_mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcn._dcn_low_rank_mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcn._dcn_low_rank_mlps, "0").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcn._dcn_low_rank_mlps, "0").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_weight: "f16[6354, 384][384, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcn._dcn_match_mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcn._dcn_match_mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcn._dcn_match_mlps, "0").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._dcn._dcn_match_mlps, "0").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcn_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._post_dcn_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_weight: "f16[3072, 6354][6354, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "0").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "0").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "0").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "0").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_weight: "f16[1536, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "1").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "1").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "1").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "1").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "1").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "1").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_weight: "f16[3072, 1536][1536, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "2").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "2").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "2").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "2").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_weight: "f16[1536, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "3").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "3").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "3").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "3").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "3").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "3").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_weight: "f16[3072, 1536][1536, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "4").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "4").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "4").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._mlps, "4").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._residual_activation, "2").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._residual_activation, "2").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._residual_activation, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._residual_mlp._residual_activation, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_weight: "f16[9216, 3072][3072, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._snn_projection.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._snn_projection.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._ln_on_dhen_layer._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "1")._ln_on_dhen_layer._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w: "f16[72, 102][102, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._fused_lce_module._compression_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b: "f16[72, 1][1, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._fused_lce_module._compression_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._fused_lce_module._ln_lce._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._fused_lce_module._ln_lce._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_weight: "f16[768, 4608][4608, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_weight: "f16[768, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "3").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "3").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "5")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_mlp.mlp_net, "5")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_weight: "f16[768, 4608][4608, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_weight: "f16[768, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "3").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "3").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "5")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_mlp.mlp_net, "5")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight: "f16[4896, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_post_match_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_post_match_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_post_match_mlp.mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._weight_arch_post_match_mlp.mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight: "f16[9216, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_post_match_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_post_match_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_post_match_mlp.mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp._resnet_arch_post_match_mlp.mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w: "f16[48][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp.compressed_tensor_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b: "f16[48][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcpp.compressed_tensor_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w: "f16[4896][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcpp_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b: "f16[4896][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcpp_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_weight: "f16[2048, 4896][4896, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcpp_fc._mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcpp_fc._mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight: "f16[2048][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcpp_fc._mlps, "0").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias: "f16[2048][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcpp_fc._mlps, "0").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcpp_fc._mlps, "0").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcpp_fc._mlps, "0").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._ln_on_dsi._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._ln_on_dsi._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight: "f16[384, 6354][6354, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcn._dcn_low_rank_mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcn._dcn_low_rank_mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcn._dcn_low_rank_mlps, "0").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcn._dcn_low_rank_mlps, "0").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_weight: "f16[6354, 384][384, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcn._dcn_match_mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcn._dcn_match_mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcn._dcn_match_mlps, "0").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._dcn._dcn_match_mlps, "0").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcn_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._post_dcn_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_weight: "f16[3072, 6354][6354, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "0").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "0").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "0").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "0").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_weight: "f16[1536, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "1").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "1").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "1").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "1").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "1").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "1").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_weight: "f16[3072, 1536][1536, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "2").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "2").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "2").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "2").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_weight: "f16[1536, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "3").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "3").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "3").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "3").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "3").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "3").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_weight: "f16[3072, 1536][1536, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "4").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "4").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "4").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._mlps, "4").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._residual_activation, "2").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._residual_activation, "2").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._residual_activation, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._residual_mlp._residual_activation, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_weight: "f16[9216, 3072][3072, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._snn_projection.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._snn_projection.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._ln_on_dhen_layer._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "2")._ln_on_dhen_layer._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w: "f16[24, 102][102, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._input_compression._compression_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b: "f16[24, 1][1, 1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._input_compression._compression_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._input_compression._ln_lce._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b: "f16[192][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._input_compression._ln_lce._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_weight: "f16[768, 4608][4608, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_weight: "f16[768, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "3").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "3").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "5")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_mlp.mlp_net, "5")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_weight: "f16[768, 4608][4608, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_weight: "f16[768, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "3").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "3").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias: "f16[768][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "5")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b: "f16[768][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_mlp.mlp_net, "5")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight: "f16[4896, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_post_match_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_post_match_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_post_match_mlp.mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b: "f16[4896][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._weight_arch_post_match_mlp.mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight: "f16[9216, 768][768, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_post_match_mlp.mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_post_match_mlp.mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_post_match_mlp.mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b: "f16[9216][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp._resnet_arch_post_match_mlp.mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w: "f16[48][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp.compressed_tensor_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b: "f16[48][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcpp.compressed_tensor_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w: "f16[4896][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcpp_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b: "f16[4896][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcpp_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_weight: "f16[2048, 4896][4896, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcpp_fc._mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcpp_fc._mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight: "f16[2048][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcpp_fc._mlps, "0").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias: "f16[2048][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcpp_fc._mlps, "0").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcpp_fc._mlps, "0").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b: "f16[2048][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcpp_fc._mlps, "0").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._ln_on_dsi._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._ln_on_dsi._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight: "f16[384, 6354][6354, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcn._dcn_low_rank_mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcn._dcn_low_rank_mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcn._dcn_low_rank_mlps, "0").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b: "f16[384][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcn._dcn_low_rank_mlps, "0").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_weight: "f16[6354, 384][384, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcn._dcn_match_mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcn._dcn_match_mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcn._dcn_match_mlps, "0").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b: "f16[6354][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._dcn._dcn_match_mlps, "0").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcn_ln._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b: "f16[6354][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._post_dcn_ln._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_weight: "f16[3072, 6354][6354, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "0").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "0").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "0").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "0").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "0").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "0").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_weight: "f16[1536, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "1").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "1").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "1").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "1").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "1").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "1").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_weight: "f16[3072, 1536][1536, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "2").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "2").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "2").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "2").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_weight: "f16[1536, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "3").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "3").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "3").mlp_net, "1").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias: "f16[1536][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "3").mlp_net, "1").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "3").mlp_net, "2")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b: "f16[1536][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "3").mlp_net, "2")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_weight: "f16[3072, 1536][1536, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "4").mlp_net, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "4").mlp_net, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "4").mlp_net, "1")._init_w
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._mlps, "4").mlp_net, "1")._init_b
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._residual_activation, "2").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._residual_activation, "2").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._residual_activation, "4").norm, "0").weight
        submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias: "f16[3072][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.pytorch_dhen.dhen_arch.layers, "3")._residual_mlp._residual_activation, "4").norm, "0").bias
        submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w: "f16[512, 3072][3072, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.cyclegan.encoder.linear_archs, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b: "f16[512][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.cyclegan.encoder.linear_archs, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w: "f16[3072, 512][512, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.cyclegan.encoder.linear_archs, "1").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b: "f16[3072][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.cyclegan.encoder.linear_archs, "1").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w: "f16[512, 3072][3072, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.cyclegan.decoder.linear_archs, "0").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b: "f16[512][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.cyclegan.decoder.linear_archs, "0").shards, "0").b
        submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w: "f16[3072, 512][512, 1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.cyclegan.decoder.linear_archs, "1").shards, "0").w
        submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b: "f16[3072][1]cuda:0" = getattr(getattr(self.submod_0.main_module.impl.impl.shared_arch.cyclegan.decoder.linear_archs, "1").shards, "0").b
        submod_0_main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias: "f16[1][1]cuda:0" = getattr(self.submod_0.main_module.impl.impl.dependent_tasks, "1:SALR_STANDALONE").aggregator_module.task_arch.sparse_aggregates_logistic_regression.global_bias
        submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w: "f16[3072, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "0").shards, "0").w
        submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b: "f16[3072][1]cuda:0" = getattr(getattr(getattr(getattr(self.submod_0.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.dense_arch.dense_projection_arch.gating_archs, "0").gn_arch.submodules, "0").shards, "0").b
        submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w: "f16[512, 3072][3072, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.dense_arch.dense_projection_arch.linear_archs, "0").shards, "0").w
        submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b: "f16[512][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.dense_arch.dense_projection_arch.linear_archs, "0").shards, "0").b
        submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w: "f16[1, 512][512, 1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.dense_arch.dense_projection_arch.linear_archs, "1").shards, "0").w
        submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b: "f16[1][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.dense_arch.dense_projection_arch.linear_archs, "1").shards, "0").b
        submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale: "f16[512][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.dense_arch.dense_projection_arch.activations, "0").norm.submodules, "0").scale
        submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias: "f16[512][1]cuda:0" = getattr(getattr(getattr(self.submod_0.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.dense_arch.dense_projection_arch.activations, "0").norm.submodules, "0").bias
        _tensor_constant2: "f16[1][1]cuda:0" = self._tensor_constant2
        submod_0_cat_fusion_gpu__offset_dim_list: "i64[277][1]cuda:0" = self.submod_0.cat_fusion_gpu._offset_dim_list
        submod_0_cat_fusion_gpu__permute: "i64[276][1]cuda:0" = self.submod_0.cat_fusion_gpu._permute
        submod_0_cat_fusion_gpu__inv_permute: "i64[276][1]cuda:0" = self.submod_0.cat_fusion_gpu._inv_permute
        submod_0_cat_fusion_gpu__inv_offset_dim_list: "i64[277][1]cuda:0" = self.submod_0.cat_fusion_gpu._inv_offset_dim_list
        submod_0_cat_fusion_cpu__offset_dim_list: "i64[183][1]cuda:0" = self.submod_0.cat_fusion_cpu._offset_dim_list
        submod_0_cat_fusion_cpu__permute: "i64[182][1]cuda:0" = self.submod_0.cat_fusion_cpu._permute
        submod_0_cat_fusion_cpu__inv_permute: "i64[182][1]cuda:0" = self.submod_0.cat_fusion_cpu._inv_permute
        submod_0_cat_fusion_cpu__inv_offset_dim_list: "i64[183][1]cuda:0" = self.submod_0.cat_fusion_cpu._inv_offset_dim_list
        submod_1__tensor_constant1: "f16[][]cuda:0" = self.submod_1._tensor_constant1
        submod_1_main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_positive_weight_calibration_bias: "f16[1][1]cuda:0" = getattr(self.submod_1.main_module.impl.impl.task_archs, "1:Optimized").prediction_arch.calibration.positive_weight_calibration_bias
        
         # File: <torch_package_1>.caffe2/torch/fb/model_transform/serving_paradigm/split_concat_transform_structs.py:132 in forward, code: catted = torch.cat(unpadded_tensors, dim=1)
        cat: "f16[s0, 36284][36284, 1]cuda:0" = torch.ops.aten.cat.default([arg608_1, arg609_1, arg610_1, arg611_1], 1);  arg609_1 = arg610_1 = arg611_1 = None
        
         # File: <torch_package_1>.caffe2/torch/fb/model_transform/serving_paradigm/split_concat_transform_structs.py:143 in forward, code: permuted = torch.ops.fbgemm.permute_pooled_embs_auto_grad(
        permute_pooled_embs_auto_grad: "f16[s0, 36284][36284, 1]cuda:0" = torch.ops.fbgemm.permute_pooled_embs_auto_grad.default(cat, submod_0_cat_fusion_gpu__offset_dim_list, submod_0_cat_fusion_gpu__permute, submod_0_cat_fusion_gpu__inv_offset_dim_list, submod_0_cat_fusion_gpu__inv_permute);  cat = submod_0_cat_fusion_gpu__offset_dim_list = submod_0_cat_fusion_gpu__permute = submod_0_cat_fusion_gpu__inv_offset_dim_list = submod_0_cat_fusion_gpu__inv_permute = None
        
         # File: <torch_package_1>.caffe2/torch/fb/model_transform/serving_paradigm/split_concat_transform_structs.py:155 in forward, code: res = permuted.split_with_sizes(self.res_dim_list, dim=1)
        split_with_sizes = torch.ops.aten.split_with_sizes.default(permute_pooled_embs_auto_grad, [36, 228, 32, 32, 80, 32, 16, 72, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2880, 3648, 768, 192, 1152, 960, 576, 192, 768, 384, 384, 1152, 768, 384, 192, 384, 192, 384, 384, 768, 1152, 576, 2880, 384, 192, 1920, 9792, 192, 576, 192, 384, 576, 192, 192], 1);  permute_pooled_embs_auto_grad = None
        getitem: "f16[s0, 36][36284, 1]cuda:0" = split_with_sizes[0]
        getitem_1: "f16[s0, 228][36284, 1]cuda:0" = split_with_sizes[1]
        getitem_2: "f16[s0, 32][36284, 1]cuda:0" = split_with_sizes[2]
        getitem_3: "f16[s0, 32][36284, 1]cuda:0" = split_with_sizes[3]
        getitem_4: "f16[s0, 80][36284, 1]cuda:0" = split_with_sizes[4]
        getitem_5: "f16[s0, 32][36284, 1]cuda:0" = split_with_sizes[5]
        getitem_6: "f16[s0, 16][36284, 1]cuda:0" = split_with_sizes[6]
        getitem_7: "f16[s0, 72][36284, 1]cuda:0" = split_with_sizes[7]
        getitem_8: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[8]
        getitem_9: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[9]
        getitem_10: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[10]
        getitem_11: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[11]
        getitem_12: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[12]
        getitem_13: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[13]
        getitem_14: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[14]
        getitem_15: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[15]
        getitem_16: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[16]
        getitem_17: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[17]
        getitem_18: "f16[s0, 4][36284, 1]cuda:0" = split_with_sizes[18]
        getitem_19: "f16[s0, 2880][36284, 1]cuda:0" = split_with_sizes[19]
        getitem_20: "f16[s0, 3648][36284, 1]cuda:0" = split_with_sizes[20]
        getitem_21: "f16[s0, 768][36284, 1]cuda:0" = split_with_sizes[21]
        getitem_22: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[22]
        getitem_23: "f16[s0, 1152][36284, 1]cuda:0" = split_with_sizes[23]
        getitem_24: "f16[s0, 960][36284, 1]cuda:0" = split_with_sizes[24]
        getitem_25: "f16[s0, 576][36284, 1]cuda:0" = split_with_sizes[25]
        getitem_26: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[26]
        getitem_27: "f16[s0, 768][36284, 1]cuda:0" = split_with_sizes[27]
        getitem_28: "f16[s0, 384][36284, 1]cuda:0" = split_with_sizes[28]
        getitem_29: "f16[s0, 384][36284, 1]cuda:0" = split_with_sizes[29]
        getitem_30: "f16[s0, 1152][36284, 1]cuda:0" = split_with_sizes[30]
        getitem_31: "f16[s0, 768][36284, 1]cuda:0" = split_with_sizes[31]
        getitem_32: "f16[s0, 384][36284, 1]cuda:0" = split_with_sizes[32]
        getitem_33: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[33]
        getitem_34: "f16[s0, 384][36284, 1]cuda:0" = split_with_sizes[34]
        getitem_35: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[35]
        getitem_36: "f16[s0, 384][36284, 1]cuda:0" = split_with_sizes[36]
        getitem_37: "f16[s0, 384][36284, 1]cuda:0" = split_with_sizes[37]
        getitem_38: "f16[s0, 768][36284, 1]cuda:0" = split_with_sizes[38]
        getitem_39: "f16[s0, 1152][36284, 1]cuda:0" = split_with_sizes[39]
        getitem_40: "f16[s0, 576][36284, 1]cuda:0" = split_with_sizes[40]
        getitem_41: "f16[s0, 2880][36284, 1]cuda:0" = split_with_sizes[41]
        getitem_42: "f16[s0, 384][36284, 1]cuda:0" = split_with_sizes[42]
        getitem_43: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[43]
        getitem_44: "f16[s0, 1920][36284, 1]cuda:0" = split_with_sizes[44]
        getitem_45: "f16[s0, 9792][36284, 1]cuda:0" = split_with_sizes[45]
        getitem_46: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[46]
        getitem_47: "f16[s0, 576][36284, 1]cuda:0" = split_with_sizes[47]
        getitem_48: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[48]
        getitem_49: "f16[s0, 384][36284, 1]cuda:0" = split_with_sizes[49]
        getitem_50: "f16[s0, 576][36284, 1]cuda:0" = split_with_sizes[50]
        getitem_51: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[51]
        getitem_52: "f16[s0, 192][36284, 1]cuda:0" = split_with_sizes[52];  split_with_sizes = None
        
         # File: <torch_package_1>.caffe2/torch/fb/model_transform/serving_paradigm/split_concat_transform_structs.py:143 in forward, code: permuted = torch.ops.fbgemm.permute_pooled_embs_auto_grad(
        permute_pooled_embs_auto_grad_1: "f16[s0, 30516][30516, 1]cuda:0" = torch.ops.fbgemm.permute_pooled_embs_auto_grad.default(arg612_1, submod_0_cat_fusion_cpu__offset_dim_list, submod_0_cat_fusion_cpu__permute, submod_0_cat_fusion_cpu__inv_offset_dim_list, submod_0_cat_fusion_cpu__inv_permute);  arg612_1 = submod_0_cat_fusion_cpu__offset_dim_list = submod_0_cat_fusion_cpu__permute = submod_0_cat_fusion_cpu__inv_offset_dim_list = submod_0_cat_fusion_cpu__inv_permute = None
        
         # File: <torch_package_1>.caffe2/torch/fb/model_transform/serving_paradigm/split_concat_transform_structs.py:155 in forward, code: res = permuted.split_with_sizes(self.res_dim_list, dim=1)
        split_with_sizes_1 = torch.ops.aten.split_with_sizes.default(permute_pooled_embs_auto_grad_1, [28, 16, 32, 32, 16, 32, 16, 4, 192, 192, 192, 384, 192, 192, 768, 192, 384, 192, 192, 192, 192, 192, 384, 192, 192, 384, 13056, 192, 192, 192, 384, 192, 192, 384, 192, 768, 192, 384, 2496, 192, 768, 5760, 4], 1);  permute_pooled_embs_auto_grad_1 = None
        getitem_53: "f16[s0, 28][30516, 1]cuda:0" = split_with_sizes_1[0]
        getitem_54: "f16[s0, 16][30516, 1]cuda:0" = split_with_sizes_1[1]
        getitem_55: "f16[s0, 32][30516, 1]cuda:0" = split_with_sizes_1[2]
        getitem_56: "f16[s0, 32][30516, 1]cuda:0" = split_with_sizes_1[3]
        getitem_57: "f16[s0, 16][30516, 1]cuda:0" = split_with_sizes_1[4]
        getitem_58: "f16[s0, 32][30516, 1]cuda:0" = split_with_sizes_1[5]
        getitem_59: "f16[s0, 16][30516, 1]cuda:0" = split_with_sizes_1[6]
        getitem_60: "f16[s0, 4][30516, 1]cuda:0" = split_with_sizes_1[7]
        getitem_61: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[8]
        getitem_62: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[9]
        getitem_63: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[10]
        getitem_64: "f16[s0, 384][30516, 1]cuda:0" = split_with_sizes_1[11]
        getitem_65: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[12]
        getitem_66: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[13]
        getitem_67: "f16[s0, 768][30516, 1]cuda:0" = split_with_sizes_1[14]
        getitem_68: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[15]
        getitem_69: "f16[s0, 384][30516, 1]cuda:0" = split_with_sizes_1[16]
        getitem_70: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[17]
        getitem_71: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[18]
        getitem_72: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[19]
        getitem_73: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[20]
        getitem_74: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[21]
        getitem_75: "f16[s0, 384][30516, 1]cuda:0" = split_with_sizes_1[22]
        getitem_76: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[23]
        getitem_77: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[24]
        getitem_78: "f16[s0, 384][30516, 1]cuda:0" = split_with_sizes_1[25]
        getitem_79: "f16[s0, 13056][30516, 1]cuda:0" = split_with_sizes_1[26]
        getitem_80: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[27]
        getitem_81: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[28]
        getitem_82: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[29]
        getitem_83: "f16[s0, 384][30516, 1]cuda:0" = split_with_sizes_1[30]
        getitem_84: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[31]
        getitem_85: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[32]
        getitem_86: "f16[s0, 384][30516, 1]cuda:0" = split_with_sizes_1[33]
        getitem_87: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[34]
        getitem_88: "f16[s0, 768][30516, 1]cuda:0" = split_with_sizes_1[35]
        getitem_89: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[36]
        getitem_90: "f16[s0, 384][30516, 1]cuda:0" = split_with_sizes_1[37]
        getitem_91: "f16[s0, 2496][30516, 1]cuda:0" = split_with_sizes_1[38]
        getitem_92: "f16[s0, 192][30516, 1]cuda:0" = split_with_sizes_1[39]
        getitem_93: "f16[s0, 768][30516, 1]cuda:0" = split_with_sizes_1[40]
        getitem_94: "f16[s0, 5760][30516, 1]cuda:0" = split_with_sizes_1[41];  split_with_sizes_1 = None
        
         # File: <eval_with_key>.27:103 in forward, code: split_with_sizes = torch.split_with_sizes(input = getitem_8, split_sizes = [3026, 240, 240, 192, 192], dim = 1);  getitem_8 = None
        split_with_sizes_2 = torch.ops.aten.split_with_sizes.default(arg606_1, [3026, 240, 240, 192, 192], 1)
        getitem_96: "f16[s0, 3026][3890, 1]cuda:0" = split_with_sizes_2[0]
        getitem_97: "f16[s0, 240][3890, 1]cuda:0" = split_with_sizes_2[1]
        getitem_98: "f16[s0, 240][3890, 1]cuda:0" = split_with_sizes_2[2]
        getitem_99: "f16[s0, 192][3890, 1]cuda:0" = split_with_sizes_2[3]
        getitem_100: "f16[s0, 192][3890, 1]cuda:0" = split_with_sizes_2[4];  split_with_sizes_2 = None
        
         # File: <eval_with_key>.27:109 in forward, code: split_with_sizes_1 = torch.split_with_sizes(input = getitem_7, split_sizes = [96, 72, 96, 96, 96, 96, 72, 96, 96, 96, 72, 96, 64, 96, 64, 72, 72, 96, 64, 72, 72, 72, 64, 64, 64, 144, 144, 64, 64, 64, 96, 96], dim = 1);  getitem_7 = None
        split_with_sizes_3 = torch.ops.aten.split_with_sizes.default(arg607_1, [96, 72, 96, 96, 96, 96, 72, 96, 96, 96, 72, 96, 64, 96, 64, 72, 72, 96, 64, 72, 72, 72, 64, 64, 64, 144, 144, 64, 64, 64, 96, 96], 1);  arg607_1 = None
        getitem_101: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[0]
        getitem_102: "f16[s0, 72][2688, 1]cuda:0" = split_with_sizes_3[1]
        getitem_103: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[2]
        getitem_104: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[3]
        getitem_105: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[4]
        getitem_106: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[5]
        getitem_107: "f16[s0, 72][2688, 1]cuda:0" = split_with_sizes_3[6]
        getitem_108: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[7]
        getitem_109: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[8]
        getitem_110: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[9]
        getitem_111: "f16[s0, 72][2688, 1]cuda:0" = split_with_sizes_3[10]
        getitem_112: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[11]
        getitem_113: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[12]
        getitem_114: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[13]
        getitem_115: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[14]
        getitem_116: "f16[s0, 72][2688, 1]cuda:0" = split_with_sizes_3[15]
        getitem_117: "f16[s0, 72][2688, 1]cuda:0" = split_with_sizes_3[16]
        getitem_118: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[17]
        getitem_119: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[18]
        getitem_120: "f16[s0, 72][2688, 1]cuda:0" = split_with_sizes_3[19]
        getitem_121: "f16[s0, 72][2688, 1]cuda:0" = split_with_sizes_3[20]
        getitem_122: "f16[s0, 72][2688, 1]cuda:0" = split_with_sizes_3[21]
        getitem_123: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[22]
        getitem_124: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[23]
        getitem_125: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[24]
        getitem_126: "f16[s0, 144][2688, 1]cuda:0" = split_with_sizes_3[25]
        getitem_127: "f16[s0, 144][2688, 1]cuda:0" = split_with_sizes_3[26]
        getitem_128: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[27]
        getitem_129: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[28]
        getitem_130: "f16[s0, 64][2688, 1]cuda:0" = split_with_sizes_3[29]
        getitem_131: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[30]
        getitem_132: "f16[s0, 96][2688, 1]cuda:0" = split_with_sizes_3[31];  split_with_sizes_3 = None
        
         # File: <eval_with_key>.27:113 in forward, code: linear = torch._C._nn.linear(getitem_105, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_105 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute: "f16[240, 192][1, 240]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_101: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_97, permute);  getitem_97 = permute = None
        add_tensor_101: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_101, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_101 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:280 in forward, code: layer_norm = torch.nn.functional.layer_norm(linear, getitem_141, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias, eps = 1e-05);  linear = getitem_141 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias = None
        convert_element_type_120: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_101, torch.float32);  add_tensor_101 = None
        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_120, [1], correction = 0, keepdim = True)
        getitem_133: "f32[s0, 1][1, 1]cuda:0" = var_mean[0]
        getitem_134: "f32[s0, 1][1, 1]cuda:0" = var_mean[1];  var_mean = None
        
         # File: <eval_with_key>.27:116 in forward, code: linear_1 = torch._C._nn.linear(getitem_106, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_106 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_1: "f16[240, 192][1, 240]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_100: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_98, permute_1);  getitem_98 = permute_1 = None
        add_tensor_100: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_100, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_100 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:283 in forward, code: layer_norm_1 = torch.nn.functional.layer_norm(linear_1, getitem_142, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias, eps = 1e-05);  linear_1 = getitem_142 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias = None
        convert_element_type_122: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_100, torch.float32);  add_tensor_100 = None
        var_mean_1 = torch.ops.aten.var_mean.correction(convert_element_type_122, [1], correction = 0, keepdim = True)
        getitem_135: "f32[s0, 1][1, 1]cuda:0" = var_mean_1[0]
        getitem_136: "f32[s0, 1][1, 1]cuda:0" = var_mean_1[1];  var_mean_1 = None
        
         # File: <eval_with_key>.27:119 in forward, code: linear_2 = torch._C._nn.linear(getitem_107, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_107 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_2: "f16[192, 192][1, 192]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_99: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_99, permute_2);  getitem_99 = permute_2 = None
        add_tensor_99: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_99, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_99 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:286 in forward, code: layer_norm_2 = torch.nn.functional.layer_norm(linear_2, getitem_143, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias, eps = 1e-05);  linear_2 = getitem_143 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias = None
        convert_element_type_124: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_99, torch.float32);  add_tensor_99 = None
        var_mean_2 = torch.ops.aten.var_mean.correction(convert_element_type_124, [1], correction = 0, keepdim = True)
        getitem_137: "f32[s0, 1][1, 1]cuda:0" = var_mean_2[0]
        getitem_138: "f32[s0, 1][1, 1]cuda:0" = var_mean_2[1];  var_mean_2 = None
        
         # File: <eval_with_key>.27:122 in forward, code: linear_3 = torch._C._nn.linear(getitem_108, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_108 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_3: "f16[192, 192][1, 192]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_98: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_100, permute_3);  getitem_100 = permute_3 = None
        add_tensor_98: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_98, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_98 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:289 in forward, code: layer_norm_3 = torch.nn.functional.layer_norm(linear_3, getitem_144, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias, eps = 1e-05);  linear_3 = getitem_144 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias = None
        convert_element_type_126: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_98, torch.float32);  add_tensor_98 = None
        var_mean_3 = torch.ops.aten.var_mean.correction(convert_element_type_126, [1], correction = 0, keepdim = True)
        getitem_139: "f32[s0, 1][1, 1]cuda:0" = var_mean_3[0]
        getitem_140: "f32[s0, 1][1, 1]cuda:0" = var_mean_3[1];  var_mean_3 = None
        
         # File: <eval_with_key>.27:158 in forward, code: linear_4 = torch._C._nn.linear(getitem_109, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_109 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_4: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_97: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_101, permute_4);  getitem_101 = permute_4 = None
        add_tensor_97: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_97, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_97 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:358 in forward, code: layer_norm_4 = torch.nn.functional.layer_norm(linear_4, getitem_145, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_4 = getitem_145 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_128: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_97, torch.float32);  add_tensor_97 = None
        var_mean_4 = torch.ops.aten.var_mean.correction(convert_element_type_128, [1], correction = 0, keepdim = True)
        getitem_141: "f32[s0, 1][1, 1]cuda:0" = var_mean_4[0]
        getitem_142: "f32[s0, 1][1, 1]cuda:0" = var_mean_4[1];  var_mean_4 = None
        
         # File: <eval_with_key>.27:161 in forward, code: linear_5 = torch._C._nn.linear(getitem_110, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_110 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_5: "f16[72, 192][1, 72]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_96: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_102, permute_5);  getitem_102 = permute_5 = None
        add_tensor_96: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_96, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_96 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:361 in forward, code: layer_norm_5 = torch.nn.functional.layer_norm(linear_5, getitem_146, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_5 = getitem_146 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_130: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_96, torch.float32);  add_tensor_96 = None
        var_mean_5 = torch.ops.aten.var_mean.correction(convert_element_type_130, [1], correction = 0, keepdim = True)
        getitem_143: "f32[s0, 1][1, 1]cuda:0" = var_mean_5[0]
        getitem_144: "f32[s0, 1][1, 1]cuda:0" = var_mean_5[1];  var_mean_5 = None
        
         # File: <eval_with_key>.27:164 in forward, code: linear_6 = torch._C._nn.linear(getitem_111, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_111 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_6: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_95: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_103, permute_6);  getitem_103 = permute_6 = None
        add_tensor_95: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_95, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_95 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:364 in forward, code: layer_norm_6 = torch.nn.functional.layer_norm(linear_6, getitem_147, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_6 = getitem_147 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_132: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_95, torch.float32);  add_tensor_95 = None
        var_mean_6 = torch.ops.aten.var_mean.correction(convert_element_type_132, [1], correction = 0, keepdim = True)
        getitem_145: "f32[s0, 1][1, 1]cuda:0" = var_mean_6[0]
        getitem_146: "f32[s0, 1][1, 1]cuda:0" = var_mean_6[1];  var_mean_6 = None
        
         # File: <eval_with_key>.27:167 in forward, code: linear_7 = torch._C._nn.linear(getitem_112, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_112 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_7: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_94: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_104, permute_7);  getitem_104 = permute_7 = None
        add_tensor_94: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_94, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_94 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:367 in forward, code: layer_norm_7 = torch.nn.functional.layer_norm(linear_7, getitem_148, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_7 = getitem_148 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_134: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_94, torch.float32);  add_tensor_94 = None
        var_mean_7 = torch.ops.aten.var_mean.correction(convert_element_type_134, [1], correction = 0, keepdim = True)
        getitem_147: "f32[s0, 1][1, 1]cuda:0" = var_mean_7[0]
        getitem_148: "f32[s0, 1][1, 1]cuda:0" = var_mean_7[1];  var_mean_7 = None
        
         # File: <eval_with_key>.27:170 in forward, code: linear_8 = torch._C._nn.linear(getitem_113, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_113 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_8: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_93: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_105, permute_8);  getitem_105 = permute_8 = None
        add_tensor_93: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_93, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_93 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:370 in forward, code: layer_norm_8 = torch.nn.functional.layer_norm(linear_8, getitem_149, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias, eps = 1e-05);  linear_8 = getitem_149 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias = None
        convert_element_type_136: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_93, torch.float32);  add_tensor_93 = None
        var_mean_8 = torch.ops.aten.var_mean.correction(convert_element_type_136, [1], correction = 0, keepdim = True)
        getitem_149: "f32[s0, 1][1, 1]cuda:0" = var_mean_8[0]
        getitem_150: "f32[s0, 1][1, 1]cuda:0" = var_mean_8[1];  var_mean_8 = None
        
         # File: <eval_with_key>.27:173 in forward, code: linear_9 = torch._C._nn.linear(getitem_114, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_114 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_9: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_92: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_106, permute_9);  getitem_106 = permute_9 = None
        add_tensor_92: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_92, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_92 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:373 in forward, code: layer_norm_9 = torch.nn.functional.layer_norm(linear_9, getitem_150, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_9 = getitem_150 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_138: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_92, torch.float32);  add_tensor_92 = None
        var_mean_9 = torch.ops.aten.var_mean.correction(convert_element_type_138, [1], correction = 0, keepdim = True)
        getitem_151: "f32[s0, 1][1, 1]cuda:0" = var_mean_9[0]
        getitem_152: "f32[s0, 1][1, 1]cuda:0" = var_mean_9[1];  var_mean_9 = None
        
         # File: <eval_with_key>.27:176 in forward, code: linear_10 = torch._C._nn.linear(getitem_115, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_115 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_10: "f16[72, 192][1, 72]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_91: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_107, permute_10);  getitem_107 = permute_10 = None
        add_tensor_91: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_91, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_91 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:376 in forward, code: layer_norm_10 = torch.nn.functional.layer_norm(linear_10, getitem_151, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_10 = getitem_151 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_140: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_91, torch.float32);  add_tensor_91 = None
        var_mean_10 = torch.ops.aten.var_mean.correction(convert_element_type_140, [1], correction = 0, keepdim = True)
        getitem_153: "f32[s0, 1][1, 1]cuda:0" = var_mean_10[0]
        getitem_154: "f32[s0, 1][1, 1]cuda:0" = var_mean_10[1];  var_mean_10 = None
        
         # File: <eval_with_key>.27:179 in forward, code: linear_11 = torch._C._nn.linear(getitem_116, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_116 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_11: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_90: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_108, permute_11);  getitem_108 = permute_11 = None
        add_tensor_90: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_90, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_90 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:379 in forward, code: layer_norm_11 = torch.nn.functional.layer_norm(linear_11, getitem_152, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_11 = getitem_152 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_142: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_90, torch.float32);  add_tensor_90 = None
        var_mean_11 = torch.ops.aten.var_mean.correction(convert_element_type_142, [1], correction = 0, keepdim = True)
        getitem_155: "f32[s0, 1][1, 1]cuda:0" = var_mean_11[0]
        getitem_156: "f32[s0, 1][1, 1]cuda:0" = var_mean_11[1];  var_mean_11 = None
        
         # File: <eval_with_key>.27:182 in forward, code: linear_12 = torch._C._nn.linear(getitem_117, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_117 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_12: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_89: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_109, permute_12);  getitem_109 = permute_12 = None
        add_tensor_89: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_89, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_89 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:382 in forward, code: layer_norm_12 = torch.nn.functional.layer_norm(linear_12, getitem_153, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias, eps = 1e-05);  linear_12 = getitem_153 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias = None
        convert_element_type_144: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_89, torch.float32);  add_tensor_89 = None
        var_mean_12 = torch.ops.aten.var_mean.correction(convert_element_type_144, [1], correction = 0, keepdim = True)
        getitem_157: "f32[s0, 1][1, 1]cuda:0" = var_mean_12[0]
        getitem_158: "f32[s0, 1][1, 1]cuda:0" = var_mean_12[1];  var_mean_12 = None
        
         # File: <eval_with_key>.27:185 in forward, code: linear_13 = torch._C._nn.linear(getitem_118, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_118 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_13: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_88: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_110, permute_13);  getitem_110 = permute_13 = None
        add_tensor_88: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_88, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_88 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:385 in forward, code: layer_norm_13 = torch.nn.functional.layer_norm(linear_13, getitem_154, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_13 = getitem_154 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_146: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_88, torch.float32);  add_tensor_88 = None
        var_mean_13 = torch.ops.aten.var_mean.correction(convert_element_type_146, [1], correction = 0, keepdim = True)
        getitem_159: "f32[s0, 1][1, 1]cuda:0" = var_mean_13[0]
        getitem_160: "f32[s0, 1][1, 1]cuda:0" = var_mean_13[1];  var_mean_13 = None
        
         # File: <eval_with_key>.27:188 in forward, code: linear_14 = torch._C._nn.linear(getitem_119, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_119 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_14: "f16[72, 192][1, 72]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_87: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_111, permute_14);  getitem_111 = permute_14 = None
        add_tensor_87: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_87, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_87 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:388 in forward, code: layer_norm_14 = torch.nn.functional.layer_norm(linear_14, getitem_155, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_14 = getitem_155 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_148: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_87, torch.float32);  add_tensor_87 = None
        var_mean_14 = torch.ops.aten.var_mean.correction(convert_element_type_148, [1], correction = 0, keepdim = True)
        getitem_161: "f32[s0, 1][1, 1]cuda:0" = var_mean_14[0]
        getitem_162: "f32[s0, 1][1, 1]cuda:0" = var_mean_14[1];  var_mean_14 = None
        
         # File: <eval_with_key>.27:191 in forward, code: linear_15 = torch._C._nn.linear(getitem_120, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_120 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_15: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_86: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_112, permute_15);  getitem_112 = permute_15 = None
        add_tensor_86: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_86, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_86 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:391 in forward, code: layer_norm_15 = torch.nn.functional.layer_norm(linear_15, getitem_156, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_15 = getitem_156 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_150: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_86, torch.float32);  add_tensor_86 = None
        var_mean_15 = torch.ops.aten.var_mean.correction(convert_element_type_150, [1], correction = 0, keepdim = True)
        getitem_163: "f32[s0, 1][1, 1]cuda:0" = var_mean_15[0]
        getitem_164: "f32[s0, 1][1, 1]cuda:0" = var_mean_15[1];  var_mean_15 = None
        
         # File: <eval_with_key>.27:194 in forward, code: linear_16 = torch._C._nn.linear(getitem_121, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_121 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_16: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_85: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_113, permute_16);  getitem_113 = permute_16 = None
        add_tensor_85: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_85, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_85 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:394 in forward, code: layer_norm_16 = torch.nn.functional.layer_norm(linear_16, getitem_157, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_16 = getitem_157 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_152: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_85, torch.float32);  add_tensor_85 = None
        var_mean_16 = torch.ops.aten.var_mean.correction(convert_element_type_152, [1], correction = 0, keepdim = True)
        getitem_165: "f32[s0, 1][1, 1]cuda:0" = var_mean_16[0]
        getitem_166: "f32[s0, 1][1, 1]cuda:0" = var_mean_16[1];  var_mean_16 = None
        
         # File: <eval_with_key>.27:197 in forward, code: linear_17 = torch._C._nn.linear(getitem_122, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_122 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_17: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_84: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_114, permute_17);  getitem_114 = permute_17 = None
        add_tensor_84: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_84, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_84 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:397 in forward, code: layer_norm_17 = torch.nn.functional.layer_norm(linear_17, getitem_158, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_17 = getitem_158 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_154: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_84, torch.float32);  add_tensor_84 = None
        var_mean_17 = torch.ops.aten.var_mean.correction(convert_element_type_154, [1], correction = 0, keepdim = True)
        getitem_167: "f32[s0, 1][1, 1]cuda:0" = var_mean_17[0]
        getitem_168: "f32[s0, 1][1, 1]cuda:0" = var_mean_17[1];  var_mean_17 = None
        
         # File: <eval_with_key>.27:200 in forward, code: linear_18 = torch._C._nn.linear(getitem_123, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_123 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_18: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_83: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_115, permute_18);  getitem_115 = permute_18 = None
        add_tensor_83: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_83, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_83 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:400 in forward, code: layer_norm_18 = torch.nn.functional.layer_norm(linear_18, getitem_159, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_18 = getitem_159 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_156: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_83, torch.float32);  add_tensor_83 = None
        var_mean_18 = torch.ops.aten.var_mean.correction(convert_element_type_156, [1], correction = 0, keepdim = True)
        getitem_169: "f32[s0, 1][1, 1]cuda:0" = var_mean_18[0]
        getitem_170: "f32[s0, 1][1, 1]cuda:0" = var_mean_18[1];  var_mean_18 = None
        
         # File: <eval_with_key>.27:203 in forward, code: linear_19 = torch._C._nn.linear(getitem_124, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_124 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_19: "f16[72, 192][1, 72]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_82: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_116, permute_19);  getitem_116 = permute_19 = None
        add_tensor_82: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_82, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_82 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:403 in forward, code: layer_norm_19 = torch.nn.functional.layer_norm(linear_19, getitem_160, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_19 = getitem_160 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_158: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_82, torch.float32);  add_tensor_82 = None
        var_mean_19 = torch.ops.aten.var_mean.correction(convert_element_type_158, [1], correction = 0, keepdim = True)
        getitem_171: "f32[s0, 1][1, 1]cuda:0" = var_mean_19[0]
        getitem_172: "f32[s0, 1][1, 1]cuda:0" = var_mean_19[1];  var_mean_19 = None
        
         # File: <eval_with_key>.27:206 in forward, code: linear_20 = torch._C._nn.linear(getitem_125, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_125 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_20: "f16[72, 192][1, 72]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_81: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_117, permute_20);  getitem_117 = permute_20 = None
        add_tensor_81: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_81, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_81 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:406 in forward, code: layer_norm_20 = torch.nn.functional.layer_norm(linear_20, getitem_161, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_20 = getitem_161 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_160: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_81, torch.float32);  add_tensor_81 = None
        var_mean_20 = torch.ops.aten.var_mean.correction(convert_element_type_160, [1], correction = 0, keepdim = True)
        getitem_173: "f32[s0, 1][1, 1]cuda:0" = var_mean_20[0]
        getitem_174: "f32[s0, 1][1, 1]cuda:0" = var_mean_20[1];  var_mean_20 = None
        
         # File: <eval_with_key>.27:209 in forward, code: linear_21 = torch._C._nn.linear(getitem_126, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_126 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_21: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_80: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_118, permute_21);  getitem_118 = permute_21 = None
        add_tensor_80: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_80, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_80 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:409 in forward, code: layer_norm_21 = torch.nn.functional.layer_norm(linear_21, getitem_162, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_21 = getitem_162 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_162: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_80, torch.float32);  add_tensor_80 = None
        var_mean_21 = torch.ops.aten.var_mean.correction(convert_element_type_162, [1], correction = 0, keepdim = True)
        getitem_175: "f32[s0, 1][1, 1]cuda:0" = var_mean_21[0]
        getitem_176: "f32[s0, 1][1, 1]cuda:0" = var_mean_21[1];  var_mean_21 = None
        
         # File: <eval_with_key>.27:212 in forward, code: linear_22 = torch._C._nn.linear(getitem_127, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_127 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_22: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_79: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_119, permute_22);  getitem_119 = permute_22 = None
        add_tensor_79: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_79, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_79 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:412 in forward, code: layer_norm_22 = torch.nn.functional.layer_norm(linear_22, getitem_163, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias, eps = 1e-05);  linear_22 = getitem_163 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias = None
        convert_element_type_164: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_79, torch.float32);  add_tensor_79 = None
        var_mean_22 = torch.ops.aten.var_mean.correction(convert_element_type_164, [1], correction = 0, keepdim = True)
        getitem_177: "f32[s0, 1][1, 1]cuda:0" = var_mean_22[0]
        getitem_178: "f32[s0, 1][1, 1]cuda:0" = var_mean_22[1];  var_mean_22 = None
        
         # File: <eval_with_key>.27:215 in forward, code: linear_23 = torch._C._nn.linear(getitem_128, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_128 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_23: "f16[72, 192][1, 72]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_78: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_120, permute_23);  getitem_120 = permute_23 = None
        add_tensor_78: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_78, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_78 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:415 in forward, code: layer_norm_23 = torch.nn.functional.layer_norm(linear_23, getitem_164, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_23 = getitem_164 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_166: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_78, torch.float32);  add_tensor_78 = None
        var_mean_23 = torch.ops.aten.var_mean.correction(convert_element_type_166, [1], correction = 0, keepdim = True)
        getitem_179: "f32[s0, 1][1, 1]cuda:0" = var_mean_23[0]
        getitem_180: "f32[s0, 1][1, 1]cuda:0" = var_mean_23[1];  var_mean_23 = None
        
         # File: <eval_with_key>.27:218 in forward, code: linear_24 = torch._C._nn.linear(getitem_129, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_129 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_24: "f16[72, 192][1, 72]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_77: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_121, permute_24);  getitem_121 = permute_24 = None
        add_tensor_77: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_77, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_77 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:418 in forward, code: layer_norm_24 = torch.nn.functional.layer_norm(linear_24, getitem_165, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias, eps = 1e-05);  linear_24 = getitem_165 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias = None
        convert_element_type_168: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_77, torch.float32);  add_tensor_77 = None
        var_mean_24 = torch.ops.aten.var_mean.correction(convert_element_type_168, [1], correction = 0, keepdim = True)
        getitem_181: "f32[s0, 1][1, 1]cuda:0" = var_mean_24[0]
        getitem_182: "f32[s0, 1][1, 1]cuda:0" = var_mean_24[1];  var_mean_24 = None
        
         # File: <eval_with_key>.27:221 in forward, code: linear_25 = torch._C._nn.linear(getitem_130, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_130 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_25: "f16[72, 192][1, 72]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_76: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_122, permute_25);  getitem_122 = permute_25 = None
        add_tensor_76: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_76, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_76 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:421 in forward, code: layer_norm_25 = torch.nn.functional.layer_norm(linear_25, getitem_166, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_25 = getitem_166 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_170: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_76, torch.float32);  add_tensor_76 = None
        var_mean_25 = torch.ops.aten.var_mean.correction(convert_element_type_170, [1], correction = 0, keepdim = True)
        getitem_183: "f32[s0, 1][1, 1]cuda:0" = var_mean_25[0]
        getitem_184: "f32[s0, 1][1, 1]cuda:0" = var_mean_25[1];  var_mean_25 = None
        
         # File: <eval_with_key>.27:224 in forward, code: linear_26 = torch._C._nn.linear(getitem_131, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_131 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_26: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_75: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_123, permute_26);  getitem_123 = permute_26 = None
        add_tensor_75: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_75, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_75 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:424 in forward, code: layer_norm_26 = torch.nn.functional.layer_norm(linear_26, getitem_167, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_26 = getitem_167 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_172: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_75, torch.float32);  add_tensor_75 = None
        var_mean_26 = torch.ops.aten.var_mean.correction(convert_element_type_172, [1], correction = 0, keepdim = True)
        getitem_185: "f32[s0, 1][1, 1]cuda:0" = var_mean_26[0]
        getitem_186: "f32[s0, 1][1, 1]cuda:0" = var_mean_26[1];  var_mean_26 = None
        
         # File: <eval_with_key>.27:227 in forward, code: linear_27 = torch._C._nn.linear(getitem_132, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_132 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_27: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_74: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_124, permute_27);  getitem_124 = permute_27 = None
        add_tensor_74: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_74, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_74 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:427 in forward, code: layer_norm_27 = torch.nn.functional.layer_norm(linear_27, getitem_168, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_27 = getitem_168 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_174: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_74, torch.float32);  add_tensor_74 = None
        var_mean_27 = torch.ops.aten.var_mean.correction(convert_element_type_174, [1], correction = 0, keepdim = True)
        getitem_187: "f32[s0, 1][1, 1]cuda:0" = var_mean_27[0]
        getitem_188: "f32[s0, 1][1, 1]cuda:0" = var_mean_27[1];  var_mean_27 = None
        
         # File: <eval_with_key>.27:230 in forward, code: linear_28 = torch._C._nn.linear(getitem_133, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_133 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_28: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_73: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_125, permute_28);  getitem_125 = permute_28 = None
        add_tensor_73: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_73, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_73 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:430 in forward, code: layer_norm_28 = torch.nn.functional.layer_norm(linear_28, getitem_169, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_28 = getitem_169 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_176: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_73, torch.float32);  add_tensor_73 = None
        var_mean_28 = torch.ops.aten.var_mean.correction(convert_element_type_176, [1], correction = 0, keepdim = True)
        getitem_189: "f32[s0, 1][1, 1]cuda:0" = var_mean_28[0]
        getitem_190: "f32[s0, 1][1, 1]cuda:0" = var_mean_28[1];  var_mean_28 = None
        
         # File: <eval_with_key>.27:233 in forward, code: linear_29 = torch._C._nn.linear(getitem_134, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_134 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_29: "f16[144, 192][1, 144]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_72: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_126, permute_29);  getitem_126 = permute_29 = None
        add_tensor_72: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_72, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_72 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:433 in forward, code: layer_norm_29 = torch.nn.functional.layer_norm(linear_29, getitem_170, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias, eps = 1e-05);  linear_29 = getitem_170 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias = None
        convert_element_type_178: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_72, torch.float32);  add_tensor_72 = None
        var_mean_29 = torch.ops.aten.var_mean.correction(convert_element_type_178, [1], correction = 0, keepdim = True)
        getitem_191: "f32[s0, 1][1, 1]cuda:0" = var_mean_29[0]
        getitem_192: "f32[s0, 1][1, 1]cuda:0" = var_mean_29[1];  var_mean_29 = None
        
         # File: <eval_with_key>.27:236 in forward, code: linear_30 = torch._C._nn.linear(getitem_135, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_135 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_30: "f16[144, 192][1, 144]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_71: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_127, permute_30);  getitem_127 = permute_30 = None
        add_tensor_71: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_71, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_71 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:436 in forward, code: layer_norm_30 = torch.nn.functional.layer_norm(linear_30, getitem_171, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias, eps = 1e-05);  linear_30 = getitem_171 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias = None
        convert_element_type_180: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_71, torch.float32);  add_tensor_71 = None
        var_mean_30 = torch.ops.aten.var_mean.correction(convert_element_type_180, [1], correction = 0, keepdim = True)
        getitem_193: "f32[s0, 1][1, 1]cuda:0" = var_mean_30[0]
        getitem_194: "f32[s0, 1][1, 1]cuda:0" = var_mean_30[1];  var_mean_30 = None
        
         # File: <eval_with_key>.27:239 in forward, code: linear_31 = torch._C._nn.linear(getitem_136, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_136 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_31: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_70: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_128, permute_31);  getitem_128 = permute_31 = None
        add_tensor_70: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_70, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_70 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:439 in forward, code: layer_norm_31 = torch.nn.functional.layer_norm(linear_31, getitem_172, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_31 = getitem_172 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_182: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_70, torch.float32);  add_tensor_70 = None
        var_mean_31 = torch.ops.aten.var_mean.correction(convert_element_type_182, [1], correction = 0, keepdim = True)
        getitem_195: "f32[s0, 1][1, 1]cuda:0" = var_mean_31[0]
        getitem_196: "f32[s0, 1][1, 1]cuda:0" = var_mean_31[1];  var_mean_31 = None
        
         # File: <eval_with_key>.27:242 in forward, code: linear_32 = torch._C._nn.linear(getitem_137, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_137 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_32: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_69: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_129, permute_32);  getitem_129 = permute_32 = None
        add_tensor_69: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_69, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_69 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:442 in forward, code: layer_norm_32 = torch.nn.functional.layer_norm(linear_32, getitem_173, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_32 = getitem_173 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_184: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_69, torch.float32);  add_tensor_69 = None
        var_mean_32 = torch.ops.aten.var_mean.correction(convert_element_type_184, [1], correction = 0, keepdim = True)
        getitem_197: "f32[s0, 1][1, 1]cuda:0" = var_mean_32[0]
        getitem_198: "f32[s0, 1][1, 1]cuda:0" = var_mean_32[1];  var_mean_32 = None
        
         # File: <eval_with_key>.27:245 in forward, code: linear_33 = torch._C._nn.linear(getitem_138, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_138 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_33: "f16[64, 192][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_68: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_130, permute_33);  getitem_130 = permute_33 = None
        add_tensor_68: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_68, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_68 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:445 in forward, code: layer_norm_33 = torch.nn.functional.layer_norm(linear_33, getitem_174, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_33 = getitem_174 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_186: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_68, torch.float32);  add_tensor_68 = None
        var_mean_33 = torch.ops.aten.var_mean.correction(convert_element_type_186, [1], correction = 0, keepdim = True)
        getitem_199: "f32[s0, 1][1, 1]cuda:0" = var_mean_33[0]
        getitem_200: "f32[s0, 1][1, 1]cuda:0" = var_mean_33[1];  var_mean_33 = None
        
         # File: <eval_with_key>.27:248 in forward, code: linear_34 = torch._C._nn.linear(getitem_139, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_139 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_34: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_67: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_131, permute_34);  getitem_131 = permute_34 = None
        add_tensor_67: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_67, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_67 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:448 in forward, code: layer_norm_34 = torch.nn.functional.layer_norm(linear_34, getitem_175, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_34 = getitem_175 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_188: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_67, torch.float32);  add_tensor_67 = None
        var_mean_34 = torch.ops.aten.var_mean.correction(convert_element_type_188, [1], correction = 0, keepdim = True)
        getitem_201: "f32[s0, 1][1, 1]cuda:0" = var_mean_34[0]
        getitem_202: "f32[s0, 1][1, 1]cuda:0" = var_mean_34[1];  var_mean_34 = None
        
         # File: <eval_with_key>.27:251 in forward, code: linear_35 = torch._C._nn.linear(getitem_140, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  getitem_140 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        permute_35: "f16[96, 192][1, 96]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_66: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.mm.default(getitem_132, permute_35);  getitem_132 = permute_35 = None
        add_tensor_66: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_66, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b);  mm_default_66 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:451 in forward, code: layer_norm_35 = torch.nn.functional.layer_norm(linear_35, getitem_176, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_35 = getitem_176 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_190: "f32[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_66, torch.float32);  add_tensor_66 = None
        var_mean_35 = torch.ops.aten.var_mean.correction(convert_element_type_190, [1], correction = 0, keepdim = True)
        getitem_203: "f32[s0, 1][1, 1]cuda:0" = var_mean_35[0]
        getitem_204: "f32[s0, 1][1, 1]cuda:0" = var_mean_35[1];  var_mean_35 = None
        
        # No stacktrace found for following nodes
        cat_3: "f16[256][1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_b]);  submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_b = None
        
         # File: <eval_with_key>.27:110 in forward, code: pow_1 = torch.pow(getitem_104, 2)
        pow_1: "f16[s0, 3026][3026, 1]cuda:0" = torch.ops.aten.pow.Tensor_Scalar(getitem_96, 2)
        
         # File: <eval_with_key>.27:155 in forward, code: cat = torch.cat(tensors = [getitem_104, pow_1], dim = 1);  pow_1 = None
        cat_1: "f16[s0, 6052][6052, 1]cuda:0" = torch.ops.aten.cat.default([getitem_96, pow_1], 1);  pow_1 = None
        
        # No stacktrace found for following nodes
        cat_2: "f16[256, 6052][6052, 1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_w]);  submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_0_shards_1_w = None
        permute_36: "f16[6052, 256][1, 6052]cuda:0" = torch.ops.aten.permute.default(cat_2, [1, 0]);  cat_2 = None
        mm_default_65: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.mm.default(cat_1, permute_36);  cat_1 = permute_36 = None
        add_tensor_65: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_65, cat_3);  mm_default_65 = cat_3 = None
        
         # File: <eval_with_key>.27:461 in forward, code: layer_norm_36 = torch.nn.functional.layer_norm(cat_38, getitem_177, weight = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale, bias = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias, eps = 1e-05);  getitem_177 = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = None
        convert_element_type_192: "f32[s0, 256][256, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_65, torch.float32)
        var_mean_36 = torch.ops.aten.var_mean.correction(convert_element_type_192, [1], correction = 0, keepdim = True)
        getitem_205: "f32[s0, 1][1, 1]cuda:0" = var_mean_36[0]
        getitem_206: "f32[s0, 1][1, 1]cuda:0" = var_mean_36[1];  var_mean_36 = None
        
        # No stacktrace found for following nodes
        cat_6: "f16[512][1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b, submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_b]);  submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_b = submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:462 in forward, code: cat_39 = torch.cat(tensors = [getitem_61, getitem_103, getitem_60, getitem_102, getitem_59, getitem_101, getitem_58, getitem_100, getitem_57, getitem_99, getitem_56, getitem_98, getitem_55, getitem_97, getitem_54], dim = 1);  getitem_61 = getitem_103 = getitem_60 = getitem_102 = getitem_59 = getitem_101 = getitem_58 = getitem_100 = getitem_57 = getitem_99 = getitem_56 = getitem_98 = getitem_55 = getitem_97 = getitem_54 = None
        cat_4: "f16[s0, 700][700, 1]cuda:0" = torch.ops.aten.cat.default([getitem, getitem_53, getitem_1, getitem_54, getitem_2, getitem_55, getitem_3, getitem_56, getitem_4, getitem_57, getitem_5, getitem_58, getitem_6, getitem_59, getitem_7], 1);  getitem = getitem_53 = getitem_1 = getitem_54 = getitem_2 = getitem_55 = getitem_3 = getitem_56 = getitem_4 = getitem_57 = getitem_5 = getitem_58 = getitem_6 = getitem_59 = getitem_7 = None
        
        # No stacktrace found for following nodes
        cat_5: "f16[512, 700][700, 1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w, submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_w]);  submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_0_shards_0_w = submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_0_submodules_0_shards_0_w = None
        permute_37: "f16[700, 512][1, 700]cuda:0" = torch.ops.aten.permute.default(cat_5, [1, 0]);  cat_5 = None
        addmm_37: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.addmm.default(cat_6, cat_4, permute_37);  cat_6 = cat_4 = permute_37 = None
        slice_2: "f16[s0, 256][512, 1]cuda:0" = torch.ops.aten.slice.Tensor(addmm_37, 1, 0, 256)
        clone: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.clone.default(slice_2, memory_format = torch.contiguous_format);  slice_2 = None
        
         # File: <eval_with_key>.27:493 in forward, code: layer_norm_37 = torch.nn.functional.layer_norm(linear_38, getitem_178, weight = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale, bias = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias, eps = 1e-05);  getitem_178 = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = None
        convert_element_type_202: "f32[s0, 256][256, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone, torch.float32)
        var_mean_37 = torch.ops.aten.var_mean.correction(convert_element_type_202, [1], correction = 0, keepdim = True)
        getitem_207: "f32[s0, 1][1, 1]cuda:0" = var_mean_37[0]
        getitem_208: "f32[s0, 1][1, 1]cuda:0" = var_mean_37[1];  var_mean_37 = None
        
         # File: <eval_with_key>.27:505 in forward, code: add_9 = getitem_1 + main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb;  main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb = None
        add_1095: "f16[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(arg613_1, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_pos_emb = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_210: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1095, torch.float32);  add_1095 = None
        var_mean_38 = torch.ops.aten.var_mean.correction(convert_element_type_210, [2], correction = 0, keepdim = True)
        getitem_209: "f32[s0, 200, 1][200, 1, 1]cuda:0" = var_mean_38[0]
        getitem_210: "f32[s0, 200, 1][200, 1, 1]cuda:0" = var_mean_38[1];  var_mean_38 = None
        
         # File: <eval_with_key>.27:507 in forward, code: add_10 = getitem + main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb;  main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb = None
        add_1100: "f16[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(arg614_1, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_pos_emb = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_212: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1100, torch.float32);  add_1100 = None
        var_mean_39 = torch.ops.aten.var_mean.correction(convert_element_type_212, [2], correction = 0, keepdim = True)
        getitem_211: "f32[s0, 200, 1][200, 1, 1]cuda:0" = var_mean_39[0]
        getitem_212: "f32[s0, 200, 1][200, 1, 1]cuda:0" = var_mean_39[1];  var_mean_39 = None
        
         # File: <torch_package_1>.caffe2/torch/fb/predictor/modules/tensors_to_device_module.py:57 in forward, code: return [
        sym_size_int: "Sym(s0)" = torch.ops.aten.sym_size.int(arg606_1, 0);  arg606_1 = None
        
         # File: <eval_with_key>.27:537 in forward, code: repeat = main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb.repeat(getitem_179, 1, 1);  main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb = getitem_179 = None
        repeat: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.repeat.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb, [sym_size_int, 1, 1]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_224: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(repeat, torch.float32)
        var_mean_40 = torch.ops.aten.var_mean.correction(convert_element_type_224, [2], correction = 0, keepdim = True)
        getitem_213: "f32[s0, 32, 1][32, 1, 1]cuda:0" = var_mean_40[0]
        getitem_214: "f32[s0, 32, 1][32, 1, 1]cuda:0" = var_mean_40[1];  var_mean_40 = None
        
         # File: <eval_with_key>.27:541 in forward, code: repeat_1 = main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb.repeat(getitem_180, 1, 1);  main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb = getitem_180 = None
        repeat_1: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.repeat.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb, [sym_size_int, 1, 1]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_226: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(repeat_1, torch.float32)
        var_mean_41 = torch.ops.aten.var_mean.correction(convert_element_type_226, [2], correction = 0, keepdim = True)
        getitem_215: "f32[s0, 32, 1][32, 1, 1]cuda:0" = var_mean_41[0]
        getitem_216: "f32[s0, 32, 1][32, 1, 1]cuda:0" = var_mean_41[1];  var_mean_41 = None
        
         # File: <eval_with_key>.27:461 in forward, code: layer_norm_36 = torch.nn.functional.layer_norm(cat_38, getitem_177, weight = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale, bias = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias, eps = 1e-05);  getitem_177 = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = None
        sub_343: "f32[s0, 256][256, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_192, getitem_206);  convert_element_type_192 = getitem_206 = None
        add_998: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_205, 1e-05);  getitem_205 = None
        rsqrt_36: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_998);  add_998 = None
        mul_599: "f32[s0, 256][256, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_343, rsqrt_36);  sub_343 = rsqrt_36 = None
        mul_600: "f32[s0, 256][256, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_599, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale);  mul_599 = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = None
        add_999: "f32[s0, 256][256, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_600, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias);  mul_600 = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = None
        convert_element_type_193: "f16[s0, 256][256, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_999, torch.float16);  add_999 = None
        
         # File: <eval_with_key>.27:464 in forward, code: sigmoid = torch.sigmoid(layer_norm_36);  layer_norm_36 = None
        sigmoid: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_193);  convert_element_type_193 = None
        
         # File: <eval_with_key>.27:490 in forward, code: mul = cat_38 * unsqueeze_n_times;  cat_38 = unsqueeze_n_times = None
        mul_635: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_65, sigmoid);  add_tensor_65 = sigmoid = None
        
         # File: <eval_with_key>.27:500 in forward, code: linear_42 = torch._C._nn.linear(mul, main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w, main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b);  mul = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b = None
        permute_40: "f16[256, 3026][1, 256]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_64: "f16[s0, 3026][3026, 1]cuda:0" = torch.ops.aten.mm.default(mul_635, permute_40);  mul_635 = permute_40 = None
        add_tensor_64: "f16[s0, 3026][3026, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_64, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b);  mm_default_64 = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_1_shards_0_b = None
        
         # File: <eval_with_key>.27:503 in forward, code: sigmoid_2 = torch.sigmoid(linear_42);  linear_42 = None
        sigmoid_2: "f16[s0, 3026][3026, 1]cuda:0" = torch.ops.aten.sigmoid.default(add_tensor_64);  add_tensor_64 = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        mul_659: "f16[s0, 3026][3026, 1]cuda:0" = torch.ops.aten.mul.Tensor(getitem_96, sigmoid_2);  getitem_96 = sigmoid_2 = None
        
         # File: <eval_with_key>.27:523 in forward, code: linear_43 = torch._C._nn.linear(main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_mul_module, main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w, main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b);  main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = None
        permute_41: "f16[3026, 256][1, 3026]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w = None
        addmm_41: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.addmm.default(submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b, mul_659, permute_41);  submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = permute_41 = None
        
         # File: <eval_with_key>.27:532 in forward, code: cat_40 = torch.cat(tensors = [linear_43, main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_mul_module], dim = 1);  linear_43 = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_gating_archs_0_mul_module = None
        cat_7: "f16[s0, 3282][3282, 1]cuda:0" = torch.ops.aten.cat.default([addmm_41, mul_659], 1);  addmm_41 = mul_659 = None
        
         # File: <eval_with_key>.27:560 in forward, code: layer_norm_38 = torch.nn.functional.layer_norm(cat_40, getitem_183, weight = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale, bias = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias, eps = 1e-05);  getitem_183 = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = None
        convert_element_type_234: "f32[s0, 3282][3282, 1]cuda:0" = torch.ops.prims.convert_element_type.default(cat_7, torch.float32)
        var_mean_42 = torch.ops.aten.var_mean.correction(convert_element_type_234, [1], correction = 0, keepdim = True)
        getitem_217: "f32[s0, 1][1, 1]cuda:0" = var_mean_42[0]
        getitem_218: "f32[s0, 1][1, 1]cuda:0" = var_mean_42[1];  var_mean_42 = None
        
         # File: <eval_with_key>.27:493 in forward, code: layer_norm_37 = torch.nn.functional.layer_norm(linear_38, getitem_178, weight = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale, bias = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias, eps = 1e-05);  getitem_178 = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = None
        sub_364: "f32[s0, 256][256, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_202, getitem_208);  convert_element_type_202 = getitem_208 = None
        add_1064: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_207, 1e-05);  getitem_207 = None
        rsqrt_37: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1064);  add_1064 = None
        mul_638: "f32[s0, 256][256, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_364, rsqrt_37);  sub_364 = rsqrt_37 = None
        mul_639: "f32[s0, 256][256, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_638, submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale);  mul_638 = submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_scale = None
        add_1065: "f32[s0, 256][256, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_639, submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias);  mul_639 = submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_0_submodules_1_norm_submodules_0_bias = None
        convert_element_type_203: "f16[s0, 256][256, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1065, torch.float16);  add_1065 = None
        
         # File: <eval_with_key>.27:501 in forward, code: sigmoid_1 = torch.sigmoid(layer_norm_37);  layer_norm_37 = None
        sigmoid_1: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_203);  convert_element_type_203 = None
        
         # File: <eval_with_key>.27:525 in forward, code: mul_1 = linear_38 * unsqueeze_n_times_1;  linear_38 = unsqueeze_n_times_1 = None
        mul_682: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone, sigmoid_1);  clone = sigmoid_1 = None
        
         # File: <eval_with_key>.27:535 in forward, code: linear_44 = torch._C._nn.linear(mul_1, main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b);  mul_1 = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b = None
        permute_44: "f16[256, 1024][1, 256]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_63: "f16[s0, 1024][1024, 1]cuda:0" = torch.ops.aten.mm.default(mul_682, permute_44);  mul_682 = permute_44 = None
        add_tensor_63: "f16[s0, 1024][1024, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_63, submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b);  mm_default_63 = submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:563 in forward, code: layer_norm_39 = torch.nn.functional.layer_norm(linear_44, getitem_184, weight = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale, bias = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias, eps = 1e-05);  getitem_184 = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias = None
        convert_element_type_236: "f32[s0, 1024][1024, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_63, torch.float32)
        var_mean_43 = torch.ops.aten.var_mean.correction(convert_element_type_236, [1], correction = 0, keepdim = True)
        getitem_219: "f32[s0, 1][1, 1]cuda:0" = var_mean_43[0]
        getitem_220: "f32[s0, 1][1, 1]cuda:0" = var_mean_43[1];  var_mean_43 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_400: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_224, getitem_214);  convert_element_type_224 = getitem_214 = None
        add_1188: "f32[s0, 32, 1][32, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_213, 1e-05);  getitem_213 = None
        rsqrt_40: "f32[s0, 32, 1][32, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1188);  add_1188 = None
        mul_725: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_400, rsqrt_40);  sub_400 = rsqrt_40 = None
        mul_726: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_725, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight);  mul_725 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_weight = None
        add_1189: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_726, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias);  mul_726 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_x_0_bias = None
        convert_element_type_225: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1189, torch.float16);  add_1189 = None
        
         # File: <eval_with_key>.27:537 in forward, code: repeat = main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb.repeat(getitem_179, 1, 1);  main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_seed_emb = getitem_179 = None
        sym_size_int_13: "Sym(s0)" = torch.ops.aten.sym_size.int(repeat, 0)
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        mul_744: "Sym(32*s0)" = sym_size_int_13 * 32
        view_4: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_225, [mul_744, 64]);  convert_element_type_225 = mul_744 = None
        permute_45: "f16[64, 64][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight = None
        addmm_43: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.addmm.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias, view_4, permute_45);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias = view_4 = permute_45 = None
        view_5: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.reshape.default(addmm_43, [sym_size_int_13, 32, 64]);  addmm_43 = None
        
         # File: <eval_with_key>.27:576 in forward, code: view_2 = main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj.view(getitem_185, getitem_186, 1, 64);  main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_q_proj = None
        view_10: "f16[s0, 32, 1, 64][2048, 64, 64, 1]cuda:0" = torch.ops.aten.reshape.default(view_5, [sym_size_int, 32, 1, 64]);  view_5 = None
        
         # File: <eval_with_key>.27:582 in forward, code: permute_2 = view_2.permute(0, 2, 1, 3);  view_2 = None
        permute_49: "f16[s0, 1, 32, 64][2048, 64, 64, 1]cuda:0" = torch.ops.aten.permute.default(view_10, [0, 2, 1, 3]);  view_10 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_378: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_210, getitem_210);  convert_element_type_210 = getitem_210 = None
        add_1112: "f32[s0, 200, 1][200, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_209, 1e-05);  getitem_209 = None
        rsqrt_38: "f32[s0, 200, 1][200, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1112);  add_1112 = None
        mul_662: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_378, rsqrt_38);  sub_378 = rsqrt_38 = None
        mul_663: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_662, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight);  mul_662 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_weight = None
        add_1113: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_663, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias);  mul_663 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0_bias = None
        convert_element_type_211: "f16[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1113, torch.float16);  add_1113 = None
        
         # File: <torch_package_1>.caffe2/torch/fb/predictor/modules/tensors_to_device_module.py:57 in forward, code: return [
        sym_size_int_7: "Sym(s0)" = torch.ops.aten.sym_size.int(arg613_1, 0);  arg613_1 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        mul_687: "Sym(200*s0)" = sym_size_int_7 * 200
        view: "f16[200*s0, 64][64, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_211, [mul_687, 64]);  mul_687 = None
        permute_42: "f16[64, 64][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight = None
        mm: "f16[200*s0, 64][64, 1]cuda:0" = torch.ops.aten.mm.default(view, permute_42);  view = permute_42 = None
        view_1: "f16[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.reshape.default(mm, [sym_size_int_7, 200, 64]);  mm = sym_size_int_7 = None
        
         # File: <eval_with_key>.27:574 in forward, code: view = main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj.view(getitem_185, getitem_181, 1, 64);  main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_attns_0_k_proj = None
        view_8: "f16[s0, 200, 1, 64][12800, 64, 64, 1]cuda:0" = torch.ops.aten.reshape.default(view_1, [sym_size_int, 200, 1, 64]);  view_1 = None
        
         # File: <eval_with_key>.27:580 in forward, code: permute = view.permute(0, 2, 1, 3);  view = None
        permute_47: "f16[s0, 1, 200, 64][12800, 64, 64, 1]cuda:0" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
        
         # File: <eval_with_key>.27:575 in forward, code: view_1 = main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0.view(getitem_185, getitem_181, 1, 64);  main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_y_0 = getitem_181 = None
        view_9: "f16[s0, 200, 1, 64][12800, 64, 64, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_211, [sym_size_int, 200, 1, 64]);  convert_element_type_211 = None
        
         # File: <eval_with_key>.27:581 in forward, code: permute_1 = view_1.permute(0, 2, 1, 3);  view_1 = None
        permute_48: "f16[s0, 1, 200, 64][12800, 64, 64, 1]cuda:0" = torch.ops.aten.permute.default(view_9, [0, 2, 1, 3]);  view_9 = None
        
         # File: <eval_with_key>.27:598 in forward, code: scaled_dot_product_attention = torch._C._nn.scaled_dot_product_attention(permute_2, permute, permute_1, attn_mask = None, dropout_p = 0.0, is_causal = False);  permute_2 = permute = permute_1 = None
        _scaled_dot_product_flash_attention = torch.ops.aten._scaled_dot_product_flash_attention.default(permute_49, permute_47, permute_48, scale = 0.125);  permute_49 = permute_47 = permute_48 = None
        getitem_221: "f16[s0, 1, 32, 64][2048, 64, 64, 1]cuda:0" = _scaled_dot_product_flash_attention[0];  _scaled_dot_product_flash_attention = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_404: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_226, getitem_216);  convert_element_type_226 = getitem_216 = None
        add_1202: "f32[s0, 32, 1][32, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_215, 1e-05);  getitem_215 = None
        rsqrt_41: "f32[s0, 32, 1][32, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1202);  add_1202 = None
        mul_733: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_404, rsqrt_41);  sub_404 = rsqrt_41 = None
        mul_734: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_733, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight);  mul_733 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_weight = None
        add_1203: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_734, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias);  mul_734 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_x_0_bias = None
        convert_element_type_227: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1203, torch.float16);  add_1203 = None
        
         # File: <eval_with_key>.27:541 in forward, code: repeat_1 = main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb.repeat(getitem_180, 1, 1);  main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_seed_emb = getitem_180 = None
        sym_size_int_14: "Sym(s0)" = torch.ops.aten.sym_size.int(repeat_1, 0)
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        mul_754: "Sym(32*s0)" = sym_size_int_14 * 32
        view_6: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_227, [mul_754, 64]);  convert_element_type_227 = mul_754 = None
        permute_46: "f16[64, 64][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_weight = None
        addmm_44: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.addmm.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias, view_6, permute_46);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj_bias = view_6 = permute_46 = None
        view_7: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.reshape.default(addmm_44, [sym_size_int_14, 32, 64]);  addmm_44 = None
        
         # File: <eval_with_key>.27:579 in forward, code: view_5 = main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj.view(getitem_188, getitem_189, 1, 64);  main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_q_proj = None
        view_13: "f16[s0, 32, 1, 64][2048, 64, 64, 1]cuda:0" = torch.ops.aten.reshape.default(view_7, [sym_size_int, 32, 1, 64]);  view_7 = None
        
         # File: <eval_with_key>.27:585 in forward, code: permute_5 = view_5.permute(0, 2, 1, 3);  view_5 = None
        permute_52: "f16[s0, 1, 32, 64][2048, 64, 64, 1]cuda:0" = torch.ops.aten.permute.default(view_13, [0, 2, 1, 3]);  view_13 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_382: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_212, getitem_212);  convert_element_type_212 = getitem_212 = None
        add_1126: "f32[s0, 200, 1][200, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_211, 1e-05);  getitem_211 = None
        rsqrt_39: "f32[s0, 200, 1][200, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1126);  add_1126 = None
        mul_670: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_382, rsqrt_39);  sub_382 = rsqrt_39 = None
        mul_671: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_670, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight);  mul_670 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_weight = None
        add_1127: "f32[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_671, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias);  mul_671 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0_bias = None
        convert_element_type_213: "f16[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1127, torch.float16);  add_1127 = None
        
         # File: <torch_package_1>.caffe2/torch/fb/predictor/modules/tensors_to_device_module.py:57 in forward, code: return [
        sym_size_int_8: "Sym(s0)" = torch.ops.aten.sym_size.int(arg614_1, 0);  arg614_1 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        mul_703: "Sym(200*s0)" = sym_size_int_8 * 200
        view_2: "f16[200*s0, 64][64, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_213, [mul_703, 64]);  mul_703 = None
        permute_43: "f16[64, 64][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj_weight = None
        mm_1: "f16[200*s0, 64][64, 1]cuda:0" = torch.ops.aten.mm.default(view_2, permute_43);  view_2 = permute_43 = None
        view_3: "f16[s0, 200, 64][12800, 64, 1]cuda:0" = torch.ops.aten.reshape.default(mm_1, [sym_size_int_8, 200, 64]);  mm_1 = sym_size_int_8 = None
        
         # File: <eval_with_key>.27:577 in forward, code: view_3 = main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj.view(getitem_188, getitem_182, 1, 64);  main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_attns_0_k_proj = None
        view_11: "f16[s0, 200, 1, 64][12800, 64, 64, 1]cuda:0" = torch.ops.aten.reshape.default(view_3, [sym_size_int, 200, 1, 64]);  view_3 = None
        
         # File: <eval_with_key>.27:583 in forward, code: permute_3 = view_3.permute(0, 2, 1, 3);  view_3 = None
        permute_50: "f16[s0, 1, 200, 64][12800, 64, 64, 1]cuda:0" = torch.ops.aten.permute.default(view_11, [0, 2, 1, 3]);  view_11 = None
        
         # File: <eval_with_key>.27:578 in forward, code: view_4 = main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0.view(getitem_188, getitem_182, 1, 64);  main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_y_0 = getitem_182 = None
        view_12: "f16[s0, 200, 1, 64][12800, 64, 64, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_213, [sym_size_int, 200, 1, 64]);  convert_element_type_213 = None
        
         # File: <eval_with_key>.27:584 in forward, code: permute_4 = view_4.permute(0, 2, 1, 3);  view_4 = None
        permute_51: "f16[s0, 1, 200, 64][12800, 64, 64, 1]cuda:0" = torch.ops.aten.permute.default(view_12, [0, 2, 1, 3]);  view_12 = None
        
         # File: <eval_with_key>.27:599 in forward, code: scaled_dot_product_attention_1 = torch._C._nn.scaled_dot_product_attention(permute_5, permute_3, permute_4, attn_mask = None, dropout_p = 0.0, is_causal = False);  permute_5 = permute_3 = permute_4 = None
        _scaled_dot_product_flash_attention_1 = torch.ops.aten._scaled_dot_product_flash_attention.default(permute_52, permute_50, permute_51, scale = 0.125);  permute_52 = permute_50 = permute_51 = None
        getitem_230: "f16[s0, 1, 32, 64][2048, 64, 64, 1]cuda:0" = _scaled_dot_product_flash_attention_1[0];  _scaled_dot_product_flash_attention_1 = None
        
         # File: <eval_with_key>.27:604 in forward, code: permute_6 = scaled_dot_product_attention.permute(0, 2, 1, 3);  scaled_dot_product_attention = None
        permute_53: "f16[s0, 32, 1, 64][2048, 64, 64, 1]cuda:0" = torch.ops.aten.permute.default(getitem_221, [0, 2, 1, 3]);  getitem_221 = None
        
         # File: <eval_with_key>.27:626 in forward, code: view_6 = contiguous.view(getitem_185, getitem_186, getitem_187);  contiguous = getitem_185 = getitem_186 = getitem_187 = None
        view_14: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.reshape.default(permute_53, [sym_size_int, 32, 64]);  permute_53 = None
        
         # File: <eval_with_key>.27:627 in forward, code: add_14 = view_6 + repeat;  view_6 = repeat = None
        add_1419: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(view_14, repeat);  view_14 = repeat = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_241: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1419, torch.float32)
        var_mean_44 = torch.ops.aten.var_mean.correction(convert_element_type_241, [2], correction = 0, keepdim = True)
        getitem_239: "f32[s0, 32, 1][32, 1, 1]cuda:0" = var_mean_44[0]
        getitem_240: "f32[s0, 32, 1][32, 1, 1]cuda:0" = var_mean_44[1];  var_mean_44 = None
        
         # File: <eval_with_key>.27:605 in forward, code: permute_7 = scaled_dot_product_attention_1.permute(0, 2, 1, 3);  scaled_dot_product_attention_1 = None
        permute_54: "f16[s0, 32, 1, 64][2048, 64, 64, 1]cuda:0" = torch.ops.aten.permute.default(getitem_230, [0, 2, 1, 3]);  getitem_230 = None
        
         # File: <eval_with_key>.27:628 in forward, code: view_7 = contiguous_1.view(getitem_188, getitem_189, getitem_190);  contiguous_1 = getitem_188 = getitem_189 = getitem_190 = None
        view_15: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.reshape.default(permute_54, [sym_size_int, 32, 64]);  permute_54 = None
        
         # File: <eval_with_key>.27:629 in forward, code: add_15 = view_7 + repeat_1;  view_7 = repeat_1 = None
        add_1428: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(view_15, repeat_1);  view_15 = repeat_1 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_243: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1428, torch.float32)
        var_mean_45 = torch.ops.aten.var_mean.correction(convert_element_type_243, [2], correction = 0, keepdim = True)
        getitem_241: "f32[s0, 32, 1][32, 1, 1]cuda:0" = var_mean_45[0]
        getitem_242: "f32[s0, 32, 1][32, 1, 1]cuda:0" = var_mean_45[1];  var_mean_45 = None
        sub_471: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_243, getitem_242);  convert_element_type_243 = getitem_242 = None
        add_1447: "f32[s0, 32, 1][32, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_241, 1e-05);  getitem_241 = None
        rsqrt_45: "f32[s0, 32, 1][32, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1447);  add_1447 = None
        mul_879: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_471, rsqrt_45);  sub_471 = rsqrt_45 = None
        mul_880: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_879, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight);  mul_879 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight = None
        add_1448: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_880, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias);  mul_880 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias = None
        convert_element_type_244: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1448, torch.float16);  add_1448 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        mul_900: "Sym(32*s0)" = sym_size_int_14 * 32
        view_18: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_244, [mul_900, 64]);  convert_element_type_244 = mul_900 = None
        permute_57: "f16[64, 128][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_62: "f16[32*s0, 128][128, 1]cuda:0" = torch.ops.aten.mm.default(view_18, permute_57);  view_18 = permute_57 = None
        add_tensor_62: "f16[32*s0, 128][128, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_62, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias);  mm_default_62 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        view_19: "f16[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.reshape.default(add_tensor_62, [sym_size_int_14, 32, 128]);  add_tensor_62 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
        convert_element_type_253: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.prims.convert_element_type.default(view_19, torch.float32);  view_19 = None
        mul_912: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.mul.Tensor(convert_element_type_253, 0.5)
        mul_913: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.mul.Tensor(convert_element_type_253, 0.7071067811865476);  convert_element_type_253 = None
        erf_1: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.erf.default(mul_913);  mul_913 = None
        add_1486: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
        mul_914: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_912, add_1486);  mul_912 = add_1486 = None
        convert_element_type_254: "f16[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_914, torch.float16);  mul_914 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        mul_932: "Sym(32*s0)" = sym_size_int_14 * 32
        view_22: "f16[32*s0, 128][128, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_254, [mul_932, 128]);  convert_element_type_254 = mul_932 = None
        permute_59: "f16[128, 64][1, 128]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_weight = None
        
        # No stacktrace found for following nodes
        mm_default_61: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.mm.default(view_22, permute_59);  view_22 = permute_59 = None
        add_tensor_61: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_61, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias);  mm_default_61 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        view_23: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.reshape.default(add_tensor_61, [sym_size_int_14, 32, 64]);  add_tensor_61 = None
        
         # File: <eval_with_key>.27:639 in forward, code: add_17 = add_15 + main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2;  add_15 = main_module_impl_impl_shared_arch_event_submodels_dict_user_conv_ads_event_relevance_model_pre_norm_pma_mab_mlps_0_2 = None
        add_1516: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1428, view_23);  add_1428 = view_23 = None
        
         # File: <eval_with_key>.27:641 in forward, code: equally_split_1 = torch.ops.fb.equally_split(add_17, 32, 1);  add_17 = None
        split_with_sizes_4 = torch.ops.aten.split_with_sizes.default(add_1516, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 1);  add_1516 = None
        getitem_243: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[0]
        getitem_244: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[1]
        getitem_245: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[2]
        getitem_246: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[3]
        getitem_247: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[4]
        getitem_248: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[5]
        getitem_249: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[6]
        getitem_250: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[7]
        getitem_251: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[8]
        getitem_252: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[9]
        getitem_253: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[10]
        getitem_254: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[11]
        getitem_255: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[12]
        getitem_256: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[13]
        getitem_257: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[14]
        getitem_258: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[15]
        getitem_259: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[16]
        getitem_260: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[17]
        getitem_261: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[18]
        getitem_262: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[19]
        getitem_263: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[20]
        getitem_264: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[21]
        getitem_265: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[22]
        getitem_266: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[23]
        getitem_267: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[24]
        getitem_268: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[25]
        getitem_269: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[26]
        getitem_270: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[27]
        getitem_271: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[28]
        getitem_272: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[29]
        getitem_273: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[30]
        getitem_274: "f16[s0, 1, 64][2048, 64, 1]cuda:0" = split_with_sizes_4[31];  split_with_sizes_4 = None
        
         # File: <torch_package_1>.caffe2/torch/fb/predictor/modules/tensors_to_device_module.py:57 in forward, code: return [
        sym_size_int_2: "Sym(s0)" = torch.ops.aten.sym_size.int(arg608_1, 0);  arg608_1 = None
        
         # File: <eval_with_key>.27:909 in forward, code: matmul = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w, reshape_128);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w = None
        expand: "f16[s0, 174, 458][0, 458, 1]cuda:0" = torch.ops.aten.expand.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w, [sym_size_int_2, 174, 458]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w = None
        view_58: "f16[s0, 174, 458][0, 458, 1]cuda:0" = torch.ops.aten.reshape.default(expand, [sym_size_int_2, 174, 458]);  expand = None
        
        # No stacktrace found for following nodes
        cat_9: "f16[1152][1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_b, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_b, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_b, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_b, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_b, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_b]);  submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_b = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_b = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_b = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_b = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_b = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:560 in forward, code: layer_norm_38 = torch.nn.functional.layer_norm(cat_40, getitem_183, weight = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale, bias = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias, eps = 1e-05);  getitem_183 = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = None
        sub_414: "f32[s0, 3282][3282, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_234, getitem_218);  convert_element_type_234 = getitem_218 = None
        add_1236: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_217, 1e-05);  getitem_217 = None
        rsqrt_42: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1236);  add_1236 = None
        mul_761: "f32[s0, 3282][3282, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_414, rsqrt_42);  sub_414 = rsqrt_42 = None
        mul_762: "f32[s0, 3282][3282, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_761, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale);  mul_761 = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = None
        add_1237: "f32[s0, 3282][3282, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_762, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias);  mul_762 = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = None
        convert_element_type_235: "f16[s0, 3282][3282, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1237, torch.float16);  add_1237 = None
        
         # File: <eval_with_key>.27:572 in forward, code: sigmoid_3 = torch.sigmoid(layer_norm_38);  layer_norm_38 = None
        sigmoid_3: "f16[s0, 3282][3282, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_235);  convert_element_type_235 = None
        
         # File: <eval_with_key>.27:601 in forward, code: mul_2 = cat_40 * unsqueeze_n_times_2;  cat_40 = unsqueeze_n_times_2 = None
        mul_809: "f16[s0, 3282][3282, 1]cuda:0" = torch.ops.aten.mul.Tensor(cat_7, sigmoid_3);  cat_7 = sigmoid_3 = None
        
        # No stacktrace found for following nodes
        cat_8: "f16[1152, 3282][3282, 1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_w, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_w, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_w, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_w, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_w, submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_w]);  submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_0_submodules_0_shards_0_w = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_1_submodules_0_shards_0_w = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_2_submodules_0_shards_0_w = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_3_submodules_0_shards_0_w = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_4_submodules_0_shards_0_w = submod_0_main_module_impl_impl_shared_arch_dense_arch_dense_embedding_archs_0_submodules_dense_embedding_5_submodules_0_shards_0_w = None
        permute_55: "f16[3282, 1152][1, 3282]cuda:0" = torch.ops.aten.permute.default(cat_8, [1, 0]);  cat_8 = None
        addmm_45: "f16[s0, 1152][1152, 1]cuda:0" = torch.ops.aten.addmm.default(cat_9, mul_809, permute_55);  cat_9 = permute_55 = None
        slice_6: "f16[s0, 192][1152, 1]cuda:0" = torch.ops.aten.slice.Tensor(addmm_45, 1, 0, 192)
        clone_2: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.clone.default(slice_6, memory_format = torch.contiguous_format);  slice_6 = None
        slice_8: "f16[s0, 192][1152, 1]cuda:0" = torch.ops.aten.slice.Tensor(addmm_45, 1, 192, 384)
        clone_3: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.clone.default(slice_8, memory_format = torch.contiguous_format);  slice_8 = None
        slice_10: "f16[s0, 192][1152, 1]cuda:0" = torch.ops.aten.slice.Tensor(addmm_45, 1, 384, 576)
        clone_4: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.clone.default(slice_10, memory_format = torch.contiguous_format);  slice_10 = None
        slice_12: "f16[s0, 192][1152, 1]cuda:0" = torch.ops.aten.slice.Tensor(addmm_45, 1, 576, 768)
        clone_5: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.clone.default(slice_12, memory_format = torch.contiguous_format);  slice_12 = None
        slice_14: "f16[s0, 192][1152, 1]cuda:0" = torch.ops.aten.slice.Tensor(addmm_45, 1, 768, 960)
        clone_6: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.clone.default(slice_14, memory_format = torch.contiguous_format);  slice_14 = None
        slice_16: "f16[s0, 192][1152, 1]cuda:0" = torch.ops.aten.slice.Tensor(addmm_45, 1, 960, 1152)
        clone_7: "f16[s0, 192][192, 1]cuda:0" = torch.ops.aten.clone.default(slice_16, memory_format = torch.contiguous_format);  slice_16 = None
        slice_4: "f16[s0, 256][512, 1]cuda:0" = torch.ops.aten.slice.Tensor(addmm_37, 1, 256, 512)
        clone_1: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.clone.default(slice_4, memory_format = torch.contiguous_format);  slice_4 = None
        relu: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.relu.default(clone_1);  clone_1 = None
        convert_element_type_198: "f32[s0, 256][256, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu, torch.float32)
        eq_327: "b8[s0, 256][256, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_198, inf);  convert_element_type_198 = None
        scalar_tensor_2: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        convert_element_type_197: "f32[s0, 256][256, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu, torch.float32)
        eq_326: "b8[s0, 256][256, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_197, -inf);  convert_element_type_197 = None
        scalar_tensor_1: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(-65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        isnan: "b8[s0, 256][256, 1]cuda:0" = torch.ops.aten.isnan.default(relu)
        scalar_tensor: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        where: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.where.self(isnan, scalar_tensor, relu);  isnan = scalar_tensor = relu = None
        where_1: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.where.self(eq_326, scalar_tensor_1, where);  eq_326 = scalar_tensor_1 = where = None
        where_2: "f16[s0, 256][256, 1]cuda:0" = torch.ops.aten.where.self(eq_327, scalar_tensor_2, where_1);  eq_327 = scalar_tensor_2 = where_1 = None
        
         # File: <eval_with_key>.27:487 in forward, code: linear_40 = torch._C._nn.linear(relu, main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w, main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b);  relu = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b = None
        permute_38: "f16[256, 960][1, 256]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_w = None
        addmm_38: "f16[s0, 960][960, 1]cuda:0" = torch.ops.aten.addmm.default(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b, where_2, permute_38);  submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_0_arch_submodules_1_submodules_0_shards_0_b = where_2 = permute_38 = None
        
         # File: <eval_with_key>.27:496 in forward, code: linear_41 = torch._C._nn.linear(linear_40, main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w, main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b);  linear_40 = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b = None
        permute_39: "f16[960, 1536][1, 960]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_w = None
        addmm_39: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.addmm.default(submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b, addmm_38, permute_39);  submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_to_dot_submodules_1_linear_arch_shards_0_b = addmm_38 = permute_39 = None
        
         # File: <eval_with_key>.27:358 in forward, code: layer_norm_4 = torch.nn.functional.layer_norm(linear_4, getitem_145, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_4 = getitem_145 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias = None
        sub_213: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_128, getitem_142);  convert_element_type_128 = getitem_142 = None
        add_638: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_141, 1e-05);  getitem_141 = None
        rsqrt_4: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_638);  add_638 = None
        mul_405: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_213, rsqrt_4);  sub_213 = rsqrt_4 = None
        mul_406: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_405, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale);  mul_405 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_scale = None
        add_639: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_406, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias);  mul_406 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_129: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_639, torch.float16);  add_639 = None
        
         # File: <eval_with_key>.27:361 in forward, code: layer_norm_5 = torch.nn.functional.layer_norm(linear_5, getitem_146, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_5 = getitem_146 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias = None
        sub_217: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_130, getitem_144);  convert_element_type_130 = getitem_144 = None
        add_649: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_143, 1e-05);  getitem_143 = None
        rsqrt_5: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_649);  add_649 = None
        mul_411: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_217, rsqrt_5);  sub_217 = rsqrt_5 = None
        mul_412: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_411, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale);  mul_411 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_scale = None
        add_650: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_412, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias);  mul_412 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_291594492_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_131: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_650, torch.float16);  add_650 = None
        
         # File: <eval_with_key>.27:280 in forward, code: layer_norm = torch.nn.functional.layer_norm(linear, getitem_141, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias, eps = 1e-05);  linear = getitem_141 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias = None
        sub_195: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_120, getitem_134);  convert_element_type_120 = getitem_134 = None
        add_587: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_133, 1e-05);  getitem_133 = None
        rsqrt: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_587);  add_587 = None
        mul_379: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_195, rsqrt);  sub_195 = rsqrt = None
        mul_380: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_379, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale);  mul_379 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_scale = None
        add_588: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_380, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias);  mul_380 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_3_submodules_1_bias = None
        convert_element_type_121: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_588, torch.float16);  add_588 = None
        
         # File: <eval_with_key>.27:364 in forward, code: layer_norm_6 = torch.nn.functional.layer_norm(linear_6, getitem_147, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_6 = getitem_147 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias = None
        sub_221: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_132, getitem_146);  convert_element_type_132 = getitem_146 = None
        add_660: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_145, 1e-05);  getitem_145 = None
        rsqrt_6: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_660);  add_660 = None
        mul_417: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_221, rsqrt_6);  sub_221 = rsqrt_6 = None
        mul_418: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_417, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale);  mul_417 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_scale = None
        add_661: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_418, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias);  mul_418 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_421801413_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_133: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_661, torch.float16);  add_661 = None
        
         # File: <eval_with_key>.27:367 in forward, code: layer_norm_7 = torch.nn.functional.layer_norm(linear_7, getitem_148, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_7 = getitem_148 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias = None
        sub_225: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_134, getitem_148);  convert_element_type_134 = getitem_148 = None
        add_671: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_147, 1e-05);  getitem_147 = None
        rsqrt_7: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_671);  add_671 = None
        mul_423: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_225, rsqrt_7);  sub_225 = rsqrt_7 = None
        mul_424: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_423, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale);  mul_423 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_scale = None
        add_672: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_424, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias);  mul_424 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_135: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_672, torch.float16);  add_672 = None
        
         # File: <eval_with_key>.27:370 in forward, code: layer_norm_8 = torch.nn.functional.layer_norm(linear_8, getitem_149, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias, eps = 1e-05);  linear_8 = getitem_149 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias = None
        sub_229: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_136, getitem_150);  convert_element_type_136 = getitem_150 = None
        add_682: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_149, 1e-05);  getitem_149 = None
        rsqrt_8: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_682);  add_682 = None
        mul_429: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_229, rsqrt_8);  sub_229 = rsqrt_8 = None
        mul_430: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_429, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale);  mul_429 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_scale = None
        add_683: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_430, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias);  mul_430 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_2_avg_3_submodules_1_bias = None
        convert_element_type_137: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_683, torch.float16);  add_683 = None
        
         # File: <eval_with_key>.27:283 in forward, code: layer_norm_1 = torch.nn.functional.layer_norm(linear_1, getitem_142, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias, eps = 1e-05);  linear_1 = getitem_142 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias = None
        sub_199: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_122, getitem_136);  convert_element_type_122 = getitem_136 = None
        add_598: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_135, 1e-05);  getitem_135 = None
        rsqrt_1: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_598);  add_598 = None
        mul_385: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_199, rsqrt_1);  sub_199 = rsqrt_1 = None
        mul_386: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_385, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale);  mul_385 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_scale = None
        add_599: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_386, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias);  mul_386 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_2_submodules_1_bias = None
        convert_element_type_123: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_599, torch.float16);  add_599 = None
        
         # File: <eval_with_key>.27:373 in forward, code: layer_norm_9 = torch.nn.functional.layer_norm(linear_9, getitem_150, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_9 = getitem_150 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias = None
        sub_233: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_138, getitem_152);  convert_element_type_138 = getitem_152 = None
        add_693: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_151, 1e-05);  getitem_151 = None
        rsqrt_9: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_693);  add_693 = None
        mul_435: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_233, rsqrt_9);  sub_233 = rsqrt_9 = None
        mul_436: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_435, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale);  mul_435 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_scale = None
        add_694: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_436, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias);  mul_436 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_323876380_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_139: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_694, torch.float16);  add_694 = None
        
         # File: <eval_with_key>.27:376 in forward, code: layer_norm_10 = torch.nn.functional.layer_norm(linear_10, getitem_151, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_10 = getitem_151 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias = None
        sub_237: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_140, getitem_154);  convert_element_type_140 = getitem_154 = None
        add_704: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_153, 1e-05);  getitem_153 = None
        rsqrt_10: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_704);  add_704 = None
        mul_441: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_237, rsqrt_10);  sub_237 = rsqrt_10 = None
        mul_442: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_441, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale);  mul_441 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_scale = None
        add_705: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_442, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias);  mul_442 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_141: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_705, torch.float16);  add_705 = None
        
         # File: <eval_with_key>.27:379 in forward, code: layer_norm_11 = torch.nn.functional.layer_norm(linear_11, getitem_152, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_11 = getitem_152 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias = None
        sub_241: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_142, getitem_156);  convert_element_type_142 = getitem_156 = None
        add_715: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_155, 1e-05);  getitem_155 = None
        rsqrt_11: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_715);  add_715 = None
        mul_447: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_241, rsqrt_11);  sub_241 = rsqrt_11 = None
        mul_448: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_447, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale);  mul_447 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_scale = None
        add_716: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_448, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias);  mul_448 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_368273801_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_143: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_716, torch.float16);  add_716 = None
        
         # File: <eval_with_key>.27:286 in forward, code: layer_norm_2 = torch.nn.functional.layer_norm(linear_2, getitem_143, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias, eps = 1e-05);  linear_2 = getitem_143 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias = None
        sub_203: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_124, getitem_138);  convert_element_type_124 = getitem_138 = None
        add_609: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_137, 1e-05);  getitem_137 = None
        rsqrt_2: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_609);  add_609 = None
        mul_391: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_203, rsqrt_2);  sub_203 = rsqrt_2 = None
        mul_392: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_391, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale);  mul_391 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_scale = None
        add_610: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_392, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias);  mul_392 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_1_submodules_1_bias = None
        convert_element_type_125: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_610, torch.float16);  add_610 = None
        
         # File: <eval_with_key>.27:289 in forward, code: layer_norm_3 = torch.nn.functional.layer_norm(linear_3, getitem_144, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias, eps = 1e-05);  linear_3 = getitem_144 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias = None
        sub_207: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_126, getitem_140);  convert_element_type_126 = getitem_140 = None
        add_620: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_139, 1e-05);  getitem_139 = None
        rsqrt_3: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_620);  add_620 = None
        mul_397: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_207, rsqrt_3);  sub_207 = rsqrt_3 = None
        mul_398: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_397, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale);  mul_397 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_scale = None
        add_621: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_398, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias);  mul_398 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adpublisher_ads_graph_learning_flexible_batch_graph_learning_ad_side_embedding_feature_f3_graph_learning_embedding_feature_entity_equivalence_key_0_submodules_1_bias = None
        convert_element_type_127: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_621, torch.float16);  add_621 = None
        
         # File: <eval_with_key>.27:382 in forward, code: layer_norm_12 = torch.nn.functional.layer_norm(linear_12, getitem_153, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias, eps = 1e-05);  linear_12 = getitem_153 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias = None
        sub_245: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_144, getitem_158);  convert_element_type_144 = getitem_158 = None
        add_726: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_157, 1e-05);  getitem_157 = None
        rsqrt_12: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_726);  add_726 = None
        mul_453: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_245, rsqrt_12);  sub_245 = rsqrt_12 = None
        mul_454: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_453, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale);  mul_453 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_scale = None
        add_727: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_454, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias);  mul_454 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_3_avg_3_submodules_1_bias = None
        convert_element_type_145: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_727, torch.float16);  add_727 = None
        
         # File: <eval_with_key>.27:385 in forward, code: layer_norm_13 = torch.nn.functional.layer_norm(linear_13, getitem_154, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_13 = getitem_154 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias = None
        sub_249: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_146, getitem_160);  convert_element_type_146 = getitem_160 = None
        add_737: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_159, 1e-05);  getitem_159 = None
        rsqrt_13: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_737);  add_737 = None
        mul_459: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_249, rsqrt_13);  sub_249 = rsqrt_13 = None
        mul_460: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_459, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale);  mul_459 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_scale = None
        add_738: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_460, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias);  mul_460 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_147: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_738, torch.float16);  add_738 = None
        
         # File: <eval_with_key>.27:388 in forward, code: layer_norm_14 = torch.nn.functional.layer_norm(linear_14, getitem_155, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_14 = getitem_155 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias = None
        sub_253: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_148, getitem_162);  convert_element_type_148 = getitem_162 = None
        add_748: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_161, 1e-05);  getitem_161 = None
        rsqrt_14: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_748);  add_748 = None
        mul_465: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_253, rsqrt_14);  sub_253 = rsqrt_14 = None
        mul_466: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_465, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale);  mul_465 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_scale = None
        add_749: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_466, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias);  mul_466 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246015958_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_149: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_749, torch.float16);  add_749 = None
        
         # File: <eval_with_key>.27:391 in forward, code: layer_norm_15 = torch.nn.functional.layer_norm(linear_15, getitem_156, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_15 = getitem_156 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias = None
        sub_257: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_150, getitem_164);  convert_element_type_150 = getitem_164 = None
        add_759: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_163, 1e-05);  getitem_163 = None
        rsqrt_15: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_759);  add_759 = None
        mul_471: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_257, rsqrt_15);  sub_257 = rsqrt_15 = None
        mul_472: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_471, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale);  mul_471 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_scale = None
        add_760: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_472, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias);  mul_472 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_151: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_760, torch.float16);  add_760 = None
        
         # File: <eval_with_key>.27:394 in forward, code: layer_norm_16 = torch.nn.functional.layer_norm(linear_16, getitem_157, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_16 = getitem_157 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias = None
        sub_261: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_152, getitem_166);  convert_element_type_152 = getitem_166 = None
        add_770: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_165, 1e-05);  getitem_165 = None
        rsqrt_16: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_770);  add_770 = None
        mul_477: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_261, rsqrt_16);  sub_261 = rsqrt_16 = None
        mul_478: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_477, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale);  mul_477 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_scale = None
        add_771: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_478, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias);  mul_478 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_153: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_771, torch.float16);  add_771 = None
        
         # File: <eval_with_key>.27:397 in forward, code: layer_norm_17 = torch.nn.functional.layer_norm(linear_17, getitem_158, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_17 = getitem_158 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias = None
        sub_265: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_154, getitem_168);  convert_element_type_154 = getitem_168 = None
        add_781: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_167, 1e-05);  getitem_167 = None
        rsqrt_17: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_781);  add_781 = None
        mul_483: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_265, rsqrt_17);  sub_265 = rsqrt_17 = None
        mul_484: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_483, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale);  mul_483 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_scale = None
        add_782: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_484, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias);  mul_484 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_487599076_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_155: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_782, torch.float16);  add_782 = None
        
         # File: <eval_with_key>.27:400 in forward, code: layer_norm_18 = torch.nn.functional.layer_norm(linear_18, getitem_159, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_18 = getitem_159 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias = None
        sub_269: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_156, getitem_170);  convert_element_type_156 = getitem_170 = None
        add_792: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_169, 1e-05);  getitem_169 = None
        rsqrt_18: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_792);  add_792 = None
        mul_489: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_269, rsqrt_18);  sub_269 = rsqrt_18 = None
        mul_490: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_489, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale);  mul_489 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_scale = None
        add_793: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_490, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias);  mul_490 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_246272433_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_157: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_793, torch.float16);  add_793 = None
        
         # File: <eval_with_key>.27:403 in forward, code: layer_norm_19 = torch.nn.functional.layer_norm(linear_19, getitem_160, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_19 = getitem_160 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias = None
        sub_273: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_158, getitem_172);  convert_element_type_158 = getitem_172 = None
        add_803: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_171, 1e-05);  getitem_171 = None
        rsqrt_19: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_803);  add_803 = None
        mul_495: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_273, rsqrt_19);  sub_273 = rsqrt_19 = None
        mul_496: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_495, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale);  mul_495 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_scale = None
        add_804: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_496, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias);  mul_496 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_159: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_804, torch.float16);  add_804 = None
        
         # File: <eval_with_key>.27:406 in forward, code: layer_norm_20 = torch.nn.functional.layer_norm(linear_20, getitem_161, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_20 = getitem_161 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias = None
        sub_277: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_160, getitem_174);  convert_element_type_160 = getitem_174 = None
        add_814: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_173, 1e-05);  getitem_173 = None
        rsqrt_20: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_814);  add_814 = None
        mul_501: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_277, rsqrt_20);  sub_277 = rsqrt_20 = None
        mul_502: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_501, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale);  mul_501 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_scale = None
        add_815: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_502, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias);  mul_502 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_161: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_815, torch.float16);  add_815 = None
        
         # File: <eval_with_key>.27:409 in forward, code: layer_norm_21 = torch.nn.functional.layer_norm(linear_21, getitem_162, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_21 = getitem_162 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias = None
        sub_281: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_162, getitem_176);  convert_element_type_162 = getitem_176 = None
        add_825: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_175, 1e-05);  getitem_175 = None
        rsqrt_21: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_825);  add_825 = None
        mul_507: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_281, rsqrt_21);  sub_281 = rsqrt_21 = None
        mul_508: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_507, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale);  mul_507 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_scale = None
        add_826: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_508, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias);  mul_508 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_early_stage_features_early_stage_scaling_user_model_367428337_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_163: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_826, torch.float16);  add_826 = None
        
         # File: <eval_with_key>.27:412 in forward, code: layer_norm_22 = torch.nn.functional.layer_norm(linear_22, getitem_163, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias, eps = 1e-05);  linear_22 = getitem_163 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias = None
        sub_285: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_164, getitem_178);  convert_element_type_164 = getitem_178 = None
        add_836: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_177, 1e-05);  getitem_177 = None
        rsqrt_22: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_836);  add_836 = None
        mul_513: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_285, rsqrt_22);  sub_285 = rsqrt_22 = None
        mul_514: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_513, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale);  mul_513 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_scale = None
        add_837: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_514, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias);  mul_514 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_uds_uhm_onsite_conversion_uhm_onsite_conversion_single_channel_ctr_submodules_1_bias = None
        convert_element_type_165: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_837, torch.float16);  add_837 = None
        
         # File: <eval_with_key>.27:415 in forward, code: layer_norm_23 = torch.nn.functional.layer_norm(linear_23, getitem_164, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_23 = getitem_164 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias = None
        sub_289: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_166, getitem_180);  convert_element_type_166 = getitem_180 = None
        add_847: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_179, 1e-05);  getitem_179 = None
        rsqrt_23: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_847);  add_847 = None
        mul_519: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_289, rsqrt_23);  sub_289 = rsqrt_23 = None
        mul_520: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_519, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale);  mul_519 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_scale = None
        add_848: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_520, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias);  mul_520 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_343512182_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_167: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_848, torch.float16);  add_848 = None
        
         # File: <eval_with_key>.27:418 in forward, code: layer_norm_24 = torch.nn.functional.layer_norm(linear_24, getitem_165, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias, eps = 1e-05);  linear_24 = getitem_165 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias = None
        sub_293: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_168, getitem_182);  convert_element_type_168 = getitem_182 = None
        add_858: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_181, 1e-05);  getitem_181 = None
        rsqrt_24: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_858);  add_858 = None
        mul_525: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_293, rsqrt_24);  sub_293 = rsqrt_24 = None
        mul_526: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_525, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale);  mul_525 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_scale = None
        add_859: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_526, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias);  mul_526 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_f3_bulk_eval_daily_user_side_embedding_feature_graph_learning_embedding_feature_user_graph_f3_daily_bulk_eval_2023_h1_2_submodules_1_bias = None
        convert_element_type_169: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_859, torch.float16);  add_859 = None
        
         # File: <eval_with_key>.27:421 in forward, code: layer_norm_25 = torch.nn.functional.layer_norm(linear_25, getitem_166, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_25 = getitem_166 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias = None
        sub_297: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_170, getitem_184);  convert_element_type_170 = getitem_184 = None
        add_869: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_183, 1e-05);  getitem_183 = None
        rsqrt_25: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_869);  add_869 = None
        mul_531: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_297, rsqrt_25);  sub_297 = rsqrt_25 = None
        mul_532: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_531, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale);  mul_531 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_scale = None
        add_870: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_532, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias);  mul_532 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_309862198_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_171: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_870, torch.float16);  add_870 = None
        
         # File: <eval_with_key>.27:424 in forward, code: layer_norm_26 = torch.nn.functional.layer_norm(linear_26, getitem_167, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_26 = getitem_167 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias = None
        sub_301: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_172, getitem_186);  convert_element_type_172 = getitem_186 = None
        add_880: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_185, 1e-05);  getitem_185 = None
        rsqrt_26: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_880);  add_880 = None
        mul_537: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_301, rsqrt_26);  sub_301 = rsqrt_26 = None
        mul_538: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_537, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale);  mul_537 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_scale = None
        add_881: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_538, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias);  mul_538 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_173: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_881, torch.float16);  add_881 = None
        
         # File: <eval_with_key>.27:427 in forward, code: layer_norm_27 = torch.nn.functional.layer_norm(linear_27, getitem_168, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_27 = getitem_168 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias = None
        sub_305: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_174, getitem_188);  convert_element_type_174 = getitem_188 = None
        add_891: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_187, 1e-05);  getitem_187 = None
        rsqrt_27: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_891);  add_891 = None
        mul_543: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_305, rsqrt_27);  sub_305 = rsqrt_27 = None
        mul_544: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_543, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale);  mul_543 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_scale = None
        add_892: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_544, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias);  mul_544 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_175: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_892, torch.float16);  add_892 = None
        
         # File: <eval_with_key>.27:430 in forward, code: layer_norm_28 = torch.nn.functional.layer_norm(linear_28, getitem_169, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_28 = getitem_169 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias = None
        sub_309: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_176, getitem_190);  convert_element_type_176 = getitem_190 = None
        add_902: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_189, 1e-05);  getitem_189 = None
        rsqrt_28: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_902);  add_902 = None
        mul_549: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_309, rsqrt_28);  sub_309 = rsqrt_28 = None
        mul_550: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_549, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale);  mul_549 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_scale = None
        add_903: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_550, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias);  mul_550 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_360324426_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_177: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_903, torch.float16);  add_903 = None
        
         # File: <eval_with_key>.27:433 in forward, code: layer_norm_29 = torch.nn.functional.layer_norm(linear_29, getitem_170, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias, eps = 1e-05);  linear_29 = getitem_170 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias = None
        sub_313: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_178, getitem_192);  convert_element_type_178 = getitem_192 = None
        add_913: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_191, 1e-05);  getitem_191 = None
        rsqrt_29: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_913);  add_913 = None
        mul_555: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_313, rsqrt_29);  sub_313 = rsqrt_29 = None
        mul_556: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_555, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale);  mul_555 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_scale = None
        add_914: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_556, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias);  mul_556 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_0_submodules_1_bias = None
        convert_element_type_179: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_914, torch.float16);  add_914 = None
        
         # File: <eval_with_key>.27:436 in forward, code: layer_norm_30 = torch.nn.functional.layer_norm(linear_30, getitem_171, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias, eps = 1e-05);  linear_30 = getitem_171 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias = None
        sub_317: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_180, getitem_194);  convert_element_type_180 = getitem_194 = None
        add_924: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_193, 1e-05);  getitem_193 = None
        rsqrt_30: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_924);  add_924 = None
        mul_561: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_317, rsqrt_30);  sub_317 = rsqrt_30 = None
        mul_562: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_561, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale);  mul_561 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_scale = None
        add_925: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_562, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias);  mul_562 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_graph_learning_flexible_batch_graph_learning_user_side_embedding_feature_f3_graph_learning_embedding_feature_separable_id_1_submodules_1_bias = None
        convert_element_type_181: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_925, torch.float16);  add_925 = None
        
         # File: <eval_with_key>.27:439 in forward, code: layer_norm_31 = torch.nn.functional.layer_norm(linear_31, getitem_172, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_31 = getitem_172 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias = None
        sub_321: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_182, getitem_196);  convert_element_type_182 = getitem_196 = None
        add_935: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_195, 1e-05);  getitem_195 = None
        rsqrt_31: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_935);  add_935 = None
        mul_567: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_321, rsqrt_31);  sub_321 = rsqrt_31 = None
        mul_568: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_567, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale);  mul_567 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_scale = None
        add_936: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_568, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias);  mul_568 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_prod_features_scaling_user_model_346472987_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_183: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_936, torch.float16);  add_936 = None
        
         # File: <eval_with_key>.27:442 in forward, code: layer_norm_32 = torch.nn.functional.layer_norm(linear_32, getitem_173, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_32 = getitem_173 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias = None
        sub_325: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_184, getitem_198);  convert_element_type_184 = getitem_198 = None
        add_946: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_197, 1e-05);  getitem_197 = None
        rsqrt_32: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_946);  add_946 = None
        mul_573: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_325, rsqrt_32);  sub_325 = rsqrt_32 = None
        mul_574: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_573, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale);  mul_573 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_scale = None
        add_947: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_574, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias);  mul_574 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_185: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_947, torch.float16);  add_947 = None
        
         # File: <eval_with_key>.27:445 in forward, code: layer_norm_33 = torch.nn.functional.layer_norm(linear_33, getitem_174, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_33 = getitem_174 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias = None
        sub_329: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_186, getitem_200);  convert_element_type_186 = getitem_200 = None
        add_957: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_199, 1e-05);  getitem_199 = None
        rsqrt_33: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_957);  add_957 = None
        mul_579: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_329, rsqrt_33);  sub_329 = rsqrt_33 = None
        mul_580: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_579, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale);  mul_579 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_scale = None
        add_958: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_580, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias);  mul_580 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_post_model_eval_ads_scaling_user_model_realtime_cvr_v0_scaling_user_model_510272006_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_187: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_958, torch.float16);  add_958 = None
        
         # File: <eval_with_key>.27:448 in forward, code: layer_norm_34 = torch.nn.functional.layer_norm(linear_34, getitem_175, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias, eps = 1e-05);  linear_34 = getitem_175 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias = None
        sub_333: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_188, getitem_202);  convert_element_type_188 = getitem_202 = None
        add_968: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_201, 1e-05);  getitem_201 = None
        rsqrt_34: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_968);  add_968 = None
        mul_585: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_333, rsqrt_34);  sub_333 = rsqrt_34 = None
        mul_586: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_585, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale);  mul_585 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_scale = None
        add_969: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_586, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias);  mul_586 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_0_avg_3_submodules_1_bias = None
        convert_element_type_189: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_969, torch.float16);  add_969 = None
        
         # File: <eval_with_key>.27:451 in forward, code: layer_norm_35 = torch.nn.functional.layer_norm(linear_35, getitem_176, weight = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale, bias = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias, eps = 1e-05);  linear_35 = getitem_176 = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale = main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias = None
        sub_337: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_190, getitem_204);  convert_element_type_190 = getitem_204 = None
        add_979: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_203, 1e-05);  getitem_203 = None
        rsqrt_35: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_979);  add_979 = None
        mul_591: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_337, rsqrt_35);  sub_337 = rsqrt_35 = None
        mul_592: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_591, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale);  mul_591 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_scale = None
        add_980: "f32[s0, 192][192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_592, submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias);  mul_592 = submod_0_main_module_impl_impl_shared_arch_embedding_feature_arch_embedding_projection_arch_f3_adfinder_user_ads_scaling_user_model_sg_scale_v0_early_stage_scaling_user_model_530332232_embedding_1_avg_3_submodules_1_bias = None
        convert_element_type_191: "f16[s0, 192][192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_980, torch.float16);  add_980 = None
        
         # File: <eval_with_key>.27:738 in forward, code: reshape_32 = getitem_223.reshape(-1, 64);  getitem_223 = None
        view_24: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_243, [sym_size_int, 64]);  getitem_243 = None
        
        # No stacktrace found for following nodes
        unsqueeze: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_24, 0);  view_24 = None
        
         # File: <eval_with_key>.27:739 in forward, code: reshape_33 = getitem_224.reshape(-1, 64);  getitem_224 = None
        view_25: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_244, [sym_size_int, 64]);  getitem_244 = None
        
        # No stacktrace found for following nodes
        unsqueeze_1: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_25, 0);  view_25 = None
        
         # File: <eval_with_key>.27:740 in forward, code: reshape_34 = getitem_225.reshape(-1, 64);  getitem_225 = None
        view_26: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_245, [sym_size_int, 64]);  getitem_245 = None
        
        # No stacktrace found for following nodes
        unsqueeze_2: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_26, 0);  view_26 = None
        
         # File: <eval_with_key>.27:741 in forward, code: reshape_35 = getitem_226.reshape(-1, 64);  getitem_226 = None
        view_27: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_246, [sym_size_int, 64]);  getitem_246 = None
        
        # No stacktrace found for following nodes
        unsqueeze_3: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_27, 0);  view_27 = None
        
         # File: <eval_with_key>.27:742 in forward, code: reshape_36 = getitem_227.reshape(-1, 64);  getitem_227 = None
        view_28: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_247, [sym_size_int, 64]);  getitem_247 = None
        
        # No stacktrace found for following nodes
        unsqueeze_4: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_28, 0);  view_28 = None
        
         # File: <eval_with_key>.27:743 in forward, code: reshape_37 = getitem_228.reshape(-1, 64);  getitem_228 = None
        view_29: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_248, [sym_size_int, 64]);  getitem_248 = None
        
        # No stacktrace found for following nodes
        unsqueeze_5: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_29, 0);  view_29 = None
        
         # File: <eval_with_key>.27:744 in forward, code: reshape_38 = getitem_229.reshape(-1, 64);  getitem_229 = None
        view_30: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_249, [sym_size_int, 64]);  getitem_249 = None
        
        # No stacktrace found for following nodes
        unsqueeze_6: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_30, 0);  view_30 = None
        
         # File: <eval_with_key>.27:745 in forward, code: reshape_39 = getitem_230.reshape(-1, 64);  getitem_230 = None
        view_31: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_250, [sym_size_int, 64]);  getitem_250 = None
        
        # No stacktrace found for following nodes
        unsqueeze_7: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_31, 0);  view_31 = None
        
         # File: <eval_with_key>.27:746 in forward, code: reshape_40 = getitem_231.reshape(-1, 64);  getitem_231 = None
        view_32: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_251, [sym_size_int, 64]);  getitem_251 = None
        
        # No stacktrace found for following nodes
        unsqueeze_8: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_32, 0);  view_32 = None
        
         # File: <eval_with_key>.27:747 in forward, code: reshape_41 = getitem_232.reshape(-1, 64);  getitem_232 = None
        view_33: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_252, [sym_size_int, 64]);  getitem_252 = None
        
        # No stacktrace found for following nodes
        unsqueeze_9: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_33, 0);  view_33 = None
        
         # File: <eval_with_key>.27:748 in forward, code: reshape_42 = getitem_233.reshape(-1, 64);  getitem_233 = None
        view_34: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_253, [sym_size_int, 64]);  getitem_253 = None
        
        # No stacktrace found for following nodes
        unsqueeze_10: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_34, 0);  view_34 = None
        
         # File: <eval_with_key>.27:749 in forward, code: reshape_43 = getitem_234.reshape(-1, 64);  getitem_234 = None
        view_35: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_254, [sym_size_int, 64]);  getitem_254 = None
        
        # No stacktrace found for following nodes
        unsqueeze_11: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_35, 0);  view_35 = None
        
         # File: <eval_with_key>.27:750 in forward, code: reshape_44 = getitem_235.reshape(-1, 64);  getitem_235 = None
        view_36: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_255, [sym_size_int, 64]);  getitem_255 = None
        
        # No stacktrace found for following nodes
        unsqueeze_12: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_36, 0);  view_36 = None
        
         # File: <eval_with_key>.27:751 in forward, code: reshape_45 = getitem_236.reshape(-1, 64);  getitem_236 = None
        view_37: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_256, [sym_size_int, 64]);  getitem_256 = None
        
        # No stacktrace found for following nodes
        unsqueeze_13: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_37, 0);  view_37 = None
        
         # File: <eval_with_key>.27:752 in forward, code: reshape_46 = getitem_237.reshape(-1, 64);  getitem_237 = None
        view_38: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_257, [sym_size_int, 64]);  getitem_257 = None
        
        # No stacktrace found for following nodes
        unsqueeze_14: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_38, 0);  view_38 = None
        
         # File: <eval_with_key>.27:753 in forward, code: reshape_47 = getitem_238.reshape(-1, 64);  getitem_238 = None
        view_39: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_258, [sym_size_int, 64]);  getitem_258 = None
        
        # No stacktrace found for following nodes
        unsqueeze_15: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_39, 0);  view_39 = None
        
         # File: <eval_with_key>.27:754 in forward, code: reshape_48 = getitem_239.reshape(-1, 64);  getitem_239 = None
        view_40: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_259, [sym_size_int, 64]);  getitem_259 = None
        
        # No stacktrace found for following nodes
        unsqueeze_16: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_40, 0);  view_40 = None
        
         # File: <eval_with_key>.27:755 in forward, code: reshape_49 = getitem_240.reshape(-1, 64);  getitem_240 = None
        view_41: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_260, [sym_size_int, 64]);  getitem_260 = None
        
        # No stacktrace found for following nodes
        unsqueeze_17: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_41, 0);  view_41 = None
        
         # File: <eval_with_key>.27:756 in forward, code: reshape_50 = getitem_241.reshape(-1, 64);  getitem_241 = None
        view_42: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_261, [sym_size_int, 64]);  getitem_261 = None
        
        # No stacktrace found for following nodes
        unsqueeze_18: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_42, 0);  view_42 = None
        
         # File: <eval_with_key>.27:757 in forward, code: reshape_51 = getitem_242.reshape(-1, 64);  getitem_242 = None
        view_43: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_262, [sym_size_int, 64]);  getitem_262 = None
        
        # No stacktrace found for following nodes
        unsqueeze_19: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_43, 0);  view_43 = None
        
         # File: <eval_with_key>.27:758 in forward, code: reshape_52 = getitem_243.reshape(-1, 64);  getitem_243 = None
        view_44: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_263, [sym_size_int, 64]);  getitem_263 = None
        
        # No stacktrace found for following nodes
        unsqueeze_20: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_44, 0);  view_44 = None
        
         # File: <eval_with_key>.27:759 in forward, code: reshape_53 = getitem_244.reshape(-1, 64);  getitem_244 = None
        view_45: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_264, [sym_size_int, 64]);  getitem_264 = None
        
        # No stacktrace found for following nodes
        unsqueeze_21: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_45, 0);  view_45 = None
        
         # File: <eval_with_key>.27:760 in forward, code: reshape_54 = getitem_245.reshape(-1, 64);  getitem_245 = None
        view_46: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_265, [sym_size_int, 64]);  getitem_265 = None
        
        # No stacktrace found for following nodes
        unsqueeze_22: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_46, 0);  view_46 = None
        
         # File: <eval_with_key>.27:761 in forward, code: reshape_55 = getitem_246.reshape(-1, 64);  getitem_246 = None
        view_47: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_266, [sym_size_int, 64]);  getitem_266 = None
        
        # No stacktrace found for following nodes
        unsqueeze_23: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_47, 0);  view_47 = None
        
         # File: <eval_with_key>.27:762 in forward, code: reshape_56 = getitem_247.reshape(-1, 64);  getitem_247 = None
        view_48: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_267, [sym_size_int, 64]);  getitem_267 = None
        
        # No stacktrace found for following nodes
        unsqueeze_24: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_48, 0);  view_48 = None
        
         # File: <eval_with_key>.27:763 in forward, code: reshape_57 = getitem_248.reshape(-1, 64);  getitem_248 = None
        view_49: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_268, [sym_size_int, 64]);  getitem_268 = None
        
        # No stacktrace found for following nodes
        unsqueeze_25: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_49, 0);  view_49 = None
        
         # File: <eval_with_key>.27:764 in forward, code: reshape_58 = getitem_249.reshape(-1, 64);  getitem_249 = None
        view_50: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_269, [sym_size_int, 64]);  getitem_269 = None
        
        # No stacktrace found for following nodes
        unsqueeze_26: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_50, 0);  view_50 = None
        
         # File: <eval_with_key>.27:765 in forward, code: reshape_59 = getitem_250.reshape(-1, 64);  getitem_250 = None
        view_51: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_270, [sym_size_int, 64]);  getitem_270 = None
        
        # No stacktrace found for following nodes
        unsqueeze_27: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_51, 0);  view_51 = None
        
         # File: <eval_with_key>.27:766 in forward, code: reshape_60 = getitem_251.reshape(-1, 64);  getitem_251 = None
        view_52: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_271, [sym_size_int, 64]);  getitem_271 = None
        
        # No stacktrace found for following nodes
        unsqueeze_28: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_52, 0);  view_52 = None
        
         # File: <eval_with_key>.27:767 in forward, code: reshape_61 = getitem_252.reshape(-1, 64);  getitem_252 = None
        view_53: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_272, [sym_size_int, 64]);  getitem_272 = None
        
        # No stacktrace found for following nodes
        unsqueeze_29: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_53, 0);  view_53 = None
        
         # File: <eval_with_key>.27:768 in forward, code: reshape_62 = getitem_253.reshape(-1, 64);  getitem_253 = None
        view_54: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_273, [sym_size_int, 64]);  getitem_273 = None
        
        # No stacktrace found for following nodes
        unsqueeze_30: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_54, 0);  view_54 = None
        
         # File: <eval_with_key>.27:769 in forward, code: reshape_63 = getitem_254.reshape(-1, 64);  getitem_254 = None
        view_55: "f16[s0, 64][2048, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_274, [sym_size_int, 64]);  getitem_274 = None
        
        # No stacktrace found for following nodes
        unsqueeze_31: "f16[1, s0, 64][2048*s0, 2048, 1]cuda:0" = torch.ops.aten.unsqueeze.default(view_55, 0);  view_55 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_467: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_241, getitem_240);  convert_element_type_241 = getitem_240 = None
        add_1433: "f32[s0, 32, 1][32, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_239, 1e-05);  getitem_239 = None
        rsqrt_44: "f32[s0, 32, 1][32, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1433);  add_1433 = None
        mul_871: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_467, rsqrt_44);  sub_467 = rsqrt_44 = None
        mul_872: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_871, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight);  mul_871 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_weight = None
        add_1434: "f32[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_872, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias);  mul_872 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_ln_ffn_0_bias = None
        convert_element_type_242: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1434, torch.float16);  add_1434 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        mul_890: "Sym(32*s0)" = sym_size_int_13 * 32
        view_16: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_242, [mul_890, 64]);  convert_element_type_242 = mul_890 = None
        permute_56: "f16[64, 128][1, 64]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_60: "f16[32*s0, 128][128, 1]cuda:0" = torch.ops.aten.mm.default(view_16, permute_56);  view_16 = permute_56 = None
        add_tensor_60: "f16[32*s0, 128][128, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_60, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias);  mm_default_60 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        view_17: "f16[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.reshape.default(add_tensor_60, [sym_size_int_13, 32, 128]);  add_tensor_60 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
        convert_element_type_251: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.prims.convert_element_type.default(view_17, torch.float32);  view_17 = None
        mul_907: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.mul.Tensor(convert_element_type_251, 0.5)
        mul_908: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.mul.Tensor(convert_element_type_251, 0.7071067811865476);  convert_element_type_251 = None
        erf: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.erf.default(mul_908);  mul_908 = None
        add_1481: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
        mul_909: "f32[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_907, add_1481);  mul_907 = add_1481 = None
        convert_element_type_252: "f16[s0, 32, 128][4096, 128, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_909, torch.float16);  mul_909 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        mul_920: "Sym(32*s0)" = sym_size_int_13 * 32
        view_20: "f16[32*s0, 128][128, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_252, [mul_920, 128]);  convert_element_type_252 = mul_920 = None
        permute_58: "f16[128, 64][1, 128]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_weight = None
        
        # No stacktrace found for following nodes
        mm_default_59: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.mm.default(view_20, permute_58);  view_20 = permute_58 = None
        add_tensor_59: "f16[32*s0, 64][64, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_59, submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias);  mm_default_59 = submod_0_main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        view_21: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.reshape.default(add_tensor_59, [sym_size_int_13, 32, 64]);  add_tensor_59 = sym_size_int_13 = None
        
         # File: <eval_with_key>.27:637 in forward, code: add_16 = add_14 + main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2;  add_14 = main_module_impl_impl_shared_arch_event_submodels_dict_iaw_relevance_model_pre_norm_pma_mab_mlps_0_2 = None
        add_1501: "f16[s0, 32, 64][2048, 64, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1419, view_21);  add_1419 = view_21 = None
        
        # No stacktrace found for following nodes
        permute_60: "f16[32, s0, 64][64, 2048, 1]cuda:0" = torch.ops.aten.permute.default(add_1501, [1, 0, 2]);  add_1501 = None
        
         # File: <eval_with_key>.27:770 in forward, code: stack = torch.stack(tensors = [reshape_32, reshape_33, reshape_34, reshape_35, reshape_36, reshape_37, reshape_38, reshape_39, reshape_40, reshape_41, reshape_42, reshape_43, reshape_44, reshape_45, reshape_46, reshape_47, reshape_48, reshape_49, reshape_50, reshape_51, reshape_52, reshape_53, reshape_54, reshape_55, reshape_56, reshape_57, reshape_58, reshape_59, reshape_60, reshape_61, reshape_62, reshape_63, reshape, reshape_1, reshape_2, reshape_3, reshape_4, reshape_5, reshape_6, reshape_7, reshape_8, reshape_9, reshape_10, reshape_11, reshape_12, reshape_13, reshape_14, reshape_15, reshape_16, reshape_17, reshape_18, reshape_19, reshape_20, reshape_21, reshape_22, reshape_23, reshape_24, reshape_25, reshape_26, reshape_27, reshape_28, reshape_29, reshape_30, reshape_31], dim = 0);  reshape_32 = reshape_33 = reshape_34 = reshape_35 = reshape_36 = reshape_37 = reshape_38 = reshape_39 = reshape_40 = reshape_41 = reshape_42 = reshape_43 = reshape_44 = reshape_45 = reshape_46 = reshape_47 = reshape_48 = reshape_49 = reshape_50 = reshape_51 = reshape_52 = reshape_53 = reshape_54 = reshape_55 = reshape_56 = reshape_57 = reshape_58 = reshape_59 = reshape_60 = reshape_61 = reshape_62 = reshape_63 = reshape = reshape_1 = reshape_2 = reshape_3 = reshape_4 = reshape_5 = reshape_6 = reshape_7 = reshape_8 = reshape_9 = reshape_10 = reshape_11 = reshape_12 = reshape_13 = reshape_14 = reshape_15 = reshape_16 = reshape_17 = reshape_18 = reshape_19 = reshape_20 = reshape_21 = reshape_22 = reshape_23 = reshape_24 = reshape_25 = reshape_26 = reshape_27 = reshape_28 = reshape_29 = reshape_30 = reshape_31 = None
        cat_10: "f16[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.cat.default([unsqueeze, unsqueeze_1, unsqueeze_2, unsqueeze_3, unsqueeze_4, unsqueeze_5, unsqueeze_6, unsqueeze_7, unsqueeze_8, unsqueeze_9, unsqueeze_10, unsqueeze_11, unsqueeze_12, unsqueeze_13, unsqueeze_14, unsqueeze_15, unsqueeze_16, unsqueeze_17, unsqueeze_18, unsqueeze_19, unsqueeze_20, unsqueeze_21, unsqueeze_22, unsqueeze_23, unsqueeze_24, unsqueeze_25, unsqueeze_26, unsqueeze_27, unsqueeze_28, unsqueeze_29, unsqueeze_30, unsqueeze_31, permute_60]);  unsqueeze = unsqueeze_1 = unsqueeze_2 = unsqueeze_3 = unsqueeze_4 = unsqueeze_5 = unsqueeze_6 = unsqueeze_7 = unsqueeze_8 = unsqueeze_9 = unsqueeze_10 = unsqueeze_11 = unsqueeze_12 = unsqueeze_13 = unsqueeze_14 = unsqueeze_15 = unsqueeze_16 = unsqueeze_17 = unsqueeze_18 = unsqueeze_19 = unsqueeze_20 = unsqueeze_21 = unsqueeze_22 = unsqueeze_23 = unsqueeze_24 = unsqueeze_25 = unsqueeze_26 = unsqueeze_27 = unsqueeze_28 = unsqueeze_29 = unsqueeze_30 = unsqueeze_31 = permute_60 = None
        
         # File: <eval_with_key>.27:771 in forward, code: nan_to_num = torch.nan_to_num(stack, 0.0);  stack = None
        convert_element_type_262: "f32[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(cat_10, torch.float32)
        eq_584: "b8[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_262, inf);  convert_element_type_262 = None
        scalar_tensor_5: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        convert_element_type_261: "f32[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(cat_10, torch.float32)
        eq_583: "b8[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_261, -inf);  convert_element_type_261 = None
        scalar_tensor_4: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(-65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        isnan_1: "b8[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.isnan.default(cat_10)
        scalar_tensor_3: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        where_3: "f16[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.where.self(isnan_1, scalar_tensor_3, cat_10);  isnan_1 = scalar_tensor_3 = cat_10 = None
        where_4: "f16[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.where.self(eq_583, scalar_tensor_4, where_3);  eq_583 = scalar_tensor_4 = where_3 = None
        where_5: "f16[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.where.self(eq_584, scalar_tensor_5, where_4);  eq_584 = scalar_tensor_5 = where_4 = None
        
         # File: <eval_with_key>.27:772 in forward, code: clamp = nan_to_num.clamp(min = -1000.1, max = 1000.1);  nan_to_num = None
        convert_element_type_263: "f32[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(where_5, torch.float32);  where_5 = None
        clamp_min: "f32[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.clamp_min.default(convert_element_type_263, -1000.1);  convert_element_type_263 = None
        clamp_max: "f32[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.aten.clamp_max.default(clamp_min, 1000.1);  clamp_min = None
        convert_element_type_264: "f16[64, s0, 64][64*s0, 64, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clamp_max, torch.float16);  clamp_max = None
        
         # File: <eval_with_key>.27:775 in forward, code: baddbmm = torch.baddbmm(main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias, clamp, main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight);  main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias = clamp = main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight = None
        baddbmm: "f16[64, s0, 192][192*s0, 192, 1]cuda:0" = torch.ops.aten.baddbmm.default(submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias, convert_element_type_264, submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight);  submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_bias = convert_element_type_264 = submod_0_main_module_impl_impl_shared_arch_embedding_projection_arch_first_fused_mlp_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        permute_61: "f16[s0, 64, 192][192, 192*s0, 1]cuda:0" = torch.ops.aten.permute.default(baddbmm, [1, 0, 2]);  baddbmm = None
        clone_8: "f16[s0, 64, 192][12288, 192, 1]cuda:0" = torch.ops.aten.clone.default(permute_61, memory_format = torch.contiguous_format);  permute_61 = None
        mul_1182: "Sym(64*s0)" = sym_size_int_14 * 64;  sym_size_int_14 = None
        mul_1183: "Sym(12288*s0)" = mul_1182 * 192;  mul_1182 = None
        floordiv: "Sym(s0)" = mul_1183 // 12288;  mul_1183 = None
        view_56: "f16[s0, 12288][12288, 1]cuda:0" = torch.ops.aten.reshape.default(clone_8, [floordiv, 12288]);  clone_8 = floordiv = None
        
         # File: <eval_with_key>.27:906 in forward, code: cat_41 = torch.cat(tensors = [getitem_42, getitem_95, getitem_41, getitem_94, getitem_40, getitem_93, getitem_39, getitem_92, getitem_38, getitem_91, getitem_37, getitem_90, getitem_36, getitem_89, getitem_35, getitem_88, getitem_34, getitem_87, getitem_33, getitem_86, getitem_32, getitem_85, getitem_31, getitem_84, getitem_30, getitem_83, getitem_29, getitem_82, getitem_28, getitem_81, getitem_27, getitem_80, getitem_26, getitem_79, getitem_25, getitem_78, getitem_24, getitem_77, getitem_23, getitem_76, getitem_22, getitem_75, getitem_21, getitem_74, getitem_20, getitem_73, getitem_19, getitem_72, getitem_18, getitem_71, getitem_17, getitem_70, getitem_16, getitem_69, getitem_15, getitem_68, getitem_14, getitem_67, getitem_13, getitem_66, getitem_12, getitem_65, getitem_11, getitem_64, getitem_10, getitem_63, getitem_9, getitem_62, linear_45, linear_46, linear_47, linear_48, linear_49, linear_50, linear_41, layer_norm_4, layer_norm_5, layer_norm, layer_norm_6, layer_norm_7, layer_norm_8, layer_norm_1, layer_norm_9, layer_norm_10, layer_norm_11, layer_norm_2, layer_norm_3, layer_norm_12, layer_norm_13, layer_norm_14, layer_norm_15, layer_norm_16, layer_norm_17, layer_norm_18, layer_norm_19, layer_norm_20, layer_norm_21, layer_norm_22, layer_norm_23, layer_norm_24, layer_norm_25, layer_norm_26, layer_norm_27, layer_norm_28, layer_norm_29, layer_norm_30, layer_norm_31, layer_norm_32, layer_norm_33, layer_norm_34, layer_norm_35, reshape_64, reshape_65, reshape_66, reshape_67, reshape_68, reshape_69, reshape_70, reshape_71, reshape_72, reshape_73, reshape_74, reshape_75, reshape_76, reshape_77, reshape_78, reshape_79, reshape_80, reshape_81, reshape_82, reshape_83, reshape_84, reshape_85, reshape_86, reshape_87, reshape_88, reshape_89, reshape_90, reshape_91, reshape_92, reshape_93, reshape_94, reshape_95, reshape_96, reshape_97, reshape_98, reshape_99, reshape_100, reshape_101, reshape_102, reshape_103, reshape_104, reshape_105, reshape_106, reshape_107, reshape_108, reshape_109, reshape_110, reshape_111, reshape_112, reshape_113, reshape_114, reshape_115, reshape_116, reshape_117, reshape_118, reshape_119, reshape_120, reshape_121, reshape_122, reshape_123, reshape_124, reshape_125, reshape_126, reshape_127], dim = 1);  getitem_42 = getitem_95 = getitem_41 = getitem_94 = getitem_40 = getitem_93 = getitem_39 = getitem_92 = getitem_38 = getitem_91 = getitem_37 = getitem_90 = getitem_36 = getitem_89 = getitem_35 = getitem_88 = getitem_34 = getitem_87 = getitem_33 = getitem_86 = getitem_32 = getitem_85 = getitem_31 = getitem_84 = getitem_30 = getitem_83 = getitem_29 = getitem_82 = getitem_28 = getitem_81 = getitem_27 = getitem_80 = getitem_26 = getitem_79 = getitem_25 = getitem_78 = getitem_24 = getitem_77 = getitem_23 = getitem_76 = getitem_22 = getitem_75 = getitem_21 = getitem_74 = getitem_20 = getitem_73 = getitem_19 = getitem_72 = getitem_18 = getitem_71 = getitem_17 = getitem_70 = getitem_16 = getitem_69 = getitem_15 = getitem_68 = getitem_14 = getitem_67 = getitem_13 = getitem_66 = getitem_12 = getitem_65 = getitem_11 = getitem_64 = getitem_10 = getitem_63 = getitem_9 = getitem_62 = linear_41 = layer_norm_4 = layer_norm_5 = layer_norm = layer_norm_6 = layer_norm_7 = layer_norm_8 = layer_norm_1 = layer_norm_9 = layer_norm_10 = layer_norm_11 = layer_norm_2 = layer_norm_3 = layer_norm_12 = layer_norm_13 = layer_norm_14 = layer_norm_15 = layer_norm_16 = layer_norm_17 = layer_norm_18 = layer_norm_19 = layer_norm_20 = layer_norm_21 = layer_norm_22 = layer_norm_23 = layer_norm_24 = layer_norm_25 = layer_norm_26 = layer_norm_27 = layer_norm_28 = layer_norm_29 = layer_norm_30 = layer_norm_31 = layer_norm_32 = layer_norm_33 = layer_norm_34 = layer_norm_35 = reshape_64 = reshape_65 = reshape_66 = reshape_67 = reshape_68 = reshape_69 = reshape_70 = reshape_71 = reshape_72 = reshape_73 = reshape_74 = reshape_75 = reshape_76 = reshape_77 = reshape_78 = reshape_79 = reshape_80 = reshape_81 = reshape_82 = reshape_83 = reshape_84 = reshape_85 = reshape_86 = reshape_87 = reshape_88 = reshape_89 = reshape_90 = reshape_91 = reshape_92 = reshape_93 = reshape_94 = reshape_95 = reshape_96 = reshape_97 = reshape_98 = reshape_99 = reshape_100 = reshape_101 = reshape_102 = reshape_103 = reshape_104 = reshape_105 = reshape_106 = reshape_107 = reshape_108 = reshape_109 = reshape_110 = reshape_111 = reshape_112 = reshape_113 = reshape_114 = reshape_115 = reshape_116 = reshape_117 = reshape_118 = reshape_119 = reshape_120 = reshape_121 = reshape_122 = reshape_123 = reshape_124 = reshape_125 = reshape_126 = reshape_127 = None
        cat_11: "f16[s0, 87936][87936, 1]cuda:0" = torch.ops.aten.cat.default([getitem_19, getitem_61, getitem_20, getitem_62, getitem_21, getitem_63, getitem_22, getitem_64, getitem_23, getitem_65, getitem_24, getitem_66, getitem_25, getitem_67, getitem_26, getitem_68, getitem_27, getitem_69, getitem_28, getitem_70, getitem_29, getitem_71, getitem_30, getitem_72, getitem_31, getitem_73, getitem_32, getitem_74, getitem_33, getitem_75, getitem_34, getitem_76, getitem_35, getitem_77, getitem_36, getitem_78, getitem_37, getitem_79, getitem_38, getitem_80, getitem_39, getitem_81, getitem_40, getitem_82, getitem_41, getitem_83, getitem_42, getitem_84, getitem_43, getitem_85, getitem_44, getitem_86, getitem_45, getitem_87, getitem_46, getitem_88, getitem_47, getitem_89, getitem_48, getitem_90, getitem_49, getitem_91, getitem_50, getitem_92, getitem_51, getitem_93, getitem_52, getitem_94, clone_2, clone_3, clone_4, clone_5, clone_6, clone_7, addmm_39, convert_element_type_129, convert_element_type_131, convert_element_type_121, convert_element_type_133, convert_element_type_135, convert_element_type_137, convert_element_type_123, convert_element_type_139, convert_element_type_141, convert_element_type_143, convert_element_type_125, convert_element_type_127, convert_element_type_145, convert_element_type_147, convert_element_type_149, convert_element_type_151, convert_element_type_153, convert_element_type_155, convert_element_type_157, convert_element_type_159, convert_element_type_161, convert_element_type_163, convert_element_type_165, convert_element_type_167, convert_element_type_169, convert_element_type_171, convert_element_type_173, convert_element_type_175, convert_element_type_177, convert_element_type_179, convert_element_type_181, convert_element_type_183, convert_element_type_185, convert_element_type_187, convert_element_type_189, convert_element_type_191, view_56], 1);  getitem_19 = getitem_61 = getitem_20 = getitem_62 = getitem_21 = getitem_63 = getitem_22 = getitem_64 = getitem_23 = getitem_65 = getitem_24 = getitem_66 = getitem_25 = getitem_67 = getitem_26 = getitem_68 = getitem_27 = getitem_69 = getitem_28 = getitem_70 = getitem_29 = getitem_71 = getitem_30 = getitem_72 = getitem_31 = getitem_73 = getitem_32 = getitem_74 = getitem_33 = getitem_75 = getitem_34 = getitem_76 = getitem_35 = getitem_77 = getitem_36 = getitem_78 = getitem_37 = getitem_79 = getitem_38 = getitem_80 = getitem_39 = getitem_81 = getitem_40 = getitem_82 = getitem_41 = getitem_83 = getitem_42 = getitem_84 = getitem_43 = getitem_85 = getitem_44 = getitem_86 = getitem_45 = getitem_87 = getitem_46 = getitem_88 = getitem_47 = getitem_89 = getitem_48 = getitem_90 = getitem_49 = getitem_91 = getitem_50 = getitem_92 = getitem_51 = getitem_93 = getitem_52 = getitem_94 = addmm_39 = convert_element_type_129 = convert_element_type_131 = convert_element_type_121 = convert_element_type_133 = convert_element_type_135 = convert_element_type_137 = convert_element_type_123 = convert_element_type_139 = convert_element_type_141 = convert_element_type_143 = convert_element_type_125 = convert_element_type_127 = convert_element_type_145 = convert_element_type_147 = convert_element_type_149 = convert_element_type_151 = convert_element_type_153 = convert_element_type_155 = convert_element_type_157 = convert_element_type_159 = convert_element_type_161 = convert_element_type_163 = convert_element_type_165 = convert_element_type_167 = convert_element_type_169 = convert_element_type_171 = convert_element_type_173 = convert_element_type_175 = convert_element_type_177 = convert_element_type_179 = convert_element_type_181 = convert_element_type_183 = convert_element_type_185 = convert_element_type_187 = convert_element_type_189 = convert_element_type_191 = view_56 = None
        
         # File: <eval_with_key>.27:907 in forward, code: reshape_128 = torch.reshape(cat_41, [-1, 458, 192]);  cat_41 = None
        view_57: "f16[s0, 458, 192][87936, 192, 1]cuda:0" = torch.ops.aten.reshape.default(cat_11, [-1, 458, 192]);  cat_11 = None
        
         # File: <eval_with_key>.27:909 in forward, code: matmul = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w, reshape_128);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_w = None
        expand_1: "f16[s0, 458, 192][87936, 192, 1]cuda:0" = torch.ops.aten.expand.default(view_57, [sym_size_int_2, 458, 192])
        view_59: "f16[s0, 458, 192][87936, 192, 1]cuda:0" = torch.ops.aten.reshape.default(expand_1, [sym_size_int_2, 458, 192]);  expand_1 = None
        bmm: "f16[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.aten.bmm.default(view_58, view_59);  view_58 = view_59 = None
        view_60: "f16[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.aten.reshape.default(bmm, [sym_size_int_2, 174, 192]);  bmm = None
        
         # File: <eval_with_key>.27:911 in forward, code: add_18 = matmul + main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b;  matmul = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b = None
        add_1894: "f16[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(view_60, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b);  view_60 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__compression_b = None
        
         # File: <eval_with_key>.27:917 in forward, code: layer_norm_40 = torch.nn.functional.layer_norm(add_18, getitem_319, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b, eps = 1e-05);  add_18 = getitem_319 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b = None
        convert_element_type_267: "f32[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1894, torch.float32);  add_1894 = None
        var_mean_46 = torch.ops.aten.var_mean.correction(convert_element_type_267, [2], correction = 0, keepdim = True)
        getitem_275: "f32[s0, 174, 1][174, 1, 1]cuda:0" = var_mean_46[0]
        getitem_276: "f32[s0, 174, 1][174, 1, 1]cuda:0" = var_mean_46[1];  var_mean_46 = None
        sub_605: "f32[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_267, getitem_276);  convert_element_type_267 = getitem_276 = None
        add_1903: "f32[s0, 174, 1][174, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_275, 1e-05);  getitem_275 = None
        rsqrt_46: "f32[s0, 174, 1][174, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1903);  add_1903 = None
        mul_1224: "f32[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_605, rsqrt_46);  sub_605 = rsqrt_46 = None
        mul_1225: "f32[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1224, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w);  mul_1224 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_w = None
        add_1904: "f32[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1225, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b);  mul_1225 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__fused_lce_module__ln_lce__init_b = None
        convert_element_type_268: "f16[s0, 174, 192][33408, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1904, torch.float16);  add_1904 = None
        
         # File: <eval_with_key>.27:918 in forward, code: split = torch.functional.split(layer_norm_40, [48, 24, 102], dim = 1);  layer_norm_40 = None
        split_with_sizes_5 = torch.ops.aten.split_with_sizes.default(convert_element_type_268, [48, 24, 102], 1);  convert_element_type_268 = None
        getitem_277: "f16[s0, 48, 192][33408, 192, 1]cuda:0" = split_with_sizes_5[0]
        getitem_278: "f16[s0, 24, 192][33408, 192, 1]cuda:0" = split_with_sizes_5[1]
        getitem_279: "f16[s0, 102, 192][33408, 192, 1]cuda:0" = split_with_sizes_5[2];  split_with_sizes_5 = None
        
        # No stacktrace found for following nodes
        cat_13: "f16[1536][1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_bias, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_bias]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_bias = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:923 in forward, code: reshape_130 = torch.reshape(getitem_321, (-1, 4608));  getitem_321 = None
        view_62: "f16[s0, 4608][33408, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_278, [sym_size_int, 4608]);  getitem_278 = None
        
        # No stacktrace found for following nodes
        cat_12: "f16[1536, 4608][4608, 1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_weight, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_weight]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0_weight = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0_weight = None
        permute_63: "f16[4608, 1536][1, 4608]cuda:0" = torch.ops.aten.permute.default(cat_12, [1, 0]);  cat_12 = None
        mm_default_58: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(view_62, permute_63);  view_62 = permute_63 = None
        add_tensor_58: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_58, cat_13);  mm_default_58 = cat_13 = None
        slice_18: "f16[s0, 768][1536, 1]cuda:0" = torch.ops.aten.slice.Tensor(add_tensor_58, 1, 0, 768)
        clone_9: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.clone.default(slice_18, memory_format = torch.contiguous_format);  slice_18 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_272: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone_9, torch.float32)
        var_mean_47 = torch.ops.aten.var_mean.correction(convert_element_type_272, [1], correction = 0, keepdim = True)
        getitem_280: "f32[s0, 1][1, 1]cuda:0" = var_mean_47[0]
        getitem_281: "f32[s0, 1][1, 1]cuda:0" = var_mean_47[1];  var_mean_47 = None
        
        # No stacktrace found for following nodes
        slice_20: "f16[s0, 768][1536, 1]cuda:0" = torch.ops.aten.slice.Tensor(add_tensor_58, 1, 768, 1536);  add_tensor_58 = None
        clone_10: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.clone.default(slice_20, memory_format = torch.contiguous_format);  slice_20 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_274: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone_10, torch.float32)
        var_mean_48 = torch.ops.aten.var_mean.correction(convert_element_type_274, [1], correction = 0, keepdim = True)
        getitem_282: "f32[s0, 1][1, 1]cuda:0" = var_mean_48[0]
        getitem_283: "f32[s0, 1][1, 1]cuda:0" = var_mean_48[1];  var_mean_48 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_621: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_272, getitem_281);  convert_element_type_272 = getitem_281 = None
        add_1956: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_280, 1e-05);  getitem_280 = None
        rsqrt_47: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1956);  add_1956 = None
        mul_1258: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_621, rsqrt_47);  sub_621 = rsqrt_47 = None
        mul_1259: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1258, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight);  mul_1258 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = None
        add_1957: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1259, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias);  mul_1259 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = None
        convert_element_type_273: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1957, torch.float16);  add_1957 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_5: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_273);  convert_element_type_273 = None
        
         # File: <eval_with_key>.27:929 in forward, code: mul_4 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_1_norm_1 = None
        mul_1272: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone_9, sigmoid_5);  clone_9 = sigmoid_5 = None
        
         # File: <eval_with_key>.27:934 in forward, code: layer_norm_41 = torch.nn.functional.layer_norm(mul_4, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_4 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_276: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1272, torch.float32);  mul_1272 = None
        var_mean_49 = torch.ops.aten.var_mean.correction(convert_element_type_276, [1], correction = 0, keepdim = True)
        getitem_284: "f32[s0, 1][1, 1]cuda:0" = var_mean_49[0]
        getitem_285: "f32[s0, 1][1, 1]cuda:0" = var_mean_49[1];  var_mean_49 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_625: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_274, getitem_283);  convert_element_type_274 = getitem_283 = None
        add_1967: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_282, 1e-05);  getitem_282 = None
        rsqrt_48: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1967);  add_1967 = None
        mul_1264: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_625, rsqrt_48);  sub_625 = rsqrt_48 = None
        mul_1265: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1264, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight);  mul_1264 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = None
        add_1968: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1265, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias);  mul_1265 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = None
        convert_element_type_275: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1968, torch.float16);  add_1968 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_6: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_275);  convert_element_type_275 = None
        
         # File: <eval_with_key>.27:931 in forward, code: mul_5 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_1_norm_1 = None
        mul_1277: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone_10, sigmoid_6);  clone_10 = sigmoid_6 = None
        
         # File: <eval_with_key>.27:937 in forward, code: layer_norm_42 = torch.nn.functional.layer_norm(mul_5, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_5 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_278: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1277, torch.float32);  mul_1277 = None
        var_mean_50 = torch.ops.aten.var_mean.correction(convert_element_type_278, [1], correction = 0, keepdim = True)
        getitem_286: "f32[s0, 1][1, 1]cuda:0" = var_mean_50[0]
        getitem_287: "f32[s0, 1][1, 1]cuda:0" = var_mean_50[1];  var_mean_50 = None
        
         # File: <eval_with_key>.27:934 in forward, code: layer_norm_41 = torch.nn.functional.layer_norm(mul_4, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_4 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        sub_633: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_276, getitem_285);  convert_element_type_276 = getitem_285 = None
        add_1990: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_284, 1e-05);  getitem_284 = None
        rsqrt_49: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1990);  add_1990 = None
        mul_1280: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_633, rsqrt_49);  sub_633 = rsqrt_49 = None
        mul_1281: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1280, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w);  mul_1280 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_w = None
        add_1991: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1281, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b);  mul_1281 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_277: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1991, torch.float16);  add_1991 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_64: "f16[768, 768][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_weight = None
        
        # No stacktrace found for following nodes
        mm_default_57: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_277, permute_64);  convert_element_type_277 = permute_64 = None
        add_tensor_57: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_57, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias);  mm_default_57 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_286: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_57, torch.float32)
        var_mean_51 = torch.ops.aten.var_mean.correction(convert_element_type_286, [1], correction = 0, keepdim = True)
        getitem_288: "f32[s0, 1][1, 1]cuda:0" = var_mean_51[0]
        getitem_289: "f32[s0, 1][1, 1]cuda:0" = var_mean_51[1];  var_mean_51 = None
        
         # File: <eval_with_key>.27:937 in forward, code: layer_norm_42 = torch.nn.functional.layer_norm(mul_5, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_5 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        sub_637: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_278, getitem_287);  convert_element_type_278 = getitem_287 = None
        add_2001: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_286, 1e-05);  getitem_286 = None
        rsqrt_50: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2001);  add_2001 = None
        mul_1286: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_637, rsqrt_50);  sub_637 = rsqrt_50 = None
        mul_1287: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1286, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w);  mul_1286 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_w = None
        add_2002: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1287, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b);  mul_1287 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_279: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2002, torch.float16);  add_2002 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_65: "f16[768, 768][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_weight = None
        
        # No stacktrace found for following nodes
        mm_default_56: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_279, permute_65);  convert_element_type_279 = permute_65 = None
        add_tensor_56: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_56, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias);  mm_default_56 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_288: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_56, torch.float32)
        var_mean_52 = torch.ops.aten.var_mean.correction(convert_element_type_288, [1], correction = 0, keepdim = True)
        getitem_290: "f32[s0, 1][1, 1]cuda:0" = var_mean_52[0]
        getitem_291: "f32[s0, 1][1, 1]cuda:0" = var_mean_52[1];  var_mean_52 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_643: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_286, getitem_289);  convert_element_type_286 = getitem_289 = None
        add_2018: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_288, 1e-05);  getitem_288 = None
        rsqrt_51: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2018);  add_2018 = None
        mul_1296: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_643, rsqrt_51);  sub_643 = rsqrt_51 = None
        mul_1297: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1296, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight);  mul_1296 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = None
        add_2019: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1297, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias);  mul_1297 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = None
        convert_element_type_287: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2019, torch.float16);  add_2019 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_7: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_287);  convert_element_type_287 = None
        
         # File: <eval_with_key>.27:943 in forward, code: mul_6 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_4_norm_1 = None
        mul_1310: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_57, sigmoid_7);  add_tensor_57 = sigmoid_7 = None
        
         # File: <eval_with_key>.27:948 in forward, code: layer_norm_43 = torch.nn.functional.layer_norm(mul_6, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_6 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_290: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1310, torch.float32);  mul_1310 = None
        var_mean_53 = torch.ops.aten.var_mean.correction(convert_element_type_290, [1], correction = 0, keepdim = True)
        getitem_292: "f32[s0, 1][1, 1]cuda:0" = var_mean_53[0]
        getitem_293: "f32[s0, 1][1, 1]cuda:0" = var_mean_53[1];  var_mean_53 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_647: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_288, getitem_291);  convert_element_type_288 = getitem_291 = None
        add_2029: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_290, 1e-05);  getitem_290 = None
        rsqrt_52: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2029);  add_2029 = None
        mul_1302: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_647, rsqrt_52);  sub_647 = rsqrt_52 = None
        mul_1303: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1302, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight);  mul_1302 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = None
        add_2030: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1303, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias);  mul_1303 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = None
        convert_element_type_289: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2030, torch.float16);  add_2030 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_8: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_289);  convert_element_type_289 = None
        
         # File: <eval_with_key>.27:945 in forward, code: mul_7 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_4_norm_1 = None
        mul_1315: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_56, sigmoid_8);  add_tensor_56 = sigmoid_8 = None
        
         # File: <eval_with_key>.27:951 in forward, code: layer_norm_44 = torch.nn.functional.layer_norm(mul_7, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_7 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_292: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1315, torch.float32);  mul_1315 = None
        var_mean_54 = torch.ops.aten.var_mean.correction(convert_element_type_292, [1], correction = 0, keepdim = True)
        getitem_294: "f32[s0, 1][1, 1]cuda:0" = var_mean_54[0]
        getitem_295: "f32[s0, 1][1, 1]cuda:0" = var_mean_54[1];  var_mean_54 = None
        
         # File: <eval_with_key>.27:948 in forward, code: layer_norm_43 = torch.nn.functional.layer_norm(mul_6, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_6 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        sub_655: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_290, getitem_293);  convert_element_type_290 = getitem_293 = None
        add_2052: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_292, 1e-05);  getitem_292 = None
        rsqrt_53: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2052);  add_2052 = None
        mul_1318: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_655, rsqrt_53);  sub_655 = rsqrt_53 = None
        mul_1319: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1318, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w);  mul_1318 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_w = None
        add_2053: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1319, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b);  mul_1319 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_291: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2053, torch.float16);  add_2053 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_66: "f16[768, 21984][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_55: "f16[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_291, permute_66);  convert_element_type_291 = permute_66 = None
        add_tensor_55: "f16[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_55, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias);  mm_default_55 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:956 in forward, code: layer_norm_45 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0, (21984,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_300: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_55, torch.float32);  add_tensor_55 = None
        var_mean_55 = torch.ops.aten.var_mean.correction(convert_element_type_300, [1], correction = 0, keepdim = True)
        getitem_296: "f32[s0, 1][1, 1]cuda:0" = var_mean_55[0]
        getitem_297: "f32[s0, 1][1, 1]cuda:0" = var_mean_55[1];  var_mean_55 = None
        
         # File: <eval_with_key>.27:951 in forward, code: layer_norm_44 = torch.nn.functional.layer_norm(mul_7, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_7 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        sub_659: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_292, getitem_295);  convert_element_type_292 = getitem_295 = None
        add_2063: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_294, 1e-05);  getitem_294 = None
        rsqrt_54: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2063);  add_2063 = None
        mul_1324: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_659, rsqrt_54);  sub_659 = rsqrt_54 = None
        mul_1325: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1324, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w);  mul_1324 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_w = None
        add_2064: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1325, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b);  mul_1325 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_293: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2064, torch.float16);  add_2064 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_67: "f16[768, 9216][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_54: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_293, permute_67);  convert_element_type_293 = permute_67 = None
        add_tensor_54: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_54, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias);  mm_default_54 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:959 in forward, code: layer_norm_46 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0, (9216,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_302: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_54, torch.float32);  add_tensor_54 = None
        var_mean_56 = torch.ops.aten.var_mean.correction(convert_element_type_302, [1], correction = 0, keepdim = True)
        getitem_298: "f32[s0, 1][1, 1]cuda:0" = var_mean_56[0]
        getitem_299: "f32[s0, 1][1, 1]cuda:0" = var_mean_56[1];  var_mean_56 = None
        sub_669: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_302, getitem_299);  convert_element_type_302 = getitem_299 = None
        add_2091: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_298, 1e-05);  getitem_298 = None
        rsqrt_56: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2091);  add_2091 = None
        mul_1340: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_669, rsqrt_56);  sub_669 = rsqrt_56 = None
        mul_1341: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1340, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w);  mul_1340 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = None
        add_2092: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1341, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b);  mul_1341 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_303: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2092, torch.float16);  add_2092 = None
        
         # File: <eval_with_key>.27:961 in forward, code: reshape_132 = torch.reshape(layer_norm_46, (-1, 192, 48));  layer_norm_46 = None
        view_64: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_303, [-1, 192, 48]);  convert_element_type_303 = None
        
         # File: <eval_with_key>.27:912 in forward, code: permute_8 = reshape_128.permute(0, 2, 1)
        permute_62: "f16[s0, 192, 458][87936, 1, 192]cuda:0" = torch.ops.aten.permute.default(view_57, [0, 2, 1])
        
         # File: <eval_with_key>.27:956 in forward, code: layer_norm_45 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0, (21984,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        sub_665: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_300, getitem_297);  convert_element_type_300 = getitem_297 = None
        add_2080: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_296, 1e-05);  getitem_296 = None
        rsqrt_55: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2080);  add_2080 = None
        mul_1334: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_665, rsqrt_55);  sub_665 = rsqrt_55 = None
        mul_1335: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1334, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w);  mul_1334 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = None
        add_2081: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1335, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b);  mul_1335 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_301: "f16[s0, 21984][21984, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2081, torch.float16);  add_2081 = None
        
         # File: <eval_with_key>.27:960 in forward, code: reshape_131 = torch.reshape(layer_norm_45, (-1, 458, 48));  layer_norm_45 = None
        view_63: "f16[s0, 458, 48][21984, 48, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_301, [-1, 458, 48]);  convert_element_type_301 = None
        
         # File: <eval_with_key>.27:962 in forward, code: bmm = torch.bmm(permute_8, reshape_131);  permute_8 = reshape_131 = None
        bmm_1: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.bmm.default(permute_62, view_63);  permute_62 = view_63 = None
        
         # File: <eval_with_key>.27:963 in forward, code: add_19 = reshape_132 + bmm;  reshape_132 = bmm = None
        add_2114: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.add.Tensor(view_64, bmm_1);  view_64 = bmm_1 = None
        
         # File: <eval_with_key>.27:966 in forward, code: layer_norm_47 = torch.nn.functional.layer_norm(add_19, (48,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b, eps = 1e-05);  add_19 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b = None
        convert_element_type_306: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2114, torch.float32);  add_2114 = None
        var_mean_57 = torch.ops.aten.var_mean.correction(convert_element_type_306, [2], correction = 0, keepdim = True)
        getitem_300: "f32[s0, 192, 1][192, 1, 1]cuda:0" = var_mean_57[0]
        getitem_301: "f32[s0, 192, 1][192, 1, 1]cuda:0" = var_mean_57[1];  var_mean_57 = None
        sub_677: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_306, getitem_301);  convert_element_type_306 = getitem_301 = None
        add_2119: "f32[s0, 192, 1][192, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_300, 1e-05);  getitem_300 = None
        rsqrt_57: "f32[s0, 192, 1][192, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2119);  add_2119 = None
        mul_1354: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_677, rsqrt_57);  sub_677 = rsqrt_57 = None
        mul_1355: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1354, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w);  mul_1354 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_w = None
        add_2120: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1355, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b);  mul_1355 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcpp_compressed_tensor_ln__init_b = None
        convert_element_type_307: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2120, torch.float16);  add_2120 = None
        
         # File: <eval_with_key>.27:967 in forward, code: bmm_1 = torch.bmm(reshape_128, layer_norm_47);  reshape_128 = layer_norm_47 = None
        bmm_2: "f16[s0, 458, 48][21984, 48, 1]cuda:0" = torch.ops.aten.bmm.default(view_57, convert_element_type_307);  view_57 = convert_element_type_307 = None
        
         # File: <eval_with_key>.27:968 in forward, code: flatten = torch.flatten(bmm_1, start_dim = -2);  bmm_1 = None
        view_65: "f16[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.reshape.default(bmm_2, [sym_size_int, 21984]);  bmm_2 = None
        
         # File: <eval_with_key>.27:973 in forward, code: layer_norm_48 = torch.nn.functional.layer_norm(flatten, getitem_323, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b, eps = 1e-05);  flatten = getitem_323 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b = None
        convert_element_type_310: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.prims.convert_element_type.default(view_65, torch.float32);  view_65 = None
        var_mean_58 = torch.ops.aten.var_mean.correction(convert_element_type_310, [1], correction = 0, keepdim = True)
        getitem_302: "f32[s0, 1][1, 1]cuda:0" = var_mean_58[0]
        getitem_303: "f32[s0, 1][1, 1]cuda:0" = var_mean_58[1];  var_mean_58 = None
        sub_683: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_310, getitem_303);  convert_element_type_310 = getitem_303 = None
        add_2140: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_302, 1e-05);  getitem_302 = None
        rsqrt_58: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2140);  add_2140 = None
        mul_1366: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_683, rsqrt_58);  sub_683 = rsqrt_58 = None
        mul_1367: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1366, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w);  mul_1366 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_w = None
        add_2141: "f32[s0, 21984][21984, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1367, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b);  mul_1367 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_ln__init_b = None
        convert_element_type_311: "f16[s0, 21984][21984, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2141, torch.float16);  add_2141 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_68: "f16[21984, 2048][1, 21984]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_53: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_311, permute_68);  convert_element_type_311 = permute_68 = None
        add_tensor_53: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_53, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias);  mm_default_53 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_315: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_53, torch.float32)
        var_mean_59 = torch.ops.aten.var_mean.correction(convert_element_type_315, [1], correction = 0, keepdim = True)
        getitem_304: "f32[s0, 1][1, 1]cuda:0" = var_mean_59[0]
        getitem_305: "f32[s0, 1][1, 1]cuda:0" = var_mean_59[1];  var_mean_59 = None
        sub_688: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_315, getitem_305);  convert_element_type_315 = getitem_305 = None
        add_2154: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_304, 1e-05);  getitem_304 = None
        rsqrt_59: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2154);  add_2154 = None
        mul_1374: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_688, rsqrt_59);  sub_688 = rsqrt_59 = None
        mul_1375: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1374, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight);  mul_1374 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = None
        add_2155: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1375, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias);  mul_1375 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = None
        convert_element_type_316: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2155, torch.float16);  add_2155 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_9: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_316);  convert_element_type_316 = None
        
         # File: <eval_with_key>.27:977 in forward, code: mul_8 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_1_norm_1 = None
        mul_1382: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_53, sigmoid_9);  add_tensor_53 = sigmoid_9 = None
        
         # File: <eval_with_key>.27:980 in forward, code: layer_norm_49 = torch.nn.functional.layer_norm(mul_8, (2048,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_8 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        convert_element_type_317: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1382, torch.float32);  mul_1382 = None
        var_mean_60 = torch.ops.aten.var_mean.correction(convert_element_type_317, [1], correction = 0, keepdim = True)
        getitem_306: "f32[s0, 1][1, 1]cuda:0" = var_mean_60[0]
        getitem_307: "f32[s0, 1][1, 1]cuda:0" = var_mean_60[1];  var_mean_60 = None
        
         # File: <eval_with_key>.27:563 in forward, code: layer_norm_39 = torch.nn.functional.layer_norm(linear_44, getitem_184, weight = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale, bias = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias, eps = 1e-05);  getitem_184 = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale = main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias = None
        sub_418: "f32[s0, 1024][1024, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_236, getitem_220);  convert_element_type_236 = getitem_220 = None
        add_1247: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_219, 1e-05);  getitem_219 = None
        rsqrt_43: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_1247);  add_1247 = None
        mul_767: "f32[s0, 1024][1024, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_418, rsqrt_43);  sub_418 = rsqrt_43 = None
        mul_768: "f32[s0, 1024][1024, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_767, submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale);  mul_767 = submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_scale = None
        add_1248: "f32[s0, 1024][1024, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_768, submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias);  mul_768 = submod_0_main_module_impl_impl_shared_arch_specialized_arch_specialized_module_list_0_specialized_arch_submodules_0_arch_submodules_1_submodules_1_norm_submodules_0_bias = None
        convert_element_type_237: "f16[s0, 1024][1024, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_1248, torch.float16);  add_1248 = None
        
         # File: <eval_with_key>.27:573 in forward, code: sigmoid_4 = torch.sigmoid(layer_norm_39);  layer_norm_39 = None
        sigmoid_4: "f16[s0, 1024][1024, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_237);  convert_element_type_237 = None
        
         # File: <eval_with_key>.27:603 in forward, code: mul_3 = linear_44 * unsqueeze_n_times_3;  linear_44 = unsqueeze_n_times_3 = None
        mul_812: "f16[s0, 1024][1024, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_63, sigmoid_4);  add_tensor_63 = sigmoid_4 = None
        
         # File: <eval_with_key>.27:980 in forward, code: layer_norm_49 = torch.nn.functional.layer_norm(mul_8, (2048,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_8 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        sub_694: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_317, getitem_307);  convert_element_type_317 = getitem_307 = None
        add_2171: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_306, 1e-05);  getitem_306 = None
        rsqrt_60: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2171);  add_2171 = None
        mul_1385: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_694, rsqrt_60);  sub_694 = rsqrt_60 = None
        mul_1386: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1385, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w);  mul_1385 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_w = None
        add_2172: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1386, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b);  mul_1386 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        convert_element_type_318: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2172, torch.float16);  add_2172 = None
        
         # File: <eval_with_key>.27:981 in forward, code: cat_42 = torch.cat([mul_3, mul_2, layer_norm_49], dim = 1);  layer_norm_49 = None
        cat_14: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.cat.default([mul_812, mul_809, convert_element_type_318], 1);  convert_element_type_318 = None
        
         # File: <eval_with_key>.27:986 in forward, code: layer_norm_50 = torch.nn.functional.layer_norm(cat_42, getitem_324, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b, eps = 1e-05);  cat_42 = getitem_324 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b = None
        convert_element_type_319: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(cat_14, torch.float32);  cat_14 = None
        var_mean_61 = torch.ops.aten.var_mean.correction(convert_element_type_319, [1], correction = 0, keepdim = True)
        getitem_308: "f32[s0, 1][1, 1]cuda:0" = var_mean_61[0]
        getitem_309: "f32[s0, 1][1, 1]cuda:0" = var_mean_61[1];  var_mean_61 = None
        sub_699: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_319, getitem_309);  convert_element_type_319 = getitem_309 = None
        add_2185: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_308, 1e-05);  getitem_308 = None
        rsqrt_61: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2185);  add_2185 = None
        mul_1393: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_699, rsqrt_61);  sub_699 = rsqrt_61 = None
        mul_1394: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1393, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w);  mul_1393 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_w = None
        add_2186: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1394, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b);  mul_1394 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dsi__init_b = None
        convert_element_type_320: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2186, torch.float16);  add_2186 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_69: "f16[6354, 384][1, 6354]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_52: "f16[s0, 384][384, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_320, permute_69);  permute_69 = None
        add_tensor_52: "f16[s0, 384][384, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_52, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias);  mm_default_52 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:990 in forward, code: layer_norm_51 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0, (384,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = None
        convert_element_type_324: "f32[s0, 384][384, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_52, torch.float32);  add_tensor_52 = None
        var_mean_62 = torch.ops.aten.var_mean.correction(convert_element_type_324, [1], correction = 0, keepdim = True)
        getitem_310: "f32[s0, 1][1, 1]cuda:0" = var_mean_62[0]
        getitem_311: "f32[s0, 1][1, 1]cuda:0" = var_mean_62[1];  var_mean_62 = None
        sub_704: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_324, getitem_311);  convert_element_type_324 = getitem_311 = None
        add_2199: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_310, 1e-05);  getitem_310 = None
        rsqrt_62: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2199);  add_2199 = None
        mul_1401: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_704, rsqrt_62);  sub_704 = rsqrt_62 = None
        mul_1402: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1401, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w);  mul_1401 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = None
        add_2200: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1402, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b);  mul_1402 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = None
        convert_element_type_325: "f16[s0, 384][384, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2200, torch.float16);  add_2200 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_70: "f16[384, 6354][1, 384]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_51: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_325, permute_70);  convert_element_type_325 = permute_70 = None
        add_tensor_51: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_51, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias);  mm_default_51 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:994 in forward, code: layer_norm_52 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0, (6354,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        convert_element_type_329: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_51, torch.float32);  add_tensor_51 = None
        var_mean_63 = torch.ops.aten.var_mean.correction(convert_element_type_329, [1], correction = 0, keepdim = True)
        getitem_312: "f32[s0, 1][1, 1]cuda:0" = var_mean_63[0]
        getitem_313: "f32[s0, 1][1, 1]cuda:0" = var_mean_63[1];  var_mean_63 = None
        
         # File: <eval_with_key>.27:995 in forward, code: addcmul = torch.addcmul(input = layer_norm_50, tensor1 = layer_norm_50, tensor2 = layer_norm_52, value = 1.0);  layer_norm_50 = layer_norm_52 = None
        convert_element_type_331: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(convert_element_type_320, torch.float32)
        convert_element_type_332: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(convert_element_type_320, torch.float32);  convert_element_type_320 = None
        mul_1415: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(convert_element_type_332, 1.0);  convert_element_type_332 = None
        
         # File: <eval_with_key>.27:994 in forward, code: layer_norm_52 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0, (6354,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        sub_709: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_329, getitem_313);  convert_element_type_329 = getitem_313 = None
        add_2213: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_312, 1e-05);  getitem_312 = None
        rsqrt_63: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2213);  add_2213 = None
        mul_1409: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_709, rsqrt_63);  sub_709 = rsqrt_63 = None
        mul_1410: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1409, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w);  mul_1409 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_w = None
        add_2214: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1410, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b);  mul_1410 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        
         # File: <eval_with_key>.27:995 in forward, code: addcmul = torch.addcmul(input = layer_norm_50, tensor1 = layer_norm_50, tensor2 = layer_norm_52, value = 1.0);  layer_norm_50 = layer_norm_52 = None
        mul_1416: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1415, add_2214);  mul_1415 = add_2214 = None
        add_2224: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_331, mul_1416);  convert_element_type_331 = mul_1416 = None
        
         # File: <eval_with_key>.27:1000 in forward, code: layer_norm_53 = torch.nn.functional.layer_norm(addcmul, getitem_325, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b, eps = 1e-05);  addcmul = getitem_325 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b = None
        var_mean_64 = torch.ops.aten.var_mean.correction(add_2224, [1], correction = 0, keepdim = True)
        getitem_314: "f32[s0, 1][1, 1]cuda:0" = var_mean_64[0]
        getitem_315: "f32[s0, 1][1, 1]cuda:0" = var_mean_64[1];  var_mean_64 = None
        sub_714: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(add_2224, getitem_315);  add_2224 = getitem_315 = None
        add_2228: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_314, 1e-05);  getitem_314 = None
        rsqrt_64: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2228);  add_2228 = None
        mul_1419: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_714, rsqrt_64);  sub_714 = rsqrt_64 = None
        mul_1420: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1419, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w);  mul_1419 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_w = None
        add_2229: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1420, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b);  mul_1420 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__post_dcn_ln__init_b = None
        convert_element_type_336: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2229, torch.float16);  add_2229 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_71: "f16[6354, 3072][1, 6354]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_50: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_336, permute_71);  convert_element_type_336 = permute_71 = None
        add_tensor_50: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_50, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias);  mm_default_50 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_340: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_50, torch.float32)
        var_mean_65 = torch.ops.aten.var_mean.correction(convert_element_type_340, [1], correction = 0, keepdim = True)
        getitem_316: "f32[s0, 1][1, 1]cuda:0" = var_mean_65[0]
        getitem_317: "f32[s0, 1][1, 1]cuda:0" = var_mean_65[1];  var_mean_65 = None
        sub_719: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_340, getitem_317);  convert_element_type_340 = getitem_317 = None
        add_2242: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_316, 1e-05);  getitem_316 = None
        rsqrt_65: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2242);  add_2242 = None
        mul_1427: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_719, rsqrt_65);  sub_719 = rsqrt_65 = None
        mul_1428: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1427, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight);  mul_1427 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = None
        add_2243: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1428, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias);  mul_1428 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = None
        convert_element_type_341: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2243, torch.float16);  add_2243 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_10: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_341);  convert_element_type_341 = None
        
         # File: <eval_with_key>.27:1004 in forward, code: mul_9 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_1_norm_1 = None
        mul_1435: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_50, sigmoid_10);  add_tensor_50 = sigmoid_10 = None
        
         # File: <eval_with_key>.27:1007 in forward, code: layer_norm_54 = torch.nn.functional.layer_norm(mul_9, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_9 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b = None
        convert_element_type_342: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1435, torch.float32);  mul_1435 = None
        var_mean_66 = torch.ops.aten.var_mean.correction(convert_element_type_342, [1], correction = 0, keepdim = True)
        getitem_318: "f32[s0, 1][1, 1]cuda:0" = var_mean_66[0]
        getitem_319: "f32[s0, 1][1, 1]cuda:0" = var_mean_66[1];  var_mean_66 = None
        sub_725: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_342, getitem_319);  convert_element_type_342 = getitem_319 = None
        add_2259: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_318, 1e-05);  getitem_318 = None
        rsqrt_66: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2259);  add_2259 = None
        mul_1438: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_725, rsqrt_66);  sub_725 = rsqrt_66 = None
        mul_1439: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1438, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w);  mul_1438 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_w = None
        add_2260: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1439, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b);  mul_1439 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_0_mlp_net_2__init_b = None
        convert_element_type_343: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2260, torch.float16);  add_2260 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_72: "f16[3072, 1536][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_49: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_343, permute_72);  permute_72 = None
        add_tensor_49: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_49, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias);  mm_default_49 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_347: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_49, torch.float32)
        var_mean_67 = torch.ops.aten.var_mean.correction(convert_element_type_347, [1], correction = 0, keepdim = True)
        getitem_320: "f32[s0, 1][1, 1]cuda:0" = var_mean_67[0]
        getitem_321: "f32[s0, 1][1, 1]cuda:0" = var_mean_67[1];  var_mean_67 = None
        sub_730: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_347, getitem_321);  convert_element_type_347 = getitem_321 = None
        add_2273: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_320, 1e-05);  getitem_320 = None
        rsqrt_67: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2273);  add_2273 = None
        mul_1446: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_730, rsqrt_67);  sub_730 = rsqrt_67 = None
        mul_1447: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1446, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight);  mul_1446 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = None
        add_2274: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1447, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias);  mul_1447 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = None
        convert_element_type_348: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2274, torch.float16);  add_2274 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_11: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_348);  convert_element_type_348 = None
        
         # File: <eval_with_key>.27:1011 in forward, code: mul_10 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_1_norm_1 = None
        mul_1454: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_49, sigmoid_11);  add_tensor_49 = sigmoid_11 = None
        
         # File: <eval_with_key>.27:1014 in forward, code: layer_norm_55 = torch.nn.functional.layer_norm(mul_10, (1536,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b, eps = 1e-05);  mul_10 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b = None
        convert_element_type_349: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1454, torch.float32);  mul_1454 = None
        var_mean_68 = torch.ops.aten.var_mean.correction(convert_element_type_349, [1], correction = 0, keepdim = True)
        getitem_322: "f32[s0, 1][1, 1]cuda:0" = var_mean_68[0]
        getitem_323: "f32[s0, 1][1, 1]cuda:0" = var_mean_68[1];  var_mean_68 = None
        sub_736: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_349, getitem_323);  convert_element_type_349 = getitem_323 = None
        add_2290: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_322, 1e-05);  getitem_322 = None
        rsqrt_68: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2290);  add_2290 = None
        mul_1457: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_736, rsqrt_68);  sub_736 = rsqrt_68 = None
        mul_1458: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1457, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w);  mul_1457 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_w = None
        add_2291: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1458, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b);  mul_1458 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_1_mlp_net_2__init_b = None
        convert_element_type_350: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2291, torch.float16);  add_2291 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_73: "f16[1536, 3072][1, 1536]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_48: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_350, permute_73);  convert_element_type_350 = permute_73 = None
        add_tensor_48: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_48, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias);  mm_default_48 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1018 in forward, code: layer_norm_56 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b = None
        convert_element_type_354: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_48, torch.float32);  add_tensor_48 = None
        var_mean_69 = torch.ops.aten.var_mean.correction(convert_element_type_354, [1], correction = 0, keepdim = True)
        getitem_324: "f32[s0, 1][1, 1]cuda:0" = var_mean_69[0]
        getitem_325: "f32[s0, 1][1, 1]cuda:0" = var_mean_69[1];  var_mean_69 = None
        sub_741: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_354, getitem_325);  convert_element_type_354 = getitem_325 = None
        add_2304: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_324, 1e-05);  getitem_324 = None
        rsqrt_69: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2304);  add_2304 = None
        mul_1465: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_741, rsqrt_69);  sub_741 = rsqrt_69 = None
        mul_1466: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1465, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w);  mul_1465 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_w = None
        add_2305: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1466, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b);  mul_1466 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_2_mlp_net_1__init_b = None
        convert_element_type_355: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2305, torch.float16);  add_2305 = None
        
         # File: <eval_with_key>.27:1019 in forward, code: add_20 = layer_norm_54 + layer_norm_56;  layer_norm_56 = None
        add_2315: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_343, convert_element_type_355);  convert_element_type_355 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_356: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2315, torch.float32)
        var_mean_70 = torch.ops.aten.var_mean.correction(convert_element_type_356, [1], correction = 0, keepdim = True)
        getitem_326: "f32[s0, 1][1, 1]cuda:0" = var_mean_70[0]
        getitem_327: "f32[s0, 1][1, 1]cuda:0" = var_mean_70[1];  var_mean_70 = None
        sub_746: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_356, getitem_327);  convert_element_type_356 = getitem_327 = None
        add_2319: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_326, 1e-05);  getitem_326 = None
        rsqrt_70: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2319);  add_2319 = None
        mul_1473: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_746, rsqrt_70);  sub_746 = rsqrt_70 = None
        mul_1474: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1473, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight);  mul_1473 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_weight = None
        add_2320: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1474, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias);  mul_1474 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_0_bias = None
        convert_element_type_357: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2320, torch.float16);  add_2320 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_12: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_357);  convert_element_type_357 = None
        
         # File: <eval_with_key>.27:1022 in forward, code: mul_11 = add_20 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_1;  add_20 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_2_norm_1 = None
        mul_1481: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_2315, sigmoid_12);  add_2315 = sigmoid_12 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_74: "f16[3072, 1536][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_47: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(mul_1481, permute_74);  permute_74 = None
        add_tensor_47: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_47, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias);  mm_default_47 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_361: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_47, torch.float32)
        var_mean_71 = torch.ops.aten.var_mean.correction(convert_element_type_361, [1], correction = 0, keepdim = True)
        getitem_328: "f32[s0, 1][1, 1]cuda:0" = var_mean_71[0]
        getitem_329: "f32[s0, 1][1, 1]cuda:0" = var_mean_71[1];  var_mean_71 = None
        sub_754: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_361, getitem_329);  convert_element_type_361 = getitem_329 = None
        add_2343: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_328, 1e-05);  getitem_328 = None
        rsqrt_71: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2343);  add_2343 = None
        mul_1488: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_754, rsqrt_71);  sub_754 = rsqrt_71 = None
        mul_1489: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1488, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight);  mul_1488 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = None
        add_2344: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1489, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias);  mul_1489 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = None
        convert_element_type_362: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2344, torch.float16);  add_2344 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_13: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_362);  convert_element_type_362 = None
        
         # File: <eval_with_key>.27:1027 in forward, code: mul_12 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_1_norm_1 = None
        mul_1496: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_47, sigmoid_13);  add_tensor_47 = sigmoid_13 = None
        
         # File: <eval_with_key>.27:1030 in forward, code: layer_norm_57 = torch.nn.functional.layer_norm(mul_12, (1536,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b, eps = 1e-05);  mul_12 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b = None
        convert_element_type_363: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1496, torch.float32);  mul_1496 = None
        var_mean_72 = torch.ops.aten.var_mean.correction(convert_element_type_363, [1], correction = 0, keepdim = True)
        getitem_330: "f32[s0, 1][1, 1]cuda:0" = var_mean_72[0]
        getitem_331: "f32[s0, 1][1, 1]cuda:0" = var_mean_72[1];  var_mean_72 = None
        sub_760: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_363, getitem_331);  convert_element_type_363 = getitem_331 = None
        add_2360: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_330, 1e-05);  getitem_330 = None
        rsqrt_72: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2360);  add_2360 = None
        mul_1499: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_760, rsqrt_72);  sub_760 = rsqrt_72 = None
        mul_1500: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1499, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w);  mul_1499 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_w = None
        add_2361: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1500, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b);  mul_1500 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_3_mlp_net_2__init_b = None
        convert_element_type_364: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2361, torch.float16);  add_2361 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_75: "f16[1536, 3072][1, 1536]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_46: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_364, permute_75);  convert_element_type_364 = permute_75 = None
        add_tensor_46: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_46, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias);  mm_default_46 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1034 in forward, code: layer_norm_58 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b = None
        convert_element_type_368: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_46, torch.float32);  add_tensor_46 = None
        var_mean_73 = torch.ops.aten.var_mean.correction(convert_element_type_368, [1], correction = 0, keepdim = True)
        getitem_332: "f32[s0, 1][1, 1]cuda:0" = var_mean_73[0]
        getitem_333: "f32[s0, 1][1, 1]cuda:0" = var_mean_73[1];  var_mean_73 = None
        
         # File: <eval_with_key>.27:1023 in forward, code: add_21 = layer_norm_54 + mul_11;  layer_norm_54 = None
        add_2336: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_343, mul_1481);  convert_element_type_343 = mul_1481 = None
        
         # File: <eval_with_key>.27:1034 in forward, code: layer_norm_58 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b = None
        sub_765: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_368, getitem_333);  convert_element_type_368 = getitem_333 = None
        add_2374: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_332, 1e-05);  getitem_332 = None
        rsqrt_73: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2374);  add_2374 = None
        mul_1507: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_765, rsqrt_73);  sub_765 = rsqrt_73 = None
        mul_1508: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1507, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w);  mul_1507 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_w = None
        add_2375: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1508, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b);  mul_1508 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__mlps_4_mlp_net_1__init_b = None
        convert_element_type_369: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2375, torch.float16);  add_2375 = None
        
         # File: <eval_with_key>.27:1035 in forward, code: add_22 = add_21 + layer_norm_58;  add_21 = layer_norm_58 = None
        add_2385: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(add_2336, convert_element_type_369);  add_2336 = convert_element_type_369 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_370: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2385, torch.float32)
        var_mean_74 = torch.ops.aten.var_mean.correction(convert_element_type_370, [1], correction = 0, keepdim = True)
        getitem_334: "f32[s0, 1][1, 1]cuda:0" = var_mean_74[0]
        getitem_335: "f32[s0, 1][1, 1]cuda:0" = var_mean_74[1];  var_mean_74 = None
        
         # File: <eval_with_key>.27:922 in forward, code: reshape_129 = getitem_320.reshape(-1, 9216);  getitem_320 = None
        view_61: "f16[s0, 9216][33408, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_277, [sym_size_int, 9216]);  getitem_277 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_770: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_370, getitem_335);  convert_element_type_370 = getitem_335 = None
        add_2389: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_334, 1e-05);  getitem_334 = None
        rsqrt_74: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2389);  add_2389 = None
        mul_1515: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_770, rsqrt_74);  sub_770 = rsqrt_74 = None
        mul_1516: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1515, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight);  mul_1515 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_weight = None
        add_2390: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1516, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias);  mul_1516 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_0_bias = None
        convert_element_type_371: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2390, torch.float16);  add_2390 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_14: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_371);  convert_element_type_371 = None
        
         # File: <eval_with_key>.27:1038 in forward, code: mul_13 = add_22 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_1;  add_22 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__residual_mlp__residual_activation_4_norm_1 = None
        mul_1523: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_2385, sigmoid_14);  add_2385 = sigmoid_14 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_76: "f16[3072, 9216][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_weight = None
        addmm_63: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.addmm.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias, mul_1523, permute_76);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0_bias = mul_1523 = permute_76 = None
        
         # File: <eval_with_key>.27:1040 in forward, code: cat_43 = torch.cat([linear_45, linear_46, linear_47, linear_48, linear_49, linear_50, reshape_129, main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0], dim = 1);  reshape_129 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__snn_projection_mlp_net_0 = None
        cat_15: "f16[s0, 19584][19584, 1]cuda:0" = torch.ops.aten.cat.default([clone_2, clone_3, clone_4, clone_5, clone_6, clone_7, view_61, addmm_63], 1);  view_61 = addmm_63 = None
        
         # File: <eval_with_key>.27:1041 in forward, code: _reshape_to_3d = _torch_package_1_legokit_backbones_dhen_prototype__reshape_to_3d(tensor = cat_43, emb_num = 102, emb_dim = 192);  cat_43 = None
        view_66: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.reshape.default(cat_15, [sym_size_int, 102, 192]);  cat_15 = None
        
         # File: <eval_with_key>.27:1042 in forward, code: add_23 = getitem_322 + _reshape_to_3d;  getitem_322 = _reshape_to_3d = None
        add_2416: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_279, view_66);  getitem_279 = view_66 = None
        
         # File: <eval_with_key>.27:1047 in forward, code: layer_norm_59 = torch.nn.functional.layer_norm(add_23, getitem_326, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b, eps = 1e-05);  add_23 = getitem_326 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b = None
        convert_element_type_375: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2416, torch.float32);  add_2416 = None
        var_mean_75 = torch.ops.aten.var_mean.correction(convert_element_type_375, [2], correction = 0, keepdim = True)
        getitem_336: "f32[s0, 102, 1][102, 1, 1]cuda:0" = var_mean_75[0]
        getitem_337: "f32[s0, 102, 1][102, 1, 1]cuda:0" = var_mean_75[1];  var_mean_75 = None
        
         # File: <eval_with_key>.27:1049 in forward, code: matmul_1 = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w, layer_norm_59);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w = None
        expand_2: "f16[s0, 72, 102][0, 102, 1]cuda:0" = torch.ops.aten.expand.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w, [sym_size_int_2, 72, 102]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w = None
        view_67: "f16[s0, 72, 102][0, 102, 1]cuda:0" = torch.ops.aten.reshape.default(expand_2, [sym_size_int_2, 72, 102]);  expand_2 = None
        
        # No stacktrace found for following nodes
        constant_pad_nd_default_2: "f16[s0, 72, 104][7488, 104, 1]cuda:0" = torch.ops.aten.constant_pad_nd.default(view_67, [0, 2, 0, 0, 0, 0]);  view_67 = None
        
         # File: <eval_with_key>.27:1047 in forward, code: layer_norm_59 = torch.nn.functional.layer_norm(add_23, getitem_326, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b, eps = 1e-05);  add_23 = getitem_326 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b = None
        sub_780: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_375, getitem_337);  convert_element_type_375 = getitem_337 = None
        add_2421: "f32[s0, 102, 1][102, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_336, 1e-05);  getitem_336 = None
        rsqrt_75: "f32[s0, 102, 1][102, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2421);  add_2421 = None
        mul_1534: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_780, rsqrt_75);  sub_780 = rsqrt_75 = None
        mul_1535: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1534, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w);  mul_1534 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_w = None
        add_2422: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1535, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b);  mul_1535 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_0__ln_on_dhen_layer__init_b = None
        convert_element_type_376: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2422, torch.float16);  add_2422 = None
        
         # File: <eval_with_key>.27:1049 in forward, code: matmul_1 = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w, layer_norm_59);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w = None
        expand_3: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.expand.default(convert_element_type_376, [sym_size_int_2, 102, 192])
        view_68: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.reshape.default(expand_3, [sym_size_int_2, 102, 192]);  expand_3 = None
        
        # No stacktrace found for following nodes
        constant_pad_nd_default_3: "f16[s0, 104, 192][19968, 192, 1]cuda:0" = torch.ops.aten.constant_pad_nd.default(view_68, [0, 0, 0, 2, 0, 0]);  view_68 = None
        bmm_default_1: "f16[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.bmm.default(constant_pad_nd_default_2, constant_pad_nd_default_3);  constant_pad_nd_default_2 = constant_pad_nd_default_3 = None
        
         # File: <eval_with_key>.27:1049 in forward, code: matmul_1 = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w, layer_norm_59);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_w = None
        view_69: "f16[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.reshape.default(bmm_default_1, [sym_size_int_2, 72, 192]);  bmm_default_1 = sym_size_int_2 = None
        
         # File: <eval_with_key>.27:1051 in forward, code: add_24 = matmul_1 + main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b;  matmul_1 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b = None
        add_2451: "f16[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(view_69, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b);  view_69 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__compression_b = None
        
         # File: <eval_with_key>.27:1057 in forward, code: layer_norm_60 = torch.nn.functional.layer_norm(add_24, getitem_327, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b, eps = 1e-05);  add_24 = getitem_327 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b = None
        convert_element_type_379: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2451, torch.float32);  add_2451 = None
        var_mean_76 = torch.ops.aten.var_mean.correction(convert_element_type_379, [2], correction = 0, keepdim = True)
        getitem_338: "f32[s0, 72, 1][72, 1, 1]cuda:0" = var_mean_76[0]
        getitem_339: "f32[s0, 72, 1][72, 1, 1]cuda:0" = var_mean_76[1];  var_mean_76 = None
        sub_792: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_379, getitem_339);  convert_element_type_379 = getitem_339 = None
        add_2460: "f32[s0, 72, 1][72, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_338, 1e-05);  getitem_338 = None
        rsqrt_76: "f32[s0, 72, 1][72, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2460);  add_2460 = None
        mul_1565: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_792, rsqrt_76);  sub_792 = rsqrt_76 = None
        mul_1566: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1565, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w);  mul_1565 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_w = None
        add_2461: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1566, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b);  mul_1566 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__fused_lce_module__ln_lce__init_b = None
        convert_element_type_380: "f16[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2461, torch.float16);  add_2461 = None
        
         # File: <eval_with_key>.27:1058 in forward, code: split_1 = torch.functional.split(layer_norm_60, [48, 24], dim = 1);  layer_norm_60 = None
        split_with_sizes_6 = torch.ops.aten.split_with_sizes.default(convert_element_type_380, [48, 24], 1);  convert_element_type_380 = None
        getitem_340: "f16[s0, 48, 192][13824, 192, 1]cuda:0" = split_with_sizes_6[0]
        getitem_341: "f16[s0, 24, 192][13824, 192, 1]cuda:0" = split_with_sizes_6[1];  split_with_sizes_6 = None
        
        # No stacktrace found for following nodes
        cat_17: "f16[1536][1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_bias, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_bias]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_bias = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1062 in forward, code: reshape_134 = torch.reshape(getitem_329, (-1, 4608));  getitem_329 = None
        view_71: "f16[s0, 4608][13824, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_341, [sym_size_int, 4608]);  getitem_341 = None
        
        # No stacktrace found for following nodes
        cat_16: "f16[1536, 4608][4608, 1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_weight, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_weight]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0_weight = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0_weight = None
        permute_78: "f16[4608, 1536][1, 4608]cuda:0" = torch.ops.aten.permute.default(cat_16, [1, 0]);  cat_16 = None
        mm_default_45: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(view_71, permute_78);  view_71 = permute_78 = None
        add_tensor_45: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_45, cat_17);  mm_default_45 = cat_17 = None
        slice_22: "f16[s0, 768][1536, 1]cuda:0" = torch.ops.aten.slice.Tensor(add_tensor_45, 1, 0, 768)
        clone_11: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.clone.default(slice_22, memory_format = torch.contiguous_format);  slice_22 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_384: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone_11, torch.float32)
        var_mean_77 = torch.ops.aten.var_mean.correction(convert_element_type_384, [1], correction = 0, keepdim = True)
        getitem_342: "f32[s0, 1][1, 1]cuda:0" = var_mean_77[0]
        getitem_343: "f32[s0, 1][1, 1]cuda:0" = var_mean_77[1];  var_mean_77 = None
        
        # No stacktrace found for following nodes
        slice_24: "f16[s0, 768][1536, 1]cuda:0" = torch.ops.aten.slice.Tensor(add_tensor_45, 1, 768, 1536);  add_tensor_45 = None
        clone_12: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.clone.default(slice_24, memory_format = torch.contiguous_format);  slice_24 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_386: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone_12, torch.float32)
        var_mean_78 = torch.ops.aten.var_mean.correction(convert_element_type_386, [1], correction = 0, keepdim = True)
        getitem_344: "f32[s0, 1][1, 1]cuda:0" = var_mean_78[0]
        getitem_345: "f32[s0, 1][1, 1]cuda:0" = var_mean_78[1];  var_mean_78 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_807: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_384, getitem_343);  convert_element_type_384 = getitem_343 = None
        add_2509: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_342, 1e-05);  getitem_342 = None
        rsqrt_77: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2509);  add_2509 = None
        mul_1597: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_807, rsqrt_77);  sub_807 = rsqrt_77 = None
        mul_1598: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1597, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight);  mul_1597 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = None
        add_2510: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1598, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias);  mul_1598 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = None
        convert_element_type_385: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2510, torch.float16);  add_2510 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_15: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_385);  convert_element_type_385 = None
        
         # File: <eval_with_key>.27:1068 in forward, code: mul_14 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_1_norm_1 = None
        mul_1611: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone_11, sigmoid_15);  clone_11 = sigmoid_15 = None
        
         # File: <eval_with_key>.27:1073 in forward, code: layer_norm_61 = torch.nn.functional.layer_norm(mul_14, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_14 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_388: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1611, torch.float32);  mul_1611 = None
        var_mean_79 = torch.ops.aten.var_mean.correction(convert_element_type_388, [1], correction = 0, keepdim = True)
        getitem_346: "f32[s0, 1][1, 1]cuda:0" = var_mean_79[0]
        getitem_347: "f32[s0, 1][1, 1]cuda:0" = var_mean_79[1];  var_mean_79 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_811: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_386, getitem_345);  convert_element_type_386 = getitem_345 = None
        add_2520: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_344, 1e-05);  getitem_344 = None
        rsqrt_78: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2520);  add_2520 = None
        mul_1603: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_811, rsqrt_78);  sub_811 = rsqrt_78 = None
        mul_1604: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1603, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight);  mul_1603 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = None
        add_2521: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1604, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias);  mul_1604 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = None
        convert_element_type_387: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2521, torch.float16);  add_2521 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_16: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_387);  convert_element_type_387 = None
        
         # File: <eval_with_key>.27:1070 in forward, code: mul_15 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_1_norm_1 = None
        mul_1616: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone_12, sigmoid_16);  clone_12 = sigmoid_16 = None
        
         # File: <eval_with_key>.27:1076 in forward, code: layer_norm_62 = torch.nn.functional.layer_norm(mul_15, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_15 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_390: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1616, torch.float32);  mul_1616 = None
        var_mean_80 = torch.ops.aten.var_mean.correction(convert_element_type_390, [1], correction = 0, keepdim = True)
        getitem_348: "f32[s0, 1][1, 1]cuda:0" = var_mean_80[0]
        getitem_349: "f32[s0, 1][1, 1]cuda:0" = var_mean_80[1];  var_mean_80 = None
        
         # File: <eval_with_key>.27:1073 in forward, code: layer_norm_61 = torch.nn.functional.layer_norm(mul_14, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_14 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        sub_819: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_388, getitem_347);  convert_element_type_388 = getitem_347 = None
        add_2543: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_346, 1e-05);  getitem_346 = None
        rsqrt_79: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2543);  add_2543 = None
        mul_1619: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_819, rsqrt_79);  sub_819 = rsqrt_79 = None
        mul_1620: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1619, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w);  mul_1619 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_w = None
        add_2544: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1620, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b);  mul_1620 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_389: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2544, torch.float16);  add_2544 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_79: "f16[768, 768][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_weight = None
        
        # No stacktrace found for following nodes
        mm_default_44: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_389, permute_79);  convert_element_type_389 = permute_79 = None
        add_tensor_44: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_44, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias);  mm_default_44 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_398: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_44, torch.float32)
        var_mean_81 = torch.ops.aten.var_mean.correction(convert_element_type_398, [1], correction = 0, keepdim = True)
        getitem_350: "f32[s0, 1][1, 1]cuda:0" = var_mean_81[0]
        getitem_351: "f32[s0, 1][1, 1]cuda:0" = var_mean_81[1];  var_mean_81 = None
        
         # File: <eval_with_key>.27:1076 in forward, code: layer_norm_62 = torch.nn.functional.layer_norm(mul_15, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_15 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        sub_823: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_390, getitem_349);  convert_element_type_390 = getitem_349 = None
        add_2554: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_348, 1e-05);  getitem_348 = None
        rsqrt_80: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2554);  add_2554 = None
        mul_1625: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_823, rsqrt_80);  sub_823 = rsqrt_80 = None
        mul_1626: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1625, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w);  mul_1625 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_w = None
        add_2555: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1626, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b);  mul_1626 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_391: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2555, torch.float16);  add_2555 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_80: "f16[768, 768][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_weight = None
        
        # No stacktrace found for following nodes
        mm_default_43: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_391, permute_80);  convert_element_type_391 = permute_80 = None
        add_tensor_43: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_43, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias);  mm_default_43 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_400: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_43, torch.float32)
        var_mean_82 = torch.ops.aten.var_mean.correction(convert_element_type_400, [1], correction = 0, keepdim = True)
        getitem_352: "f32[s0, 1][1, 1]cuda:0" = var_mean_82[0]
        getitem_353: "f32[s0, 1][1, 1]cuda:0" = var_mean_82[1];  var_mean_82 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_829: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_398, getitem_351);  convert_element_type_398 = getitem_351 = None
        add_2571: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_350, 1e-05);  getitem_350 = None
        rsqrt_81: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2571);  add_2571 = None
        mul_1635: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_829, rsqrt_81);  sub_829 = rsqrt_81 = None
        mul_1636: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1635, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight);  mul_1635 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = None
        add_2572: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1636, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias);  mul_1636 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = None
        convert_element_type_399: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2572, torch.float16);  add_2572 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_17: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_399);  convert_element_type_399 = None
        
         # File: <eval_with_key>.27:1082 in forward, code: mul_16 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_4_norm_1 = None
        mul_1649: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_44, sigmoid_17);  add_tensor_44 = sigmoid_17 = None
        
         # File: <eval_with_key>.27:1087 in forward, code: layer_norm_63 = torch.nn.functional.layer_norm(mul_16, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_16 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_402: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1649, torch.float32);  mul_1649 = None
        var_mean_83 = torch.ops.aten.var_mean.correction(convert_element_type_402, [1], correction = 0, keepdim = True)
        getitem_354: "f32[s0, 1][1, 1]cuda:0" = var_mean_83[0]
        getitem_355: "f32[s0, 1][1, 1]cuda:0" = var_mean_83[1];  var_mean_83 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_833: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_400, getitem_353);  convert_element_type_400 = getitem_353 = None
        add_2582: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_352, 1e-05);  getitem_352 = None
        rsqrt_82: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2582);  add_2582 = None
        mul_1641: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_833, rsqrt_82);  sub_833 = rsqrt_82 = None
        mul_1642: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1641, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight);  mul_1641 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = None
        add_2583: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1642, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias);  mul_1642 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = None
        convert_element_type_401: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2583, torch.float16);  add_2583 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_18: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_401);  convert_element_type_401 = None
        
         # File: <eval_with_key>.27:1084 in forward, code: mul_17 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_4_norm_1 = None
        mul_1654: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_43, sigmoid_18);  add_tensor_43 = sigmoid_18 = None
        
         # File: <eval_with_key>.27:1090 in forward, code: layer_norm_64 = torch.nn.functional.layer_norm(mul_17, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_17 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_404: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1654, torch.float32);  mul_1654 = None
        var_mean_84 = torch.ops.aten.var_mean.correction(convert_element_type_404, [1], correction = 0, keepdim = True)
        getitem_356: "f32[s0, 1][1, 1]cuda:0" = var_mean_84[0]
        getitem_357: "f32[s0, 1][1, 1]cuda:0" = var_mean_84[1];  var_mean_84 = None
        
         # File: <eval_with_key>.27:1087 in forward, code: layer_norm_63 = torch.nn.functional.layer_norm(mul_16, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_16 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        sub_841: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_402, getitem_355);  convert_element_type_402 = getitem_355 = None
        add_2605: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_354, 1e-05);  getitem_354 = None
        rsqrt_83: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2605);  add_2605 = None
        mul_1657: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_841, rsqrt_83);  sub_841 = rsqrt_83 = None
        mul_1658: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1657, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w);  mul_1657 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_w = None
        add_2606: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1658, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b);  mul_1658 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_403: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2606, torch.float16);  add_2606 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_81: "f16[768, 4896][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_42: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_403, permute_81);  convert_element_type_403 = permute_81 = None
        add_tensor_42: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_42, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias);  mm_default_42 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1095 in forward, code: layer_norm_65 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0, (4896,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_412: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_42, torch.float32);  add_tensor_42 = None
        var_mean_85 = torch.ops.aten.var_mean.correction(convert_element_type_412, [1], correction = 0, keepdim = True)
        getitem_358: "f32[s0, 1][1, 1]cuda:0" = var_mean_85[0]
        getitem_359: "f32[s0, 1][1, 1]cuda:0" = var_mean_85[1];  var_mean_85 = None
        
         # File: <eval_with_key>.27:1090 in forward, code: layer_norm_64 = torch.nn.functional.layer_norm(mul_17, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_17 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        sub_845: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_404, getitem_357);  convert_element_type_404 = getitem_357 = None
        add_2616: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_356, 1e-05);  getitem_356 = None
        rsqrt_84: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2616);  add_2616 = None
        mul_1663: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_845, rsqrt_84);  sub_845 = rsqrt_84 = None
        mul_1664: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1663, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w);  mul_1663 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_w = None
        add_2617: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1664, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b);  mul_1664 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_405: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2617, torch.float16);  add_2617 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_82: "f16[768, 9216][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_41: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_405, permute_82);  convert_element_type_405 = permute_82 = None
        add_tensor_41: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_41, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias);  mm_default_41 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1098 in forward, code: layer_norm_66 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0, (9216,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_414: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_41, torch.float32);  add_tensor_41 = None
        var_mean_86 = torch.ops.aten.var_mean.correction(convert_element_type_414, [1], correction = 0, keepdim = True)
        getitem_360: "f32[s0, 1][1, 1]cuda:0" = var_mean_86[0]
        getitem_361: "f32[s0, 1][1, 1]cuda:0" = var_mean_86[1];  var_mean_86 = None
        sub_855: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_414, getitem_361);  convert_element_type_414 = getitem_361 = None
        add_2644: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_360, 1e-05);  getitem_360 = None
        rsqrt_86: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2644);  add_2644 = None
        mul_1679: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_855, rsqrt_86);  sub_855 = rsqrt_86 = None
        mul_1680: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1679, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w);  mul_1679 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = None
        add_2645: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1680, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b);  mul_1680 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_415: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2645, torch.float16);  add_2645 = None
        
         # File: <eval_with_key>.27:1100 in forward, code: reshape_136 = torch.reshape(layer_norm_66, (-1, 192, 48));  layer_norm_66 = None
        view_73: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_415, [-1, 192, 48]);  convert_element_type_415 = None
        
         # File: <eval_with_key>.27:1052 in forward, code: permute_9 = layer_norm_59.permute(0, 2, 1)
        permute_77: "f16[s0, 192, 102][19584, 1, 192]cuda:0" = torch.ops.aten.permute.default(convert_element_type_376, [0, 2, 1])
        
         # File: <eval_with_key>.27:1095 in forward, code: layer_norm_65 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0, (4896,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        sub_851: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_412, getitem_359);  convert_element_type_412 = getitem_359 = None
        add_2633: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_358, 1e-05);  getitem_358 = None
        rsqrt_85: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2633);  add_2633 = None
        mul_1673: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_851, rsqrt_85);  sub_851 = rsqrt_85 = None
        mul_1674: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1673, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w);  mul_1673 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = None
        add_2634: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1674, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b);  mul_1674 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_413: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2634, torch.float16);  add_2634 = None
        
         # File: <eval_with_key>.27:1099 in forward, code: reshape_135 = torch.reshape(layer_norm_65, (-1, 102, 48));  layer_norm_65 = None
        view_72: "f16[s0, 102, 48][4896, 48, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_413, [-1, 102, 48]);  convert_element_type_413 = None
        
         # File: <eval_with_key>.27:1101 in forward, code: bmm_2 = torch.bmm(permute_9, reshape_135);  permute_9 = reshape_135 = None
        bmm_4: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.bmm.default(permute_77, view_72);  permute_77 = view_72 = None
        
         # File: <eval_with_key>.27:1102 in forward, code: add_25 = reshape_136 + bmm_2;  reshape_136 = bmm_2 = None
        add_2667: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.add.Tensor(view_73, bmm_4);  view_73 = bmm_4 = None
        
         # File: <eval_with_key>.27:1105 in forward, code: layer_norm_67 = torch.nn.functional.layer_norm(add_25, (48,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b, eps = 1e-05);  add_25 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b = None
        convert_element_type_418: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2667, torch.float32);  add_2667 = None
        var_mean_87 = torch.ops.aten.var_mean.correction(convert_element_type_418, [2], correction = 0, keepdim = True)
        getitem_362: "f32[s0, 192, 1][192, 1, 1]cuda:0" = var_mean_87[0]
        getitem_363: "f32[s0, 192, 1][192, 1, 1]cuda:0" = var_mean_87[1];  var_mean_87 = None
        sub_863: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_418, getitem_363);  convert_element_type_418 = getitem_363 = None
        add_2672: "f32[s0, 192, 1][192, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_362, 1e-05);  getitem_362 = None
        rsqrt_87: "f32[s0, 192, 1][192, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2672);  add_2672 = None
        mul_1693: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_863, rsqrt_87);  sub_863 = rsqrt_87 = None
        mul_1694: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1693, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w);  mul_1693 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_w = None
        add_2673: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1694, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b);  mul_1694 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcpp_compressed_tensor_ln__init_b = None
        convert_element_type_419: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2673, torch.float16);  add_2673 = None
        
         # File: <eval_with_key>.27:1106 in forward, code: bmm_3 = torch.bmm(layer_norm_59, layer_norm_67);  layer_norm_67 = None
        bmm_5: "f16[s0, 102, 48][4896, 48, 1]cuda:0" = torch.ops.aten.bmm.default(convert_element_type_376, convert_element_type_419);  convert_element_type_419 = None
        
         # File: <eval_with_key>.27:1107 in forward, code: flatten_1 = torch.flatten(bmm_3, start_dim = -2);  bmm_3 = None
        view_74: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.reshape.default(bmm_5, [sym_size_int, 4896]);  bmm_5 = None
        
         # File: <eval_with_key>.27:1112 in forward, code: layer_norm_68 = torch.nn.functional.layer_norm(flatten_1, getitem_330, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b, eps = 1e-05);  flatten_1 = getitem_330 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b = None
        convert_element_type_422: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(view_74, torch.float32);  view_74 = None
        var_mean_88 = torch.ops.aten.var_mean.correction(convert_element_type_422, [1], correction = 0, keepdim = True)
        getitem_364: "f32[s0, 1][1, 1]cuda:0" = var_mean_88[0]
        getitem_365: "f32[s0, 1][1, 1]cuda:0" = var_mean_88[1];  var_mean_88 = None
        sub_869: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_422, getitem_365);  convert_element_type_422 = getitem_365 = None
        add_2693: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_364, 1e-05);  getitem_364 = None
        rsqrt_88: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2693);  add_2693 = None
        mul_1705: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_869, rsqrt_88);  sub_869 = rsqrt_88 = None
        mul_1706: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1705, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w);  mul_1705 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_w = None
        add_2694: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1706, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b);  mul_1706 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_ln__init_b = None
        convert_element_type_423: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2694, torch.float16);  add_2694 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_83: "f16[4896, 2048][1, 4896]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_40: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_423, permute_83);  convert_element_type_423 = permute_83 = None
        add_tensor_40: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_40, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias);  mm_default_40 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_427: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_40, torch.float32)
        var_mean_89 = torch.ops.aten.var_mean.correction(convert_element_type_427, [1], correction = 0, keepdim = True)
        getitem_366: "f32[s0, 1][1, 1]cuda:0" = var_mean_89[0]
        getitem_367: "f32[s0, 1][1, 1]cuda:0" = var_mean_89[1];  var_mean_89 = None
        sub_874: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_427, getitem_367);  convert_element_type_427 = getitem_367 = None
        add_2707: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_366, 1e-05);  getitem_366 = None
        rsqrt_89: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2707);  add_2707 = None
        mul_1713: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_874, rsqrt_89);  sub_874 = rsqrt_89 = None
        mul_1714: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1713, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight);  mul_1713 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = None
        add_2708: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1714, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias);  mul_1714 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = None
        convert_element_type_428: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2708, torch.float16);  add_2708 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_19: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_428);  convert_element_type_428 = None
        
         # File: <eval_with_key>.27:1116 in forward, code: mul_18 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_1_norm_1 = None
        mul_1721: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_40, sigmoid_19);  add_tensor_40 = sigmoid_19 = None
        
         # File: <eval_with_key>.27:1119 in forward, code: layer_norm_69 = torch.nn.functional.layer_norm(mul_18, (2048,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_18 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        convert_element_type_429: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1721, torch.float32);  mul_1721 = None
        var_mean_90 = torch.ops.aten.var_mean.correction(convert_element_type_429, [1], correction = 0, keepdim = True)
        getitem_368: "f32[s0, 1][1, 1]cuda:0" = var_mean_90[0]
        getitem_369: "f32[s0, 1][1, 1]cuda:0" = var_mean_90[1];  var_mean_90 = None
        sub_880: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_429, getitem_369);  convert_element_type_429 = getitem_369 = None
        add_2724: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_368, 1e-05);  getitem_368 = None
        rsqrt_90: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2724);  add_2724 = None
        mul_1724: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_880, rsqrt_90);  sub_880 = rsqrt_90 = None
        mul_1725: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1724, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w);  mul_1724 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_w = None
        add_2725: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1725, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b);  mul_1725 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        convert_element_type_430: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2725, torch.float16);  add_2725 = None
        
         # File: <eval_with_key>.27:1120 in forward, code: cat_44 = torch.cat([mul_3, mul_2, layer_norm_69], dim = 1);  layer_norm_69 = None
        cat_18: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.cat.default([mul_812, mul_809, convert_element_type_430], 1);  convert_element_type_430 = None
        
         # File: <eval_with_key>.27:1125 in forward, code: layer_norm_70 = torch.nn.functional.layer_norm(cat_44, getitem_331, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b, eps = 1e-05);  cat_44 = getitem_331 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b = None
        convert_element_type_431: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(cat_18, torch.float32);  cat_18 = None
        var_mean_91 = torch.ops.aten.var_mean.correction(convert_element_type_431, [1], correction = 0, keepdim = True)
        getitem_370: "f32[s0, 1][1, 1]cuda:0" = var_mean_91[0]
        getitem_371: "f32[s0, 1][1, 1]cuda:0" = var_mean_91[1];  var_mean_91 = None
        sub_885: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_431, getitem_371);  convert_element_type_431 = getitem_371 = None
        add_2738: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_370, 1e-05);  getitem_370 = None
        rsqrt_91: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2738);  add_2738 = None
        mul_1732: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_885, rsqrt_91);  sub_885 = rsqrt_91 = None
        mul_1733: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1732, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w);  mul_1732 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_w = None
        add_2739: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1733, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b);  mul_1733 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dsi__init_b = None
        convert_element_type_432: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2739, torch.float16);  add_2739 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_84: "f16[6354, 384][1, 6354]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_39: "f16[s0, 384][384, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_432, permute_84);  permute_84 = None
        add_tensor_39: "f16[s0, 384][384, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_39, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias);  mm_default_39 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1129 in forward, code: layer_norm_71 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0, (384,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = None
        convert_element_type_436: "f32[s0, 384][384, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_39, torch.float32);  add_tensor_39 = None
        var_mean_92 = torch.ops.aten.var_mean.correction(convert_element_type_436, [1], correction = 0, keepdim = True)
        getitem_372: "f32[s0, 1][1, 1]cuda:0" = var_mean_92[0]
        getitem_373: "f32[s0, 1][1, 1]cuda:0" = var_mean_92[1];  var_mean_92 = None
        sub_890: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_436, getitem_373);  convert_element_type_436 = getitem_373 = None
        add_2752: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_372, 1e-05);  getitem_372 = None
        rsqrt_92: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2752);  add_2752 = None
        mul_1740: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_890, rsqrt_92);  sub_890 = rsqrt_92 = None
        mul_1741: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1740, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w);  mul_1740 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = None
        add_2753: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1741, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b);  mul_1741 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = None
        convert_element_type_437: "f16[s0, 384][384, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2753, torch.float16);  add_2753 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_85: "f16[384, 6354][1, 384]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_38: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_437, permute_85);  convert_element_type_437 = permute_85 = None
        add_tensor_38: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_38, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias);  mm_default_38 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1133 in forward, code: layer_norm_72 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0, (6354,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        convert_element_type_441: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_38, torch.float32);  add_tensor_38 = None
        var_mean_93 = torch.ops.aten.var_mean.correction(convert_element_type_441, [1], correction = 0, keepdim = True)
        getitem_374: "f32[s0, 1][1, 1]cuda:0" = var_mean_93[0]
        getitem_375: "f32[s0, 1][1, 1]cuda:0" = var_mean_93[1];  var_mean_93 = None
        
         # File: <eval_with_key>.27:1134 in forward, code: addcmul_1 = torch.addcmul(input = layer_norm_70, tensor1 = layer_norm_70, tensor2 = layer_norm_72, value = 1.0);  layer_norm_70 = layer_norm_72 = None
        convert_element_type_443: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(convert_element_type_432, torch.float32)
        convert_element_type_444: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(convert_element_type_432, torch.float32);  convert_element_type_432 = None
        mul_1754: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(convert_element_type_444, 1.0);  convert_element_type_444 = None
        
         # File: <eval_with_key>.27:1133 in forward, code: layer_norm_72 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0, (6354,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        sub_895: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_441, getitem_375);  convert_element_type_441 = getitem_375 = None
        add_2766: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_374, 1e-05);  getitem_374 = None
        rsqrt_93: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2766);  add_2766 = None
        mul_1748: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_895, rsqrt_93);  sub_895 = rsqrt_93 = None
        mul_1749: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1748, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w);  mul_1748 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_w = None
        add_2767: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1749, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b);  mul_1749 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        
         # File: <eval_with_key>.27:1134 in forward, code: addcmul_1 = torch.addcmul(input = layer_norm_70, tensor1 = layer_norm_70, tensor2 = layer_norm_72, value = 1.0);  layer_norm_70 = layer_norm_72 = None
        mul_1755: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1754, add_2767);  mul_1754 = add_2767 = None
        add_2777: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_443, mul_1755);  convert_element_type_443 = mul_1755 = None
        
         # File: <eval_with_key>.27:1139 in forward, code: layer_norm_73 = torch.nn.functional.layer_norm(addcmul_1, getitem_332, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b, eps = 1e-05);  addcmul_1 = getitem_332 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b = None
        var_mean_94 = torch.ops.aten.var_mean.correction(add_2777, [1], correction = 0, keepdim = True)
        getitem_376: "f32[s0, 1][1, 1]cuda:0" = var_mean_94[0]
        getitem_377: "f32[s0, 1][1, 1]cuda:0" = var_mean_94[1];  var_mean_94 = None
        sub_900: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(add_2777, getitem_377);  add_2777 = getitem_377 = None
        add_2781: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_376, 1e-05);  getitem_376 = None
        rsqrt_94: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2781);  add_2781 = None
        mul_1758: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_900, rsqrt_94);  sub_900 = rsqrt_94 = None
        mul_1759: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1758, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w);  mul_1758 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_w = None
        add_2782: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1759, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b);  mul_1759 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__post_dcn_ln__init_b = None
        convert_element_type_448: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2782, torch.float16);  add_2782 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_86: "f16[6354, 3072][1, 6354]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_37: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_448, permute_86);  convert_element_type_448 = permute_86 = None
        add_tensor_37: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_37, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias);  mm_default_37 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_452: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_37, torch.float32)
        var_mean_95 = torch.ops.aten.var_mean.correction(convert_element_type_452, [1], correction = 0, keepdim = True)
        getitem_378: "f32[s0, 1][1, 1]cuda:0" = var_mean_95[0]
        getitem_379: "f32[s0, 1][1, 1]cuda:0" = var_mean_95[1];  var_mean_95 = None
        sub_905: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_452, getitem_379);  convert_element_type_452 = getitem_379 = None
        add_2795: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_378, 1e-05);  getitem_378 = None
        rsqrt_95: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2795);  add_2795 = None
        mul_1766: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_905, rsqrt_95);  sub_905 = rsqrt_95 = None
        mul_1767: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1766, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight);  mul_1766 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = None
        add_2796: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1767, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias);  mul_1767 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = None
        convert_element_type_453: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2796, torch.float16);  add_2796 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_20: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_453);  convert_element_type_453 = None
        
         # File: <eval_with_key>.27:1143 in forward, code: mul_19 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_1_norm_1 = None
        mul_1774: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_37, sigmoid_20);  add_tensor_37 = sigmoid_20 = None
        
         # File: <eval_with_key>.27:1146 in forward, code: layer_norm_74 = torch.nn.functional.layer_norm(mul_19, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_19 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b = None
        convert_element_type_454: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1774, torch.float32);  mul_1774 = None
        var_mean_96 = torch.ops.aten.var_mean.correction(convert_element_type_454, [1], correction = 0, keepdim = True)
        getitem_380: "f32[s0, 1][1, 1]cuda:0" = var_mean_96[0]
        getitem_381: "f32[s0, 1][1, 1]cuda:0" = var_mean_96[1];  var_mean_96 = None
        sub_911: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_454, getitem_381);  convert_element_type_454 = getitem_381 = None
        add_2812: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_380, 1e-05);  getitem_380 = None
        rsqrt_96: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2812);  add_2812 = None
        mul_1777: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_911, rsqrt_96);  sub_911 = rsqrt_96 = None
        mul_1778: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1777, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w);  mul_1777 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_w = None
        add_2813: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1778, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b);  mul_1778 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_0_mlp_net_2__init_b = None
        convert_element_type_455: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2813, torch.float16);  add_2813 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_87: "f16[3072, 1536][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_36: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_455, permute_87);  permute_87 = None
        add_tensor_36: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_36, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias);  mm_default_36 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_459: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_36, torch.float32)
        var_mean_97 = torch.ops.aten.var_mean.correction(convert_element_type_459, [1], correction = 0, keepdim = True)
        getitem_382: "f32[s0, 1][1, 1]cuda:0" = var_mean_97[0]
        getitem_383: "f32[s0, 1][1, 1]cuda:0" = var_mean_97[1];  var_mean_97 = None
        sub_916: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_459, getitem_383);  convert_element_type_459 = getitem_383 = None
        add_2826: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_382, 1e-05);  getitem_382 = None
        rsqrt_97: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2826);  add_2826 = None
        mul_1785: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_916, rsqrt_97);  sub_916 = rsqrt_97 = None
        mul_1786: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1785, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight);  mul_1785 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = None
        add_2827: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1786, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias);  mul_1786 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = None
        convert_element_type_460: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2827, torch.float16);  add_2827 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_21: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_460);  convert_element_type_460 = None
        
         # File: <eval_with_key>.27:1150 in forward, code: mul_20 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_1_norm_1 = None
        mul_1793: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_36, sigmoid_21);  add_tensor_36 = sigmoid_21 = None
        
         # File: <eval_with_key>.27:1153 in forward, code: layer_norm_75 = torch.nn.functional.layer_norm(mul_20, (1536,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b, eps = 1e-05);  mul_20 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b = None
        convert_element_type_461: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1793, torch.float32);  mul_1793 = None
        var_mean_98 = torch.ops.aten.var_mean.correction(convert_element_type_461, [1], correction = 0, keepdim = True)
        getitem_384: "f32[s0, 1][1, 1]cuda:0" = var_mean_98[0]
        getitem_385: "f32[s0, 1][1, 1]cuda:0" = var_mean_98[1];  var_mean_98 = None
        sub_922: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_461, getitem_385);  convert_element_type_461 = getitem_385 = None
        add_2843: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_384, 1e-05);  getitem_384 = None
        rsqrt_98: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2843);  add_2843 = None
        mul_1796: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_922, rsqrt_98);  sub_922 = rsqrt_98 = None
        mul_1797: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1796, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w);  mul_1796 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_w = None
        add_2844: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1797, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b);  mul_1797 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_1_mlp_net_2__init_b = None
        convert_element_type_462: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2844, torch.float16);  add_2844 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_88: "f16[1536, 3072][1, 1536]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_35: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_462, permute_88);  convert_element_type_462 = permute_88 = None
        add_tensor_35: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_35, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias);  mm_default_35 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1157 in forward, code: layer_norm_76 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b = None
        convert_element_type_466: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_35, torch.float32);  add_tensor_35 = None
        var_mean_99 = torch.ops.aten.var_mean.correction(convert_element_type_466, [1], correction = 0, keepdim = True)
        getitem_386: "f32[s0, 1][1, 1]cuda:0" = var_mean_99[0]
        getitem_387: "f32[s0, 1][1, 1]cuda:0" = var_mean_99[1];  var_mean_99 = None
        sub_927: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_466, getitem_387);  convert_element_type_466 = getitem_387 = None
        add_2857: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_386, 1e-05);  getitem_386 = None
        rsqrt_99: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2857);  add_2857 = None
        mul_1804: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_927, rsqrt_99);  sub_927 = rsqrt_99 = None
        mul_1805: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1804, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w);  mul_1804 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_w = None
        add_2858: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1805, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b);  mul_1805 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_2_mlp_net_1__init_b = None
        convert_element_type_467: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2858, torch.float16);  add_2858 = None
        
         # File: <eval_with_key>.27:1158 in forward, code: add_26 = layer_norm_74 + layer_norm_76;  layer_norm_76 = None
        add_2868: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_455, convert_element_type_467);  convert_element_type_467 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_468: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2868, torch.float32)
        var_mean_100 = torch.ops.aten.var_mean.correction(convert_element_type_468, [1], correction = 0, keepdim = True)
        getitem_388: "f32[s0, 1][1, 1]cuda:0" = var_mean_100[0]
        getitem_389: "f32[s0, 1][1, 1]cuda:0" = var_mean_100[1];  var_mean_100 = None
        sub_932: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_468, getitem_389);  convert_element_type_468 = getitem_389 = None
        add_2872: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_388, 1e-05);  getitem_388 = None
        rsqrt_100: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2872);  add_2872 = None
        mul_1812: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_932, rsqrt_100);  sub_932 = rsqrt_100 = None
        mul_1813: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1812, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight);  mul_1812 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_weight = None
        add_2873: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1813, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias);  mul_1813 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_0_bias = None
        convert_element_type_469: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2873, torch.float16);  add_2873 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_22: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_469);  convert_element_type_469 = None
        
         # File: <eval_with_key>.27:1161 in forward, code: mul_21 = add_26 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_1;  add_26 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_2_norm_1 = None
        mul_1820: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_2868, sigmoid_22);  add_2868 = sigmoid_22 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_89: "f16[3072, 1536][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_34: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(mul_1820, permute_89);  permute_89 = None
        add_tensor_34: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_34, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias);  mm_default_34 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_473: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_34, torch.float32)
        var_mean_101 = torch.ops.aten.var_mean.correction(convert_element_type_473, [1], correction = 0, keepdim = True)
        getitem_390: "f32[s0, 1][1, 1]cuda:0" = var_mean_101[0]
        getitem_391: "f32[s0, 1][1, 1]cuda:0" = var_mean_101[1];  var_mean_101 = None
        sub_940: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_473, getitem_391);  convert_element_type_473 = getitem_391 = None
        add_2896: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_390, 1e-05);  getitem_390 = None
        rsqrt_101: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2896);  add_2896 = None
        mul_1827: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_940, rsqrt_101);  sub_940 = rsqrt_101 = None
        mul_1828: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1827, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight);  mul_1827 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = None
        add_2897: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1828, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias);  mul_1828 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = None
        convert_element_type_474: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2897, torch.float16);  add_2897 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_23: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_474);  convert_element_type_474 = None
        
         # File: <eval_with_key>.27:1166 in forward, code: mul_22 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_1_norm_1 = None
        mul_1835: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_34, sigmoid_23);  add_tensor_34 = sigmoid_23 = None
        
         # File: <eval_with_key>.27:1169 in forward, code: layer_norm_77 = torch.nn.functional.layer_norm(mul_22, (1536,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b, eps = 1e-05);  mul_22 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b = None
        convert_element_type_475: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1835, torch.float32);  mul_1835 = None
        var_mean_102 = torch.ops.aten.var_mean.correction(convert_element_type_475, [1], correction = 0, keepdim = True)
        getitem_392: "f32[s0, 1][1, 1]cuda:0" = var_mean_102[0]
        getitem_393: "f32[s0, 1][1, 1]cuda:0" = var_mean_102[1];  var_mean_102 = None
        sub_946: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_475, getitem_393);  convert_element_type_475 = getitem_393 = None
        add_2913: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_392, 1e-05);  getitem_392 = None
        rsqrt_102: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2913);  add_2913 = None
        mul_1838: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_946, rsqrt_102);  sub_946 = rsqrt_102 = None
        mul_1839: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1838, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w);  mul_1838 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_w = None
        add_2914: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1839, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b);  mul_1839 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_3_mlp_net_2__init_b = None
        convert_element_type_476: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2914, torch.float16);  add_2914 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_90: "f16[1536, 3072][1, 1536]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_33: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_476, permute_90);  convert_element_type_476 = permute_90 = None
        add_tensor_33: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_33, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias);  mm_default_33 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1173 in forward, code: layer_norm_78 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b = None
        convert_element_type_480: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_33, torch.float32);  add_tensor_33 = None
        var_mean_103 = torch.ops.aten.var_mean.correction(convert_element_type_480, [1], correction = 0, keepdim = True)
        getitem_394: "f32[s0, 1][1, 1]cuda:0" = var_mean_103[0]
        getitem_395: "f32[s0, 1][1, 1]cuda:0" = var_mean_103[1];  var_mean_103 = None
        
         # File: <eval_with_key>.27:1162 in forward, code: add_27 = layer_norm_74 + mul_21;  layer_norm_74 = None
        add_2889: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_455, mul_1820);  convert_element_type_455 = mul_1820 = None
        
         # File: <eval_with_key>.27:1173 in forward, code: layer_norm_78 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b = None
        sub_951: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_480, getitem_395);  convert_element_type_480 = getitem_395 = None
        add_2927: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_394, 1e-05);  getitem_394 = None
        rsqrt_103: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2927);  add_2927 = None
        mul_1846: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_951, rsqrt_103);  sub_951 = rsqrt_103 = None
        mul_1847: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1846, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w);  mul_1846 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_w = None
        add_2928: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1847, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b);  mul_1847 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__mlps_4_mlp_net_1__init_b = None
        convert_element_type_481: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2928, torch.float16);  add_2928 = None
        
         # File: <eval_with_key>.27:1174 in forward, code: add_28 = add_27 + layer_norm_78;  add_27 = layer_norm_78 = None
        add_2938: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(add_2889, convert_element_type_481);  add_2889 = convert_element_type_481 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_482: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2938, torch.float32)
        var_mean_104 = torch.ops.aten.var_mean.correction(convert_element_type_482, [1], correction = 0, keepdim = True)
        getitem_396: "f32[s0, 1][1, 1]cuda:0" = var_mean_104[0]
        getitem_397: "f32[s0, 1][1, 1]cuda:0" = var_mean_104[1];  var_mean_104 = None
        
         # File: <eval_with_key>.27:1061 in forward, code: reshape_133 = getitem_328.reshape(-1, 9216);  getitem_328 = None
        view_70: "f16[s0, 9216][13824, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_340, [sym_size_int, 9216]);  getitem_340 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_956: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_482, getitem_397);  convert_element_type_482 = getitem_397 = None
        add_2942: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_396, 1e-05);  getitem_396 = None
        rsqrt_104: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2942);  add_2942 = None
        mul_1854: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_956, rsqrt_104);  sub_956 = rsqrt_104 = None
        mul_1855: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1854, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight);  mul_1854 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_weight = None
        add_2943: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1855, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias);  mul_1855 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_0_bias = None
        convert_element_type_483: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2943, torch.float16);  add_2943 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_24: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_483);  convert_element_type_483 = None
        
         # File: <eval_with_key>.27:1177 in forward, code: mul_23 = add_28 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_1;  add_28 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__residual_mlp__residual_activation_4_norm_1 = None
        mul_1862: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_2938, sigmoid_24);  add_2938 = sigmoid_24 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_91: "f16[3072, 9216][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_weight = None
        addmm_77: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.addmm.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias, mul_1862, permute_91);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0_bias = mul_1862 = permute_91 = None
        
         # File: <eval_with_key>.27:1179 in forward, code: cat_45 = torch.cat([linear_45, linear_46, linear_47, linear_48, linear_49, linear_50, reshape_133, main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0], dim = 1);  reshape_133 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__snn_projection_mlp_net_0 = None
        cat_19: "f16[s0, 19584][19584, 1]cuda:0" = torch.ops.aten.cat.default([clone_2, clone_3, clone_4, clone_5, clone_6, clone_7, view_70, addmm_77], 1);  view_70 = addmm_77 = None
        
         # File: <eval_with_key>.27:1180 in forward, code: _reshape_to_3d_1 = _torch_package_1_legokit_backbones_dhen_prototype__reshape_to_3d(tensor = cat_45, emb_num = 102, emb_dim = 192);  cat_45 = None
        view_75: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.reshape.default(cat_19, [sym_size_int, 102, 192]);  cat_19 = None
        
         # File: <eval_with_key>.27:1181 in forward, code: add_29 = _reshape_to_3d_1 + layer_norm_59;  _reshape_to_3d_1 = layer_norm_59 = None
        add_2969: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(view_75, convert_element_type_376);  view_75 = convert_element_type_376 = None
        
         # File: <eval_with_key>.27:1186 in forward, code: layer_norm_79 = torch.nn.functional.layer_norm(add_29, getitem_333, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b, eps = 1e-05);  add_29 = getitem_333 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b = None
        convert_element_type_487: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2969, torch.float32);  add_2969 = None
        var_mean_105 = torch.ops.aten.var_mean.correction(convert_element_type_487, [2], correction = 0, keepdim = True)
        getitem_398: "f32[s0, 102, 1][102, 1, 1]cuda:0" = var_mean_105[0]
        getitem_399: "f32[s0, 102, 1][102, 1, 1]cuda:0" = var_mean_105[1];  var_mean_105 = None
        
        # No stacktrace found for following nodes
        sym_size_int_17: "Sym(s0)" = torch.ops.aten.sym_size.int(addmm_45, 0);  addmm_45 = None
        
         # File: <eval_with_key>.27:1188 in forward, code: matmul_2 = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w, layer_norm_79);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w = None
        expand_4: "f16[s0, 72, 102][0, 102, 1]cuda:0" = torch.ops.aten.expand.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w, [sym_size_int_17, 72, 102]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w = None
        view_76: "f16[s0, 72, 102][0, 102, 1]cuda:0" = torch.ops.aten.reshape.default(expand_4, [sym_size_int_17, 72, 102]);  expand_4 = None
        
        # No stacktrace found for following nodes
        constant_pad_nd_default: "f16[s0, 72, 104][7488, 104, 1]cuda:0" = torch.ops.aten.constant_pad_nd.default(view_76, [0, 2, 0, 0, 0, 0]);  view_76 = None
        
         # File: <eval_with_key>.27:1186 in forward, code: layer_norm_79 = torch.nn.functional.layer_norm(add_29, getitem_333, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b, eps = 1e-05);  add_29 = getitem_333 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b = None
        sub_966: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_487, getitem_399);  convert_element_type_487 = getitem_399 = None
        add_2974: "f32[s0, 102, 1][102, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_398, 1e-05);  getitem_398 = None
        rsqrt_105: "f32[s0, 102, 1][102, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_2974);  add_2974 = None
        mul_1873: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_966, rsqrt_105);  sub_966 = rsqrt_105 = None
        mul_1874: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1873, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w);  mul_1873 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_w = None
        add_2975: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1874, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b);  mul_1874 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_1__ln_on_dhen_layer__init_b = None
        convert_element_type_488: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_2975, torch.float16);  add_2975 = None
        
         # File: <eval_with_key>.27:1188 in forward, code: matmul_2 = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w, layer_norm_79);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w = None
        expand_5: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.expand.default(convert_element_type_488, [sym_size_int_17, 102, 192])
        view_77: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.reshape.default(expand_5, [sym_size_int_17, 102, 192]);  expand_5 = None
        
        # No stacktrace found for following nodes
        constant_pad_nd_default_1: "f16[s0, 104, 192][19968, 192, 1]cuda:0" = torch.ops.aten.constant_pad_nd.default(view_77, [0, 0, 0, 2, 0, 0]);  view_77 = None
        bmm_default: "f16[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.bmm.default(constant_pad_nd_default, constant_pad_nd_default_1);  constant_pad_nd_default = constant_pad_nd_default_1 = None
        
         # File: <eval_with_key>.27:1188 in forward, code: matmul_2 = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w, layer_norm_79);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_w = None
        view_78: "f16[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.reshape.default(bmm_default, [sym_size_int_17, 72, 192]);  bmm_default = None
        
         # File: <eval_with_key>.27:1190 in forward, code: add_30 = matmul_2 + main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b;  matmul_2 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b = None
        add_3004: "f16[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(view_78, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b);  view_78 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__compression_b = None
        
         # File: <eval_with_key>.27:1196 in forward, code: layer_norm_80 = torch.nn.functional.layer_norm(add_30, getitem_334, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b, eps = 1e-05);  add_30 = getitem_334 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b = None
        convert_element_type_491: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3004, torch.float32);  add_3004 = None
        var_mean_106 = torch.ops.aten.var_mean.correction(convert_element_type_491, [2], correction = 0, keepdim = True)
        getitem_400: "f32[s0, 72, 1][72, 1, 1]cuda:0" = var_mean_106[0]
        getitem_401: "f32[s0, 72, 1][72, 1, 1]cuda:0" = var_mean_106[1];  var_mean_106 = None
        sub_978: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_491, getitem_401);  convert_element_type_491 = getitem_401 = None
        add_3013: "f32[s0, 72, 1][72, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_400, 1e-05);  getitem_400 = None
        rsqrt_106: "f32[s0, 72, 1][72, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3013);  add_3013 = None
        mul_1904: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_978, rsqrt_106);  sub_978 = rsqrt_106 = None
        mul_1905: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1904, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w);  mul_1904 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_w = None
        add_3014: "f32[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1905, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b);  mul_1905 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__fused_lce_module__ln_lce__init_b = None
        convert_element_type_492: "f16[s0, 72, 192][13824, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3014, torch.float16);  add_3014 = None
        
         # File: <eval_with_key>.27:1197 in forward, code: split_2 = torch.functional.split(layer_norm_80, [48, 24], dim = 1);  layer_norm_80 = None
        split_with_sizes_7 = torch.ops.aten.split_with_sizes.default(convert_element_type_492, [48, 24], 1);  convert_element_type_492 = None
        getitem_402: "f16[s0, 48, 192][13824, 192, 1]cuda:0" = split_with_sizes_7[0]
        getitem_403: "f16[s0, 24, 192][13824, 192, 1]cuda:0" = split_with_sizes_7[1];  split_with_sizes_7 = None
        
        # No stacktrace found for following nodes
        cat_21: "f16[1536][1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_bias, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_bias]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_bias = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1201 in forward, code: reshape_138 = torch.reshape(getitem_336, (-1, 4608));  getitem_336 = None
        view_80: "f16[s0, 4608][13824, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_403, [sym_size_int, 4608]);  getitem_403 = None
        
        # No stacktrace found for following nodes
        cat_20: "f16[1536, 4608][4608, 1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_weight, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_weight]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0_weight = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0_weight = None
        permute_93: "f16[4608, 1536][1, 4608]cuda:0" = torch.ops.aten.permute.default(cat_20, [1, 0]);  cat_20 = None
        mm_default_32: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(view_80, permute_93);  view_80 = permute_93 = None
        add_tensor_32: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_32, cat_21);  mm_default_32 = cat_21 = None
        slice_26: "f16[s0, 768][1536, 1]cuda:0" = torch.ops.aten.slice.Tensor(add_tensor_32, 1, 0, 768)
        clone_13: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.clone.default(slice_26, memory_format = torch.contiguous_format);  slice_26 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_496: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone_13, torch.float32)
        var_mean_107 = torch.ops.aten.var_mean.correction(convert_element_type_496, [1], correction = 0, keepdim = True)
        getitem_404: "f32[s0, 1][1, 1]cuda:0" = var_mean_107[0]
        getitem_405: "f32[s0, 1][1, 1]cuda:0" = var_mean_107[1];  var_mean_107 = None
        
        # No stacktrace found for following nodes
        slice_28: "f16[s0, 768][1536, 1]cuda:0" = torch.ops.aten.slice.Tensor(add_tensor_32, 1, 768, 1536);  add_tensor_32 = None
        clone_14: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.clone.default(slice_28, memory_format = torch.contiguous_format);  slice_28 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_498: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone_14, torch.float32)
        var_mean_108 = torch.ops.aten.var_mean.correction(convert_element_type_498, [1], correction = 0, keepdim = True)
        getitem_406: "f32[s0, 1][1, 1]cuda:0" = var_mean_108[0]
        getitem_407: "f32[s0, 1][1, 1]cuda:0" = var_mean_108[1];  var_mean_108 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_993: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_496, getitem_405);  convert_element_type_496 = getitem_405 = None
        add_3062: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_404, 1e-05);  getitem_404 = None
        rsqrt_107: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3062);  add_3062 = None
        mul_1936: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_993, rsqrt_107);  sub_993 = rsqrt_107 = None
        mul_1937: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1936, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight);  mul_1936 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = None
        add_3063: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1937, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias);  mul_1937 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = None
        convert_element_type_497: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3063, torch.float16);  add_3063 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_25: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_497);  convert_element_type_497 = None
        
         # File: <eval_with_key>.27:1207 in forward, code: mul_24 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_1_norm_1 = None
        mul_1950: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone_13, sigmoid_25);  clone_13 = sigmoid_25 = None
        
         # File: <eval_with_key>.27:1212 in forward, code: layer_norm_81 = torch.nn.functional.layer_norm(mul_24, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_24 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_500: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1950, torch.float32);  mul_1950 = None
        var_mean_109 = torch.ops.aten.var_mean.correction(convert_element_type_500, [1], correction = 0, keepdim = True)
        getitem_408: "f32[s0, 1][1, 1]cuda:0" = var_mean_109[0]
        getitem_409: "f32[s0, 1][1, 1]cuda:0" = var_mean_109[1];  var_mean_109 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_997: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_498, getitem_407);  convert_element_type_498 = getitem_407 = None
        add_3073: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_406, 1e-05);  getitem_406 = None
        rsqrt_108: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3073);  add_3073 = None
        mul_1942: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_997, rsqrt_108);  sub_997 = rsqrt_108 = None
        mul_1943: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1942, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight);  mul_1942 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = None
        add_3074: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1943, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias);  mul_1943 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = None
        convert_element_type_499: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3074, torch.float16);  add_3074 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_26: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_499);  convert_element_type_499 = None
        
         # File: <eval_with_key>.27:1209 in forward, code: mul_25 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_1_norm_1 = None
        mul_1955: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone_14, sigmoid_26);  clone_14 = sigmoid_26 = None
        
         # File: <eval_with_key>.27:1215 in forward, code: layer_norm_82 = torch.nn.functional.layer_norm(mul_25, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_25 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_502: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1955, torch.float32);  mul_1955 = None
        var_mean_110 = torch.ops.aten.var_mean.correction(convert_element_type_502, [1], correction = 0, keepdim = True)
        getitem_410: "f32[s0, 1][1, 1]cuda:0" = var_mean_110[0]
        getitem_411: "f32[s0, 1][1, 1]cuda:0" = var_mean_110[1];  var_mean_110 = None
        
         # File: <eval_with_key>.27:1212 in forward, code: layer_norm_81 = torch.nn.functional.layer_norm(mul_24, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_24 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        sub_1005: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_500, getitem_409);  convert_element_type_500 = getitem_409 = None
        add_3096: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_408, 1e-05);  getitem_408 = None
        rsqrt_109: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3096);  add_3096 = None
        mul_1958: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1005, rsqrt_109);  sub_1005 = rsqrt_109 = None
        mul_1959: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1958, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w);  mul_1958 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_w = None
        add_3097: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1959, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b);  mul_1959 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_501: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3097, torch.float16);  add_3097 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_94: "f16[768, 768][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_weight = None
        
        # No stacktrace found for following nodes
        mm_default_31: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_501, permute_94);  convert_element_type_501 = permute_94 = None
        add_tensor_31: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_31, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias);  mm_default_31 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_510: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_31, torch.float32)
        var_mean_111 = torch.ops.aten.var_mean.correction(convert_element_type_510, [1], correction = 0, keepdim = True)
        getitem_412: "f32[s0, 1][1, 1]cuda:0" = var_mean_111[0]
        getitem_413: "f32[s0, 1][1, 1]cuda:0" = var_mean_111[1];  var_mean_111 = None
        
         # File: <eval_with_key>.27:1215 in forward, code: layer_norm_82 = torch.nn.functional.layer_norm(mul_25, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_25 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        sub_1009: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_502, getitem_411);  convert_element_type_502 = getitem_411 = None
        add_3107: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_410, 1e-05);  getitem_410 = None
        rsqrt_110: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3107);  add_3107 = None
        mul_1964: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1009, rsqrt_110);  sub_1009 = rsqrt_110 = None
        mul_1965: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1964, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w);  mul_1964 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_w = None
        add_3108: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1965, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b);  mul_1965 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_503: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3108, torch.float16);  add_3108 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_95: "f16[768, 768][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_weight = None
        
        # No stacktrace found for following nodes
        mm_default_30: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_503, permute_95);  convert_element_type_503 = permute_95 = None
        add_tensor_30: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_30, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias);  mm_default_30 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_512: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_30, torch.float32)
        var_mean_112 = torch.ops.aten.var_mean.correction(convert_element_type_512, [1], correction = 0, keepdim = True)
        getitem_414: "f32[s0, 1][1, 1]cuda:0" = var_mean_112[0]
        getitem_415: "f32[s0, 1][1, 1]cuda:0" = var_mean_112[1];  var_mean_112 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_1015: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_510, getitem_413);  convert_element_type_510 = getitem_413 = None
        add_3124: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_412, 1e-05);  getitem_412 = None
        rsqrt_111: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3124);  add_3124 = None
        mul_1974: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1015, rsqrt_111);  sub_1015 = rsqrt_111 = None
        mul_1975: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1974, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight);  mul_1974 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = None
        add_3125: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1975, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias);  mul_1975 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = None
        convert_element_type_511: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3125, torch.float16);  add_3125 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_27: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_511);  convert_element_type_511 = None
        
         # File: <eval_with_key>.27:1221 in forward, code: mul_26 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_4_norm_1 = None
        mul_1988: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_31, sigmoid_27);  add_tensor_31 = sigmoid_27 = None
        
         # File: <eval_with_key>.27:1226 in forward, code: layer_norm_83 = torch.nn.functional.layer_norm(mul_26, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_26 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_514: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1988, torch.float32);  mul_1988 = None
        var_mean_113 = torch.ops.aten.var_mean.correction(convert_element_type_514, [1], correction = 0, keepdim = True)
        getitem_416: "f32[s0, 1][1, 1]cuda:0" = var_mean_113[0]
        getitem_417: "f32[s0, 1][1, 1]cuda:0" = var_mean_113[1];  var_mean_113 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_1019: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_512, getitem_415);  convert_element_type_512 = getitem_415 = None
        add_3135: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_414, 1e-05);  getitem_414 = None
        rsqrt_112: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3135);  add_3135 = None
        mul_1980: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1019, rsqrt_112);  sub_1019 = rsqrt_112 = None
        mul_1981: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1980, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight);  mul_1980 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = None
        add_3136: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1981, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias);  mul_1981 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = None
        convert_element_type_513: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3136, torch.float16);  add_3136 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_28: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_513);  convert_element_type_513 = None
        
         # File: <eval_with_key>.27:1223 in forward, code: mul_27 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_4_norm_1 = None
        mul_1993: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_30, sigmoid_28);  add_tensor_30 = sigmoid_28 = None
        
         # File: <eval_with_key>.27:1229 in forward, code: layer_norm_84 = torch.nn.functional.layer_norm(mul_27, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_27 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_516: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_1993, torch.float32);  mul_1993 = None
        var_mean_114 = torch.ops.aten.var_mean.correction(convert_element_type_516, [1], correction = 0, keepdim = True)
        getitem_418: "f32[s0, 1][1, 1]cuda:0" = var_mean_114[0]
        getitem_419: "f32[s0, 1][1, 1]cuda:0" = var_mean_114[1];  var_mean_114 = None
        
         # File: <eval_with_key>.27:1226 in forward, code: layer_norm_83 = torch.nn.functional.layer_norm(mul_26, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_26 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        sub_1027: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_514, getitem_417);  convert_element_type_514 = getitem_417 = None
        add_3158: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_416, 1e-05);  getitem_416 = None
        rsqrt_113: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3158);  add_3158 = None
        mul_1996: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1027, rsqrt_113);  sub_1027 = rsqrt_113 = None
        mul_1997: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_1996, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w);  mul_1996 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_w = None
        add_3159: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_1997, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b);  mul_1997 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_515: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3159, torch.float16);  add_3159 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_96: "f16[768, 4896][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_29: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_515, permute_96);  convert_element_type_515 = permute_96 = None
        add_tensor_29: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_29, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias);  mm_default_29 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1234 in forward, code: layer_norm_85 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0, (4896,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_524: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_29, torch.float32);  add_tensor_29 = None
        var_mean_115 = torch.ops.aten.var_mean.correction(convert_element_type_524, [1], correction = 0, keepdim = True)
        getitem_420: "f32[s0, 1][1, 1]cuda:0" = var_mean_115[0]
        getitem_421: "f32[s0, 1][1, 1]cuda:0" = var_mean_115[1];  var_mean_115 = None
        
         # File: <eval_with_key>.27:1229 in forward, code: layer_norm_84 = torch.nn.functional.layer_norm(mul_27, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_27 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        sub_1031: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_516, getitem_419);  convert_element_type_516 = getitem_419 = None
        add_3169: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_418, 1e-05);  getitem_418 = None
        rsqrt_114: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3169);  add_3169 = None
        mul_2002: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1031, rsqrt_114);  sub_1031 = rsqrt_114 = None
        mul_2003: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2002, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w);  mul_2002 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_w = None
        add_3170: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2003, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b);  mul_2003 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_517: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3170, torch.float16);  add_3170 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_97: "f16[768, 9216][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_28: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_517, permute_97);  convert_element_type_517 = permute_97 = None
        add_tensor_28: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_28, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias);  mm_default_28 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1237 in forward, code: layer_norm_86 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0, (9216,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_526: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_28, torch.float32);  add_tensor_28 = None
        var_mean_116 = torch.ops.aten.var_mean.correction(convert_element_type_526, [1], correction = 0, keepdim = True)
        getitem_422: "f32[s0, 1][1, 1]cuda:0" = var_mean_116[0]
        getitem_423: "f32[s0, 1][1, 1]cuda:0" = var_mean_116[1];  var_mean_116 = None
        sub_1041: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_526, getitem_423);  convert_element_type_526 = getitem_423 = None
        add_3197: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_422, 1e-05);  getitem_422 = None
        rsqrt_116: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3197);  add_3197 = None
        mul_2018: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1041, rsqrt_116);  sub_1041 = rsqrt_116 = None
        mul_2019: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2018, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w);  mul_2018 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = None
        add_3198: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2019, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b);  mul_2019 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_527: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3198, torch.float16);  add_3198 = None
        
         # File: <eval_with_key>.27:1239 in forward, code: reshape_140 = torch.reshape(layer_norm_86, (-1, 192, 48));  layer_norm_86 = None
        view_82: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_527, [-1, 192, 48]);  convert_element_type_527 = None
        
         # File: <eval_with_key>.27:1191 in forward, code: permute_10 = layer_norm_79.permute(0, 2, 1)
        permute_92: "f16[s0, 192, 102][19584, 1, 192]cuda:0" = torch.ops.aten.permute.default(convert_element_type_488, [0, 2, 1])
        
         # File: <eval_with_key>.27:1234 in forward, code: layer_norm_85 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0, (4896,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        sub_1037: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_524, getitem_421);  convert_element_type_524 = getitem_421 = None
        add_3186: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_420, 1e-05);  getitem_420 = None
        rsqrt_115: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3186);  add_3186 = None
        mul_2012: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1037, rsqrt_115);  sub_1037 = rsqrt_115 = None
        mul_2013: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2012, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w);  mul_2012 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = None
        add_3187: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2013, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b);  mul_2013 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_525: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3187, torch.float16);  add_3187 = None
        
         # File: <eval_with_key>.27:1238 in forward, code: reshape_139 = torch.reshape(layer_norm_85, (-1, 102, 48));  layer_norm_85 = None
        view_81: "f16[s0, 102, 48][4896, 48, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_525, [-1, 102, 48]);  convert_element_type_525 = None
        
         # File: <eval_with_key>.27:1240 in forward, code: bmm_4 = torch.bmm(permute_10, reshape_139);  permute_10 = reshape_139 = None
        bmm_7: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.bmm.default(permute_92, view_81);  permute_92 = view_81 = None
        
         # File: <eval_with_key>.27:1241 in forward, code: add_31 = reshape_140 + bmm_4;  reshape_140 = bmm_4 = None
        add_3220: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.add.Tensor(view_82, bmm_7);  view_82 = bmm_7 = None
        
         # File: <eval_with_key>.27:1244 in forward, code: layer_norm_87 = torch.nn.functional.layer_norm(add_31, (48,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b, eps = 1e-05);  add_31 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b = None
        convert_element_type_530: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3220, torch.float32);  add_3220 = None
        var_mean_117 = torch.ops.aten.var_mean.correction(convert_element_type_530, [2], correction = 0, keepdim = True)
        getitem_424: "f32[s0, 192, 1][192, 1, 1]cuda:0" = var_mean_117[0]
        getitem_425: "f32[s0, 192, 1][192, 1, 1]cuda:0" = var_mean_117[1];  var_mean_117 = None
        sub_1049: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_530, getitem_425);  convert_element_type_530 = getitem_425 = None
        add_3225: "f32[s0, 192, 1][192, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_424, 1e-05);  getitem_424 = None
        rsqrt_117: "f32[s0, 192, 1][192, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3225);  add_3225 = None
        mul_2032: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1049, rsqrt_117);  sub_1049 = rsqrt_117 = None
        mul_2033: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2032, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w);  mul_2032 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_w = None
        add_3226: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2033, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b);  mul_2033 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcpp_compressed_tensor_ln__init_b = None
        convert_element_type_531: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3226, torch.float16);  add_3226 = None
        
         # File: <eval_with_key>.27:1245 in forward, code: bmm_5 = torch.bmm(layer_norm_79, layer_norm_87);  layer_norm_87 = None
        bmm_8: "f16[s0, 102, 48][4896, 48, 1]cuda:0" = torch.ops.aten.bmm.default(convert_element_type_488, convert_element_type_531);  convert_element_type_531 = None
        
         # File: <eval_with_key>.27:1246 in forward, code: flatten_2 = torch.flatten(bmm_5, start_dim = -2);  bmm_5 = None
        view_83: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.reshape.default(bmm_8, [sym_size_int, 4896]);  bmm_8 = None
        
         # File: <eval_with_key>.27:1251 in forward, code: layer_norm_88 = torch.nn.functional.layer_norm(flatten_2, getitem_337, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b, eps = 1e-05);  flatten_2 = getitem_337 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b = None
        convert_element_type_534: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(view_83, torch.float32);  view_83 = None
        var_mean_118 = torch.ops.aten.var_mean.correction(convert_element_type_534, [1], correction = 0, keepdim = True)
        getitem_426: "f32[s0, 1][1, 1]cuda:0" = var_mean_118[0]
        getitem_427: "f32[s0, 1][1, 1]cuda:0" = var_mean_118[1];  var_mean_118 = None
        sub_1055: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_534, getitem_427);  convert_element_type_534 = getitem_427 = None
        add_3246: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_426, 1e-05);  getitem_426 = None
        rsqrt_118: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3246);  add_3246 = None
        mul_2044: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1055, rsqrt_118);  sub_1055 = rsqrt_118 = None
        mul_2045: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2044, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w);  mul_2044 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_w = None
        add_3247: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2045, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b);  mul_2045 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_ln__init_b = None
        convert_element_type_535: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3247, torch.float16);  add_3247 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_98: "f16[4896, 2048][1, 4896]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_27: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_535, permute_98);  convert_element_type_535 = permute_98 = None
        add_tensor_27: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_27, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias);  mm_default_27 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_539: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_27, torch.float32)
        var_mean_119 = torch.ops.aten.var_mean.correction(convert_element_type_539, [1], correction = 0, keepdim = True)
        getitem_428: "f32[s0, 1][1, 1]cuda:0" = var_mean_119[0]
        getitem_429: "f32[s0, 1][1, 1]cuda:0" = var_mean_119[1];  var_mean_119 = None
        sub_1060: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_539, getitem_429);  convert_element_type_539 = getitem_429 = None
        add_3260: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_428, 1e-05);  getitem_428 = None
        rsqrt_119: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3260);  add_3260 = None
        mul_2052: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1060, rsqrt_119);  sub_1060 = rsqrt_119 = None
        mul_2053: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2052, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight);  mul_2052 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = None
        add_3261: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2053, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias);  mul_2053 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = None
        convert_element_type_540: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3261, torch.float16);  add_3261 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_29: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_540);  convert_element_type_540 = None
        
         # File: <eval_with_key>.27:1255 in forward, code: mul_28 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_1_norm_1 = None
        mul_2060: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_27, sigmoid_29);  add_tensor_27 = sigmoid_29 = None
        
         # File: <eval_with_key>.27:1258 in forward, code: layer_norm_89 = torch.nn.functional.layer_norm(mul_28, (2048,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_28 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        convert_element_type_541: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2060, torch.float32);  mul_2060 = None
        var_mean_120 = torch.ops.aten.var_mean.correction(convert_element_type_541, [1], correction = 0, keepdim = True)
        getitem_430: "f32[s0, 1][1, 1]cuda:0" = var_mean_120[0]
        getitem_431: "f32[s0, 1][1, 1]cuda:0" = var_mean_120[1];  var_mean_120 = None
        sub_1066: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_541, getitem_431);  convert_element_type_541 = getitem_431 = None
        add_3277: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_430, 1e-05);  getitem_430 = None
        rsqrt_120: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3277);  add_3277 = None
        mul_2063: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1066, rsqrt_120);  sub_1066 = rsqrt_120 = None
        mul_2064: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2063, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w);  mul_2063 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_w = None
        add_3278: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2064, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b);  mul_2064 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        convert_element_type_542: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3278, torch.float16);  add_3278 = None
        
         # File: <eval_with_key>.27:1259 in forward, code: cat_46 = torch.cat([mul_3, mul_2, layer_norm_89], dim = 1);  layer_norm_89 = None
        cat_22: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.cat.default([mul_812, mul_809, convert_element_type_542], 1);  convert_element_type_542 = None
        
         # File: <eval_with_key>.27:1264 in forward, code: layer_norm_90 = torch.nn.functional.layer_norm(cat_46, getitem_338, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b, eps = 1e-05);  cat_46 = getitem_338 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b = None
        convert_element_type_543: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(cat_22, torch.float32);  cat_22 = None
        var_mean_121 = torch.ops.aten.var_mean.correction(convert_element_type_543, [1], correction = 0, keepdim = True)
        getitem_432: "f32[s0, 1][1, 1]cuda:0" = var_mean_121[0]
        getitem_433: "f32[s0, 1][1, 1]cuda:0" = var_mean_121[1];  var_mean_121 = None
        sub_1071: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_543, getitem_433);  convert_element_type_543 = getitem_433 = None
        add_3291: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_432, 1e-05);  getitem_432 = None
        rsqrt_121: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3291);  add_3291 = None
        mul_2071: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1071, rsqrt_121);  sub_1071 = rsqrt_121 = None
        mul_2072: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2071, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w);  mul_2071 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_w = None
        add_3292: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2072, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b);  mul_2072 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dsi__init_b = None
        convert_element_type_544: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3292, torch.float16);  add_3292 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_99: "f16[6354, 384][1, 6354]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_26: "f16[s0, 384][384, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_544, permute_99);  permute_99 = None
        add_tensor_26: "f16[s0, 384][384, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_26, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias);  mm_default_26 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1268 in forward, code: layer_norm_91 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0, (384,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = None
        convert_element_type_548: "f32[s0, 384][384, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_26, torch.float32);  add_tensor_26 = None
        var_mean_122 = torch.ops.aten.var_mean.correction(convert_element_type_548, [1], correction = 0, keepdim = True)
        getitem_434: "f32[s0, 1][1, 1]cuda:0" = var_mean_122[0]
        getitem_435: "f32[s0, 1][1, 1]cuda:0" = var_mean_122[1];  var_mean_122 = None
        sub_1076: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_548, getitem_435);  convert_element_type_548 = getitem_435 = None
        add_3305: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_434, 1e-05);  getitem_434 = None
        rsqrt_122: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3305);  add_3305 = None
        mul_2079: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1076, rsqrt_122);  sub_1076 = rsqrt_122 = None
        mul_2080: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2079, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w);  mul_2079 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = None
        add_3306: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2080, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b);  mul_2080 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = None
        convert_element_type_549: "f16[s0, 384][384, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3306, torch.float16);  add_3306 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_100: "f16[384, 6354][1, 384]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_25: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_549, permute_100);  convert_element_type_549 = permute_100 = None
        add_tensor_25: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_25, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias);  mm_default_25 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1272 in forward, code: layer_norm_92 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0, (6354,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        convert_element_type_553: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_25, torch.float32);  add_tensor_25 = None
        var_mean_123 = torch.ops.aten.var_mean.correction(convert_element_type_553, [1], correction = 0, keepdim = True)
        getitem_436: "f32[s0, 1][1, 1]cuda:0" = var_mean_123[0]
        getitem_437: "f32[s0, 1][1, 1]cuda:0" = var_mean_123[1];  var_mean_123 = None
        
         # File: <eval_with_key>.27:1273 in forward, code: addcmul_2 = torch.addcmul(input = layer_norm_90, tensor1 = layer_norm_90, tensor2 = layer_norm_92, value = 1.0);  layer_norm_90 = layer_norm_92 = None
        convert_element_type_555: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(convert_element_type_544, torch.float32)
        convert_element_type_556: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(convert_element_type_544, torch.float32);  convert_element_type_544 = None
        mul_2093: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(convert_element_type_556, 1.0);  convert_element_type_556 = None
        
         # File: <eval_with_key>.27:1272 in forward, code: layer_norm_92 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0, (6354,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        sub_1081: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_553, getitem_437);  convert_element_type_553 = getitem_437 = None
        add_3319: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_436, 1e-05);  getitem_436 = None
        rsqrt_123: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3319);  add_3319 = None
        mul_2087: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1081, rsqrt_123);  sub_1081 = rsqrt_123 = None
        mul_2088: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2087, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w);  mul_2087 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_w = None
        add_3320: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2088, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b);  mul_2088 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        
         # File: <eval_with_key>.27:1273 in forward, code: addcmul_2 = torch.addcmul(input = layer_norm_90, tensor1 = layer_norm_90, tensor2 = layer_norm_92, value = 1.0);  layer_norm_90 = layer_norm_92 = None
        mul_2094: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2093, add_3320);  mul_2093 = add_3320 = None
        add_3330: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_555, mul_2094);  convert_element_type_555 = mul_2094 = None
        
         # File: <eval_with_key>.27:1278 in forward, code: layer_norm_93 = torch.nn.functional.layer_norm(addcmul_2, getitem_339, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b, eps = 1e-05);  addcmul_2 = getitem_339 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b = None
        var_mean_124 = torch.ops.aten.var_mean.correction(add_3330, [1], correction = 0, keepdim = True)
        getitem_438: "f32[s0, 1][1, 1]cuda:0" = var_mean_124[0]
        getitem_439: "f32[s0, 1][1, 1]cuda:0" = var_mean_124[1];  var_mean_124 = None
        sub_1086: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(add_3330, getitem_439);  add_3330 = getitem_439 = None
        add_3334: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_438, 1e-05);  getitem_438 = None
        rsqrt_124: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3334);  add_3334 = None
        mul_2097: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1086, rsqrt_124);  sub_1086 = rsqrt_124 = None
        mul_2098: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2097, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w);  mul_2097 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_w = None
        add_3335: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2098, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b);  mul_2098 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__post_dcn_ln__init_b = None
        convert_element_type_560: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3335, torch.float16);  add_3335 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_101: "f16[6354, 3072][1, 6354]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_24: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_560, permute_101);  convert_element_type_560 = permute_101 = None
        add_tensor_24: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_24, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias);  mm_default_24 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_564: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_24, torch.float32)
        var_mean_125 = torch.ops.aten.var_mean.correction(convert_element_type_564, [1], correction = 0, keepdim = True)
        getitem_440: "f32[s0, 1][1, 1]cuda:0" = var_mean_125[0]
        getitem_441: "f32[s0, 1][1, 1]cuda:0" = var_mean_125[1];  var_mean_125 = None
        sub_1091: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_564, getitem_441);  convert_element_type_564 = getitem_441 = None
        add_3348: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_440, 1e-05);  getitem_440 = None
        rsqrt_125: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3348);  add_3348 = None
        mul_2105: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1091, rsqrt_125);  sub_1091 = rsqrt_125 = None
        mul_2106: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2105, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight);  mul_2105 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = None
        add_3349: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2106, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias);  mul_2106 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = None
        convert_element_type_565: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3349, torch.float16);  add_3349 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_30: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_565);  convert_element_type_565 = None
        
         # File: <eval_with_key>.27:1282 in forward, code: mul_29 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_1_norm_1 = None
        mul_2113: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_24, sigmoid_30);  add_tensor_24 = sigmoid_30 = None
        
         # File: <eval_with_key>.27:1285 in forward, code: layer_norm_94 = torch.nn.functional.layer_norm(mul_29, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_29 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b = None
        convert_element_type_566: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2113, torch.float32);  mul_2113 = None
        var_mean_126 = torch.ops.aten.var_mean.correction(convert_element_type_566, [1], correction = 0, keepdim = True)
        getitem_442: "f32[s0, 1][1, 1]cuda:0" = var_mean_126[0]
        getitem_443: "f32[s0, 1][1, 1]cuda:0" = var_mean_126[1];  var_mean_126 = None
        sub_1097: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_566, getitem_443);  convert_element_type_566 = getitem_443 = None
        add_3365: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_442, 1e-05);  getitem_442 = None
        rsqrt_126: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3365);  add_3365 = None
        mul_2116: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1097, rsqrt_126);  sub_1097 = rsqrt_126 = None
        mul_2117: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2116, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w);  mul_2116 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_w = None
        add_3366: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2117, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b);  mul_2117 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_0_mlp_net_2__init_b = None
        convert_element_type_567: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3366, torch.float16);  add_3366 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_102: "f16[3072, 1536][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_23: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_567, permute_102);  permute_102 = None
        add_tensor_23: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_23, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias);  mm_default_23 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_571: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_23, torch.float32)
        var_mean_127 = torch.ops.aten.var_mean.correction(convert_element_type_571, [1], correction = 0, keepdim = True)
        getitem_444: "f32[s0, 1][1, 1]cuda:0" = var_mean_127[0]
        getitem_445: "f32[s0, 1][1, 1]cuda:0" = var_mean_127[1];  var_mean_127 = None
        sub_1102: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_571, getitem_445);  convert_element_type_571 = getitem_445 = None
        add_3379: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_444, 1e-05);  getitem_444 = None
        rsqrt_127: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3379);  add_3379 = None
        mul_2124: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1102, rsqrt_127);  sub_1102 = rsqrt_127 = None
        mul_2125: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2124, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight);  mul_2124 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = None
        add_3380: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2125, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias);  mul_2125 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = None
        convert_element_type_572: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3380, torch.float16);  add_3380 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_31: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_572);  convert_element_type_572 = None
        
         # File: <eval_with_key>.27:1289 in forward, code: mul_30 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_1_norm_1 = None
        mul_2132: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_23, sigmoid_31);  add_tensor_23 = sigmoid_31 = None
        
         # File: <eval_with_key>.27:1292 in forward, code: layer_norm_95 = torch.nn.functional.layer_norm(mul_30, (1536,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b, eps = 1e-05);  mul_30 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b = None
        convert_element_type_573: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2132, torch.float32);  mul_2132 = None
        var_mean_128 = torch.ops.aten.var_mean.correction(convert_element_type_573, [1], correction = 0, keepdim = True)
        getitem_446: "f32[s0, 1][1, 1]cuda:0" = var_mean_128[0]
        getitem_447: "f32[s0, 1][1, 1]cuda:0" = var_mean_128[1];  var_mean_128 = None
        sub_1108: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_573, getitem_447);  convert_element_type_573 = getitem_447 = None
        add_3396: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_446, 1e-05);  getitem_446 = None
        rsqrt_128: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3396);  add_3396 = None
        mul_2135: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1108, rsqrt_128);  sub_1108 = rsqrt_128 = None
        mul_2136: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2135, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w);  mul_2135 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_w = None
        add_3397: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2136, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b);  mul_2136 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_1_mlp_net_2__init_b = None
        convert_element_type_574: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3397, torch.float16);  add_3397 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_103: "f16[1536, 3072][1, 1536]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_22: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_574, permute_103);  convert_element_type_574 = permute_103 = None
        add_tensor_22: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_22, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias);  mm_default_22 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1296 in forward, code: layer_norm_96 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b = None
        convert_element_type_578: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_22, torch.float32);  add_tensor_22 = None
        var_mean_129 = torch.ops.aten.var_mean.correction(convert_element_type_578, [1], correction = 0, keepdim = True)
        getitem_448: "f32[s0, 1][1, 1]cuda:0" = var_mean_129[0]
        getitem_449: "f32[s0, 1][1, 1]cuda:0" = var_mean_129[1];  var_mean_129 = None
        sub_1113: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_578, getitem_449);  convert_element_type_578 = getitem_449 = None
        add_3410: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_448, 1e-05);  getitem_448 = None
        rsqrt_129: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3410);  add_3410 = None
        mul_2143: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1113, rsqrt_129);  sub_1113 = rsqrt_129 = None
        mul_2144: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2143, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w);  mul_2143 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_w = None
        add_3411: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2144, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b);  mul_2144 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_2_mlp_net_1__init_b = None
        convert_element_type_579: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3411, torch.float16);  add_3411 = None
        
         # File: <eval_with_key>.27:1297 in forward, code: add_32 = layer_norm_94 + layer_norm_96;  layer_norm_96 = None
        add_3421: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_567, convert_element_type_579);  convert_element_type_579 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_580: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3421, torch.float32)
        var_mean_130 = torch.ops.aten.var_mean.correction(convert_element_type_580, [1], correction = 0, keepdim = True)
        getitem_450: "f32[s0, 1][1, 1]cuda:0" = var_mean_130[0]
        getitem_451: "f32[s0, 1][1, 1]cuda:0" = var_mean_130[1];  var_mean_130 = None
        sub_1118: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_580, getitem_451);  convert_element_type_580 = getitem_451 = None
        add_3425: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_450, 1e-05);  getitem_450 = None
        rsqrt_130: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3425);  add_3425 = None
        mul_2151: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1118, rsqrt_130);  sub_1118 = rsqrt_130 = None
        mul_2152: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2151, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight);  mul_2151 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_weight = None
        add_3426: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2152, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias);  mul_2152 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_0_bias = None
        convert_element_type_581: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3426, torch.float16);  add_3426 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_32: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_581);  convert_element_type_581 = None
        
         # File: <eval_with_key>.27:1300 in forward, code: mul_31 = add_32 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_1;  add_32 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_2_norm_1 = None
        mul_2159: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_3421, sigmoid_32);  add_3421 = sigmoid_32 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_104: "f16[3072, 1536][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_21: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(mul_2159, permute_104);  permute_104 = None
        add_tensor_21: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_21, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias);  mm_default_21 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_585: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_21, torch.float32)
        var_mean_131 = torch.ops.aten.var_mean.correction(convert_element_type_585, [1], correction = 0, keepdim = True)
        getitem_452: "f32[s0, 1][1, 1]cuda:0" = var_mean_131[0]
        getitem_453: "f32[s0, 1][1, 1]cuda:0" = var_mean_131[1];  var_mean_131 = None
        sub_1126: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_585, getitem_453);  convert_element_type_585 = getitem_453 = None
        add_3449: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_452, 1e-05);  getitem_452 = None
        rsqrt_131: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3449);  add_3449 = None
        mul_2166: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1126, rsqrt_131);  sub_1126 = rsqrt_131 = None
        mul_2167: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2166, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight);  mul_2166 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = None
        add_3450: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2167, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias);  mul_2167 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = None
        convert_element_type_586: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3450, torch.float16);  add_3450 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_33: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_586);  convert_element_type_586 = None
        
         # File: <eval_with_key>.27:1305 in forward, code: mul_32 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_1_norm_1 = None
        mul_2174: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_21, sigmoid_33);  add_tensor_21 = sigmoid_33 = None
        
         # File: <eval_with_key>.27:1308 in forward, code: layer_norm_97 = torch.nn.functional.layer_norm(mul_32, (1536,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b, eps = 1e-05);  mul_32 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b = None
        convert_element_type_587: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2174, torch.float32);  mul_2174 = None
        var_mean_132 = torch.ops.aten.var_mean.correction(convert_element_type_587, [1], correction = 0, keepdim = True)
        getitem_454: "f32[s0, 1][1, 1]cuda:0" = var_mean_132[0]
        getitem_455: "f32[s0, 1][1, 1]cuda:0" = var_mean_132[1];  var_mean_132 = None
        sub_1132: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_587, getitem_455);  convert_element_type_587 = getitem_455 = None
        add_3466: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_454, 1e-05);  getitem_454 = None
        rsqrt_132: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3466);  add_3466 = None
        mul_2177: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1132, rsqrt_132);  sub_1132 = rsqrt_132 = None
        mul_2178: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2177, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w);  mul_2177 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_w = None
        add_3467: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2178, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b);  mul_2178 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_3_mlp_net_2__init_b = None
        convert_element_type_588: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3467, torch.float16);  add_3467 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_105: "f16[1536, 3072][1, 1536]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_20: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_588, permute_105);  convert_element_type_588 = permute_105 = None
        add_tensor_20: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_20, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias);  mm_default_20 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1312 in forward, code: layer_norm_98 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b = None
        convert_element_type_592: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_20, torch.float32);  add_tensor_20 = None
        var_mean_133 = torch.ops.aten.var_mean.correction(convert_element_type_592, [1], correction = 0, keepdim = True)
        getitem_456: "f32[s0, 1][1, 1]cuda:0" = var_mean_133[0]
        getitem_457: "f32[s0, 1][1, 1]cuda:0" = var_mean_133[1];  var_mean_133 = None
        
         # File: <eval_with_key>.27:1301 in forward, code: add_33 = layer_norm_94 + mul_31;  layer_norm_94 = None
        add_3442: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_567, mul_2159);  convert_element_type_567 = mul_2159 = None
        
         # File: <eval_with_key>.27:1312 in forward, code: layer_norm_98 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b = None
        sub_1137: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_592, getitem_457);  convert_element_type_592 = getitem_457 = None
        add_3480: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_456, 1e-05);  getitem_456 = None
        rsqrt_133: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3480);  add_3480 = None
        mul_2185: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1137, rsqrt_133);  sub_1137 = rsqrt_133 = None
        mul_2186: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2185, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w);  mul_2185 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_w = None
        add_3481: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2186, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b);  mul_2186 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__mlps_4_mlp_net_1__init_b = None
        convert_element_type_593: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3481, torch.float16);  add_3481 = None
        
         # File: <eval_with_key>.27:1313 in forward, code: add_34 = add_33 + layer_norm_98;  add_33 = layer_norm_98 = None
        add_3491: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(add_3442, convert_element_type_593);  add_3442 = convert_element_type_593 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_594: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3491, torch.float32)
        var_mean_134 = torch.ops.aten.var_mean.correction(convert_element_type_594, [1], correction = 0, keepdim = True)
        getitem_458: "f32[s0, 1][1, 1]cuda:0" = var_mean_134[0]
        getitem_459: "f32[s0, 1][1, 1]cuda:0" = var_mean_134[1];  var_mean_134 = None
        
         # File: <eval_with_key>.27:1200 in forward, code: reshape_137 = getitem_335.reshape(-1, 9216);  getitem_335 = None
        view_79: "f16[s0, 9216][13824, 1]cuda:0" = torch.ops.aten.reshape.default(getitem_402, [sym_size_int, 9216]);  getitem_402 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_1142: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_594, getitem_459);  convert_element_type_594 = getitem_459 = None
        add_3495: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_458, 1e-05);  getitem_458 = None
        rsqrt_134: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3495);  add_3495 = None
        mul_2193: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1142, rsqrt_134);  sub_1142 = rsqrt_134 = None
        mul_2194: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2193, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight);  mul_2193 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_weight = None
        add_3496: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2194, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias);  mul_2194 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_0_bias = None
        convert_element_type_595: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3496, torch.float16);  add_3496 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_34: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_595);  convert_element_type_595 = None
        
         # File: <eval_with_key>.27:1316 in forward, code: mul_33 = add_34 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_1;  add_34 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__residual_mlp__residual_activation_4_norm_1 = None
        mul_2201: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_3491, sigmoid_34);  add_3491 = sigmoid_34 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_106: "f16[3072, 9216][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_weight = None
        addmm_91: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.addmm.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias, mul_2201, permute_106);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0_bias = mul_2201 = permute_106 = None
        
         # File: <eval_with_key>.27:1318 in forward, code: cat_47 = torch.cat([linear_45, linear_46, linear_47, linear_48, linear_49, linear_50, reshape_137, main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0], dim = 1);  linear_45 = linear_46 = linear_47 = linear_48 = linear_49 = linear_50 = reshape_137 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__snn_projection_mlp_net_0 = None
        cat_23: "f16[s0, 19584][19584, 1]cuda:0" = torch.ops.aten.cat.default([clone_2, clone_3, clone_4, clone_5, clone_6, clone_7, view_79, addmm_91], 1);  clone_2 = clone_3 = clone_4 = clone_5 = clone_6 = clone_7 = view_79 = addmm_91 = None
        
         # File: <eval_with_key>.27:1319 in forward, code: _reshape_to_3d_2 = _torch_package_1_legokit_backbones_dhen_prototype__reshape_to_3d(tensor = cat_47, emb_num = 102, emb_dim = 192);  cat_47 = None
        view_84: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.reshape.default(cat_23, [sym_size_int, 102, 192]);  cat_23 = None
        
         # File: <eval_with_key>.27:1320 in forward, code: add_35 = _reshape_to_3d_2 + layer_norm_79;  _reshape_to_3d_2 = layer_norm_79 = None
        add_3522: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(view_84, convert_element_type_488);  view_84 = convert_element_type_488 = None
        
         # File: <eval_with_key>.27:1325 in forward, code: layer_norm_99 = torch.nn.functional.layer_norm(add_35, getitem_340, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b, eps = 1e-05);  add_35 = getitem_340 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b = None
        convert_element_type_599: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3522, torch.float32);  add_3522 = None
        var_mean_135 = torch.ops.aten.var_mean.correction(convert_element_type_599, [2], correction = 0, keepdim = True)
        getitem_460: "f32[s0, 102, 1][102, 1, 1]cuda:0" = var_mean_135[0]
        getitem_461: "f32[s0, 102, 1][102, 1, 1]cuda:0" = var_mean_135[1];  var_mean_135 = None
        
         # File: <eval_with_key>.27:1327 in forward, code: matmul_3 = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w, layer_norm_99);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w = None
        expand_6: "f16[s0, 24, 102][0, 102, 1]cuda:0" = torch.ops.aten.expand.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w, [sym_size_int_17, 24, 102]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w = None
        view_85: "f16[s0, 24, 102][0, 102, 1]cuda:0" = torch.ops.aten.reshape.default(expand_6, [sym_size_int_17, 24, 102]);  expand_6 = None
        
         # File: <eval_with_key>.27:1325 in forward, code: layer_norm_99 = torch.nn.functional.layer_norm(add_35, getitem_340, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b, eps = 1e-05);  add_35 = getitem_340 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b = None
        sub_1152: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_599, getitem_461);  convert_element_type_599 = getitem_461 = None
        add_3527: "f32[s0, 102, 1][102, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_460, 1e-05);  getitem_460 = None
        rsqrt_135: "f32[s0, 102, 1][102, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3527);  add_3527 = None
        mul_2212: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1152, rsqrt_135);  sub_1152 = rsqrt_135 = None
        mul_2213: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2212, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w);  mul_2212 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_w = None
        add_3528: "f32[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2213, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b);  mul_2213 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_2__ln_on_dhen_layer__init_b = None
        convert_element_type_600: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3528, torch.float16);  add_3528 = None
        
         # File: <eval_with_key>.27:1327 in forward, code: matmul_3 = torch.matmul(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w, layer_norm_99);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_w = None
        expand_7: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.expand.default(convert_element_type_600, [sym_size_int_17, 102, 192])
        view_86: "f16[s0, 102, 192][19584, 192, 1]cuda:0" = torch.ops.aten.reshape.default(expand_7, [sym_size_int_17, 102, 192]);  expand_7 = None
        bmm_9: "f16[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.aten.bmm.default(view_85, view_86);  view_85 = view_86 = None
        view_87: "f16[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.aten.reshape.default(bmm_9, [sym_size_int_17, 24, 192]);  bmm_9 = sym_size_int_17 = None
        
         # File: <eval_with_key>.27:1329 in forward, code: add_36 = matmul_3 + main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b;  matmul_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b = None
        add_3557: "f16[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(view_87, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b);  view_87 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__compression_b = None
        
         # File: <eval_with_key>.27:1335 in forward, code: layer_norm_100 = torch.nn.functional.layer_norm(add_36, getitem_341, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b, eps = 1e-05);  add_36 = getitem_341 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b = None
        convert_element_type_603: "f32[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3557, torch.float32);  add_3557 = None
        var_mean_136 = torch.ops.aten.var_mean.correction(convert_element_type_603, [2], correction = 0, keepdim = True)
        getitem_462: "f32[s0, 24, 1][24, 1, 1]cuda:0" = var_mean_136[0]
        getitem_463: "f32[s0, 24, 1][24, 1, 1]cuda:0" = var_mean_136[1];  var_mean_136 = None
        
        # No stacktrace found for following nodes
        cat_25: "f16[1536][1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_bias, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_bias]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_bias = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1335 in forward, code: layer_norm_100 = torch.nn.functional.layer_norm(add_36, getitem_341, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b, eps = 1e-05);  add_36 = getitem_341 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b = None
        sub_1164: "f32[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_603, getitem_463);  convert_element_type_603 = getitem_463 = None
        add_3566: "f32[s0, 24, 1][24, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_462, 1e-05);  getitem_462 = None
        rsqrt_136: "f32[s0, 24, 1][24, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3566);  add_3566 = None
        mul_2243: "f32[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1164, rsqrt_136);  sub_1164 = rsqrt_136 = None
        mul_2244: "f32[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2243, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w);  mul_2243 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_w = None
        add_3567: "f32[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2244, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b);  mul_2244 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__input_compression__ln_lce__init_b = None
        convert_element_type_604: "f16[s0, 24, 192][4608, 192, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3567, torch.float16);  add_3567 = None
        
         # File: <eval_with_key>.27:1336 in forward, code: reshape_141 = torch.reshape(layer_norm_100, (-1, 4608));  layer_norm_100 = None
        view_88: "f16[s0, 4608][4608, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_604, [-1, 4608]);  convert_element_type_604 = None
        
        # No stacktrace found for following nodes
        cat_24: "f16[1536, 4608][4608, 1]cuda:0" = torch.ops.aten.cat.default([submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_weight, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_weight]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0_weight = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0_weight = None
        permute_108: "f16[4608, 1536][1, 4608]cuda:0" = torch.ops.aten.permute.default(cat_24, [1, 0]);  cat_24 = None
        mm_default_19: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(view_88, permute_108);  view_88 = permute_108 = None
        add_tensor_19: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_19, cat_25);  mm_default_19 = cat_25 = None
        slice_30: "f16[s0, 768][1536, 1]cuda:0" = torch.ops.aten.slice.Tensor(add_tensor_19, 1, 0, 768)
        clone_15: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.clone.default(slice_30, memory_format = torch.contiguous_format);  slice_30 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_608: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone_15, torch.float32)
        var_mean_137 = torch.ops.aten.var_mean.correction(convert_element_type_608, [1], correction = 0, keepdim = True)
        getitem_464: "f32[s0, 1][1, 1]cuda:0" = var_mean_137[0]
        getitem_465: "f32[s0, 1][1, 1]cuda:0" = var_mean_137[1];  var_mean_137 = None
        
        # No stacktrace found for following nodes
        slice_32: "f16[s0, 768][1536, 1]cuda:0" = torch.ops.aten.slice.Tensor(add_tensor_19, 1, 768, 1536);  add_tensor_19 = None
        clone_16: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.clone.default(slice_32, memory_format = torch.contiguous_format);  slice_32 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_610: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(clone_16, torch.float32)
        var_mean_138 = torch.ops.aten.var_mean.correction(convert_element_type_610, [1], correction = 0, keepdim = True)
        getitem_466: "f32[s0, 1][1, 1]cuda:0" = var_mean_138[0]
        getitem_467: "f32[s0, 1][1, 1]cuda:0" = var_mean_138[1];  var_mean_138 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_1176: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_608, getitem_465);  convert_element_type_608 = getitem_465 = None
        add_3604: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_464, 1e-05);  getitem_464 = None
        rsqrt_137: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3604);  add_3604 = None
        mul_2269: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1176, rsqrt_137);  sub_1176 = rsqrt_137 = None
        mul_2270: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2269, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight);  mul_2269 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_weight = None
        add_3605: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2270, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias);  mul_2270 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_0_bias = None
        convert_element_type_609: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3605, torch.float16);  add_3605 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_35: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_609);  convert_element_type_609 = None
        
         # File: <eval_with_key>.27:1342 in forward, code: mul_34 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_1_norm_1 = None
        mul_2283: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone_15, sigmoid_35);  clone_15 = sigmoid_35 = None
        
         # File: <eval_with_key>.27:1347 in forward, code: layer_norm_101 = torch.nn.functional.layer_norm(mul_34, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_34 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_612: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2283, torch.float32);  mul_2283 = None
        var_mean_139 = torch.ops.aten.var_mean.correction(convert_element_type_612, [1], correction = 0, keepdim = True)
        getitem_468: "f32[s0, 1][1, 1]cuda:0" = var_mean_139[0]
        getitem_469: "f32[s0, 1][1, 1]cuda:0" = var_mean_139[1];  var_mean_139 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_1180: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_610, getitem_467);  convert_element_type_610 = getitem_467 = None
        add_3615: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_466, 1e-05);  getitem_466 = None
        rsqrt_138: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3615);  add_3615 = None
        mul_2275: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1180, rsqrt_138);  sub_1180 = rsqrt_138 = None
        mul_2276: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2275, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight);  mul_2275 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_weight = None
        add_3616: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2276, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias);  mul_2276 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_0_bias = None
        convert_element_type_611: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3616, torch.float16);  add_3616 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_36: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_611);  convert_element_type_611 = None
        
         # File: <eval_with_key>.27:1344 in forward, code: mul_35 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_1_norm_1 = None
        mul_2288: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(clone_16, sigmoid_36);  clone_16 = sigmoid_36 = None
        
         # File: <eval_with_key>.27:1350 in forward, code: layer_norm_102 = torch.nn.functional.layer_norm(mul_35, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_35 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_614: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2288, torch.float32);  mul_2288 = None
        var_mean_140 = torch.ops.aten.var_mean.correction(convert_element_type_614, [1], correction = 0, keepdim = True)
        getitem_470: "f32[s0, 1][1, 1]cuda:0" = var_mean_140[0]
        getitem_471: "f32[s0, 1][1, 1]cuda:0" = var_mean_140[1];  var_mean_140 = None
        
         # File: <eval_with_key>.27:1347 in forward, code: layer_norm_101 = torch.nn.functional.layer_norm(mul_34, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_34 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        sub_1188: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_612, getitem_469);  convert_element_type_612 = getitem_469 = None
        add_3638: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_468, 1e-05);  getitem_468 = None
        rsqrt_139: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3638);  add_3638 = None
        mul_2291: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1188, rsqrt_139);  sub_1188 = rsqrt_139 = None
        mul_2292: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2291, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w);  mul_2291 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_w = None
        add_3639: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2292, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b);  mul_2292 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_613: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3639, torch.float16);  add_3639 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_109: "f16[768, 768][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_weight = None
        
        # No stacktrace found for following nodes
        mm_default_18: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_613, permute_109);  convert_element_type_613 = permute_109 = None
        add_tensor_18: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_18, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias);  mm_default_18 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_622: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_18, torch.float32)
        var_mean_141 = torch.ops.aten.var_mean.correction(convert_element_type_622, [1], correction = 0, keepdim = True)
        getitem_472: "f32[s0, 1][1, 1]cuda:0" = var_mean_141[0]
        getitem_473: "f32[s0, 1][1, 1]cuda:0" = var_mean_141[1];  var_mean_141 = None
        
         # File: <eval_with_key>.27:1350 in forward, code: layer_norm_102 = torch.nn.functional.layer_norm(mul_35, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b, eps = 1e-05);  mul_35 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        sub_1192: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_614, getitem_471);  convert_element_type_614 = getitem_471 = None
        add_3649: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_470, 1e-05);  getitem_470 = None
        rsqrt_140: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3649);  add_3649 = None
        mul_2297: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1192, rsqrt_140);  sub_1192 = rsqrt_140 = None
        mul_2298: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2297, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w);  mul_2297 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_w = None
        add_3650: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2298, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b);  mul_2298 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_2__init_b = None
        convert_element_type_615: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3650, torch.float16);  add_3650 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_110: "f16[768, 768][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_weight = None
        
        # No stacktrace found for following nodes
        mm_default_17: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_615, permute_110);  convert_element_type_615 = permute_110 = None
        add_tensor_17: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_17, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias);  mm_default_17 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_624: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_17, torch.float32)
        var_mean_142 = torch.ops.aten.var_mean.correction(convert_element_type_624, [1], correction = 0, keepdim = True)
        getitem_474: "f32[s0, 1][1, 1]cuda:0" = var_mean_142[0]
        getitem_475: "f32[s0, 1][1, 1]cuda:0" = var_mean_142[1];  var_mean_142 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_1198: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_622, getitem_473);  convert_element_type_622 = getitem_473 = None
        add_3666: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_472, 1e-05);  getitem_472 = None
        rsqrt_141: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3666);  add_3666 = None
        mul_2307: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1198, rsqrt_141);  sub_1198 = rsqrt_141 = None
        mul_2308: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2307, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight);  mul_2307 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_weight = None
        add_3667: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2308, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias);  mul_2308 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_0_bias = None
        convert_element_type_623: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3667, torch.float16);  add_3667 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_37: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_623);  convert_element_type_623 = None
        
         # File: <eval_with_key>.27:1356 in forward, code: mul_36 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_4_norm_1 = None
        mul_2321: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_18, sigmoid_37);  add_tensor_18 = sigmoid_37 = None
        
         # File: <eval_with_key>.27:1361 in forward, code: layer_norm_103 = torch.nn.functional.layer_norm(mul_36, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_36 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_626: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2321, torch.float32);  mul_2321 = None
        var_mean_143 = torch.ops.aten.var_mean.correction(convert_element_type_626, [1], correction = 0, keepdim = True)
        getitem_476: "f32[s0, 1][1, 1]cuda:0" = var_mean_143[0]
        getitem_477: "f32[s0, 1][1, 1]cuda:0" = var_mean_143[1];  var_mean_143 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_1202: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_624, getitem_475);  convert_element_type_624 = getitem_475 = None
        add_3677: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_474, 1e-05);  getitem_474 = None
        rsqrt_142: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3677);  add_3677 = None
        mul_2313: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1202, rsqrt_142);  sub_1202 = rsqrt_142 = None
        mul_2314: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2313, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight);  mul_2313 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_weight = None
        add_3678: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2314, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias);  mul_2314 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_0_bias = None
        convert_element_type_625: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3678, torch.float16);  add_3678 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_38: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_625);  convert_element_type_625 = None
        
         # File: <eval_with_key>.27:1358 in forward, code: mul_37 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_3 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_4_norm_1 = None
        mul_2326: "f16[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_17, sigmoid_38);  add_tensor_17 = sigmoid_38 = None
        
         # File: <eval_with_key>.27:1364 in forward, code: layer_norm_104 = torch.nn.functional.layer_norm(mul_37, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_37 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_628: "f32[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2326, torch.float32);  mul_2326 = None
        var_mean_144 = torch.ops.aten.var_mean.correction(convert_element_type_628, [1], correction = 0, keepdim = True)
        getitem_478: "f32[s0, 1][1, 1]cuda:0" = var_mean_144[0]
        getitem_479: "f32[s0, 1][1, 1]cuda:0" = var_mean_144[1];  var_mean_144 = None
        
         # File: <eval_with_key>.27:1361 in forward, code: layer_norm_103 = torch.nn.functional.layer_norm(mul_36, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_36 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        sub_1210: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_626, getitem_477);  convert_element_type_626 = getitem_477 = None
        add_3700: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_476, 1e-05);  getitem_476 = None
        rsqrt_143: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3700);  add_3700 = None
        mul_2329: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1210, rsqrt_143);  sub_1210 = rsqrt_143 = None
        mul_2330: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2329, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w);  mul_2329 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_w = None
        add_3701: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2330, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b);  mul_2330 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_627: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3701, torch.float16);  add_3701 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_111: "f16[768, 4896][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_16: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_627, permute_111);  convert_element_type_627 = permute_111 = None
        add_tensor_16: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_16, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias);  mm_default_16 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1369 in forward, code: layer_norm_105 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0, (4896,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_636: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_16, torch.float32);  add_tensor_16 = None
        var_mean_145 = torch.ops.aten.var_mean.correction(convert_element_type_636, [1], correction = 0, keepdim = True)
        getitem_480: "f32[s0, 1][1, 1]cuda:0" = var_mean_145[0]
        getitem_481: "f32[s0, 1][1, 1]cuda:0" = var_mean_145[1];  var_mean_145 = None
        
         # File: <eval_with_key>.27:1364 in forward, code: layer_norm_104 = torch.nn.functional.layer_norm(mul_37, (768,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b, eps = 1e-05);  mul_37 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        sub_1214: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_628, getitem_479);  convert_element_type_628 = getitem_479 = None
        add_3711: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_478, 1e-05);  getitem_478 = None
        rsqrt_144: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3711);  add_3711 = None
        mul_2335: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1214, rsqrt_144);  sub_1214 = rsqrt_144 = None
        mul_2336: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2335, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w);  mul_2335 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_w = None
        add_3712: "f32[s0, 768][768, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2336, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b);  mul_2336 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_mlp_mlp_net_5__init_b = None
        convert_element_type_629: "f16[s0, 768][768, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3712, torch.float16);  add_3712 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_112: "f16[768, 9216][1, 768]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_15: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_629, permute_112);  convert_element_type_629 = permute_112 = None
        add_tensor_15: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_15, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias);  mm_default_15 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1372 in forward, code: layer_norm_106 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0, (9216,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_638: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_15, torch.float32);  add_tensor_15 = None
        var_mean_146 = torch.ops.aten.var_mean.correction(convert_element_type_638, [1], correction = 0, keepdim = True)
        getitem_482: "f32[s0, 1][1, 1]cuda:0" = var_mean_146[0]
        getitem_483: "f32[s0, 1][1, 1]cuda:0" = var_mean_146[1];  var_mean_146 = None
        sub_1224: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_638, getitem_483);  convert_element_type_638 = getitem_483 = None
        add_3739: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_482, 1e-05);  getitem_482 = None
        rsqrt_146: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3739);  add_3739 = None
        mul_2351: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1224, rsqrt_146);  sub_1224 = rsqrt_146 = None
        mul_2352: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2351, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w);  mul_2351 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_w = None
        add_3740: "f32[s0, 9216][9216, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2352, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b);  mul_2352 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__resnet_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_639: "f16[s0, 9216][9216, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3740, torch.float16);  add_3740 = None
        
         # File: <eval_with_key>.27:1374 in forward, code: reshape_143 = torch.reshape(layer_norm_106, (-1, 192, 48));  layer_norm_106 = None
        view_90: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_639, [-1, 192, 48]);  convert_element_type_639 = None
        
         # File: <eval_with_key>.27:1330 in forward, code: permute_11 = layer_norm_99.permute(0, 2, 1)
        permute_107: "f16[s0, 192, 102][19584, 1, 192]cuda:0" = torch.ops.aten.permute.default(convert_element_type_600, [0, 2, 1])
        
         # File: <eval_with_key>.27:1369 in forward, code: layer_norm_105 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0, (4896,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        sub_1220: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_636, getitem_481);  convert_element_type_636 = getitem_481 = None
        add_3728: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_480, 1e-05);  getitem_480 = None
        rsqrt_145: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3728);  add_3728 = None
        mul_2345: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1220, rsqrt_145);  sub_1220 = rsqrt_145 = None
        mul_2346: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2345, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w);  mul_2345 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_w = None
        add_3729: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2346, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b);  mul_2346 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp__weight_arch_post_match_mlp_mlp_net_1__init_b = None
        convert_element_type_637: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3729, torch.float16);  add_3729 = None
        
         # File: <eval_with_key>.27:1373 in forward, code: reshape_142 = torch.reshape(layer_norm_105, (-1, 102, 48));  layer_norm_105 = None
        view_89: "f16[s0, 102, 48][4896, 48, 1]cuda:0" = torch.ops.aten.reshape.default(convert_element_type_637, [-1, 102, 48]);  convert_element_type_637 = None
        
         # File: <eval_with_key>.27:1375 in forward, code: bmm_6 = torch.bmm(permute_11, reshape_142);  permute_11 = reshape_142 = None
        bmm_10: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.bmm.default(permute_107, view_89);  permute_107 = view_89 = None
        
         # File: <eval_with_key>.27:1376 in forward, code: add_37 = reshape_143 + bmm_6;  reshape_143 = bmm_6 = None
        add_3762: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.add.Tensor(view_90, bmm_10);  view_90 = bmm_10 = None
        
         # File: <eval_with_key>.27:1379 in forward, code: layer_norm_107 = torch.nn.functional.layer_norm(add_37, (48,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b, eps = 1e-05);  add_37 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b = None
        convert_element_type_642: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3762, torch.float32);  add_3762 = None
        var_mean_147 = torch.ops.aten.var_mean.correction(convert_element_type_642, [2], correction = 0, keepdim = True)
        getitem_484: "f32[s0, 192, 1][192, 1, 1]cuda:0" = var_mean_147[0]
        getitem_485: "f32[s0, 192, 1][192, 1, 1]cuda:0" = var_mean_147[1];  var_mean_147 = None
        sub_1232: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_642, getitem_485);  convert_element_type_642 = getitem_485 = None
        add_3767: "f32[s0, 192, 1][192, 1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_484, 1e-05);  getitem_484 = None
        rsqrt_147: "f32[s0, 192, 1][192, 1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3767);  add_3767 = None
        mul_2365: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1232, rsqrt_147);  sub_1232 = rsqrt_147 = None
        mul_2366: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2365, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w);  mul_2365 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_w = None
        add_3768: "f32[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2366, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b);  mul_2366 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcpp_compressed_tensor_ln__init_b = None
        convert_element_type_643: "f16[s0, 192, 48][9216, 48, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3768, torch.float16);  add_3768 = None
        
         # File: <eval_with_key>.27:1380 in forward, code: bmm_7 = torch.bmm(layer_norm_99, layer_norm_107);  layer_norm_99 = layer_norm_107 = None
        bmm_11: "f16[s0, 102, 48][4896, 48, 1]cuda:0" = torch.ops.aten.bmm.default(convert_element_type_600, convert_element_type_643);  convert_element_type_600 = convert_element_type_643 = None
        
         # File: <eval_with_key>.27:1381 in forward, code: flatten_3 = torch.flatten(bmm_7, start_dim = -2);  bmm_7 = None
        view_91: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.reshape.default(bmm_11, [sym_size_int, 4896]);  bmm_11 = sym_size_int = None
        
         # File: <eval_with_key>.27:1386 in forward, code: layer_norm_108 = torch.nn.functional.layer_norm(flatten_3, getitem_342, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b, eps = 1e-05);  flatten_3 = getitem_342 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b = None
        convert_element_type_646: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(view_91, torch.float32);  view_91 = None
        var_mean_148 = torch.ops.aten.var_mean.correction(convert_element_type_646, [1], correction = 0, keepdim = True)
        getitem_486: "f32[s0, 1][1, 1]cuda:0" = var_mean_148[0]
        getitem_487: "f32[s0, 1][1, 1]cuda:0" = var_mean_148[1];  var_mean_148 = None
        sub_1238: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_646, getitem_487);  convert_element_type_646 = getitem_487 = None
        add_3788: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_486, 1e-05);  getitem_486 = None
        rsqrt_148: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3788);  add_3788 = None
        mul_2377: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1238, rsqrt_148);  sub_1238 = rsqrt_148 = None
        mul_2378: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2377, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w);  mul_2377 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_w = None
        add_3789: "f32[s0, 4896][4896, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2378, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b);  mul_2378 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_ln__init_b = None
        convert_element_type_647: "f16[s0, 4896][4896, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3789, torch.float16);  add_3789 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_113: "f16[4896, 2048][1, 4896]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_14: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_647, permute_113);  convert_element_type_647 = permute_113 = None
        add_tensor_14: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_14, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias);  mm_default_14 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_651: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_14, torch.float32)
        var_mean_149 = torch.ops.aten.var_mean.correction(convert_element_type_651, [1], correction = 0, keepdim = True)
        getitem_488: "f32[s0, 1][1, 1]cuda:0" = var_mean_149[0]
        getitem_489: "f32[s0, 1][1, 1]cuda:0" = var_mean_149[1];  var_mean_149 = None
        sub_1243: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_651, getitem_489);  convert_element_type_651 = getitem_489 = None
        add_3802: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_488, 1e-05);  getitem_488 = None
        rsqrt_149: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3802);  add_3802 = None
        mul_2385: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1243, rsqrt_149);  sub_1243 = rsqrt_149 = None
        mul_2386: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2385, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight);  mul_2385 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_weight = None
        add_3803: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2386, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias);  mul_2386 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_0_bias = None
        convert_element_type_652: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3803, torch.float16);  add_3803 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_39: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_652);  convert_element_type_652 = None
        
         # File: <eval_with_key>.27:1390 in forward, code: mul_38 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_1_norm_1 = None
        mul_2393: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_14, sigmoid_39);  add_tensor_14 = sigmoid_39 = None
        
         # File: <eval_with_key>.27:1393 in forward, code: layer_norm_109 = torch.nn.functional.layer_norm(mul_38, (2048,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_38 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        convert_element_type_653: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2393, torch.float32);  mul_2393 = None
        var_mean_150 = torch.ops.aten.var_mean.correction(convert_element_type_653, [1], correction = 0, keepdim = True)
        getitem_490: "f32[s0, 1][1, 1]cuda:0" = var_mean_150[0]
        getitem_491: "f32[s0, 1][1, 1]cuda:0" = var_mean_150[1];  var_mean_150 = None
        sub_1249: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_653, getitem_491);  convert_element_type_653 = getitem_491 = None
        add_3819: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_490, 1e-05);  getitem_490 = None
        rsqrt_150: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3819);  add_3819 = None
        mul_2396: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1249, rsqrt_150);  sub_1249 = rsqrt_150 = None
        mul_2397: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2396, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w);  mul_2396 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_w = None
        add_3820: "f32[s0, 2048][2048, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2397, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b);  mul_2397 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcpp_fc__mlps_0_mlp_net_2__init_b = None
        convert_element_type_654: "f16[s0, 2048][2048, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3820, torch.float16);  add_3820 = None
        
         # File: <eval_with_key>.27:1394 in forward, code: cat_48 = torch.cat([mul_3, mul_2, layer_norm_109], dim = 1);  mul_3 = mul_2 = layer_norm_109 = None
        cat_26: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.cat.default([mul_812, mul_809, convert_element_type_654], 1);  mul_812 = mul_809 = convert_element_type_654 = None
        
         # File: <eval_with_key>.27:1399 in forward, code: layer_norm_110 = torch.nn.functional.layer_norm(cat_48, getitem_343, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b, eps = 1e-05);  cat_48 = getitem_343 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b = None
        convert_element_type_655: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(cat_26, torch.float32);  cat_26 = None
        var_mean_151 = torch.ops.aten.var_mean.correction(convert_element_type_655, [1], correction = 0, keepdim = True)
        getitem_492: "f32[s0, 1][1, 1]cuda:0" = var_mean_151[0]
        getitem_493: "f32[s0, 1][1, 1]cuda:0" = var_mean_151[1];  var_mean_151 = None
        sub_1254: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_655, getitem_493);  convert_element_type_655 = getitem_493 = None
        add_3833: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_492, 1e-05);  getitem_492 = None
        rsqrt_151: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3833);  add_3833 = None
        mul_2404: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1254, rsqrt_151);  sub_1254 = rsqrt_151 = None
        mul_2405: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2404, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w);  mul_2404 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_w = None
        add_3834: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2405, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b);  mul_2405 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__ln_on_dsi__init_b = None
        convert_element_type_656: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3834, torch.float16);  add_3834 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_114: "f16[6354, 384][1, 6354]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_13: "f16[s0, 384][384, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_656, permute_114);  permute_114 = None
        add_tensor_13: "f16[s0, 384][384, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_13, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias);  mm_default_13 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1403 in forward, code: layer_norm_111 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0, (384,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = None
        convert_element_type_660: "f32[s0, 384][384, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_13, torch.float32);  add_tensor_13 = None
        var_mean_152 = torch.ops.aten.var_mean.correction(convert_element_type_660, [1], correction = 0, keepdim = True)
        getitem_494: "f32[s0, 1][1, 1]cuda:0" = var_mean_152[0]
        getitem_495: "f32[s0, 1][1, 1]cuda:0" = var_mean_152[1];  var_mean_152 = None
        sub_1259: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_660, getitem_495);  convert_element_type_660 = getitem_495 = None
        add_3847: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_494, 1e-05);  getitem_494 = None
        rsqrt_152: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3847);  add_3847 = None
        mul_2412: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1259, rsqrt_152);  sub_1259 = rsqrt_152 = None
        mul_2413: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2412, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w);  mul_2412 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_w = None
        add_3848: "f32[s0, 384][384, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2413, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b);  mul_2413 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_low_rank_mlps_0_mlp_net_1__init_b = None
        convert_element_type_661: "f16[s0, 384][384, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3848, torch.float16);  add_3848 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_115: "f16[384, 6354][1, 384]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_12: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_661, permute_115);  convert_element_type_661 = permute_115 = None
        add_tensor_12: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_12, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias);  mm_default_12 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1407 in forward, code: layer_norm_112 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0, (6354,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        convert_element_type_665: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_12, torch.float32);  add_tensor_12 = None
        var_mean_153 = torch.ops.aten.var_mean.correction(convert_element_type_665, [1], correction = 0, keepdim = True)
        getitem_496: "f32[s0, 1][1, 1]cuda:0" = var_mean_153[0]
        getitem_497: "f32[s0, 1][1, 1]cuda:0" = var_mean_153[1];  var_mean_153 = None
        
         # File: <eval_with_key>.27:1408 in forward, code: addcmul_3 = torch.addcmul(input = layer_norm_110, tensor1 = layer_norm_110, tensor2 = layer_norm_112, value = 1.0);  layer_norm_110 = layer_norm_112 = None
        convert_element_type_667: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(convert_element_type_656, torch.float32)
        convert_element_type_668: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(convert_element_type_656, torch.float32);  convert_element_type_656 = None
        mul_2426: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(convert_element_type_668, 1.0);  convert_element_type_668 = None
        
         # File: <eval_with_key>.27:1407 in forward, code: layer_norm_112 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0, (6354,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        sub_1264: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_665, getitem_497);  convert_element_type_665 = getitem_497 = None
        add_3861: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_496, 1e-05);  getitem_496 = None
        rsqrt_153: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3861);  add_3861 = None
        mul_2420: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1264, rsqrt_153);  sub_1264 = rsqrt_153 = None
        mul_2421: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2420, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w);  mul_2420 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_w = None
        add_3862: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2421, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b);  mul_2421 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__dcn__dcn_match_mlps_0_mlp_net_1__init_b = None
        
         # File: <eval_with_key>.27:1408 in forward, code: addcmul_3 = torch.addcmul(input = layer_norm_110, tensor1 = layer_norm_110, tensor2 = layer_norm_112, value = 1.0);  layer_norm_110 = layer_norm_112 = None
        mul_2427: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2426, add_3862);  mul_2426 = add_3862 = None
        add_3872: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_667, mul_2427);  convert_element_type_667 = mul_2427 = None
        
         # File: <eval_with_key>.27:1413 in forward, code: layer_norm_113 = torch.nn.functional.layer_norm(addcmul_3, getitem_344, weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b, eps = 1e-05);  addcmul_3 = getitem_344 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b = None
        var_mean_154 = torch.ops.aten.var_mean.correction(add_3872, [1], correction = 0, keepdim = True)
        getitem_498: "f32[s0, 1][1, 1]cuda:0" = var_mean_154[0]
        getitem_499: "f32[s0, 1][1, 1]cuda:0" = var_mean_154[1];  var_mean_154 = None
        sub_1269: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.sub.Tensor(add_3872, getitem_499);  add_3872 = getitem_499 = None
        add_3876: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_498, 1e-05);  getitem_498 = None
        rsqrt_154: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3876);  add_3876 = None
        mul_2430: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1269, rsqrt_154);  sub_1269 = rsqrt_154 = None
        mul_2431: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2430, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w);  mul_2430 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_w = None
        add_3877: "f32[s0, 6354][6354, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2431, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b);  mul_2431 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__post_dcn_ln__init_b = None
        convert_element_type_672: "f16[s0, 6354][6354, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3877, torch.float16);  add_3877 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_116: "f16[6354, 3072][1, 6354]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_11: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_672, permute_116);  convert_element_type_672 = permute_116 = None
        add_tensor_11: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_11, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias);  mm_default_11 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_676: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_11, torch.float32)
        var_mean_155 = torch.ops.aten.var_mean.correction(convert_element_type_676, [1], correction = 0, keepdim = True)
        getitem_500: "f32[s0, 1][1, 1]cuda:0" = var_mean_155[0]
        getitem_501: "f32[s0, 1][1, 1]cuda:0" = var_mean_155[1];  var_mean_155 = None
        sub_1274: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_676, getitem_501);  convert_element_type_676 = getitem_501 = None
        add_3890: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_500, 1e-05);  getitem_500 = None
        rsqrt_155: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3890);  add_3890 = None
        mul_2438: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1274, rsqrt_155);  sub_1274 = rsqrt_155 = None
        mul_2439: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2438, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight);  mul_2438 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_weight = None
        add_3891: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2439, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias);  mul_2439 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_0_bias = None
        convert_element_type_677: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3891, torch.float16);  add_3891 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_40: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_677);  convert_element_type_677 = None
        
         # File: <eval_with_key>.27:1417 in forward, code: mul_39 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_1_norm_1 = None
        mul_2446: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_11, sigmoid_40);  add_tensor_11 = sigmoid_40 = None
        
         # File: <eval_with_key>.27:1420 in forward, code: layer_norm_114 = torch.nn.functional.layer_norm(mul_39, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b, eps = 1e-05);  mul_39 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b = None
        convert_element_type_678: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2446, torch.float32);  mul_2446 = None
        var_mean_156 = torch.ops.aten.var_mean.correction(convert_element_type_678, [1], correction = 0, keepdim = True)
        getitem_502: "f32[s0, 1][1, 1]cuda:0" = var_mean_156[0]
        getitem_503: "f32[s0, 1][1, 1]cuda:0" = var_mean_156[1];  var_mean_156 = None
        sub_1280: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_678, getitem_503);  convert_element_type_678 = getitem_503 = None
        add_3907: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_502, 1e-05);  getitem_502 = None
        rsqrt_156: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3907);  add_3907 = None
        mul_2449: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1280, rsqrt_156);  sub_1280 = rsqrt_156 = None
        mul_2450: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2449, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w);  mul_2449 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_w = None
        add_3908: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2450, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b);  mul_2450 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_0_mlp_net_2__init_b = None
        convert_element_type_679: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3908, torch.float16);  add_3908 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_117: "f16[3072, 1536][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_10: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_679, permute_117);  permute_117 = None
        add_tensor_10: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_10, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias);  mm_default_10 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_683: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_10, torch.float32)
        var_mean_157 = torch.ops.aten.var_mean.correction(convert_element_type_683, [1], correction = 0, keepdim = True)
        getitem_504: "f32[s0, 1][1, 1]cuda:0" = var_mean_157[0]
        getitem_505: "f32[s0, 1][1, 1]cuda:0" = var_mean_157[1];  var_mean_157 = None
        sub_1285: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_683, getitem_505);  convert_element_type_683 = getitem_505 = None
        add_3921: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_504, 1e-05);  getitem_504 = None
        rsqrt_157: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3921);  add_3921 = None
        mul_2457: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1285, rsqrt_157);  sub_1285 = rsqrt_157 = None
        mul_2458: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2457, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight);  mul_2457 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_weight = None
        add_3922: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2458, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias);  mul_2458 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_0_bias = None
        convert_element_type_684: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3922, torch.float16);  add_3922 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_41: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_684);  convert_element_type_684 = None
        
         # File: <eval_with_key>.27:1424 in forward, code: mul_40 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_1_norm_1 = None
        mul_2465: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_10, sigmoid_41);  add_tensor_10 = sigmoid_41 = None
        
         # File: <eval_with_key>.27:1427 in forward, code: layer_norm_115 = torch.nn.functional.layer_norm(mul_40, (1536,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b, eps = 1e-05);  mul_40 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b = None
        convert_element_type_685: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2465, torch.float32);  mul_2465 = None
        var_mean_158 = torch.ops.aten.var_mean.correction(convert_element_type_685, [1], correction = 0, keepdim = True)
        getitem_506: "f32[s0, 1][1, 1]cuda:0" = var_mean_158[0]
        getitem_507: "f32[s0, 1][1, 1]cuda:0" = var_mean_158[1];  var_mean_158 = None
        sub_1291: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_685, getitem_507);  convert_element_type_685 = getitem_507 = None
        add_3938: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_506, 1e-05);  getitem_506 = None
        rsqrt_158: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3938);  add_3938 = None
        mul_2468: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1291, rsqrt_158);  sub_1291 = rsqrt_158 = None
        mul_2469: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2468, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w);  mul_2468 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_w = None
        add_3939: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2469, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b);  mul_2469 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_1_mlp_net_2__init_b = None
        convert_element_type_686: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3939, torch.float16);  add_3939 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_118: "f16[1536, 3072][1, 1536]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_9: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_686, permute_118);  convert_element_type_686 = permute_118 = None
        add_tensor_9: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_9, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias);  mm_default_9 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1431 in forward, code: layer_norm_116 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b = None
        convert_element_type_690: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_9, torch.float32);  add_tensor_9 = None
        var_mean_159 = torch.ops.aten.var_mean.correction(convert_element_type_690, [1], correction = 0, keepdim = True)
        getitem_508: "f32[s0, 1][1, 1]cuda:0" = var_mean_159[0]
        getitem_509: "f32[s0, 1][1, 1]cuda:0" = var_mean_159[1];  var_mean_159 = None
        sub_1296: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_690, getitem_509);  convert_element_type_690 = getitem_509 = None
        add_3952: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_508, 1e-05);  getitem_508 = None
        rsqrt_159: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3952);  add_3952 = None
        mul_2476: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1296, rsqrt_159);  sub_1296 = rsqrt_159 = None
        mul_2477: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2476, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w);  mul_2476 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_w = None
        add_3953: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2477, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b);  mul_2477 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_2_mlp_net_1__init_b = None
        convert_element_type_691: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3953, torch.float16);  add_3953 = None
        
         # File: <eval_with_key>.27:1432 in forward, code: add_38 = layer_norm_114 + layer_norm_116;  layer_norm_116 = None
        add_3963: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_679, convert_element_type_691);  convert_element_type_691 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_692: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3963, torch.float32)
        var_mean_160 = torch.ops.aten.var_mean.correction(convert_element_type_692, [1], correction = 0, keepdim = True)
        getitem_510: "f32[s0, 1][1, 1]cuda:0" = var_mean_160[0]
        getitem_511: "f32[s0, 1][1, 1]cuda:0" = var_mean_160[1];  var_mean_160 = None
        sub_1301: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_692, getitem_511);  convert_element_type_692 = getitem_511 = None
        add_3967: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_510, 1e-05);  getitem_510 = None
        rsqrt_160: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3967);  add_3967 = None
        mul_2484: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1301, rsqrt_160);  sub_1301 = rsqrt_160 = None
        mul_2485: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2484, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight);  mul_2484 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_weight = None
        add_3968: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2485, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias);  mul_2485 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_0_bias = None
        convert_element_type_693: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3968, torch.float16);  add_3968 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_42: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_693);  convert_element_type_693 = None
        
         # File: <eval_with_key>.27:1435 in forward, code: mul_41 = add_38 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_1;  add_38 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_2_norm_1 = None
        mul_2492: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_3963, sigmoid_42);  add_3963 = sigmoid_42 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_119: "f16[3072, 1536][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_8: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mm.default(mul_2492, permute_119);  permute_119 = None
        add_tensor_8: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_8, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias);  mm_default_8 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0_bias = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_697: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_8, torch.float32)
        var_mean_161 = torch.ops.aten.var_mean.correction(convert_element_type_697, [1], correction = 0, keepdim = True)
        getitem_512: "f32[s0, 1][1, 1]cuda:0" = var_mean_161[0]
        getitem_513: "f32[s0, 1][1, 1]cuda:0" = var_mean_161[1];  var_mean_161 = None
        sub_1309: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_697, getitem_513);  convert_element_type_697 = getitem_513 = None
        add_3991: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_512, 1e-05);  getitem_512 = None
        rsqrt_161: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_3991);  add_3991 = None
        mul_2499: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1309, rsqrt_161);  sub_1309 = rsqrt_161 = None
        mul_2500: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2499, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight);  mul_2499 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_weight = None
        add_3992: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2500, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias);  mul_2500 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_0_bias = None
        convert_element_type_698: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_3992, torch.float16);  add_3992 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_43: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_698);  convert_element_type_698 = None
        
         # File: <eval_with_key>.27:1440 in forward, code: mul_42 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_1;  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_1_norm_1 = None
        mul_2507: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_8, sigmoid_43);  add_tensor_8 = sigmoid_43 = None
        
         # File: <eval_with_key>.27:1443 in forward, code: layer_norm_117 = torch.nn.functional.layer_norm(mul_42, (1536,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b, eps = 1e-05);  mul_42 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b = None
        convert_element_type_699: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(mul_2507, torch.float32);  mul_2507 = None
        var_mean_162 = torch.ops.aten.var_mean.correction(convert_element_type_699, [1], correction = 0, keepdim = True)
        getitem_514: "f32[s0, 1][1, 1]cuda:0" = var_mean_162[0]
        getitem_515: "f32[s0, 1][1, 1]cuda:0" = var_mean_162[1];  var_mean_162 = None
        sub_1315: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_699, getitem_515);  convert_element_type_699 = getitem_515 = None
        add_4008: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_514, 1e-05);  getitem_514 = None
        rsqrt_162: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_4008);  add_4008 = None
        mul_2510: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1315, rsqrt_162);  sub_1315 = rsqrt_162 = None
        mul_2511: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2510, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w);  mul_2510 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_w = None
        add_4009: "f32[s0, 1536][1536, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2511, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b);  mul_2511 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_3_mlp_net_2__init_b = None
        convert_element_type_700: "f16[s0, 1536][1536, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_4009, torch.float16);  add_4009 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
        permute_120: "f16[1536, 3072][1, 1536]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_weight, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_weight = None
        
        # No stacktrace found for following nodes
        mm_default_7: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(convert_element_type_700, permute_120);  convert_element_type_700 = permute_120 = None
        add_tensor_7: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_7, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias);  mm_default_7 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0_bias = None
        
         # File: <eval_with_key>.27:1447 in forward, code: layer_norm_118 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b = None
        convert_element_type_704: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_7, torch.float32);  add_tensor_7 = None
        var_mean_163 = torch.ops.aten.var_mean.correction(convert_element_type_704, [1], correction = 0, keepdim = True)
        getitem_516: "f32[s0, 1][1, 1]cuda:0" = var_mean_163[0]
        getitem_517: "f32[s0, 1][1, 1]cuda:0" = var_mean_163[1];  var_mean_163 = None
        
         # File: <eval_with_key>.27:1436 in forward, code: add_39 = layer_norm_114 + mul_41;  layer_norm_114 = None
        add_3984: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_679, mul_2492);  convert_element_type_679 = mul_2492 = None
        
         # File: <eval_with_key>.27:1447 in forward, code: layer_norm_118 = torch.nn.functional.layer_norm(main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0, (3072,), weight = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w, bias = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b, eps = 1e-05);  main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_0 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b = None
        sub_1320: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_704, getitem_517);  convert_element_type_704 = getitem_517 = None
        add_4022: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_516, 1e-05);  getitem_516 = None
        rsqrt_163: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_4022);  add_4022 = None
        mul_2518: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1320, rsqrt_163);  sub_1320 = rsqrt_163 = None
        mul_2519: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2518, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w);  mul_2518 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_w = None
        add_4023: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2519, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b);  mul_2519 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__mlps_4_mlp_net_1__init_b = None
        convert_element_type_705: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_4023, torch.float16);  add_4023 = None
        
         # File: <eval_with_key>.27:1448 in forward, code: add_40 = add_39 + layer_norm_118;  add_39 = layer_norm_118 = None
        add_4033: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(add_3984, convert_element_type_705);  add_3984 = convert_element_type_705 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        convert_element_type_706: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_4033, torch.float32)
        var_mean_164 = torch.ops.aten.var_mean.correction(convert_element_type_706, [1], correction = 0, keepdim = True)
        getitem_518: "f32[s0, 1][1, 1]cuda:0" = var_mean_164[0]
        getitem_519: "f32[s0, 1][1, 1]cuda:0" = var_mean_164[1];  var_mean_164 = None
        
        # No stacktrace found for following nodes
        sym_size_int_9: "Sym(s0)" = torch.ops.aten.sym_size.int(addmm_37, 0);  addmm_37 = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        full: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.full.default([sym_size_int_9, 3072], 0.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
        sub_1325: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_706, getitem_519);  convert_element_type_706 = getitem_519 = None
        add_4037: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_518, 1e-05);  getitem_518 = None
        rsqrt_164: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_4037);  add_4037 = None
        mul_2526: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1325, rsqrt_164);  sub_1325 = rsqrt_164 = None
        mul_2527: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2526, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight);  mul_2526 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_weight = None
        add_4038: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2527, submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias);  mul_2527 = submod_0_main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_0_bias = None
        convert_element_type_707: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_4038, torch.float16);  add_4038 = None
        
         # File: /data/users/shangdiy/fbsource/buck-out/v2/gen/fbcode/d29ee94b913014f1/caffe2/torch/fb/model_transform/experimental/benchmark/__mts_gpu_benchmark__/mts_gpu_benchmark#link-tree/torch/nn/modules/activation.py:327 in forward, code: return torch.sigmoid(input)
        sigmoid_44: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_707);  convert_element_type_707 = None
        
         # File: <eval_with_key>.27:1451 in forward, code: mul_43 = add_40 * main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_1;  add_40 = main_module_impl_impl_shared_arch_pytorch_dhen_dhen_arch_layers_3__residual_mlp__residual_activation_4_norm_1 = None
        mul_2534: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_4033, sigmoid_44);  add_4033 = sigmoid_44 = None
        
         # File: <eval_with_key>.27:1454 in forward, code: linear_51 = torch._C._nn.linear(mul_43, main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w, main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b);  main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w = main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b = None
        permute_121: "f16[3072, 512][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_6: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.mm.default(mul_2534, permute_121);  permute_121 = None
        add_tensor_6: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_6, submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b);  mm_default_6 = submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_0_shards_0_b = None
        relu_1: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.relu.default(add_tensor_6);  add_tensor_6 = None
        convert_element_type_712: "f32[s0, 512][512, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu_1, torch.float32)
        eq_1267: "b8[s0, 512][512, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_712, inf);  convert_element_type_712 = None
        scalar_tensor_8: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        convert_element_type_711: "f32[s0, 512][512, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu_1, torch.float32)
        eq_1266: "b8[s0, 512][512, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_711, -inf);  convert_element_type_711 = None
        scalar_tensor_7: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(-65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        isnan_2: "b8[s0, 512][512, 1]cuda:0" = torch.ops.aten.isnan.default(relu_1)
        scalar_tensor_6: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        where_6: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.where.self(isnan_2, scalar_tensor_6, relu_1);  isnan_2 = scalar_tensor_6 = relu_1 = None
        where_7: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.where.self(eq_1266, scalar_tensor_7, where_6);  eq_1266 = scalar_tensor_7 = where_6 = None
        where_8: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.where.self(eq_1267, scalar_tensor_8, where_7);  eq_1267 = scalar_tensor_8 = where_7 = None
        
         # File: <eval_with_key>.27:1458 in forward, code: linear_52 = torch._C._nn.linear(relu_1, main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w, main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b);  relu_1 = main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w = main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b = None
        permute_122: "f16[512, 3072][1, 512]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_5: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(where_8, permute_122);  where_8 = permute_122 = None
        add_tensor_5: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_5, submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b);  mm_default_5 = submod_0_main_module_impl_impl_shared_arch_cyclegan_encoder_linear_archs_1_shards_0_b = None
        relu_2: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.relu.default(add_tensor_5);  add_tensor_5 = None
        convert_element_type_717: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu_2, torch.float32)
        eq_1272: "b8[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_717, inf);  convert_element_type_717 = None
        scalar_tensor_11: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        convert_element_type_716: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu_2, torch.float32)
        eq_1271: "b8[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_716, -inf);  convert_element_type_716 = None
        scalar_tensor_10: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(-65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        isnan_3: "b8[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.isnan.default(relu_2)
        scalar_tensor_9: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        where_9: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.where.self(isnan_3, scalar_tensor_9, relu_2);  isnan_3 = scalar_tensor_9 = relu_2 = None
        where_10: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.where.self(eq_1271, scalar_tensor_10, where_9);  eq_1271 = scalar_tensor_10 = where_9 = None
        where_11: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.where.self(eq_1272, scalar_tensor_11, where_10);  eq_1272 = scalar_tensor_11 = where_10 = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        add_4072: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2534, where_11);  where_11 = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        mul_2559: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(full, add_4072)
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        add_4094: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2534, mul_2559);  mul_2534 = mul_2559 = None
        
         # File: <eval_with_key>.27:1463 in forward, code: linear_53 = torch._C._nn.linear(main_module_impl_impl_shared_arch_cyclegan_add, main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w, main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b);  main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w = main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b = None
        permute_123: "f16[3072, 512][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_4: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.mm.default(add_4072, permute_123);  add_4072 = permute_123 = None
        add_tensor_4: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_4, submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b);  mm_default_4 = submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_0_shards_0_b = None
        relu_3: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.relu.default(add_tensor_4);  add_tensor_4 = None
        convert_element_type_722: "f32[s0, 512][512, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu_3, torch.float32)
        eq_1279: "b8[s0, 512][512, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_722, inf);  convert_element_type_722 = None
        scalar_tensor_14: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        convert_element_type_721: "f32[s0, 512][512, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu_3, torch.float32)
        eq_1278: "b8[s0, 512][512, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_721, -inf);  convert_element_type_721 = None
        scalar_tensor_13: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(-65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        isnan_4: "b8[s0, 512][512, 1]cuda:0" = torch.ops.aten.isnan.default(relu_3)
        scalar_tensor_12: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        where_12: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.where.self(isnan_4, scalar_tensor_12, relu_3);  isnan_4 = scalar_tensor_12 = relu_3 = None
        where_13: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.where.self(eq_1278, scalar_tensor_13, where_12);  eq_1278 = scalar_tensor_13 = where_12 = None
        where_14: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.where.self(eq_1279, scalar_tensor_14, where_13);  eq_1279 = scalar_tensor_14 = where_13 = None
        
         # File: <eval_with_key>.27:1469 in forward, code: linear_54 = torch._C._nn.linear(relu_3, main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w, main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b);  relu_3 = main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w = main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b = None
        permute_124: "f16[512, 3072][1, 512]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_3: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(where_14, permute_124);  where_14 = permute_124 = None
        add_tensor_3: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_3, submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b);  mm_default_3 = submod_0_main_module_impl_impl_shared_arch_cyclegan_decoder_linear_archs_1_shards_0_b = None
        relu_4: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.relu.default(add_tensor_3);  add_tensor_3 = None
        convert_element_type_727: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu_4, torch.float32)
        eq_1286: "b8[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_727, inf);  convert_element_type_727 = None
        scalar_tensor_17: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        convert_element_type_726: "f32[s0, 3072][3072, 1]cuda:0" = torch.ops.prims.convert_element_type.default(relu_4, torch.float32)
        eq_1285: "b8[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.eq.Scalar(convert_element_type_726, -inf);  convert_element_type_726 = None
        scalar_tensor_16: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(-65504.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        isnan_5: "b8[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.isnan.default(relu_4)
        scalar_tensor_15: "f16[][]cuda:0" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float16, layout = torch.strided, device = device(type='cuda', index=0))
        where_15: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.where.self(isnan_5, scalar_tensor_15, relu_4);  isnan_5 = scalar_tensor_15 = relu_4 = None
        where_16: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.where.self(eq_1285, scalar_tensor_16, where_15);  eq_1285 = scalar_tensor_16 = where_15 = None
        where_17: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.where.self(eq_1286, scalar_tensor_17, where_16);  eq_1286 = scalar_tensor_17 = where_16 = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        mul_2570: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(where_17, full);  where_17 = full = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        add_4107: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(add_4094, mul_2570);  add_4094 = mul_2570 = None
        
         # File: <eval_with_key>.27:1476 in forward, code: linear_55 = torch._C._nn.linear(main_module_impl_impl_shared_arch_cyclegan_add_2, main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w, main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b);  main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b = None
        permute_125: "f16[3072, 3072][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_2: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mm.default(add_4107, permute_125);  permute_125 = None
        add_tensor_2: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_2, submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b);  mm_default_2 = submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_gn_arch_submodules_0_shards_0_b = None
        
         # File: <eval_with_key>.27:1477 in forward, code: sigmoid_5 = torch.sigmoid(linear_55);  linear_55 = None
        sigmoid_45: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.sigmoid.default(add_tensor_2);  add_tensor_2 = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        mul_2579: "f16[s0, 3072][3072, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_4107, sigmoid_45);  add_4107 = sigmoid_45 = None
        
         # File: <eval_with_key>.27:1481 in forward, code: linear_56 = torch._C._nn.linear(main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_mul_module, main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w, main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b);  main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_gating_archs_0_mul_module = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = None
        permute_126: "f16[3072, 512][1, 3072]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default_1: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.mm.default(mul_2579, permute_126);  mul_2579 = permute_126 = None
        add_tensor_1: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default_1, submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b);  mm_default_1 = submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_0_shards_0_b = None
        
         # File: <eval_with_key>.27:1489 in forward, code: layer_norm_119 = torch.nn.functional.layer_norm(linear_56, getitem_345, weight = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale, bias = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias, eps = 1e-05);  getitem_345 = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = None
        convert_element_type_734: "f32[s0, 512][512, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_tensor_1, torch.float32)
        var_mean_165 = torch.ops.aten.var_mean.correction(convert_element_type_734, [1], correction = 0, keepdim = True)
        getitem_520: "f32[s0, 1][1, 1]cuda:0" = var_mean_165[0]
        getitem_521: "f32[s0, 1][1, 1]cuda:0" = var_mean_165[1];  var_mean_165 = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        full_2: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.full.default([sym_size_int_9, 1], 1.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        
         # File: <eval_with_key>.27:1489 in forward, code: layer_norm_119 = torch.nn.functional.layer_norm(linear_56, getitem_345, weight = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale, bias = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias, eps = 1e-05);  getitem_345 = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = None
        sub_1353: "f32[s0, 512][512, 1]cuda:0" = torch.ops.aten.sub.Tensor(convert_element_type_734, getitem_521);  convert_element_type_734 = getitem_521 = None
        add_4123: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(getitem_520, 1e-05);  getitem_520 = None
        rsqrt_165: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.rsqrt.default(add_4123);  add_4123 = None
        mul_2584: "f32[s0, 512][512, 1]cuda:0" = torch.ops.aten.mul.Tensor(sub_1353, rsqrt_165);  sub_1353 = rsqrt_165 = None
        mul_2585: "f32[s0, 512][512, 1]cuda:0" = torch.ops.aten.mul.Tensor(mul_2584, submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale);  mul_2584 = submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_scale = None
        add_4124: "f32[s0, 512][512, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2585, submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias);  mul_2585 = submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_activations_0_norm_submodules_0_bias = None
        convert_element_type_735: "f16[s0, 512][512, 1]cuda:0" = torch.ops.prims.convert_element_type.default(add_4124, torch.float16);  add_4124 = None
        
         # File: <eval_with_key>.27:1490 in forward, code: sigmoid_6 = torch.sigmoid(layer_norm_119);  layer_norm_119 = None
        sigmoid_46: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.sigmoid.default(convert_element_type_735);  convert_element_type_735 = None
        
         # File: <eval_with_key>.27:1498 in forward, code: mul_44 = linear_56 * unsqueeze_n_times_4;  linear_56 = unsqueeze_n_times_4 = None
        mul_2592: "f16[s0, 512][512, 1]cuda:0" = torch.ops.aten.mul.Tensor(add_tensor_1, sigmoid_46);  add_tensor_1 = sigmoid_46 = None
        
         # File: <eval_with_key>.27:1501 in forward, code: linear_57 = torch._C._nn.linear(mul_44, main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w, main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b);  mul_44 = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w = main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b = None
        permute_127: "f16[512, 1][1, 512]cuda:0" = torch.ops.aten.permute.default(submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w, [1, 0]);  submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_w = None
        
        # No stacktrace found for following nodes
        mm_default: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.mm.default(mul_2592, permute_127);  mul_2592 = permute_127 = None
        add_tensor: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(mm_default, submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b);  mm_default = submod_0_main_module_impl_impl_task_archs_1_optimized_prediction_arch_dense_arch_dense_projection_arch_linear_archs_1_shards_0_b = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        add_4143: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_tensor, submod_1_main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_positive_weight_calibration_bias);  add_tensor = submod_1_main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_positive_weight_calibration_bias = None
        
         # File: <eval_with_key>.26:7 in forward, code: sigmoid_7 = torch.sigmoid(main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_add);  main_module_impl_impl_task_archs_1_optimized_prediction_arch_calibration_add = None
        sigmoid_47: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sigmoid.default(add_4143);  add_4143 = None
        
         # File: <torch_package_1>.dper3/core/low_level_module.py:197 in forward, code: return self.forward_pytorch(*args, **kwargs)
        full_1: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.full.default([sym_size_int_9, 1], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_9 = None
        
         # File: <eval_with_key>.26:24 in forward, code: gt = torch.gt(detach, unsqueeze_n_times_5);  unsqueeze_n_times_5 = None
        gt: "b8[s0, 1][1, 1]cuda:0" = torch.ops.aten.gt.Tensor(sigmoid_47, full_1);  full_1 = None
        
         # File: <eval_with_key>.26:25 in forward, code: to = gt.to(torch.float32);  gt = None
        convert_element_type_741: "f32[s0, 1][1, 1]cuda:0" = torch.ops.prims.convert_element_type.default(gt, torch.float32);  gt = None
        
         # File: <eval_with_key>.26:26 in forward, code: mul_45 = torch.mul(main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_const_fill_like_1, to);  main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_const_fill_like_1 = to = None
        mul_2605: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.mul.Tensor(full_2, convert_element_type_741);  full_2 = convert_element_type_741 = None
        
         # File: <eval_with_key>.26:28 in forward, code: sub_18 = _tensor_constant1.sub(mul_45);  _tensor_constant1 = None
        sub_1372: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.sub.Tensor(submod_1__tensor_constant1, mul_2605);  submod_1__tensor_constant1 = None
        
         # File: <eval_with_key>.26:30 in forward, code: mul_47 = torch.mul(detach, sub_18);  detach = sub_18 = None
        mul_2610: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.mul.Tensor(sigmoid_47, sub_1372);  sub_1372 = None
        
         # File: <eval_with_key>.26:9 in forward, code: logit = torch.logit(detach, 1e-06)
        convert_element_type_739: "f32[s0, 1][1, 1]cuda:0" = torch.ops.prims.convert_element_type.default(sigmoid_47, torch.float32);  sigmoid_47 = None
        clamp_min_1: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.clamp_min.default(convert_element_type_739, 1e-06);  convert_element_type_739 = None
        clamp_max_1: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.clamp_max.default(clamp_min_1, 0.999999);  clamp_min_1 = None
        sub_1363: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.sub.Tensor(1, clamp_max_1)
        div: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.div.Tensor(clamp_max_1, sub_1363);  clamp_max_1 = sub_1363 = None
        log: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.log.default(div);  div = None
        convert_element_type_740: "f16[s0, 1][1, 1]cuda:0" = torch.ops.prims.convert_element_type.default(log, torch.float16);  log = None
        
         # File: <eval_with_key>.27:268 in forward, code: sum_3 = torch.sum(getitem_51, [1], keepdim = True);  getitem_51 = None
        sum_3: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_10, [1], True);  getitem_10 = None
        
         # File: <eval_with_key>.27:270 in forward, code: sum_5 = torch.sum(getitem_49, [1], keepdim = True);  getitem_49 = None
        sum_5: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_12, [1], True);  getitem_12 = None
        
         # File: <eval_with_key>.27:354 in forward, code: add = torch.add(sum_3, sum_5);  sum_3 = sum_5 = None
        add_631: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(sum_3, sum_5);  sum_3 = sum_5 = None
        
         # File: <eval_with_key>.27:275 in forward, code: sum_10 = torch.sum(getitem_44, [1], keepdim = True);  getitem_44 = None
        sum_10: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_17, [1], True);  getitem_17 = None
        
         # File: <eval_with_key>.27:452 in forward, code: add_1 = torch.add(add, sum_10);  add = sum_10 = None
        add_990: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_631, sum_10);  add_631 = sum_10 = None
        
         # File: <eval_with_key>.27:276 in forward, code: sum_11 = torch.sum(getitem_43, [1], keepdim = True);  getitem_43 = None
        sum_11: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_18, [1], True);  getitem_18 = None
        
         # File: <eval_with_key>.27:458 in forward, code: add_2 = torch.add(add_1, sum_11);  add_1 = sum_11 = None
        add_994: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_990, sum_11);  add_990 = sum_11 = None
        
         # File: <eval_with_key>.27:274 in forward, code: sum_9 = torch.sum(getitem_45, [1], keepdim = True);  getitem_45 = None
        sum_9: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_16, [1], True);  getitem_16 = None
        
         # File: <eval_with_key>.27:463 in forward, code: add_3 = torch.add(add_2, sum_9);  add_2 = sum_9 = None
        add_1012: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_994, sum_9);  add_994 = sum_9 = None
        
         # File: <eval_with_key>.27:272 in forward, code: sum_7 = torch.sum(getitem_47, [1], keepdim = True);  getitem_47 = None
        sum_7: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_14, [1], True);  getitem_14 = None
        
         # File: <eval_with_key>.27:471 in forward, code: add_4 = torch.add(add_3, sum_7);  add_3 = sum_7 = None
        add_1040: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1012, sum_7);  add_1012 = sum_7 = None
        
         # File: <eval_with_key>.27:271 in forward, code: sum_6 = torch.sum(getitem_48, [1], keepdim = True);  getitem_48 = None
        sum_6: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_13, [1], True);  getitem_13 = None
        
         # File: <eval_with_key>.27:473 in forward, code: add_5 = torch.add(add_4, sum_6);  add_4 = sum_6 = None
        add_1050: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1040, sum_6);  add_1040 = sum_6 = None
        
         # File: <eval_with_key>.27:269 in forward, code: sum_4 = torch.sum(getitem_50, [1], keepdim = True);  getitem_50 = None
        sum_4: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_11, [1], True);  getitem_11 = None
        
         # File: <eval_with_key>.27:488 in forward, code: add_6 = torch.add(add_5, sum_4);  add_5 = sum_4 = None
        add_1057: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1050, sum_4);  add_1050 = sum_4 = None
        
         # File: <eval_with_key>.27:273 in forward, code: sum_8 = torch.sum(getitem_46, [1], keepdim = True);  getitem_46 = None
        sum_8: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_15, [1], True);  getitem_15 = None
        
         # File: <eval_with_key>.27:497 in forward, code: add_7 = torch.add(add_6, sum_8);  add_6 = sum_8 = None
        add_1078: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1057, sum_8);  add_1057 = sum_8 = None
        
         # File: <eval_with_key>.27:355 in forward, code: sum_12 = torch.sum(getitem_96, [1], keepdim = True);  getitem_96 = None
        sum_12: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_60, [1], True);  getitem_60 = None
        
         # File: <eval_with_key>.27:502 in forward, code: add_8 = torch.add(add_7, sum_12);  add_7 = sum_12 = None
        add_1088: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1078, sum_12);  add_1078 = sum_12 = None
        
         # File: <eval_with_key>.27:267 in forward, code: sum_2 = torch.sum(getitem_52, [1], keepdim = True);  getitem_52 = None
        sum_2: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_9, [1], True);  getitem_9 = None
        
         # File: <eval_with_key>.27:508 in forward, code: add_11 = torch.add(add_8, sum_2);  add_8 = sum_2 = None
        add_1105: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1088, sum_2);  add_1088 = sum_2 = None
        
         # File: <eval_with_key>.27:266 in forward, code: sum_1 = torch.sum(getitem_53, [1], keepdim = True);  getitem_53 = None
        sum_1: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sum.dim_IntList(getitem_8, [1], True);  getitem_8 = None
        
         # File: <eval_with_key>.27:518 in forward, code: add_12 = torch.add(add_11, sum_1);  add_11 = sum_1 = None
        add_1140: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1105, sum_1);  add_1105 = sum_1 = None
        
         # File: <eval_with_key>.27:520 in forward, code: add_13 = add_12 + main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias;  add_12 = main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias = None
        add_1144: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(add_1140, submod_0_main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias);  add_1140 = submod_0_main_module_impl_impl_dependent_tasks_1_salr_standalone_aggregator_module_task_arch_sparse_aggregates_logistic_regression_global_bias = None
        
         # File: <eval_with_key>.26:10 in forward, code: add_41 = logit + add_13;  logit = add_13 = None
        add_4156: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(convert_element_type_740, add_1144);  convert_element_type_740 = add_1144 = None
        
         # File: <eval_with_key>.26:13 in forward, code: sigmoid_8 = torch.sigmoid(add_41);  add_41 = None
        sigmoid_48: "f16[s0, 1][1, 1]cuda:0" = torch.ops.aten.sigmoid.default(add_4156);  add_4156 = None
        
         # File: <eval_with_key>.26:29 in forward, code: mul_46 = torch.mul(sigmoid_8, mul_45);  sigmoid_8 = mul_45 = None
        mul_2608: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.mul.Tensor(sigmoid_48, mul_2605);  sigmoid_48 = mul_2605 = None
        
         # File: <eval_with_key>.26:31 in forward, code: add_42 = mul_47 + mul_46;  mul_47 = mul_46 = None
        add_4187: "f32[s0, 1][1, 1]cuda:0" = torch.ops.aten.add.Tensor(mul_2610, mul_2608);  mul_2610 = mul_2608 = None
        return (add_4187, _tensor_constant2)
        # {"cat": [{"name": "cat_default_12", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "permute_pooled_embs_auto_grad": [{"name": "permute_pooled_embs_auto_grad", "target": "fbgemm.permute_pooled_embs_auto_grad.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "split_with_sizes": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_1": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_2": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_3": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_4": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_5": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_6": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_7": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_8": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_9": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_10": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_11": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_12": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_13": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_14": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_15": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_16": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_17": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_18": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_19": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_20": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_21": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_22": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_23": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_24": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_25": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_26": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_27": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_28": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_29": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_30": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_31": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_32": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_33": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_34": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_35": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_36": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_37": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_38": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_39": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_40": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_41": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_42": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_43": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_44": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_45": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_46": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_47": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_48": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_49": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_50": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_51": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_52": [{"name": "split_with_sizes_default_9", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "permute_pooled_embs_auto_grad_1": [{"name": "permute_pooled_embs_auto_grad_1", "target": "fbgemm.permute_pooled_embs_auto_grad.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "split_with_sizes_1": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_53": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_54": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_55": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_56": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_57": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_58": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_59": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_60": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_61": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_62": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_63": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_64": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_65": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_66": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_67": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_68": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_69": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_70": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_71": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_72": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_73": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_74": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_75": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_76": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_77": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_78": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_79": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_80": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_81": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_82": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_83": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_84": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_85": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_86": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_87": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_88": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_89": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_90": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_91": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_92": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_93": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_94": [{"name": "split_with_sizes_default_8", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "split_with_sizes_2": [{"name": "split_with_sizes_default_7", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_96": [{"name": "split_with_sizes_default_7", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_97": [{"name": "split_with_sizes_default_7", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_98": [{"name": "split_with_sizes_default_7", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_99": [{"name": "split_with_sizes_default_7", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_100": [{"name": "split_with_sizes_default_7", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "split_with_sizes_3": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_101": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_102": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_103": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_104": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_105": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_106": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_107": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_108": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_109": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_110": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_111": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_112": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_113": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_114": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_115": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_116": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_117": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_118": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_119": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_120": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_121": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_122": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_123": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_124": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_125": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_126": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_127": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_128": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_129": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_130": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_131": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_132": [{"name": "split_with_sizes_default_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_3", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "permute": [{"name": "linear", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_101": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247154720, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_101": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247154720, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_120": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_133": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_134": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_1": [{"name": "linear_1", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_100": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247110512, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_1", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_1", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_100": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247110512, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_1", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_1", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_1", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_1", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_1", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_1", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_122": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_1": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_135": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_136": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_2": [{"name": "linear_2", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_99": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225139145024, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_2", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_2", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_99": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225139145024, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_2", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_2", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_2", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_2", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_2", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_2", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_124": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_2": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_137": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_138": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_3": [{"name": "linear_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_98": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225138551120, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_3", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_98": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225138551120, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_3", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_3", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_3", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_126": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_3": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_139": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_140": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_4": [{"name": "linear_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_97": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225138950688, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_4", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_97": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225138950688, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_4", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_4", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_4", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_128": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_4": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_141": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_142": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_5": [{"name": "linear_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_96": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224555768496, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_5", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_96": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224555768496, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_5", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_5", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_5", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_130": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_5": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_143": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_144": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_6": [{"name": "linear_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_95": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224555537344, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_6", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_95": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224555537344, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_6", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_6", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_6", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_132": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_6": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_145": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_146": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_7": [{"name": "linear_7", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_94": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225138582928, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_7", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_7", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_94": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225138582928, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_7", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_7", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_7", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_7", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_7", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_7", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_134": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_7": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_147": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_148": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_8": [{"name": "linear_8", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_93": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225139135472, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_8", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_8", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_93": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225139135472, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_8", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_8", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_8", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_8", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_8", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_8", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_136": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_8": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_149": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_150": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_9": [{"name": "linear_9", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_92": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225138587344, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_9", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_9", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_92": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225138587344, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_9", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_9", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_9", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_9", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_9", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_9", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_138": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_9": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_151": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_152": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_10": [{"name": "linear_10", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_91": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140226673585952, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_10", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_10", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_91": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140226673585952, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_10", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_10", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_10", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_10", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_10", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_10", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_140": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_10": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_153": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_154": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_11": [{"name": "linear_11", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_90": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224556300944, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_11", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_11", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_90": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224556300944, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_11", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_11", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_11", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_11", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_11", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_11", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_142": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_11": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_155": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_156": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_12": [{"name": "linear_12", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_89": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140226674209168, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_12", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_12", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_89": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140226674209168, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_12", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_12", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_12", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_12", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_12", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_12", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_144": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_12": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_157": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_158": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_13": [{"name": "linear_13", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_88": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225138573616, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_13", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_13", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_88": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225138573616, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_13", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_13", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_13", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_13", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_13", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_13", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_146": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_13": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_159": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_160": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_14": [{"name": "linear_14", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_87": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140226674207920, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_14", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_14", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_87": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140226674207920, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_14", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_14", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_14", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_14", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_14", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_14", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_148": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_14": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_161": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_162": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_15": [{"name": "linear_15", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_86": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140226673579088, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_15", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_15", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_86": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140226673579088, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_15", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_15", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_15", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_15", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_15", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_15", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_150": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_15": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_163": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_164": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_16": [{"name": "linear_16", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_85": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526941488, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_16", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_16", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_85": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526941488, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_16", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_16", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_16", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_16", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_16", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_16", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_152": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_16": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_165": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_166": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_17": [{"name": "linear_17", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_84": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140226674362544, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_17", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_17", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_84": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140226674362544, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_17", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_17", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_17", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_17", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_17", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_17", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_154": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_17": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_167": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_168": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_18": [{"name": "linear_18", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_83": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140226674370992, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_18", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_18", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_83": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140226674370992, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_18", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_18", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_18", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_18", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_18", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_18", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_156": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_18": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_169": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_170": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_19": [{"name": "linear_19", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_82": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140226673586480, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_19", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_19", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_82": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140226673586480, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_19", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_19", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_19", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_19", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_19", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_19", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_158": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_19": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_171": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_172": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_20": [{"name": "linear_20", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_81": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224555544304, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_20", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_20", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_81": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224555544304, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_20", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_20", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_20", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_20", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_20", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_20", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_160": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_20": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_173": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_174": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_21": [{"name": "linear_21", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_80": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526120944, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_21", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_21", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_80": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526120944, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_21", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_21", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_21", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_21", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_21", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_21", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_162": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_21": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_175": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_176": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_22": [{"name": "linear_22", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_79": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247106048, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_22", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_22", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_79": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247106048, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_22", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_22", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_22", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_22", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_22", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_22", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_164": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_22": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_177": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_178": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_23": [{"name": "linear_23", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_78": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247114208, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_23", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_23", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_78": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247114208, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_23", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_23", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_23", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_23", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_23", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_23", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_166": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_23": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_179": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_180": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_24": [{"name": "linear_24", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_77": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224555762208, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_24", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_24", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_77": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224555762208, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_24", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_24", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_24", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_24", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_24", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_24", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_168": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_24": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_181": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_182": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_25": [{"name": "linear_25", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_76": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526700592, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_25", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_25", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_76": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526700592, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_25", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_25", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_25", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_25", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_25", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_25", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_170": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_25": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_183": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_184": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_26": [{"name": "linear_26", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_75": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247163888, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_26", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_26", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_75": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247163888, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_26", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_26", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_26", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_26", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_26", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_26", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_172": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_26": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_185": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_186": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_27": [{"name": "linear_27", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_74": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247104224, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_27", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_27", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_74": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247104224, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_27", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_27", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_27", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_27", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_27", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_27", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_174": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_27": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_187": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_188": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_28": [{"name": "linear_28", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_73": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247161296, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_28", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_28", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_73": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247161296, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_28", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_28", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_28", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_28", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_28", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_28", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_176": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_28": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_189": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_190": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_29": [{"name": "linear_29", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_72": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247310432, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_29", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_29", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_72": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247310432, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_29", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_29", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_29", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_29", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_29", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_29", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_178": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_29": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_191": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_192": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_30": [{"name": "linear_30", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_71": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036374064, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_30", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_30", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_71": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036374064, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_30", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_30", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_30", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_30", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_30", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_30", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_180": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_30": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_193": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_194": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_31": [{"name": "linear_31", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_70": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224248087408, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_31", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_31", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_70": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224248087408, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_31", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_31", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_31", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_31", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_31", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_31", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_182": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_31": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_195": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_196": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_32": [{"name": "linear_32", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_69": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247892576, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_32", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_32", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_69": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247892576, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_32", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_32", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_32", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_32", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_32", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_32", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_184": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_32": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_197": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_198": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_33": [{"name": "linear_33", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_68": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224248094176, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_33", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_33", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_68": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224248094176, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_33", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_33", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_33", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_33", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_33", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_33", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_186": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_33": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_199": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_200": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_34": [{"name": "linear_34", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_67": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306349776, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_34", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_34", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_67": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306349776, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_34", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_34", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_34", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_34", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_34", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_34", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_188": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_34": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_201": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_202": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_35": [{"name": "linear_35", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_66": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526700448, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_35", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_35", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_66": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526700448, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_35", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_35", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_35", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_35", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_35", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_35", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_190": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_35": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_203": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_204": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_3": [{"name": "cat_default_14", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "pow_1": [{"name": "pow_1", "target": "aten.pow.Tensor_Scalar", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_1": [{"name": "cat_default_11", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_1", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_1", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "cat_2": [{"name": "cat_default_13", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "permute_36": [{"name": "linear_default", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_default_10", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": [{"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}]}], "mm_default_65": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224556301568, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_36", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_default_10", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": [{"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}]}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_65": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224556301568, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_36", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_default_10", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": [{"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}]}]}]}, {"name": "addmm_36", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_default", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_default_10", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": [{"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}]}]}, {"name": "addmm_36", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_default", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_default_10", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": [{"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}]}]}], "convert_element_type_192": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_36": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_205": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_206": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_6": [{"name": "cat_default_16", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "cat_4": [{"name": "cat_default_9", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_3", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_3", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "cat_5": [{"name": "cat_default_15", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "permute_37": [{"name": "linear_default_1", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "addmm_37": [{"name": "linear_default_1", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_3", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_271", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}], "slice_2": [{"name": "getitem_270", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone": [{"name": "contiguous_2", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_38", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_202": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_37": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_207": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_208": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1095": [{"name": "add_779", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_210": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_38": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_209": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_210": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1100": [{"name": "add_784", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_212": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_39": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_211": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_212": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sym_size_int": [{"name": "_to_copy", "target": "aten._to_copy.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "repeat": [{"name": "repeat", "target": "aten.repeat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_224": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_40": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_213": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_214": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "repeat_1": [{"name": "repeat_1", "target": "aten.repeat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_226": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_41": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_215": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_216": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_343": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_998": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_36": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_599": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_600": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_999": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_193": [{"name": "layer_norm_36", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid": [{"name": "sigmoid", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_635": [{"name": "mul_477", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_40": [{"name": "linear_42", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_64": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224247309808, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_40", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_42", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_64": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224247309808, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_40", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_42", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_40", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_42", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_40", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_42", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "sigmoid_2": [{"name": "sigmoid_2", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_659": [{"name": "mul_497", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_41": [{"name": "linear_43", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "addmm_41": [{"name": "linear_43", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_7": [{"name": "cat_default_8", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_4", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_4", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_234": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_42": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_217": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_218": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_364": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1064": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_37": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_638": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_639": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1065": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_203": [{"name": "layer_norm_37", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_1": [{"name": "sigmoid_1", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_682": [{"name": "mul_508", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_44": [{"name": "linear_46", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_63": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644119136, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_42", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_46", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_63": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644119136, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_42", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_46", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_42", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_46", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_42", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_46", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_236": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_43": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_219": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_220": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_400": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1188": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_40": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_725": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_726": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1189": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_225": [{"name": "layer_norm_40", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sym_size_int_13": [{"name": "repeat", "target": "aten.repeat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_744": [{"name": "linear_47", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_4": [{"name": "linear_47", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_45": [{"name": "linear_47", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "addmm_43": [{"name": "linear_47", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_5": [{"name": "linear_47", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_10": [{"name": "view_2", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_49": [{"name": "permute_2", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_378": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1112": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_38": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_662": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_663": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1113": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_211": [{"name": "layer_norm_38", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sym_size_int_7": [{"name": "_to_copy_7", "target": "aten._to_copy.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_687": [{"name": "linear_44", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view": [{"name": "linear_44", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_42": [{"name": "linear_44", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm": [{"name": "linear_44", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_1": [{"name": "linear_44", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_8": [{"name": "view", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_47": [{"name": "permute", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_9": [{"name": "view_1", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_48": [{"name": "permute_1", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "_scaled_dot_product_flash_attention": [{"name": "scaled_dot_product_attention", "target": "aten.scaled_dot_product_attention.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_221": [{"name": "scaled_dot_product_attention", "target": "aten.scaled_dot_product_attention.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_404": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1202": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_41": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_733": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_734": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1203": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_227": [{"name": "layer_norm_41", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sym_size_int_14": [{"name": "repeat_1", "target": "aten.repeat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_754": [{"name": "linear_48", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_6": [{"name": "linear_48", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_46": [{"name": "linear_48", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "addmm_44": [{"name": "linear_48", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_7": [{"name": "linear_48", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_13": [{"name": "view_5", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_52": [{"name": "permute_5", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_382": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1126": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_39": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_670": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_671": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1127": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_213": [{"name": "layer_norm_39", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sym_size_int_8": [{"name": "_to_copy_8", "target": "aten._to_copy.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_703": [{"name": "linear_45", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_2": [{"name": "linear_45", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_43": [{"name": "linear_45", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_1": [{"name": "linear_45", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_3": [{"name": "linear_45", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_11": [{"name": "view_3", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_50": [{"name": "permute_3", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_12": [{"name": "view_4", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_51": [{"name": "permute_4", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "_scaled_dot_product_flash_attention_1": [{"name": "scaled_dot_product_attention_1", "target": "aten.scaled_dot_product_attention.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_230": [{"name": "scaled_dot_product_attention_1", "target": "aten.scaled_dot_product_attention.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_53": [{"name": "permute_6", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_14": [{"name": "view_6", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1419": [{"name": "add_976", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_241": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_44": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_239": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_240": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_54": [{"name": "permute_7", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_15": [{"name": "view_7", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1428": [{"name": "add_985", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_243": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_45": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_241": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_242": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_471": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1447": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_45": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_879": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_880": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1448": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_244": [{"name": "layer_norm_45", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_900": [{"name": "linear_56", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_18": [{"name": "linear_56", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_57": [{"name": "linear_56", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_62": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526707168, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_47", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_56", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_62": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526707168, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_47", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_56", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_47", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_56", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_47", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_56", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "view_19": [{"name": "linear_56", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_253": [{"name": "gelu_1", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_912": [{"name": "gelu_1", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_913": [{"name": "gelu_1", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "erf_1": [{"name": "gelu_1", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1486": [{"name": "gelu_1", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_914": [{"name": "gelu_1", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_254": [{"name": "gelu_1", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_932": [{"name": "linear_58", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_22": [{"name": "linear_58", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_59": [{"name": "linear_58", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_61": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644333824, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_49", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_58", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_61": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644333824, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_49", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_58", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_49", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_58", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_49", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_58", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "view_23": [{"name": "linear_58", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1516": [{"name": "add_1027", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "split_with_sizes_4": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_243": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_244": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_245": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_246": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_247": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_248": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_249": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_250": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_251": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_252": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_253": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_254": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_255": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_256": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_257": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_258": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_259": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_260": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_261": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_262": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_263": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_264": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_265": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_266": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_267": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_268": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_269": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_270": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_271": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_272": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_273": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_274": [{"name": "split_with_sizes_default_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_1", "target": "aten.split.Tensor", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "sym_size_int_2": [{"name": "_to_copy_2", "target": "aten._to_copy.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "expand": [{"name": "matmul", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_58": [{"name": "matmul", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_9": [{"name": "cat_default_18", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "sub_414": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1236": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_42": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_761": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_762": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1237": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_235": [{"name": "layer_norm_42", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_3": [{"name": "sigmoid_3", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_809": [{"name": "mul_567", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_8": [{"name": "cat_default_17", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "permute_55": [{"name": "linear_default_2", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "addmm_45": [{"name": "linear_default_2", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_15", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_277", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}], "slice_6": [{"name": "getitem_272", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_2": [{"name": "contiguous_4", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_49", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "slice_8": [{"name": "getitem_273", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_3": [{"name": "contiguous_5", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_50", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "slice_10": [{"name": "getitem_274", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_4": [{"name": "contiguous_6", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_51", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "slice_12": [{"name": "getitem_275", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_5": [{"name": "contiguous_7", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_52", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "slice_14": [{"name": "getitem_276", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_6": [{"name": "contiguous_8", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_53", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "slice_16": [{"name": "getitem_277", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_7": [{"name": "contiguous_9", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_54", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "slice_4": [{"name": "getitem_271", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_1": [{"name": "contiguous_3", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_39", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "relu": [{"name": "relu_default", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "create", "from_node": []}]}], "convert_element_type_198": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_327": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_2": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_197": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_326": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_1": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "isnan": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_1": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_2": [{"name": "nan_to_num_default", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "permute_38": [{"name": "linear_40", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "addmm_38": [{"name": "linear_40", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_39": [{"name": "linear_41", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "addmm_39": [{"name": "linear_41", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_213": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_638": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_4": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_405": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_406": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_639": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_129": [{"name": "layer_norm_4", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_217": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_649": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_5": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_411": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_412": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_650": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_131": [{"name": "layer_norm_5", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_195": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_587": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_379": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_380": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_588": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_121": [{"name": "layer_norm", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_221": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_660": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_6": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_417": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_418": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_661": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_133": [{"name": "layer_norm_6", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_225": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_671": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_7": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_423": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_424": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_672": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_135": [{"name": "layer_norm_7", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_229": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_682": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_8": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_429": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_430": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_683": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_137": [{"name": "layer_norm_8", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_199": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_598": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_1": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_385": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_386": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_599": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_123": [{"name": "layer_norm_1", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_233": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_693": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_9": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_435": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_436": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_694": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_139": [{"name": "layer_norm_9", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_237": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_704": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_10": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_441": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_442": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_705": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_141": [{"name": "layer_norm_10", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_241": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_715": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_11": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_447": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_448": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_716": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_143": [{"name": "layer_norm_11", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_203": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_609": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_2": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_391": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_392": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_610": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_125": [{"name": "layer_norm_2", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_207": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_620": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_3": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_397": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_398": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_621": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_127": [{"name": "layer_norm_3", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_245": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_726": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_12": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_453": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_454": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_727": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_145": [{"name": "layer_norm_12", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_249": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_737": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_13": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_459": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_460": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_738": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_147": [{"name": "layer_norm_13", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_253": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_748": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_14": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_465": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_466": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_749": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_149": [{"name": "layer_norm_14", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_257": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_759": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_15": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_471": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_472": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_760": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_151": [{"name": "layer_norm_15", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_261": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_770": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_16": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_477": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_478": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_771": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_153": [{"name": "layer_norm_16", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_265": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_781": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_17": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_483": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_484": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_782": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_155": [{"name": "layer_norm_17", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_269": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_792": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_18": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_489": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_490": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_793": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_157": [{"name": "layer_norm_18", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_273": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_803": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_19": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_495": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_496": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_804": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_159": [{"name": "layer_norm_19", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_277": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_814": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_20": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_501": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_502": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_815": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_161": [{"name": "layer_norm_20", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_281": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_825": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_21": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_507": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_508": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_826": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_163": [{"name": "layer_norm_21", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_285": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_836": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_22": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_513": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_514": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_837": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_165": [{"name": "layer_norm_22", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_289": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_847": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_23": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_519": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_520": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_848": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_167": [{"name": "layer_norm_23", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_293": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_858": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_24": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_525": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_526": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_859": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_169": [{"name": "layer_norm_24", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_297": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_869": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_25": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_531": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_532": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_870": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_171": [{"name": "layer_norm_25", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_301": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_880": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_26": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_537": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_538": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_881": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_173": [{"name": "layer_norm_26", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_305": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_891": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_27": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_543": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_544": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_892": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_175": [{"name": "layer_norm_27", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_309": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_902": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_28": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_549": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_550": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_903": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_177": [{"name": "layer_norm_28", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_313": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_913": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_29": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_555": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_556": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_914": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_179": [{"name": "layer_norm_29", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_317": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_924": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_30": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_561": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_562": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_925": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_181": [{"name": "layer_norm_30", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_321": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_935": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_31": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_567": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_568": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_936": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_183": [{"name": "layer_norm_31", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_325": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_946": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_32": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_573": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_574": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_947": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_185": [{"name": "layer_norm_32", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_329": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_957": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_33": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_579": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_580": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_958": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_187": [{"name": "layer_norm_33", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_333": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_968": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_34": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_585": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_586": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_969": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_189": [{"name": "layer_norm_34", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_337": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_979": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_35": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_591": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_592": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_980": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_191": [{"name": "layer_norm_35", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_24": [{"name": "view_40", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze": [{"name": "unsqueeze_default", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_25": [{"name": "view_41", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_1": [{"name": "unsqueeze_default_1", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_26": [{"name": "view_42", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_2": [{"name": "unsqueeze_default_2", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_27": [{"name": "view_43", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_3": [{"name": "unsqueeze_default_3", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_28": [{"name": "view_44", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_4": [{"name": "unsqueeze_default_4", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_29": [{"name": "view_45", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_5": [{"name": "unsqueeze_default_5", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_30": [{"name": "view_46", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_6": [{"name": "unsqueeze_default_6", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_31": [{"name": "view_47", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_7": [{"name": "unsqueeze_default_7", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_32": [{"name": "view_48", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_8": [{"name": "unsqueeze_default_8", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_33": [{"name": "view_49", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_9": [{"name": "unsqueeze_default_9", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_34": [{"name": "view_50", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_10": [{"name": "unsqueeze_default_10", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_35": [{"name": "view_51", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_11": [{"name": "unsqueeze_default_11", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_36": [{"name": "view_52", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_12": [{"name": "unsqueeze_default_12", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_37": [{"name": "view_53", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_13": [{"name": "unsqueeze_default_13", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_38": [{"name": "view_54", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_14": [{"name": "unsqueeze_default_14", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_39": [{"name": "view_55", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_15": [{"name": "unsqueeze_default_15", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_40": [{"name": "view_56", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_16": [{"name": "unsqueeze_default_16", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_41": [{"name": "view_57", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_17": [{"name": "unsqueeze_default_17", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_42": [{"name": "view_58", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_18": [{"name": "unsqueeze_default_18", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_43": [{"name": "view_59", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_19": [{"name": "unsqueeze_default_19", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_44": [{"name": "view_60", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_20": [{"name": "unsqueeze_default_20", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_45": [{"name": "view_61", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_21": [{"name": "unsqueeze_default_21", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_46": [{"name": "view_62", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_22": [{"name": "unsqueeze_default_22", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_47": [{"name": "view_63", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_23": [{"name": "unsqueeze_default_23", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_48": [{"name": "view_64", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_24": [{"name": "unsqueeze_default_24", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_49": [{"name": "view_65", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_25": [{"name": "unsqueeze_default_25", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_50": [{"name": "view_66", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_26": [{"name": "unsqueeze_default_26", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_51": [{"name": "view_67", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_27": [{"name": "unsqueeze_default_27", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_52": [{"name": "view_68", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_28": [{"name": "unsqueeze_default_28", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_53": [{"name": "view_69", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_29": [{"name": "unsqueeze_default_29", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_54": [{"name": "view_70", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_30": [{"name": "unsqueeze_default_30", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "view_55": [{"name": "view_71", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "unsqueeze_31": [{"name": "unsqueeze_default_31", "target": "aten.unsqueeze.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply stack_to_unsqueeze_pass", "action": "create", "from_node": []}]}], "sub_467": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1433": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_44": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_871": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_872": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1434": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_242": [{"name": "layer_norm_44", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_890": [{"name": "linear_55", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_16": [{"name": "linear_55", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_56": [{"name": "linear_55", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_60": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224555767872, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_46", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_55", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_60": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224555767872, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_46", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_55", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_46", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_55", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_46", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_55", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "view_17": [{"name": "linear_55", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_251": [{"name": "gelu", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_907": [{"name": "gelu", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_908": [{"name": "gelu", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "erf": [{"name": "gelu", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1481": [{"name": "gelu", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_909": [{"name": "gelu", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_252": [{"name": "gelu", "target": "aten.gelu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_920": [{"name": "linear_57", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_20": [{"name": "linear_57", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_58": [{"name": "linear_57", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_59": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224556407760, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_48", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_57", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_59": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224556407760, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_48", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_57", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_48", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_57", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_48", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_57", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "view_21": [{"name": "linear_57", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1501": [{"name": "add_1018", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_60": [{"name": "permute_default_1", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_chunk_reshape_unsqueeze_concat_pass", "action": "create", "from_node": []}]}], "cat_10": [{"name": "stack_default", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "stack", "target": "aten.stack.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "stack", "target": "aten.stack.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_262": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "eq_584": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "scalar_tensor_5": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_261": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "eq_583": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "scalar_tensor_4": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "isnan_1": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "scalar_tensor_3": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "where_3": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "where_4": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "where_5": [{"name": "nan_to_num", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_263": [{"name": "clamp", "target": "aten.clamp.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "clamp_min": [{"name": "clamp", "target": "aten.clamp.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "clamp_max": [{"name": "clamp", "target": "aten.clamp.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_264": [{"name": "clamp", "target": "aten.clamp.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "baddbmm": [{"name": "baddbmm", "target": "aten.baddbmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_61": [{"name": "permute_default", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_chunk_reshape_concat_pass", "action": "create", "from_node": []}]}], "clone_8": [{"name": "reshape_default", "target": "aten.reshape.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_chunk_reshape_concat_pass", "action": "create", "from_node": []}]}], "mul_1182": [{"name": "reshape_default", "target": "aten.reshape.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_chunk_reshape_concat_pass", "action": "create", "from_node": []}]}], "mul_1183": [{"name": "reshape_default", "target": "aten.reshape.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_chunk_reshape_concat_pass", "action": "create", "from_node": []}]}], "floordiv": [{"name": "reshape_default", "target": "aten.reshape.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_chunk_reshape_concat_pass", "action": "create", "from_node": []}]}], "view_56": [{"name": "reshape_default", "target": "aten.reshape.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_chunk_reshape_concat_pass", "action": "create", "from_node": []}]}], "cat_11": [{"name": "cat_default_7", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_5", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_5", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "view_57": [{"name": "view_136", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "expand_1": [{"name": "matmul", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_59": [{"name": "matmul", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm": [{"name": "matmul", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_60": [{"name": "matmul", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1894": [{"name": "add_1891", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_267": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_46": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_275": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_276": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_605": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1903": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_46": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1224": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1225": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1904": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_268": [{"name": "layer_norm_46", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "split_with_sizes_5": [{"name": "split_with_sizes_default_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_277": [{"name": "split_with_sizes_default_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_278": [{"name": "split_with_sizes_default_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_279": [{"name": "split_with_sizes_default_2", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_4", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "cat_13": [{"name": "cat_default_20", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "view_62": [{"name": "view_138", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_12": [{"name": "cat_default_19", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "permute_63": [{"name": "linear_default_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "mm_default_58": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036194704, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_50", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_19", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_279", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_58": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036194704, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_50", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_19", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_279", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}]}, {"name": "addmm_50", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_default_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_19", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_279", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}, {"name": "addmm_50", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_default_3", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_19", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_279", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}], "slice_18": [{"name": "getitem_278", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_9": [{"name": "contiguous_10", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_59", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_272": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_47": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_280": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_281": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "slice_20": [{"name": "getitem_279", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_10": [{"name": "contiguous_11", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_60", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_274": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_48": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_282": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_283": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_621": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1956": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_47": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1258": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1259": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1957": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_273": [{"name": "layer_norm_47", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_5": [{"name": "sigmoid_5", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1272": [{"name": "mul_1509", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_276": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_49": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_284": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_285": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_625": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1967": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_48": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1264": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1265": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1968": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_275": [{"name": "layer_norm_48", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_6": [{"name": "sigmoid_6", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1277": [{"name": "mul_1514", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_278": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_50": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_286": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_287": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_633": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1990": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_49": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1280": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1281": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1991": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_277": [{"name": "layer_norm_49", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_64": [{"name": "linear_61", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_57": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036384960, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_51", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_61", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_57": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036384960, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_51", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_61", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_51", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_61", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_51", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_61", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_286": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_51": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_288": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_289": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_637": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2001": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_50": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1286": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1287": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2002": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_279": [{"name": "layer_norm_50", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_65": [{"name": "linear_62", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_56": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526706448, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_52", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_62", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_56": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526706448, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_52", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_62", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_52", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_62", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_52", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_62", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_288": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_52": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_290": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_291": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_643": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2018": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_51": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1296": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1297": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2019": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_287": [{"name": "layer_norm_51", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_7": [{"name": "sigmoid_7", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1310": [{"name": "mul_1531", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_290": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_53": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_292": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_293": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_647": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2029": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_52": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1302": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1303": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2030": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_289": [{"name": "layer_norm_52", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_8": [{"name": "sigmoid_8", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1315": [{"name": "mul_1536", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_292": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_54": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_294": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_295": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_655": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2052": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_53": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1318": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1319": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2053": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_291": [{"name": "layer_norm_53", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_66": [{"name": "linear_63", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_55": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224585467744, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_53", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_63", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_55": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224585467744, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_53", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_63", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_53", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_63", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_53", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_63", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_300": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_55": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_296": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_297": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_659": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2063": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_54": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1324": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1325": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2064": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_293": [{"name": "layer_norm_54", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_67": [{"name": "linear_64", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_54": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224555536912, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_54", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_64", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_54": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224555536912, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_54", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_64", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_54", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_64", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_54", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_64", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_302": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_56": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_298": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_299": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_669": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2091": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_56": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1340": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1341": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2092": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_303": [{"name": "layer_norm_56", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_64": [{"name": "view_140", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_62": [{"name": "permute_8", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_665": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2080": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_55": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1334": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1335": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2081": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_301": [{"name": "layer_norm_55", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_63": [{"name": "view_139", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_1": [{"name": "bmm", "target": "aten.bmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2114": [{"name": "add_2006", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_306": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_57": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_300": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_301": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_677": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2119": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_57": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1354": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1355": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2120": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_307": [{"name": "layer_norm_57", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_2": [{"name": "bmm_1", "target": "aten.bmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_65": [{"name": "view_141", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_310": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_58": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_302": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_303": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_683": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2140": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_58": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1366": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1367": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2141": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_311": [{"name": "layer_norm_58", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_68": [{"name": "linear_65", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_53": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306650016, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_55", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_65", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_53": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306650016, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_55", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_65", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_55", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_65", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_55", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_65", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_315": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_59": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_304": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_305": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_688": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2154": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_59": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1374": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1375": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2155": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_316": [{"name": "layer_norm_59", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_9": [{"name": "sigmoid_9", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1382": [{"name": "mul_1580", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_317": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_60": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_306": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_307": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_418": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1247": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_43": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_767": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_768": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1248": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_237": [{"name": "layer_norm_43", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_4": [{"name": "sigmoid_4", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_812": [{"name": "mul_570", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_694": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2171": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_60": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1385": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1386": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2172": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_318": [{"name": "layer_norm_60", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_14": [{"name": "cat_default_6", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_6", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_6", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_319": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_61": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_308": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_309": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_699": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2185": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_61": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1393": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1394": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2186": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_320": [{"name": "layer_norm_61", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_69": [{"name": "linear_66", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_52": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306352224, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_56", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_66", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_52": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306352224, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_56", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_66", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_56", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_66", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_56", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_66", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_324": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_62": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_310": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_311": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_704": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2199": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_62": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1401": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1402": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2200": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_325": [{"name": "layer_norm_62", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_70": [{"name": "linear_67", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_51": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036380592, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_57", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_67", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_51": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036380592, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_57", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_67", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_57", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_67", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_57", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_67", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_329": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_63": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_312": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_313": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_331": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_332": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1415": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_709": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2213": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_63": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1409": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1410": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2214": [{"name": "layer_norm_63", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default_7", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_333", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "convert_element_type_333", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_333", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}]}], "mul_1416": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2224": [{"name": "addcmul", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default_6", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_335", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "convert_element_type_335", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_335", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}]}], "var_mean_64": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_314": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_315": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_714": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2228": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_64": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1419": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1420": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2229": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_336": [{"name": "layer_norm_64", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_71": [{"name": "linear_68", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_50": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036190480, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_58", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_68", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_50": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036190480, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_58", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_68", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_58", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_68", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_58", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_68", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_340": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_65": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_316": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_317": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_719": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2242": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_65": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1427": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1428": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2243": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_341": [{"name": "layer_norm_65", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_10": [{"name": "sigmoid_10", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1435": [{"name": "mul_1607", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_342": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_66": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_318": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_319": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_725": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2259": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_66": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1438": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1439": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2260": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_343": [{"name": "layer_norm_66", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_72": [{"name": "linear_69", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_49": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036380064, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_59", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_69", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_49": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036380064, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_59", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_69", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_59", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_69", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_59", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_69", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_347": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_67": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_320": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_321": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_730": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2273": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_67": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1446": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1447": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2274": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_348": [{"name": "layer_norm_67", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_11": [{"name": "sigmoid_11", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1454": [{"name": "mul_1618", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_349": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_68": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_322": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_323": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_736": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2290": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_68": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1457": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1458": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2291": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_350": [{"name": "layer_norm_68", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_73": [{"name": "linear_70", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_48": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306349536, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_60", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_70", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_48": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306349536, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_60", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_70", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_60", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_70", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_60", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_70", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_354": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_69": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_324": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_325": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_741": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2304": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_69": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1465": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1466": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2305": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_355": [{"name": "layer_norm_69", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2315": [{"name": "add_2100", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_356": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_70": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_326": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_327": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_746": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2319": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_70": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1473": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1474": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2320": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_357": [{"name": "layer_norm_70", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_12": [{"name": "sigmoid_12", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1481": [{"name": "mul_1633", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_74": [{"name": "linear_71", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_47": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644108144, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_61", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_71", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_47": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644108144, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_61", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_71", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_61", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_71", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_61", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_71", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_361": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_71": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_328": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_329": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_754": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2343": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_71": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1488": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1489": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2344": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_362": [{"name": "layer_norm_71", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_13": [{"name": "sigmoid_13", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1496": [{"name": "mul_1644", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_363": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_72": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_330": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_331": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_760": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2360": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_72": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1499": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1500": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2361": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_364": [{"name": "layer_norm_72", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_75": [{"name": "linear_72", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_46": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036221072, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_62", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_72", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_46": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036221072, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_62", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_72", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_62", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_72", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_62", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_72", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_368": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_73": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_332": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_333": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2336": [{"name": "add_2113", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_765": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2374": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_73": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1507": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1508": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2375": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_369": [{"name": "layer_norm_73", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2385": [{"name": "add_2138", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_370": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_74": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_334": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_335": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_61": [{"name": "view_137", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_770": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2389": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_74": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1515": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1516": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2390": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_371": [{"name": "layer_norm_74", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_14": [{"name": "sigmoid_14", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1523": [{"name": "mul_1659", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_76": [{"name": "linear_73", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "addmm_63": [{"name": "linear_73", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_15": [{"name": "cat_default_5", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_7", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_7", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "view_66": [{"name": "view_142", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2416": [{"name": "add_2161", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_375": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_75": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_336": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_337": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "expand_2": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_67": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "constant_pad_nd_default_2": [{"name": "constant_pad_nd", "target": "aten.constant_pad_nd.default", "graph_id": 140224423911600, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "bmm_3", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "replacement", "action": "replace", "from_node": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_0", "action": "create", "from_node": []}], "sub_780": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2421": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_75": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1534": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1535": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2422": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_376": [{"name": "layer_norm_75", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "expand_3": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_68": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "constant_pad_nd_default_3": [{"name": "constant_pad_nd_1", "target": "aten.constant_pad_nd.default", "graph_id": 140224423911600, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "bmm_3", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "replacement", "action": "replace", "from_node": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_0", "action": "create", "from_node": []}], "bmm_default_1": [{"name": "bmm", "target": "aten.bmm.default", "graph_id": 140224423911600, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "bmm_3", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "replacement", "action": "replace", "from_node": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "bmm_3", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "bmm_3", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "view_69": [{"name": "matmul_1", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2451": [{"name": "add_2174", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_379": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_76": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_338": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_339": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_792": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2460": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_76": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1565": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1566": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2461": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_380": [{"name": "layer_norm_76", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "split_with_sizes_6": [{"name": "split_with_sizes_default_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_5", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_5", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_340": [{"name": "split_with_sizes_default_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_5", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_5", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_341": [{"name": "split_with_sizes_default_1", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_5", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_5", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "cat_17": [{"name": "cat_default_22", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "view_71": [{"name": "view_144", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_16": [{"name": "cat_default_21", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "permute_78": [{"name": "linear_default_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "mm_default_45": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036571584, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_64", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_23", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_281", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_45": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036571584, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_64", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_23", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_281", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}]}, {"name": "addmm_64", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_default_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_23", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_281", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}, {"name": "addmm_64", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_default_4", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_23", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_281", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}], "slice_22": [{"name": "getitem_280", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_11": [{"name": "contiguous_12", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_74", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_384": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_77": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_342": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_343": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "slice_24": [{"name": "getitem_281", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_12": [{"name": "contiguous_13", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_75", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_386": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_78": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_344": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_345": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_807": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2509": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_77": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1597": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1598": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2510": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_385": [{"name": "layer_norm_77", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_15": [{"name": "sigmoid_15", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1611": [{"name": "mul_1708", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_388": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_79": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_346": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_347": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_811": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2520": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_78": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1603": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1604": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2521": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_387": [{"name": "layer_norm_78", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_16": [{"name": "sigmoid_16", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1616": [{"name": "mul_1713", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_390": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_80": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_348": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_349": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_819": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2543": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_79": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1619": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1620": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2544": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_389": [{"name": "layer_norm_79", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_79": [{"name": "linear_76", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_44": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036220448, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_65", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_76", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_44": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036220448, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_65", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_76", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_65", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_76", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_65", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_76", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_398": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_81": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_350": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_351": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_823": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2554": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_80": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1625": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1626": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2555": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_391": [{"name": "layer_norm_80", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_80": [{"name": "linear_77", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_43": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526706304, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_66", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_77", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_43": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526706304, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_66", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_77", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_66", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_77", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_66", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_77", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_400": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_82": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_352": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_353": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_829": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2571": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_81": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1635": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1636": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2572": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_399": [{"name": "layer_norm_81", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_17": [{"name": "sigmoid_17", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1649": [{"name": "mul_1730", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_402": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_83": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_354": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_355": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_833": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2582": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_82": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1641": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1642": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2583": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_401": [{"name": "layer_norm_82", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_18": [{"name": "sigmoid_18", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1654": [{"name": "mul_1735", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_404": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_84": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_356": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_357": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_841": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2605": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_83": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1657": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1658": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2606": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_403": [{"name": "layer_norm_83", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_81": [{"name": "linear_78", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_42": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224570976592, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_67", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_78", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_42": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224570976592, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_67", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_78", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_67", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_78", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_67", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_78", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_412": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_85": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_358": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_359": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_845": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2616": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_84": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1663": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1664": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2617": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_405": [{"name": "layer_norm_84", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_82": [{"name": "linear_79", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_41": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644342464, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_68", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_79", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_41": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644342464, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_68", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_79", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_68", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_79", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_68", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_79", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_414": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_86": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_360": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_361": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_855": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2644": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_86": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1679": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1680": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2645": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_415": [{"name": "layer_norm_86", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_73": [{"name": "view_146", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_77": [{"name": "permute_9", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_851": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2633": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_85": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1673": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1674": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2634": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_413": [{"name": "layer_norm_85", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_72": [{"name": "view_145", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_4": [{"name": "bmm_2", "target": "aten.bmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2667": [{"name": "add_2285", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_418": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_87": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_362": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_363": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_863": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2672": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_87": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1693": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1694": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2673": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_419": [{"name": "layer_norm_87", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_5": [{"name": "bmm_3", "target": "aten.bmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_74": [{"name": "view_147", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_422": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_88": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_364": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_365": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_869": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2693": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_88": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1705": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1706": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2694": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_423": [{"name": "layer_norm_88", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_83": [{"name": "linear_80", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_40": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140225036020000, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_69", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_80", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_40": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140225036020000, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_69", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_80", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_69", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_80", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_69", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_80", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_427": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_89": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_366": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_367": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_874": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2707": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_89": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1713": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1714": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2708": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_428": [{"name": "layer_norm_89", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_19": [{"name": "sigmoid_19", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1721": [{"name": "mul_1779", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_429": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_90": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_368": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_369": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_880": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2724": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_90": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1724": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1725": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2725": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_430": [{"name": "layer_norm_90", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_18": [{"name": "cat_default_4", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_8", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_8", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_431": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_91": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_370": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_371": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_885": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2738": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_91": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1732": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1733": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2739": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_432": [{"name": "layer_norm_91", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_84": [{"name": "linear_81", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_39": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526926272, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_70", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_81", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_39": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526926272, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_70", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_81", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_70", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_81", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_70", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_81", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_436": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_92": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_372": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_373": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_890": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2752": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_92": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1740": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1741": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2753": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_437": [{"name": "layer_norm_92", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_85": [{"name": "linear_82", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_38": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644109632, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_71", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_82", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_38": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644109632, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_71", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_82", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_71", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_82", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_71", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_82", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_441": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_93": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_374": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_375": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_443": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_444": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1754": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_895": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2766": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_93": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1748": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1749": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2767": [{"name": "layer_norm_93", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default_5", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_445", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "convert_element_type_445", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_445", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}]}], "mul_1755": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2777": [{"name": "addcmul_1", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default_4", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_447", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "convert_element_type_447", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_447", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}]}], "var_mean_94": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_376": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_377": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_900": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2781": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_94": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1758": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1759": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2782": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_448": [{"name": "layer_norm_94", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_86": [{"name": "linear_83", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_37": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526697856, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_72", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_83", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_37": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526697856, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_72", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_83", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_72", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_83", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_72", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_83", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_452": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_95": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_378": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_379": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_905": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2795": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_95": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1766": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1767": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2796": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_453": [{"name": "layer_norm_95", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_20": [{"name": "sigmoid_20", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1774": [{"name": "mul_1806", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_454": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_96": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_380": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_381": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_911": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2812": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_96": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1777": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1778": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2813": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_455": [{"name": "layer_norm_96", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_87": [{"name": "linear_84", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_36": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526659600, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_73", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_84", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_36": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526659600, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_73", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_84", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_73", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_84", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_73", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_84", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_459": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_97": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_382": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_383": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_916": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2826": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_97": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1785": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1786": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2827": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_460": [{"name": "layer_norm_97", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_21": [{"name": "sigmoid_21", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1793": [{"name": "mul_1817", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_461": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_98": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_384": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_385": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_922": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2843": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_98": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1796": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1797": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2844": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_462": [{"name": "layer_norm_98", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_88": [{"name": "linear_85", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_35": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224585015088, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_74", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_85", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_35": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224585015088, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_74", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_85", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_74", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_85", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_74", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_85", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_466": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_99": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_386": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_387": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_927": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2857": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_99": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1804": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1805": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2858": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_467": [{"name": "layer_norm_99", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2868": [{"name": "add_2379", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_468": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_100": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_388": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_389": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_932": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2872": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_100": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1812": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1813": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2873": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_469": [{"name": "layer_norm_100", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_22": [{"name": "sigmoid_22", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1820": [{"name": "mul_1832", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_89": [{"name": "linear_86", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_34": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224585471392, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_75", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_86", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_34": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224585471392, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_75", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_86", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_75", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_86", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_75", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_86", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_473": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_101": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_390": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_391": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_940": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2896": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_101": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1827": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1828": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2897": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_474": [{"name": "layer_norm_101", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_23": [{"name": "sigmoid_23", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1835": [{"name": "mul_1843", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_475": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_102": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_392": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_393": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_946": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2913": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_102": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1838": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1839": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2914": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_476": [{"name": "layer_norm_102", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_90": [{"name": "linear_87", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_33": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644339584, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_76", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_87", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_33": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644339584, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_76", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_87", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_76", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_87", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_76", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_87", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_480": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_103": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_394": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_395": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2889": [{"name": "add_2392", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_951": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2927": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_103": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1846": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1847": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2928": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_481": [{"name": "layer_norm_103", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2938": [{"name": "add_2417", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_482": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_104": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_396": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_397": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_70": [{"name": "view_143", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_956": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2942": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_104": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1854": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1855": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2943": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_483": [{"name": "layer_norm_104", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_24": [{"name": "sigmoid_24", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1862": [{"name": "mul_1858", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_91": [{"name": "linear_88", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "addmm_77": [{"name": "linear_88", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_19": [{"name": "cat_default_3", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_9", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_9", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "view_75": [{"name": "view_148", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2969": [{"name": "add_2440", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_487": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_105": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_398": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_399": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sym_size_int_17": [{"name": "getitem_272", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "expand_4": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_76": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "constant_pad_nd_default": [{"name": "constant_pad_nd", "target": "aten.constant_pad_nd.default", "graph_id": 140224423324560, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "bmm_6", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "replacement", "action": "replace", "from_node": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_0", "action": "create", "from_node": []}], "sub_966": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2974": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_105": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1873": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1874": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2975": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_488": [{"name": "layer_norm_105", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "expand_5": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_77": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "constant_pad_nd_default_1": [{"name": "constant_pad_nd_1", "target": "aten.constant_pad_nd.default", "graph_id": 140224423324560, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "bmm_6", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "replacement", "action": "replace", "from_node": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_0", "action": "create", "from_node": []}], "bmm_default": [{"name": "bmm", "target": "aten.bmm.default", "graph_id": 140224423324560, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "bmm_6", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "replacement", "action": "replace", "from_node": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "bmm_6", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "bmm_6", "target": "aten.bmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "view_78": [{"name": "matmul_2", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3004": [{"name": "add_2453", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_491": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_106": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_400": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_401": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_978": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3013": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_106": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1904": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1905": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3014": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_492": [{"name": "layer_norm_106", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "split_with_sizes_7": [{"name": "split_with_sizes_default", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_402": [{"name": "split_with_sizes_default", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "getitem_403": [{"name": "split_with_sizes_default", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "split_with_sizes_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "split_with_sizes_6", "target": "aten.split_with_sizes.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "cat_21": [{"name": "cat_default_24", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "view_80": [{"name": "view_150", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_20": [{"name": "cat_default_23", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "permute_93": [{"name": "linear_default_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "mm_default_32": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224305949728, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_78", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_27", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_283", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_32": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224305949728, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_78", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_27", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_283", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}]}, {"name": "addmm_78", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_default_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_27", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_283", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}, {"name": "addmm_78", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_default_5", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_27", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_283", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}], "slice_26": [{"name": "getitem_282", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_13": [{"name": "contiguous_14", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_89", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_496": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_107": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_404": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_405": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "slice_28": [{"name": "getitem_283", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_14": [{"name": "contiguous_15", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_90", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_498": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_108": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_406": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_407": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_993": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3062": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_107": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1936": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1937": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3063": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_497": [{"name": "layer_norm_107", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_25": [{"name": "sigmoid_25", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1950": [{"name": "mul_1907", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_500": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_109": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_408": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_409": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_997": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3073": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_108": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1942": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1943": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3074": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_499": [{"name": "layer_norm_108", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_26": [{"name": "sigmoid_26", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1955": [{"name": "mul_1912", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_502": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_110": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_410": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_411": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1005": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3096": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_109": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1958": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1959": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3097": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_501": [{"name": "layer_norm_109", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_94": [{"name": "linear_91", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_31": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224585282224, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_79", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_91", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_31": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224585282224, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_79", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_91", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_79", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_91", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_79", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_91", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_510": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_111": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_412": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_413": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1009": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3107": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_110": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1964": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1965": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3108": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_503": [{"name": "layer_norm_110", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_95": [{"name": "linear_92", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_30": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224585726896, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_80", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_92", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_30": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224585726896, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_80", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_92", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_80", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_92", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_80", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_92", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_512": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_112": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_414": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_415": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1015": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3124": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_111": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1974": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1975": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3125": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_511": [{"name": "layer_norm_111", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_27": [{"name": "sigmoid_27", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1988": [{"name": "mul_1929", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_514": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_113": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_416": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_417": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1019": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3135": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_112": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1980": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1981": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3136": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_513": [{"name": "layer_norm_112", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_28": [{"name": "sigmoid_28", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1993": [{"name": "mul_1934", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_516": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_114": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_418": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_419": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1027": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3158": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_113": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1996": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1997": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3159": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_515": [{"name": "layer_norm_113", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_96": [{"name": "linear_93", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_29": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644114384, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_81", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_93", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_29": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644114384, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_81", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_93", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_81", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_93", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_81", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_93", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_524": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_115": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_420": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_421": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1031": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3169": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_114": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2002": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2003": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3170": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_517": [{"name": "layer_norm_114", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_97": [{"name": "linear_94", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_28": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526701552, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_82", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_94", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_28": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526701552, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_82", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_94", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_82", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_94", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_82", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_94", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_526": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_116": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_422": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_423": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1041": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3197": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_116": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2018": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2019": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3198": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_527": [{"name": "layer_norm_116", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_82": [{"name": "view_152", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_92": [{"name": "permute_10", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1037": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3186": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_115": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2012": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2013": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3187": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_525": [{"name": "layer_norm_115", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_81": [{"name": "view_151", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_7": [{"name": "bmm_4", "target": "aten.bmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3220": [{"name": "add_2564", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_530": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_117": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_424": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_425": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1049": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3225": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_117": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2032": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2033": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3226": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_531": [{"name": "layer_norm_117", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_8": [{"name": "bmm_5", "target": "aten.bmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_83": [{"name": "view_153", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_534": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_118": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_426": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_427": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1055": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3246": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_118": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2044": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2045": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3247": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_535": [{"name": "layer_norm_118", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_98": [{"name": "linear_95", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_27": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306352224, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_83", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_95", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_27": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306352224, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_83", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_95", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_83", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_95", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_83", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_95", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_539": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_119": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_428": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_429": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1060": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3260": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_119": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2052": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2053": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3261": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_540": [{"name": "layer_norm_119", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_29": [{"name": "sigmoid_29", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2060": [{"name": "mul_1978", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_541": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_120": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_430": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_431": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1066": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3277": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_120": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2063": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2064": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3278": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_542": [{"name": "layer_norm_120", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_22": [{"name": "cat_default_2", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_10", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_10", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_543": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_121": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_432": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_433": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1071": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3291": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_121": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2071": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2072": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3292": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_544": [{"name": "layer_norm_121", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_99": [{"name": "linear_96", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_26": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306645600, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_84", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_96", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_26": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306645600, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_84", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_96", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_84", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_96", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_84", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_96", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_548": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_122": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_434": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_435": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1076": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3305": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_122": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2079": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2080": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3306": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_549": [{"name": "layer_norm_122", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_100": [{"name": "linear_97", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_25": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224585642384, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_85", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_97", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_25": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224585642384, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_85", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_97", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_85", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_97", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_85", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_97", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_553": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_123": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_436": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_437": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_555": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_556": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2093": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1081": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3319": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_123": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2087": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2088": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3320": [{"name": "layer_norm_123", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default_3", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_557", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "convert_element_type_557", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_557", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}]}], "mul_2094": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3330": [{"name": "addcmul_2", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default_2", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_559", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "convert_element_type_559", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_559", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}]}], "var_mean_124": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_438": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_439": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1086": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3334": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_124": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2097": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2098": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3335": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_560": [{"name": "layer_norm_124", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_101": [{"name": "linear_98", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_24": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306755040, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_86", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_98", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_24": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306755040, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_86", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_98", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_86", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_98", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_86", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_98", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_564": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_125": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_440": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_441": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1091": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3348": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_125": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2105": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2106": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3349": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_565": [{"name": "layer_norm_125", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_30": [{"name": "sigmoid_30", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2113": [{"name": "mul_2005", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_566": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_126": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_442": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_443": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1097": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3365": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_126": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2116": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2117": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3366": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_567": [{"name": "layer_norm_126", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_102": [{"name": "linear_99", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_23": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224570967088, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_87", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_99", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_23": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224570967088, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_87", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_99", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_87", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_99", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_87", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_99", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_571": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_127": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_444": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_445": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1102": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3379": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_127": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2124": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2125": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3380": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_572": [{"name": "layer_norm_127", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_31": [{"name": "sigmoid_31", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2132": [{"name": "mul_2016", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_573": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_128": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_446": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_447": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1108": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3396": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_128": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2135": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2136": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3397": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_574": [{"name": "layer_norm_128", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_103": [{"name": "linear_100", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_22": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526707792, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_88", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_100", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_22": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526707792, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_88", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_100", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_88", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_100", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_88", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_100", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_578": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_129": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_448": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_449": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1113": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3410": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_129": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2143": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2144": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3411": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_579": [{"name": "layer_norm_129", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3421": [{"name": "add_2658", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_580": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_130": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_450": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_451": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1118": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3425": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_130": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2151": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2152": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3426": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_581": [{"name": "layer_norm_130", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_32": [{"name": "sigmoid_32", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2159": [{"name": "mul_2031", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_104": [{"name": "linear_101", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_21": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644119952, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_89", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_101", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_21": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644119952, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_89", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_101", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_89", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_101", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_89", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_101", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_585": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_131": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_452": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_453": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1126": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3449": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_131": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2166": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2167": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3450": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_586": [{"name": "layer_norm_131", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_33": [{"name": "sigmoid_33", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2174": [{"name": "mul_2042", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_587": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_132": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_454": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_455": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1132": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3466": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_132": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2177": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2178": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3467": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_588": [{"name": "layer_norm_132", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_105": [{"name": "linear_102", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_20": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224644338240, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_90", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_102", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_20": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224644338240, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_90", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_102", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_90", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_102", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_90", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_102", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_592": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_133": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_456": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_457": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3442": [{"name": "add_2671", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1137": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3480": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_133": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2185": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2186": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3481": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_593": [{"name": "layer_norm_133", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3491": [{"name": "add_2696", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_594": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_134": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_458": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_459": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_79": [{"name": "view_149", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1142": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3495": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_134": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2193": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2194": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3496": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_595": [{"name": "layer_norm_134", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_34": [{"name": "sigmoid_34", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2201": [{"name": "mul_2057", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_106": [{"name": "linear_103", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "addmm_91": [{"name": "linear_103", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_23": [{"name": "cat_default_1", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_11", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_11", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "view_84": [{"name": "view_154", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3522": [{"name": "add_2719", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_599": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_135": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_460": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_461": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "expand_6": [{"name": "matmul_3", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_85": [{"name": "matmul_3", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1152": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3527": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_135": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2212": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2213": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3528": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_600": [{"name": "layer_norm_135", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "expand_7": [{"name": "matmul_3", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_86": [{"name": "matmul_3", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_9": [{"name": "matmul_3", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_87": [{"name": "matmul_3", "target": "aten.matmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3557": [{"name": "add_2732", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_603": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_136": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_462": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_463": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_25": [{"name": "cat_default_26", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "sub_1164": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3566": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_136": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2243": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2244": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3567": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_604": [{"name": "layer_norm_136", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_88": [{"name": "view_155", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_24": [{"name": "cat_default_25", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "permute_108": [{"name": "linear_default_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "mm_default_19": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224305949968, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_92", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_31", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_285", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_19": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224305949968, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_92", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_default_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_31", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_285", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}]}, {"name": "addmm_92", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_default_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_31", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_285", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}, {"name": "addmm_92", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_default_6", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}, {"name": "slice_31", "target": "aten.slice.Tensor", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "getitem_285", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}]}]}], "slice_30": [{"name": "getitem_284", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_15": [{"name": "contiguous_16", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_104", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_608": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_137": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_464": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_465": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "slice_32": [{"name": "getitem_285", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "clone_16": [{"name": "contiguous_17", "target": "aten.contiguous", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "linear_105", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_610": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_138": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_466": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_467": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1176": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3604": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_137": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2269": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2270": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3605": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_609": [{"name": "layer_norm_137", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_35": [{"name": "sigmoid_35", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2283": [{"name": "mul_2095", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_612": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_139": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_468": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_469": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1180": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3615": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_138": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2275": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2276": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3616": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_611": [{"name": "layer_norm_138", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_36": [{"name": "sigmoid_36", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2288": [{"name": "mul_2100", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_614": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_140": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_470": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_471": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1188": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3638": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_139": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2291": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2292": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3639": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_613": [{"name": "layer_norm_139", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_109": [{"name": "linear_106", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_18": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306747696, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_93", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_106", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_18": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306747696, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_93", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_106", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_93", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_106", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_93", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_106", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_622": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_141": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_472": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_473": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1192": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3649": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_140": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2297": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2298": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3650": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_615": [{"name": "layer_norm_140", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_110": [{"name": "linear_107", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_17": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306653808, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_94", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_107", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_17": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306653808, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_94", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_107", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_94", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_107", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_94", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_107", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_624": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_142": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_474": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_475": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1198": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3666": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_141": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2307": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2308": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3667": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_623": [{"name": "layer_norm_141", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_37": [{"name": "sigmoid_37", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2321": [{"name": "mul_2117", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_626": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_143": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_476": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_477": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1202": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3677": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_142": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2313": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2314": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3678": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_625": [{"name": "layer_norm_142", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_38": [{"name": "sigmoid_38", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2326": [{"name": "mul_2122", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_628": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_144": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_478": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_479": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1210": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3700": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_143": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2329": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2330": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3701": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_627": [{"name": "layer_norm_143", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_111": [{"name": "linear_108", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_16": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224643992496, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_95", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_108", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_16": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224643992496, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_95", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_108", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_95", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_108", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_95", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_108", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_636": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_145": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_480": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_481": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1214": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3711": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_144": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2335": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2336": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3712": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_629": [{"name": "layer_norm_144", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_112": [{"name": "linear_109", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_15": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306647040, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_96", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_109", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_15": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306647040, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_96", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_109", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_96", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_109", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_96", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_109", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_638": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_146": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_482": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_483": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1224": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3739": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_146": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2351": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2352": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3740": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_639": [{"name": "layer_norm_146", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_90": [{"name": "view_157", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_107": [{"name": "permute_11", "target": "aten.permute.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1220": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3728": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_145": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2345": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2346": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3729": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_637": [{"name": "layer_norm_145", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_89": [{"name": "view_156", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_10": [{"name": "bmm_6", "target": "aten.bmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3762": [{"name": "add_2832", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_642": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_147": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_484": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_485": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1232": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3767": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_147": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2365": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2366": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3768": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_643": [{"name": "layer_norm_147", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "bmm_11": [{"name": "bmm_7", "target": "aten.bmm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "view_91": [{"name": "view_158", "target": "aten.view.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_646": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_148": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_486": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_487": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1238": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3788": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_148": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2377": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2378": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3789": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_647": [{"name": "layer_norm_148", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_113": [{"name": "linear_110", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_14": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306757200, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_97", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_110", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_14": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306757200, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_97", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_110", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_97", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_110", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_97", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_110", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_651": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_149": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_488": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_489": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1243": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3802": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_149": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2385": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2386": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3803": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_652": [{"name": "layer_norm_149", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_39": [{"name": "sigmoid_39", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2393": [{"name": "mul_2166", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_653": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_150": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_490": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_491": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1249": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3819": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_150": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2396": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2397": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3820": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_654": [{"name": "layer_norm_150", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "cat_26": [{"name": "cat_default", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "cat_12", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": []}, {"name": "cat_12", "target": "aten.cat.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply normalization pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_655": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_151": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_492": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_493": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1254": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3833": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_151": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2404": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2405": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3834": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_656": [{"name": "layer_norm_151", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_114": [{"name": "linear_111", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_13": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224570974048, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_98", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_111", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_13": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224570974048, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_98", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_111", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_98", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_111", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_98", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_111", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_660": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_152": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_494": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_495": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1259": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3847": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_152": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2412": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2413": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3848": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_661": [{"name": "layer_norm_152", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_115": [{"name": "linear_112", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_12": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526707744, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_99", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_112", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_12": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526707744, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_99", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_112", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_99", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_112", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_99", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_112", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_665": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_153": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_496": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_497": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_667": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_668": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2426": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1264": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3861": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_153": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2420": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2421": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3862": [{"name": "layer_norm_153", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default_1", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_669", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "convert_element_type_669", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_669", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}]}], "mul_2427": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3872": [{"name": "addcmul_3", "target": "aten.addcmul.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_671", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "convert_element_type_671", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_671", "target": "prims.convert_element_type.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}]}], "var_mean_154": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_498": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_499": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1269": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3876": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_154": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2430": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2431": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3877": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_672": [{"name": "layer_norm_154", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_116": [{"name": "linear_113", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_11": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224643490064, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_100", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_113", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_11": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224643490064, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_100", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_113", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_100", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_113", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_100", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_113", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_676": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_155": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_500": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_501": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1274": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3890": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_155": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2438": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2439": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3891": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_677": [{"name": "layer_norm_155", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_40": [{"name": "sigmoid_40", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2446": [{"name": "mul_2193", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_678": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_156": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_502": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_503": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1280": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3907": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_156": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2449": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2450": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3908": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_679": [{"name": "layer_norm_156", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_117": [{"name": "linear_114", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_10": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526117008, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_101", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_114", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_10": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526117008, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_101", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_114", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_101", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_114", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_101", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_114", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_683": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_157": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_504": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_505": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1285": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3921": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_157": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2457": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2458": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3922": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_684": [{"name": "layer_norm_157", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_41": [{"name": "sigmoid_41", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2465": [{"name": "mul_2204", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_685": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_158": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_506": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_507": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1291": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3938": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_158": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2468": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2469": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3939": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_686": [{"name": "layer_norm_158", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_118": [{"name": "linear_115", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_9": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224305944976, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_102", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_115", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_9": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224305944976, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_102", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_115", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_102", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_115", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_102", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_115", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_690": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_159": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_508": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_509": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1296": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3952": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_159": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2476": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2477": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3953": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_691": [{"name": "layer_norm_159", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3963": [{"name": "add_2926", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_692": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_160": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_510": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_511": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1301": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3967": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_160": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2484": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2485": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3968": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_693": [{"name": "layer_norm_160", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_42": [{"name": "sigmoid_42", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2492": [{"name": "mul_2219", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_119": [{"name": "linear_116", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_8": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306352608, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_103", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_116", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_8": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306352608, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_103", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_116", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_103", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_116", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_103", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_116", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_697": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_161": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_512": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_513": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1309": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3991": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_161": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2499": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2500": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3992": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_698": [{"name": "layer_norm_161", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_43": [{"name": "sigmoid_43", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2507": [{"name": "mul_2230", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_699": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_162": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_514": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_515": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1315": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4008": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_162": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2510": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2511": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4009": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_700": [{"name": "layer_norm_162", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_120": [{"name": "linear_117", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_7": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526978736, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_104", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_117", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_7": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526978736, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_104", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_117", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_104", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_117", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_104", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_117", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_704": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_163": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_516": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_517": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3984": [{"name": "add_2939", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1320": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4022": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_163": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2518": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2519": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4023": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_705": [{"name": "layer_norm_163", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4033": [{"name": "add_2964", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_706": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_164": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_518": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_519": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sym_size_int_9": [{"name": "getitem_270", "target": "<built-in function getitem>", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)] Apply fuse_parallel_linear_pass", "action": "create", "from_node": []}]}], "full": [{"name": "full_like", "target": "aten.full_like.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub_1325": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4037": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_164": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2526": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2527": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4038": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_707": [{"name": "layer_norm_164", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_44": [{"name": "sigmoid_44", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2534": [{"name": "mul_2245", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_121": [{"name": "linear_118", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_6": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224526566160, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_105", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_118", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_6": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224526566160, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_105", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_118", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_105", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_118", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_105", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_118", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "relu_1": [{"name": "relu_default_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "create", "from_node": []}]}], "convert_element_type_712": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_1267": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_8": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_711": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_1266": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_7": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "isnan_2": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_6": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_6": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_7": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_8": [{"name": "nan_to_num_default_1", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_1", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "permute_122": [{"name": "linear_119", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_5": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306742944, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_106", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_119", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_5": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306742944, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_106", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_119", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_106", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_119", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_106", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_119", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "relu_2": [{"name": "relu_default_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "create", "from_node": []}]}], "convert_element_type_717": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_1272": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_11": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_716": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_1271": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_10": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "isnan_3": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_9": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_9": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_10": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_11": [{"name": "nan_to_num_default_2", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_2", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "add_4072": [{"name": "add_2989", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2559": [{"name": "mul_2264", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4094": [{"name": "add_3008", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_123": [{"name": "linear_120", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_4": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306355920, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_107", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_120", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_4": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306355920, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_107", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_120", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_107", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_120", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_107", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_120", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "relu_3": [{"name": "relu_default_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "create", "from_node": []}]}], "convert_element_type_722": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_1279": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_14": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_721": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_1278": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_13": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "isnan_4": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_12": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_12": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_13": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_14": [{"name": "nan_to_num_default_3", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_3", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "permute_124": [{"name": "linear_121", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_3": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224305951264, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_108", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_121", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_3": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224305951264, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_108", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_121", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_108", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_121", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_108", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_121", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "relu_4": [{"name": "relu_default_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "", "target": "", "graph_id": -1, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "create", "from_node": []}]}], "convert_element_type_727": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_1286": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_17": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "convert_element_type_726": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "eq_1285": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_16": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "isnan_5": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "scalar_tensor_15": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_15": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_16": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "where_17": [{"name": "nan_to_num_default_4", "target": "aten.nan_to_num.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "relu_4", "target": "aten.relu.default", "graph_id": 140226430922096, "pass_name": "[Pre grad(predispatch IR)]Apply relu_nan_to_num pass", "action": "replace+create", "from_node": []}]}], "mul_2570": [{"name": "mul_2273", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4107": [{"name": "add_3018", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_125": [{"name": "linear_122", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_2": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224306360816, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_109", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_122", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_2": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224306360816, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_109", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_122", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_109", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_122", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_109", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_122", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "sigmoid_45": [{"name": "sigmoid_45", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2579": [{"name": "mul_2282", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_126": [{"name": "linear_123", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default_1": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224305940032, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_110", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_123", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor_1": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224305940032, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_110", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_123", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_110", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_123", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_110", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_123", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "convert_element_type_734": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "var_mean_165": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_520": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_521": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "full_2": [{"name": "full_like_2", "target": "aten.full_like.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "sub_1353": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4123": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt_165": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2584": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2585": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4124": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_735": [{"name": "layer_norm_165", "target": "aten.layer_norm.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid_46": [{"name": "sigmoid_46", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2592": [{"name": "mul_2291", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_127": [{"name": "linear_124", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_default": [{"name": "mm", "target": "aten.mm.default", "graph_id": 140224570972752, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_111", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_124", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pattern_matcher", "action": "create", "from_node": []}, {"name": "", "target": "", "graph_id": -1, "pass_name": "pass_pattern_2", "action": "create", "from_node": []}], "add_tensor": [{"name": "add", "target": "aten.add.Tensor", "graph_id": 140224570972752, "pass_name": "Interpreter_Replacer", "action": "replace", "from_node": [{"name": "addmm_111", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "replace_by_example", "action": "replace", "from_node": [{"name": "linear_124", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}, {"name": "addmm_111", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pattern_matcher", "action": "replace+create", "from_node": [{"name": "linear_124", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}, {"name": "addmm_111", "target": "aten.addmm.default", "graph_id": 140223871892784, "pass_name": "pass_pattern_2", "action": "replace+create", "from_node": [{"name": "linear_124", "target": "aten.linear.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}], "add_4143": [{"name": "add_3046", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "sigmoid_47": [{"name": "sigmoid_47", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}, {"name": "alias", "target": "aten.alias.default", "graph_id": 140223871892784, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "detach", "target": "aten.detach.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}]}], "full_1": [{"name": "full_like_1", "target": "aten.full_like.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "gt": [{"name": "gt", "target": "aten.gt.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "convert_element_type_741": [{"name": "_to_copy_9", "target": "aten._to_copy.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "mul_2605": [{"name": "mul_2304", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "sub_1372": [{"name": "sub_950", "target": "aten.sub.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "mul_2610": [{"name": "mul_2309", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "convert_element_type_739": [{"name": "logit", "target": "aten.logit.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "clamp_min_1": [{"name": "logit", "target": "aten.logit.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "clamp_max_1": [{"name": "logit", "target": "aten.logit.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "sub_1363": [{"name": "logit", "target": "aten.logit.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "div": [{"name": "logit", "target": "aten.logit.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "log": [{"name": "logit", "target": "aten.logit.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "convert_element_type_740": [{"name": "logit", "target": "aten.logit.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "sum_3": [{"name": "sum_3", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_5": [{"name": "sum_5", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_631": [{"name": "add_605", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_10": [{"name": "sum_10", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_990": [{"name": "add_708", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_11": [{"name": "sum_11", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_994": [{"name": "add_712", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_9": [{"name": "sum_9", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1012": [{"name": "add_722", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_7": [{"name": "sum_7", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1040": [{"name": "add_735", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_6": [{"name": "sum_6", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1050": [{"name": "add_742", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_4": [{"name": "sum_4", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1057": [{"name": "add_749", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_8": [{"name": "sum_8", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1078": [{"name": "add_762", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_12": [{"name": "sum_12", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1088": [{"name": "add_772", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_2": [{"name": "sum_2", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1105": [{"name": "add_789", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sum_1": [{"name": "sum_1", "target": "aten.sum.dim_IntList", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1140": [{"name": "add_804", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1144": [{"name": "add_808", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_4156": [{"name": "add_3059", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "sigmoid_48": [{"name": "sigmoid_48", "target": "aten.sigmoid.default", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "mul_2608": [{"name": "mul_2307", "target": "aten.mul.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}], "add_4187": [{"name": "add_3090", "target": "aten.add.Tensor", "graph_id": 140226430922096, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": [{"name": "submod_1", "target": "submod_1", "graph_id": 140226673697568, "pass_name": "Interpreter_Interpreter", "action": "create", "from_node": []}]}]}